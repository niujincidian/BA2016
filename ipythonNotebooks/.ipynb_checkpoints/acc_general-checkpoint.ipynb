{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done importing\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 16, 6\n",
    "rcParams.update({'font.size': 15})\n",
    "\n",
    "from nideep.eval.learning_curve import LearningCurve\n",
    "from nideep.eval.eval_utils import Phase\n",
    "\n",
    "import nideep.eval.log_utils as lu\n",
    "\n",
    "import h5py\n",
    "import caffe\n",
    "from caffe.proto import caffe_pb2\n",
    "from google.protobuf import text_format\n",
    "\n",
    "print(\"Done importing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if there are multiple gpu devices, choose the first one \n",
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()\n",
    "## check where lies the modelfile according to experiment-record file\n",
    "# load train_val prototxt\n",
    "model_def = '/mnt/antares_raid/home/cindy/adhara/experiments/15/deploy.prototxt'\n",
    "model_weights = '/mnt/raid/dnn/cindy/modelfiles/15/te_iter_5000.caffemodel'\n",
    "net = caffe.Net(model_def,      # defines the structure of the model\n",
    "                model_weights,  # contains the trained weights\n",
    "                caffe.TEST)     # use test mode (e.g., don't perform dropout)label01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('amsFeatures', (128, 9, 16, 63)),\n",
       " ('ratemap', (128, 1, 16, 63)),\n",
       " ('label_scalar', (128, 1, 1, 1)),\n",
       " ('conv1_a', (128, 128, 9, 58)),\n",
       " ('conv2_a', (128, 128, 7, 56)),\n",
       " ('pool2_a', (128, 128, 4, 28)),\n",
       " ('ip2_a', (128, 256)),\n",
       " ('conv1_r', (128, 128, 9, 58)),\n",
       " ('conv2_r', (128, 128, 7, 56)),\n",
       " ('pool2_r', (128, 128, 4, 28)),\n",
       " ('ip2_r', (128, 256)),\n",
       " ('ip2', (128, 512)),\n",
       " ('ip3', (128, 12)),\n",
       " ('ip3_ip3_0_split_0', (128, 12)),\n",
       " ('ip3_ip3_0_split_1', (128, 12)),\n",
       " ('prediction', (128, 12)),\n",
       " ('loss', ())]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net.forward(blobs=['ip3'])\n",
    "[(k, v.data.shape) for k, v in net.blobs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "K = 11  # 11 classes\n",
    "# test iterations:how many forward() operations are needed\n",
    "# to go through all the test dataset\n",
    "test_iter = 1065\n",
    "batch_size = 128\n",
    "total = batch_size*test_iter\n",
    "\n",
    "# record lists initialization\n",
    "positive_amount = np.zeros(K)\n",
    "positive_true = np.zeros(K)\n",
    "negative_true = np.zeros(K)\n",
    "for i in range(test_iter):\n",
    "    net.forward()\n",
    "    prediction = np.argmax(net.blobs['prediction'].data,axis=1)\n",
    "    label_scalar = net.blobs['label_scalar'].data[:,0,0,0].astype(int)\n",
    "    for k in range(8):\n",
    "        temp_vec = np.ones(batch_size)*(k)\n",
    "        label_k = (temp_vec==label_scalar)\n",
    "        positive_amount[k]+=sum(label_k)\n",
    "        # count true positive\n",
    "        predict_k = (temp_vec==prediction)\n",
    "        positive_true_k = np.multiply(predict_k,label_k)\n",
    "        positive_true[k]+=sum(positive_true_k) \n",
    "        # count true negative\n",
    "        neg_label_k = [(not x) for x in label_k]\n",
    "        neg_predict_k = [(not x) for x in predict_k]\n",
    "        negative_true_k = np.multiply(neg_label_k,neg_predict_k)\n",
    "        negative_true[k]+=sum(negative_true_k)\n",
    "    for k in range(8,11):\n",
    "        temp_vec = np.ones(batch_size)*(k+1)\n",
    "        label_k = (temp_vec==label_scalar)\n",
    "        positive_amount[k]+=sum(label_k)\n",
    "        # count true positive\n",
    "        predict_k = (temp_vec==prediction)\n",
    "        positive_true_k = np.multiply(predict_k,label_k)\n",
    "        positive_true[k]+=sum(positive_true_k) \n",
    "        # count true negative\n",
    "        neg_label_k = [(not x) for x in label_k]\n",
    "        neg_predict_k = [(not x) for x in predict_k]\n",
    "        negative_true_k = np.multiply(neg_label_k,neg_predict_k)\n",
    "        negative_true[k]+=sum(negative_true_k)\n",
    "sensitivity = positive_true/positive_amount\n",
    "negative_amount = total*np.ones(K)-positive_amount\n",
    "specificity = negative_true/negative_amount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
