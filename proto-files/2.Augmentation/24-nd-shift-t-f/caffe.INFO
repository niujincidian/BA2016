Log file created at: 2016/05/11 13:22:29
Running on machine: adhara
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0511 13:22:29.942977 27330 caffe.cpp:185] Using GPUs 0
I0511 13:22:29.951856 27330 caffe.cpp:190] GPU 0: GeForce GTX 580
I0511 13:22:30.076565 27330 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1065
test_interval: 3265
base_lr: 0.0001
display: 100
max_iter: 100000
lr_policy: "step"
gamma: 0.1
momentum: 0.99
weight_decay: 0.0005
stepsize: 30000
snapshot: 5000
snapshot_prefix: "/mnt/raid/dnn/cindy/modelfiles/24/te"
solver_mode: GPU
device_id: 0
net: "/mnt/antares_raid/home/cindy/adhara/experiments/24/train_val.prototxt"
snapshot_after_train: true
I0511 13:22:30.076788 27330 solver.cpp:91] Creating training net from net file: /mnt/antares_raid/home/cindy/adhara/experiments/24/train_val.prototxt
I0511 13:22:30.078035 27330 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0511 13:22:30.078274 27330 net.cpp:49] Initializing net from parameters: 
name: "SoundNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "amsFeatures"
  top: "ratemap"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/mnt/antares_raid/home/cindy/adhara/experiments/twoears_data_train.txt"
    batch_size: 128
  }
}
layer {
  name: "ratemap"
  type: "Python"
  bottom: "ratemap"
  top: "ratemap"
  include {
    phase: TRAIN
  }
  python_param {
    module: "nideep.layers.jitterlayer"
    layer: "JitterLayer"
    param_str: "{\'min_shift_f\':-8,\'max_shift_f\':8,\'min_shift_t\':-30,\'max_shift_t\':30}"
  }
}
layer {
  name: "amsFeatures"
  type: "Python"
  bottom: "amsFeatures"
  top: "amsFeatures"
  include {
    phase: TRAIN
  }
  python_param {
    module: "nideep.layers.jitterlayer"
    layer: "JitterLayer"
    param_str: "{\'min_shift_f\':-8,\'max_shift_f\':8,\'min_shift_t\':-30,\'max_shift_t\':30}"
  }
}
layer {
  name: "conv1_a"
  type: "Convolution"
  bottom: "amsFeatures"
  top: "conv1_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 6
  }
}
layer {
  name: "relu1_a"
  type: "ReLU"
  bottom: "conv1_a"
  top: "conv1_a"
}
layer {
  name: "conv2_a"
  type: "Convolution"
  bottom: "conv1_a"
  top: "conv2_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "pool2_a"
  type: "Pooling"
  bottom: "conv2_a"
  top: "pool2_a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "relu2_a"
  type: "ReLU"
  bottom: "pool2_a"
  top: "pool2_a"
}
layer {
  name: "ip2_a"
  type: "InnerProduct"
  bottom: "pool2_a"
  top: "ip2_a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_r"
  type: "Convolution"
  bottom: "ratemap"
  top: "conv1_r"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 6
  }
}
layer {
  name: "relu1_r"
  type: "ReLU"
  bottom: "conv1_r"
  top: "conv1_r"
}
layer {
  name: "conv2_r"
  type: "Convolution"
  bottom: "conv1_r"
  top: "conv2_r"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "pool2_r"
  type: "Pooling"
  bottom: "conv2_r"
  top: "pool2_r"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "relu2_r"
  type: "ReLU"
  bottom: "pool2_r"
  top: "pool2_r"
}
layer {
  name: "ip2_r"
  type: "InnerProduct"
  bottom: "pool2_r"
  top: "ip2_r"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "concat_ar"
  type: "Concat"
  bottom: "ip2_a"
  bottom: "ip2_r"
  top: "ip2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SigmoidCrossEntropyLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0511 13:22:30.079190 27330 layer_factory.hpp:77] Creating layer data
I0511 13:22:30.079219 27330 net.cpp:91] Creating Layer data
I0511 13:22:30.079233 27330 net.cpp:399] data -> amsFeatures
I0511 13:22:30.079268 27330 net.cpp:399] data -> ratemap
I0511 13:22:30.079282 27330 net.cpp:399] data -> label
I0511 13:22:30.079298 27330 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /mnt/antares_raid/home/cindy/adhara/experiments/twoears_data_train.txt
I0511 13:22:30.079708 27330 hdf5_data_layer.cpp:93] Number of HDF5 files: 5
I0511 13:22:30.081128 27330 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0511 13:22:35.702863 27330 net.cpp:141] Setting up data
I0511 13:22:35.702920 27330 net.cpp:148] Top shape: 128 9 16 63 (1161216)
I0511 13:22:35.702940 27330 net.cpp:148] Top shape: 128 1 16 63 (129024)
I0511 13:22:35.702947 27330 net.cpp:148] Top shape: 128 1 11 1 (1408)
I0511 13:22:35.702953 27330 net.cpp:156] Memory required for data: 5166592
I0511 13:22:35.702967 27330 layer_factory.hpp:77] Creating layer ratemap
I0511 13:22:36.154541 27330 net.cpp:91] Creating Layer ratemap
I0511 13:22:36.154578 27330 net.cpp:425] ratemap <- ratemap
I0511 13:22:36.154597 27330 net.cpp:386] ratemap -> ratemap (in-place)
I0511 13:22:36.155447 27330 net.cpp:141] Setting up ratemap
I0511 13:22:36.155470 27330 net.cpp:148] Top shape: 128 1 16 63 (129024)
I0511 13:22:36.155478 27330 net.cpp:156] Memory required for data: 5682688
I0511 13:22:36.155489 27330 layer_factory.hpp:77] Creating layer amsFeatures
I0511 13:22:36.155525 27330 net.cpp:91] Creating Layer amsFeatures
I0511 13:22:36.155536 27330 net.cpp:425] amsFeatures <- amsFeatures
I0511 13:22:36.155546 27330 net.cpp:386] amsFeatures -> amsFeatures (in-place)
I0511 13:22:36.158051 27330 net.cpp:141] Setting up amsFeatures
I0511 13:22:36.158072 27330 net.cpp:148] Top shape: 128 9 16 63 (1161216)
I0511 13:22:36.158079 27330 net.cpp:156] Memory required for data: 10327552
I0511 13:22:36.158087 27330 layer_factory.hpp:77] Creating layer conv1_a
I0511 13:22:36.158116 27330 net.cpp:91] Creating Layer conv1_a
I0511 13:22:36.158125 27330 net.cpp:425] conv1_a <- amsFeatures
I0511 13:22:36.158136 27330 net.cpp:399] conv1_a -> conv1_a
I0511 13:22:36.160593 27330 net.cpp:141] Setting up conv1_a
I0511 13:22:36.160615 27330 net.cpp:148] Top shape: 128 128 9 58 (8552448)
I0511 13:22:36.160622 27330 net.cpp:156] Memory required for data: 44537344
I0511 13:22:36.160651 27330 layer_factory.hpp:77] Creating layer relu1_a
I0511 13:22:36.160665 27330 net.cpp:91] Creating Layer relu1_a
I0511 13:22:36.160671 27330 net.cpp:425] relu1_a <- conv1_a
I0511 13:22:36.160681 27330 net.cpp:386] relu1_a -> conv1_a (in-place)
I0511 13:22:36.160694 27330 net.cpp:141] Setting up relu1_a
I0511 13:22:36.160703 27330 net.cpp:148] Top shape: 128 128 9 58 (8552448)
I0511 13:22:36.160712 27330 net.cpp:156] Memory required for data: 78747136
I0511 13:22:36.160718 27330 layer_factory.hpp:77] Creating layer conv2_a
I0511 13:22:36.160730 27330 net.cpp:91] Creating Layer conv2_a
I0511 13:22:36.160737 27330 net.cpp:425] conv2_a <- conv1_a
I0511 13:22:36.160747 27330 net.cpp:399] conv2_a -> conv2_a
I0511 13:22:36.162924 27330 net.cpp:141] Setting up conv2_a
I0511 13:22:36.162947 27330 net.cpp:148] Top shape: 128 128 7 56 (6422528)
I0511 13:22:36.162956 27330 net.cpp:156] Memory required for data: 104437248
I0511 13:22:36.162971 27330 layer_factory.hpp:77] Creating layer pool2_a
I0511 13:22:36.162981 27330 net.cpp:91] Creating Layer pool2_a
I0511 13:22:36.162989 27330 net.cpp:425] pool2_a <- conv2_a
I0511 13:22:36.162998 27330 net.cpp:399] pool2_a -> pool2_a
I0511 13:22:36.163054 27330 net.cpp:141] Setting up pool2_a
I0511 13:22:36.163066 27330 net.cpp:148] Top shape: 128 128 4 28 (1835008)
I0511 13:22:36.163074 27330 net.cpp:156] Memory required for data: 111777280
I0511 13:22:36.163079 27330 layer_factory.hpp:77] Creating layer relu2_a
I0511 13:22:36.163092 27330 net.cpp:91] Creating Layer relu2_a
I0511 13:22:36.163100 27330 net.cpp:425] relu2_a <- pool2_a
I0511 13:22:36.163108 27330 net.cpp:386] relu2_a -> pool2_a (in-place)
I0511 13:22:36.163118 27330 net.cpp:141] Setting up relu2_a
I0511 13:22:36.163126 27330 net.cpp:148] Top shape: 128 128 4 28 (1835008)
I0511 13:22:36.163132 27330 net.cpp:156] Memory required for data: 119117312
I0511 13:22:36.163138 27330 layer_factory.hpp:77] Creating layer ip2_a
I0511 13:22:36.163156 27330 net.cpp:91] Creating Layer ip2_a
I0511 13:22:36.163173 27330 net.cpp:425] ip2_a <- pool2_a
I0511 13:22:36.163184 27330 net.cpp:399] ip2_a -> ip2_a
I0511 13:22:36.200894 27330 net.cpp:141] Setting up ip2_a
I0511 13:22:36.200929 27330 net.cpp:148] Top shape: 128 256 (32768)
I0511 13:22:36.200935 27330 net.cpp:156] Memory required for data: 119248384
I0511 13:22:36.200950 27330 layer_factory.hpp:77] Creating layer conv1_r
I0511 13:22:36.200970 27330 net.cpp:91] Creating Layer conv1_r
I0511 13:22:36.200978 27330 net.cpp:425] conv1_r <- ratemap
I0511 13:22:36.200987 27330 net.cpp:399] conv1_r -> conv1_r
I0511 13:22:36.201856 27330 net.cpp:141] Setting up conv1_r
I0511 13:22:36.201884 27330 net.cpp:148] Top shape: 128 128 9 58 (8552448)
I0511 13:22:36.201889 27330 net.cpp:156] Memory required for data: 153458176
I0511 13:22:36.201900 27330 layer_factory.hpp:77] Creating layer relu1_r
I0511 13:22:36.201908 27330 net.cpp:91] Creating Layer relu1_r
I0511 13:22:36.201915 27330 net.cpp:425] relu1_r <- conv1_r
I0511 13:22:36.201933 27330 net.cpp:386] relu1_r -> conv1_r (in-place)
I0511 13:22:36.201942 27330 net.cpp:141] Setting up relu1_r
I0511 13:22:36.201949 27330 net.cpp:148] Top shape: 128 128 9 58 (8552448)
I0511 13:22:36.201954 27330 net.cpp:156] Memory required for data: 187667968
I0511 13:22:36.201961 27330 layer_factory.hpp:77] Creating layer conv2_r
I0511 13:22:36.201974 27330 net.cpp:91] Creating Layer conv2_r
I0511 13:22:36.201980 27330 net.cpp:425] conv2_r <- conv1_r
I0511 13:22:36.201988 27330 net.cpp:399] conv2_r -> conv2_r
I0511 13:22:36.203902 27330 net.cpp:141] Setting up conv2_r
I0511 13:22:36.203929 27330 net.cpp:148] Top shape: 128 128 7 56 (6422528)
I0511 13:22:36.203935 27330 net.cpp:156] Memory required for data: 213358080
I0511 13:22:36.203949 27330 layer_factory.hpp:77] Creating layer pool2_r
I0511 13:22:36.203969 27330 net.cpp:91] Creating Layer pool2_r
I0511 13:22:36.203975 27330 net.cpp:425] pool2_r <- conv2_r
I0511 13:22:36.203995 27330 net.cpp:399] pool2_r -> pool2_r
I0511 13:22:36.204035 27330 net.cpp:141] Setting up pool2_r
I0511 13:22:36.204044 27330 net.cpp:148] Top shape: 128 128 4 28 (1835008)
I0511 13:22:36.204049 27330 net.cpp:156] Memory required for data: 220698112
I0511 13:22:36.204054 27330 layer_factory.hpp:77] Creating layer relu2_r
I0511 13:22:36.204064 27330 net.cpp:91] Creating Layer relu2_r
I0511 13:22:36.204071 27330 net.cpp:425] relu2_r <- pool2_r
I0511 13:22:36.204077 27330 net.cpp:386] relu2_r -> pool2_r (in-place)
I0511 13:22:36.204085 27330 net.cpp:141] Setting up relu2_r
I0511 13:22:36.204092 27330 net.cpp:148] Top shape: 128 128 4 28 (1835008)
I0511 13:22:36.204107 27330 net.cpp:156] Memory required for data: 228038144
I0511 13:22:36.204113 27330 layer_factory.hpp:77] Creating layer ip2_r
I0511 13:22:36.204121 27330 net.cpp:91] Creating Layer ip2_r
I0511 13:22:36.204126 27330 net.cpp:425] ip2_r <- pool2_r
I0511 13:22:36.204138 27330 net.cpp:399] ip2_r -> ip2_r
I0511 13:22:36.239537 27330 net.cpp:141] Setting up ip2_r
I0511 13:22:36.239581 27330 net.cpp:148] Top shape: 128 256 (32768)
I0511 13:22:36.239588 27330 net.cpp:156] Memory required for data: 228169216
I0511 13:22:36.239596 27330 layer_factory.hpp:77] Creating layer concat_ar
I0511 13:22:36.239614 27330 net.cpp:91] Creating Layer concat_ar
I0511 13:22:36.239620 27330 net.cpp:425] concat_ar <- ip2_a
I0511 13:22:36.239627 27330 net.cpp:425] concat_ar <- ip2_r
I0511 13:22:36.239634 27330 net.cpp:399] concat_ar -> ip2
I0511 13:22:36.239660 27330 net.cpp:141] Setting up concat_ar
I0511 13:22:36.239668 27330 net.cpp:148] Top shape: 128 512 (65536)
I0511 13:22:36.239673 27330 net.cpp:156] Memory required for data: 228431360
I0511 13:22:36.239680 27330 layer_factory.hpp:77] Creating layer relu2
I0511 13:22:36.239694 27330 net.cpp:91] Creating Layer relu2
I0511 13:22:36.239699 27330 net.cpp:425] relu2 <- ip2
I0511 13:22:36.239706 27330 net.cpp:386] relu2 -> ip2 (in-place)
I0511 13:22:36.239714 27330 net.cpp:141] Setting up relu2
I0511 13:22:36.239722 27330 net.cpp:148] Top shape: 128 512 (65536)
I0511 13:22:36.239727 27330 net.cpp:156] Memory required for data: 228693504
I0511 13:22:36.239732 27330 layer_factory.hpp:77] Creating layer ip3
I0511 13:22:36.239740 27330 net.cpp:91] Creating Layer ip3
I0511 13:22:36.239745 27330 net.cpp:425] ip3 <- ip2
I0511 13:22:36.239763 27330 net.cpp:399] ip3 -> ip3
I0511 13:22:36.239918 27330 net.cpp:141] Setting up ip3
I0511 13:22:36.239928 27330 net.cpp:148] Top shape: 128 11 (1408)
I0511 13:22:36.239933 27330 net.cpp:156] Memory required for data: 228699136
I0511 13:22:36.239941 27330 layer_factory.hpp:77] Creating layer loss
I0511 13:22:36.239955 27330 net.cpp:91] Creating Layer loss
I0511 13:22:36.239974 27330 net.cpp:425] loss <- ip3
I0511 13:22:36.239981 27330 net.cpp:425] loss <- label
I0511 13:22:36.239991 27330 net.cpp:399] loss -> loss
I0511 13:22:36.240030 27330 net.cpp:141] Setting up loss
I0511 13:22:36.240038 27330 net.cpp:148] Top shape: (1)
I0511 13:22:36.240043 27330 net.cpp:151]     with loss weight 1
I0511 13:22:36.240083 27330 net.cpp:156] Memory required for data: 228699140
I0511 13:22:36.240090 27330 net.cpp:217] loss needs backward computation.
I0511 13:22:36.240097 27330 net.cpp:217] ip3 needs backward computation.
I0511 13:22:36.240102 27330 net.cpp:217] relu2 needs backward computation.
I0511 13:22:36.240106 27330 net.cpp:217] concat_ar needs backward computation.
I0511 13:22:36.240113 27330 net.cpp:217] ip2_r needs backward computation.
I0511 13:22:36.240118 27330 net.cpp:217] relu2_r needs backward computation.
I0511 13:22:36.240124 27330 net.cpp:217] pool2_r needs backward computation.
I0511 13:22:36.240129 27330 net.cpp:217] conv2_r needs backward computation.
I0511 13:22:36.240134 27330 net.cpp:217] relu1_r needs backward computation.
I0511 13:22:36.240139 27330 net.cpp:217] conv1_r needs backward computation.
I0511 13:22:36.240155 27330 net.cpp:217] ip2_a needs backward computation.
I0511 13:22:36.240161 27330 net.cpp:217] relu2_a needs backward computation.
I0511 13:22:36.240166 27330 net.cpp:217] pool2_a needs backward computation.
I0511 13:22:36.240171 27330 net.cpp:217] conv2_a needs backward computation.
I0511 13:22:36.240176 27330 net.cpp:217] relu1_a needs backward computation.
I0511 13:22:36.240192 27330 net.cpp:217] conv1_a needs backward computation.
I0511 13:22:36.240197 27330 net.cpp:219] amsFeatures does not need backward computation.
I0511 13:22:36.240203 27330 net.cpp:219] ratemap does not need backward computation.
I0511 13:22:36.240209 27330 net.cpp:219] data does not need backward computation.
I0511 13:22:36.240213 27330 net.cpp:261] This network produces output loss
I0511 13:22:36.240231 27330 net.cpp:274] Network initialization done.
I0511 13:22:36.241051 27330 solver.cpp:181] Creating test net (#0) specified by net file: /mnt/antares_raid/home/cindy/adhara/experiments/24/train_val.prototxt
I0511 13:22:36.241117 27330 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0511 13:22:36.241142 27330 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer ratemap
I0511 13:22:36.241147 27330 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer amsFeatures
I0511 13:22:36.241335 27330 net.cpp:49] Initializing net from parameters: 
name: "SoundNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "amsFeatures"
  top: "ratemap"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/mnt/antares_raid/home/cindy/adhara/experiments/twoears_data_test.txt"
    batch_size: 128
  }
}
layer {
  name: "conv1_a"
  type: "Convolution"
  bottom: "amsFeatures"
  top: "conv1_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 6
  }
}
layer {
  name: "relu1_a"
  type: "ReLU"
  bottom: "conv1_a"
  top: "conv1_a"
}
layer {
  name: "conv2_a"
  type: "Convolution"
  bottom: "conv1_a"
  top: "conv2_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "pool2_a"
  type: "Pooling"
  bottom: "conv2_a"
  top: "pool2_a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "relu2_a"
  type: "ReLU"
  bottom: "pool2_a"
  top: "pool2_a"
}
layer {
  name: "ip2_a"
  type: "InnerProduct"
  bottom: "pool2_a"
  top: "ip2_a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_r"
  type: "Convolution"
  bottom: "ratemap"
  top: "conv1_r"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 6
  }
}
layer {
  name: "relu1_r"
  type: "ReLU"
  bottom: "conv1_r"
  top: "conv1_r"
}
layer {
  name: "conv2_r"
  type: "Convolution"
  bottom: "conv1_r"
  top: "conv2_r"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "pool2_r"
  type: "Pooling"
  bottom: "conv2_r"
  top: "pool2_r"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "relu2_r"
  type: "ReLU"
  bottom: "pool2_r"
  top: "pool2_r"
}
layer {
  name: "ip2_r"
  type: "InnerProduct"
  bottom: "pool2_r"
  top: "ip2_r"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "concat_ar"
  type: "Concat"
  bottom: "ip2_a"
  bottom: "ip2_r"
  top: "ip2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SigmoidCrossEntropyLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0511 13:22:36.242058 27330 layer_factory.hpp:77] Creating layer data
I0511 13:22:36.242070 27330 net.cpp:91] Creating Layer data
I0511 13:22:36.242077 27330 net.cpp:399] data -> amsFeatures
I0511 13:22:36.242090 27330 net.cpp:399] data -> ratemap
I0511 13:22:36.242110 27330 net.cpp:399] data -> label
I0511 13:22:36.242120 27330 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /mnt/antares_raid/home/cindy/adhara/experiments/twoears_data_test.txt
I0511 13:22:36.242445 27330 hdf5_data_layer.cpp:93] Number of HDF5 files: 2
I0511 13:22:41.794491 27330 net.cpp:141] Setting up data
I0511 13:22:41.794554 27330 net.cpp:148] Top shape: 128 9 16 63 (1161216)
I0511 13:22:41.794564 27330 net.cpp:148] Top shape: 128 1 16 63 (129024)
I0511 13:22:41.794572 27330 net.cpp:148] Top shape: 128 1 11 1 (1408)
I0511 13:22:41.794579 27330 net.cpp:156] Memory required for data: 5166592
I0511 13:22:41.794592 27330 layer_factory.hpp:77] Creating layer conv1_a
I0511 13:22:41.794634 27330 net.cpp:91] Creating Layer conv1_a
I0511 13:22:41.794642 27330 net.cpp:425] conv1_a <- amsFeatures
I0511 13:22:41.794653 27330 net.cpp:399] conv1_a -> conv1_a
I0511 13:22:41.795392 27330 net.cpp:141] Setting up conv1_a
I0511 13:22:41.795418 27330 net.cpp:148] Top shape: 128 128 9 58 (8552448)
I0511 13:22:41.795423 27330 net.cpp:156] Memory required for data: 39376384
I0511 13:22:41.795439 27330 layer_factory.hpp:77] Creating layer relu1_a
I0511 13:22:41.795449 27330 net.cpp:91] Creating Layer relu1_a
I0511 13:22:41.795456 27330 net.cpp:425] relu1_a <- conv1_a
I0511 13:22:41.795464 27330 net.cpp:386] relu1_a -> conv1_a (in-place)
I0511 13:22:41.795474 27330 net.cpp:141] Setting up relu1_a
I0511 13:22:41.795480 27330 net.cpp:148] Top shape: 128 128 9 58 (8552448)
I0511 13:22:41.795486 27330 net.cpp:156] Memory required for data: 73586176
I0511 13:22:41.795491 27330 layer_factory.hpp:77] Creating layer conv2_a
I0511 13:22:41.795503 27330 net.cpp:91] Creating Layer conv2_a
I0511 13:22:41.795509 27330 net.cpp:425] conv2_a <- conv1_a
I0511 13:22:41.795516 27330 net.cpp:399] conv2_a -> conv2_a
I0511 13:22:41.797479 27330 net.cpp:141] Setting up conv2_a
I0511 13:22:41.797508 27330 net.cpp:148] Top shape: 128 128 7 56 (6422528)
I0511 13:22:41.797514 27330 net.cpp:156] Memory required for data: 99276288
I0511 13:22:41.797535 27330 layer_factory.hpp:77] Creating layer pool2_a
I0511 13:22:41.797546 27330 net.cpp:91] Creating Layer pool2_a
I0511 13:22:41.797564 27330 net.cpp:425] pool2_a <- conv2_a
I0511 13:22:41.797574 27330 net.cpp:399] pool2_a -> pool2_a
I0511 13:22:41.797610 27330 net.cpp:141] Setting up pool2_a
I0511 13:22:41.797618 27330 net.cpp:148] Top shape: 128 128 4 28 (1835008)
I0511 13:22:41.797624 27330 net.cpp:156] Memory required for data: 106616320
I0511 13:22:41.797631 27330 layer_factory.hpp:77] Creating layer relu2_a
I0511 13:22:41.797637 27330 net.cpp:91] Creating Layer relu2_a
I0511 13:22:41.797643 27330 net.cpp:425] relu2_a <- pool2_a
I0511 13:22:41.797651 27330 net.cpp:386] relu2_a -> pool2_a (in-place)
I0511 13:22:41.797658 27330 net.cpp:141] Setting up relu2_a
I0511 13:22:41.797665 27330 net.cpp:148] Top shape: 128 128 4 28 (1835008)
I0511 13:22:41.797672 27330 net.cpp:156] Memory required for data: 113956352
I0511 13:22:41.797678 27330 layer_factory.hpp:77] Creating layer ip2_a
I0511 13:22:41.797688 27330 net.cpp:91] Creating Layer ip2_a
I0511 13:22:41.797693 27330 net.cpp:425] ip2_a <- pool2_a
I0511 13:22:41.797701 27330 net.cpp:399] ip2_a -> ip2_a
I0511 13:22:41.833195 27330 net.cpp:141] Setting up ip2_a
I0511 13:22:41.833230 27330 net.cpp:148] Top shape: 128 256 (32768)
I0511 13:22:41.833235 27330 net.cpp:156] Memory required for data: 114087424
I0511 13:22:41.833250 27330 layer_factory.hpp:77] Creating layer conv1_r
I0511 13:22:41.833263 27330 net.cpp:91] Creating Layer conv1_r
I0511 13:22:41.833271 27330 net.cpp:425] conv1_r <- ratemap
I0511 13:22:41.833279 27330 net.cpp:399] conv1_r -> conv1_r
I0511 13:22:41.833555 27330 net.cpp:141] Setting up conv1_r
I0511 13:22:41.833569 27330 net.cpp:148] Top shape: 128 128 9 58 (8552448)
I0511 13:22:41.833575 27330 net.cpp:156] Memory required for data: 148297216
I0511 13:22:41.833582 27330 layer_factory.hpp:77] Creating layer relu1_r
I0511 13:22:41.833592 27330 net.cpp:91] Creating Layer relu1_r
I0511 13:22:41.833601 27330 net.cpp:425] relu1_r <- conv1_r
I0511 13:22:41.833611 27330 net.cpp:386] relu1_r -> conv1_r (in-place)
I0511 13:22:41.833619 27330 net.cpp:141] Setting up relu1_r
I0511 13:22:41.833626 27330 net.cpp:148] Top shape: 128 128 9 58 (8552448)
I0511 13:22:41.833631 27330 net.cpp:156] Memory required for data: 182507008
I0511 13:22:41.833637 27330 layer_factory.hpp:77] Creating layer conv2_r
I0511 13:22:41.833650 27330 net.cpp:91] Creating Layer conv2_r
I0511 13:22:41.833655 27330 net.cpp:425] conv2_r <- conv1_r
I0511 13:22:41.833673 27330 net.cpp:399] conv2_r -> conv2_r
I0511 13:22:41.835691 27330 net.cpp:141] Setting up conv2_r
I0511 13:22:41.835711 27330 net.cpp:148] Top shape: 128 128 7 56 (6422528)
I0511 13:22:41.835717 27330 net.cpp:156] Memory required for data: 208197120
I0511 13:22:41.835729 27330 layer_factory.hpp:77] Creating layer pool2_r
I0511 13:22:41.835741 27330 net.cpp:91] Creating Layer pool2_r
I0511 13:22:41.835747 27330 net.cpp:425] pool2_r <- conv2_r
I0511 13:22:41.835755 27330 net.cpp:399] pool2_r -> pool2_r
I0511 13:22:41.835798 27330 net.cpp:141] Setting up pool2_r
I0511 13:22:41.835808 27330 net.cpp:148] Top shape: 128 128 4 28 (1835008)
I0511 13:22:41.835813 27330 net.cpp:156] Memory required for data: 215537152
I0511 13:22:41.835819 27330 layer_factory.hpp:77] Creating layer relu2_r
I0511 13:22:41.835826 27330 net.cpp:91] Creating Layer relu2_r
I0511 13:22:41.835832 27330 net.cpp:425] relu2_r <- pool2_r
I0511 13:22:41.835850 27330 net.cpp:386] relu2_r -> pool2_r (in-place)
I0511 13:22:41.835860 27330 net.cpp:141] Setting up relu2_r
I0511 13:22:41.835866 27330 net.cpp:148] Top shape: 128 128 4 28 (1835008)
I0511 13:22:41.835871 27330 net.cpp:156] Memory required for data: 222877184
I0511 13:22:41.835876 27330 layer_factory.hpp:77] Creating layer ip2_r
I0511 13:22:41.835886 27330 net.cpp:91] Creating Layer ip2_r
I0511 13:22:41.835891 27330 net.cpp:425] ip2_r <- pool2_r
I0511 13:22:41.835901 27330 net.cpp:399] ip2_r -> ip2_r
I0511 13:22:41.871939 27330 net.cpp:141] Setting up ip2_r
I0511 13:22:41.871973 27330 net.cpp:148] Top shape: 128 256 (32768)
I0511 13:22:41.871979 27330 net.cpp:156] Memory required for data: 223008256
I0511 13:22:41.871991 27330 layer_factory.hpp:77] Creating layer concat_ar
I0511 13:22:41.872004 27330 net.cpp:91] Creating Layer concat_ar
I0511 13:22:41.872010 27330 net.cpp:425] concat_ar <- ip2_a
I0511 13:22:41.872019 27330 net.cpp:425] concat_ar <- ip2_r
I0511 13:22:41.872027 27330 net.cpp:399] concat_ar -> ip2
I0511 13:22:41.872050 27330 net.cpp:141] Setting up concat_ar
I0511 13:22:41.872061 27330 net.cpp:148] Top shape: 128 512 (65536)
I0511 13:22:41.872067 27330 net.cpp:156] Memory required for data: 223270400
I0511 13:22:41.872072 27330 layer_factory.hpp:77] Creating layer relu2
I0511 13:22:41.872081 27330 net.cpp:91] Creating Layer relu2
I0511 13:22:41.872086 27330 net.cpp:425] relu2 <- ip2
I0511 13:22:41.872092 27330 net.cpp:386] relu2 -> ip2 (in-place)
I0511 13:22:41.872100 27330 net.cpp:141] Setting up relu2
I0511 13:22:41.872107 27330 net.cpp:148] Top shape: 128 512 (65536)
I0511 13:22:41.872112 27330 net.cpp:156] Memory required for data: 223532544
I0511 13:22:41.872118 27330 layer_factory.hpp:77] Creating layer ip3
I0511 13:22:41.872130 27330 net.cpp:91] Creating Layer ip3
I0511 13:22:41.872146 27330 net.cpp:425] ip3 <- ip2
I0511 13:22:41.872153 27330 net.cpp:399] ip3 -> ip3
I0511 13:22:41.872306 27330 net.cpp:141] Setting up ip3
I0511 13:22:41.872315 27330 net.cpp:148] Top shape: 128 11 (1408)
I0511 13:22:41.872320 27330 net.cpp:156] Memory required for data: 223538176
I0511 13:22:41.872328 27330 layer_factory.hpp:77] Creating layer loss
I0511 13:22:41.872340 27330 net.cpp:91] Creating Layer loss
I0511 13:22:41.872345 27330 net.cpp:425] loss <- ip3
I0511 13:22:41.872351 27330 net.cpp:425] loss <- label
I0511 13:22:41.872359 27330 net.cpp:399] loss -> loss
I0511 13:22:41.872391 27330 net.cpp:141] Setting up loss
I0511 13:22:41.872398 27330 net.cpp:148] Top shape: (1)
I0511 13:22:41.872405 27330 net.cpp:151]     with loss weight 1
I0511 13:22:41.872424 27330 net.cpp:156] Memory required for data: 223538180
I0511 13:22:41.872429 27330 net.cpp:217] loss needs backward computation.
I0511 13:22:41.872436 27330 net.cpp:217] ip3 needs backward computation.
I0511 13:22:41.872440 27330 net.cpp:217] relu2 needs backward computation.
I0511 13:22:41.872445 27330 net.cpp:217] concat_ar needs backward computation.
I0511 13:22:41.872452 27330 net.cpp:217] ip2_r needs backward computation.
I0511 13:22:41.872457 27330 net.cpp:217] relu2_r needs backward computation.
I0511 13:22:41.872460 27330 net.cpp:217] pool2_r needs backward computation.
I0511 13:22:41.872465 27330 net.cpp:217] conv2_r needs backward computation.
I0511 13:22:41.872470 27330 net.cpp:217] relu1_r needs backward computation.
I0511 13:22:41.872475 27330 net.cpp:217] conv1_r needs backward computation.
I0511 13:22:41.872480 27330 net.cpp:217] ip2_a needs backward computation.
I0511 13:22:41.872486 27330 net.cpp:217] relu2_a needs backward computation.
I0511 13:22:41.872491 27330 net.cpp:217] pool2_a needs backward computation.
I0511 13:22:41.872496 27330 net.cpp:217] conv2_a needs backward computation.
I0511 13:22:41.872501 27330 net.cpp:217] relu1_a needs backward computation.
I0511 13:22:41.872506 27330 net.cpp:217] conv1_a needs backward computation.
I0511 13:22:41.872511 27330 net.cpp:219] data does not need backward computation.
I0511 13:22:41.872516 27330 net.cpp:261] This network produces output loss
I0511 13:22:41.872532 27330 net.cpp:274] Network initialization done.
I0511 13:22:41.872619 27330 solver.cpp:60] Solver scaffolding done.
I0511 13:22:41.873139 27330 caffe.cpp:219] Starting Optimization
I0511 13:22:41.873167 27330 solver.cpp:279] Solving SoundNet
I0511 13:22:41.873173 27330 solver.cpp:280] Learning Rate Policy: step
I0511 13:22:41.874002 27330 solver.cpp:337] Iteration 0, Testing net (#0)
I0511 13:22:41.874030 27330 net.cpp:685] Ignoring source layer ratemap
I0511 13:22:41.874037 27330 net.cpp:685] Ignoring source layer amsFeatures
I0511 13:25:34.681890 27330 solver.cpp:404]     Test net output #0: loss = 7.14975 (* 1 = 7.14975 loss)
I0511 13:25:39.411386 27330 solver.cpp:228] Iteration 0, loss = 7.18191
I0511 13:25:39.411430 27330 solver.cpp:244]     Train net output #0: loss = 7.18191 (* 1 = 7.18191 loss)
I0511 13:25:39.411448 27330 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
I0511 13:35:12.216197 27330 solver.cpp:228] Iteration 100, loss = 3.64533
I0511 13:35:12.216559 27330 solver.cpp:244]     Train net output #0: loss = 3.64533 (* 1 = 3.64533 loss)
I0511 13:35:12.216580 27330 sgd_solver.cpp:106] Iteration 100, lr = 0.0001
I0511 13:44:55.336187 27330 solver.cpp:228] Iteration 200, loss = 3.42251
I0511 13:44:55.336493 27330 solver.cpp:244]     Train net output #0: loss = 3.42251 (* 1 = 3.42251 loss)
I0511 13:44:55.336508 27330 sgd_solver.cpp:106] Iteration 200, lr = 0.0001
I0511 13:54:25.542690 27330 solver.cpp:228] Iteration 300, loss = 3.08748
I0511 13:54:25.543123 27330 solver.cpp:244]     Train net output #0: loss = 3.08748 (* 1 = 3.08748 loss)
I0511 13:54:25.543143 27330 sgd_solver.cpp:106] Iteration 300, lr = 0.0001
I0511 14:04:29.764087 27330 solver.cpp:228] Iteration 400, loss = 3.0065
I0511 14:04:29.764423 27330 solver.cpp:244]     Train net output #0: loss = 3.0065 (* 1 = 3.0065 loss)
I0511 14:04:29.764439 27330 sgd_solver.cpp:106] Iteration 400, lr = 0.0001
I0511 14:14:30.942080 27330 solver.cpp:228] Iteration 500, loss = 2.83232
I0511 14:14:30.942401 27330 solver.cpp:244]     Train net output #0: loss = 2.83232 (* 1 = 2.83232 loss)
I0511 14:14:30.942417 27330 sgd_solver.cpp:106] Iteration 500, lr = 0.0001
I0511 14:24:51.410795 27330 solver.cpp:228] Iteration 600, loss = 2.98168
I0511 14:24:51.411118 27330 solver.cpp:244]     Train net output #0: loss = 2.98168 (* 1 = 2.98168 loss)
I0511 14:24:51.411134 27330 sgd_solver.cpp:106] Iteration 600, lr = 0.0001
I0511 14:34:58.176954 27330 solver.cpp:228] Iteration 700, loss = 2.79686
I0511 14:34:58.177310 27330 solver.cpp:244]     Train net output #0: loss = 2.79686 (* 1 = 2.79686 loss)
I0511 14:34:58.177326 27330 sgd_solver.cpp:106] Iteration 700, lr = 0.0001
I0511 14:45:12.519368 27330 solver.cpp:228] Iteration 800, loss = 2.56345
I0511 14:45:12.519863 27330 solver.cpp:244]     Train net output #0: loss = 2.56345 (* 1 = 2.56345 loss)
I0511 14:45:12.519878 27330 sgd_solver.cpp:106] Iteration 800, lr = 0.0001
I0511 14:55:15.314524 27330 solver.cpp:228] Iteration 900, loss = 2.5724
I0511 14:55:15.314867 27330 solver.cpp:244]     Train net output #0: loss = 2.5724 (* 1 = 2.5724 loss)
I0511 14:55:15.314882 27330 sgd_solver.cpp:106] Iteration 900, lr = 0.0001
I0511 15:04:52.321254 27330 solver.cpp:228] Iteration 1000, loss = 2.66949
I0511 15:04:52.321681 27330 solver.cpp:244]     Train net output #0: loss = 2.66949 (* 1 = 2.66949 loss)
I0511 15:04:52.321707 27330 sgd_solver.cpp:106] Iteration 1000, lr = 0.0001
I0511 15:14:54.661803 27330 solver.cpp:228] Iteration 1100, loss = 2.30424
I0511 15:14:54.662132 27330 solver.cpp:244]     Train net output #0: loss = 2.30424 (* 1 = 2.30424 loss)
I0511 15:14:54.662148 27330 sgd_solver.cpp:106] Iteration 1100, lr = 0.0001
I0511 15:25:10.009007 27330 solver.cpp:228] Iteration 1200, loss = 2.27532
I0511 15:25:10.009284 27330 solver.cpp:244]     Train net output #0: loss = 2.27532 (* 1 = 2.27532 loss)
I0511 15:25:10.009299 27330 sgd_solver.cpp:106] Iteration 1200, lr = 0.0001
I0511 15:35:20.913386 27330 solver.cpp:228] Iteration 1300, loss = 2.02799
I0511 15:35:20.913728 27330 solver.cpp:244]     Train net output #0: loss = 2.02799 (* 1 = 2.02799 loss)
I0511 15:35:20.913744 27330 sgd_solver.cpp:106] Iteration 1300, lr = 0.0001
I0511 15:45:27.409385 27330 solver.cpp:228] Iteration 1400, loss = 1.92431
I0511 15:45:27.409729 27330 solver.cpp:244]     Train net output #0: loss = 1.92431 (* 1 = 1.92431 loss)
I0511 15:45:27.409744 27330 sgd_solver.cpp:106] Iteration 1400, lr = 0.0001
I0511 15:55:19.680763 27330 solver.cpp:228] Iteration 1500, loss = 1.80094
I0511 15:55:19.681152 27330 solver.cpp:244]     Train net output #0: loss = 1.80094 (* 1 = 1.80094 loss)
I0511 15:55:19.681167 27330 sgd_solver.cpp:106] Iteration 1500, lr = 0.0001
I0511 16:05:27.306095 27330 solver.cpp:228] Iteration 1600, loss = 1.94029
I0511 16:05:27.307500 27330 solver.cpp:244]     Train net output #0: loss = 1.94029 (* 1 = 1.94029 loss)
I0511 16:05:27.307518 27330 sgd_solver.cpp:106] Iteration 1600, lr = 0.0001
I0511 16:15:25.322058 27330 solver.cpp:228] Iteration 1700, loss = 2.25501
I0511 16:15:25.322376 27330 solver.cpp:244]     Train net output #0: loss = 2.25501 (* 1 = 2.25501 loss)
I0511 16:15:25.322389 27330 sgd_solver.cpp:106] Iteration 1700, lr = 0.0001
I0511 16:25:05.613096 27330 solver.cpp:228] Iteration 1800, loss = 2.098
I0511 16:25:05.613417 27330 solver.cpp:244]     Train net output #0: loss = 2.098 (* 1 = 2.098 loss)
I0511 16:25:05.613433 27330 sgd_solver.cpp:106] Iteration 1800, lr = 0.0001
I0511 16:35:27.953547 27330 solver.cpp:228] Iteration 1900, loss = 2.12594
I0511 16:35:27.953976 27330 solver.cpp:244]     Train net output #0: loss = 2.12594 (* 1 = 2.12594 loss)
I0511 16:35:27.954000 27330 sgd_solver.cpp:106] Iteration 1900, lr = 0.0001
I0511 16:45:13.821995 27330 solver.cpp:228] Iteration 2000, loss = 2.09064
I0511 16:45:13.822304 27330 solver.cpp:244]     Train net output #0: loss = 2.09064 (* 1 = 2.09064 loss)
I0511 16:45:13.822319 27330 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I0511 16:55:21.956518 27330 solver.cpp:228] Iteration 2100, loss = 1.79434
I0511 16:55:21.956856 27330 solver.cpp:244]     Train net output #0: loss = 1.79434 (* 1 = 1.79434 loss)
I0511 16:55:21.956872 27330 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I0511 17:05:37.554808 27330 solver.cpp:228] Iteration 2200, loss = 2.03372
I0511 17:05:37.555202 27330 solver.cpp:244]     Train net output #0: loss = 2.03372 (* 1 = 2.03372 loss)
I0511 17:05:37.555217 27330 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I0511 17:15:46.018369 27330 solver.cpp:228] Iteration 2300, loss = 1.25202
I0511 17:15:46.023267 27330 solver.cpp:244]     Train net output #0: loss = 1.25202 (* 1 = 1.25202 loss)
I0511 17:15:46.023279 27330 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I0511 17:26:16.968166 27330 solver.cpp:228] Iteration 2400, loss = 1.24495
I0511 17:26:16.968485 27330 solver.cpp:244]     Train net output #0: loss = 1.24495 (* 1 = 1.24495 loss)
I0511 17:26:16.968502 27330 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I0511 17:36:24.717705 27330 solver.cpp:228] Iteration 2500, loss = 1.65208
I0511 17:36:24.719246 27330 solver.cpp:244]     Train net output #0: loss = 1.65208 (* 1 = 1.65208 loss)
I0511 17:36:24.719264 27330 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0511 17:46:33.139384 27330 solver.cpp:228] Iteration 2600, loss = 1.69369
I0511 17:46:33.139714 27330 solver.cpp:244]     Train net output #0: loss = 1.69369 (* 1 = 1.69369 loss)
I0511 17:46:33.139729 27330 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0511 17:56:41.009418 27330 solver.cpp:228] Iteration 2700, loss = 1.82836
I0511 17:56:41.009727 27330 solver.cpp:244]     Train net output #0: loss = 1.82836 (* 1 = 1.82836 loss)
I0511 17:56:41.009742 27330 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0511 18:06:32.988154 27330 solver.cpp:228] Iteration 2800, loss = 1.47361
I0511 18:06:32.988533 27330 solver.cpp:244]     Train net output #0: loss = 1.47361 (* 1 = 1.47361 loss)
I0511 18:06:32.988549 27330 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0511 18:16:37.447094 27330 solver.cpp:228] Iteration 2900, loss = 1.13635
I0511 18:16:37.447423 27330 solver.cpp:244]     Train net output #0: loss = 1.13635 (* 1 = 1.13635 loss)
I0511 18:16:37.447438 27330 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0511 18:26:52.652024 27330 solver.cpp:228] Iteration 3000, loss = 2.2167
I0511 18:26:52.655248 27330 solver.cpp:244]     Train net output #0: loss = 2.2167 (* 1 = 2.2167 loss)
I0511 18:26:52.655264 27330 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0511 18:36:54.425339 27330 solver.cpp:228] Iteration 3100, loss = 1.52174
I0511 18:36:54.425716 27330 solver.cpp:244]     Train net output #0: loss = 1.52174 (* 1 = 1.52174 loss)
I0511 18:36:54.425729 27330 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0511 18:46:51.802830 27330 solver.cpp:228] Iteration 3200, loss = 1.23147
I0511 18:46:51.803190 27330 solver.cpp:244]     Train net output #0: loss = 1.23147 (* 1 = 1.23147 loss)
I0511 18:46:51.803206 27330 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0511 18:53:21.031566 27330 solver.cpp:337] Iteration 3265, Testing net (#0)
I0511 18:53:21.035254 27330 net.cpp:685] Ignoring source layer ratemap
I0511 18:53:21.035260 27330 net.cpp:685] Ignoring source layer amsFeatures
I0511 18:56:13.372282 27330 solver.cpp:404]     Test net output #0: loss = 1.07101 (* 1 = 1.07101 loss)
I0511 18:59:53.604636 27330 solver.cpp:228] Iteration 3300, loss = 1.69781
I0511 18:59:53.607240 27330 solver.cpp:244]     Train net output #0: loss = 1.69781 (* 1 = 1.69781 loss)
I0511 18:59:53.607251 27330 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0511 19:09:54.962110 27330 solver.cpp:228] Iteration 3400, loss = 1.50354
I0511 19:09:54.962466 27330 solver.cpp:244]     Train net output #0: loss = 1.50354 (* 1 = 1.50354 loss)
I0511 19:09:54.962481 27330 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0511 19:20:53.291339 27330 solver.cpp:228] Iteration 3500, loss = 1.18136
I0511 19:20:53.291674 27330 solver.cpp:244]     Train net output #0: loss = 1.18136 (* 1 = 1.18136 loss)
I0511 19:20:53.291692 27330 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0511 19:31:24.176566 27330 solver.cpp:228] Iteration 3600, loss = 1.15138
I0511 19:31:24.176908 27330 solver.cpp:244]     Train net output #0: loss = 1.15138 (* 1 = 1.15138 loss)
I0511 19:31:24.176923 27330 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0511 19:41:40.879840 27330 solver.cpp:228] Iteration 3700, loss = 1.66293
I0511 19:41:40.880151 27330 solver.cpp:244]     Train net output #0: loss = 1.66293 (* 1 = 1.66293 loss)
I0511 19:41:40.880167 27330 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0511 19:51:48.068101 27330 solver.cpp:228] Iteration 3800, loss = 1.12113
I0511 19:51:48.068444 27330 solver.cpp:244]     Train net output #0: loss = 1.12113 (* 1 = 1.12113 loss)
I0511 19:51:48.068460 27330 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0511 20:02:10.077947 27330 solver.cpp:228] Iteration 3900, loss = 1.17112
I0511 20:02:10.083241 27330 solver.cpp:244]     Train net output #0: loss = 1.17112 (* 1 = 1.17112 loss)
I0511 20:02:10.083252 27330 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0511 20:12:25.160382 27330 solver.cpp:228] Iteration 4000, loss = 1.35952
I0511 20:12:25.160814 27330 solver.cpp:244]     Train net output #0: loss = 1.35952 (* 1 = 1.35952 loss)
I0511 20:12:25.160827 27330 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0511 20:22:40.742431 27330 solver.cpp:228] Iteration 4100, loss = 1.02699
I0511 20:22:40.742895 27330 solver.cpp:244]     Train net output #0: loss = 1.02699 (* 1 = 1.02699 loss)
I0511 20:22:40.742919 27330 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0511 20:32:43.777026 27330 solver.cpp:228] Iteration 4200, loss = 0.687598
I0511 20:32:43.777405 27330 solver.cpp:244]     Train net output #0: loss = 0.687598 (* 1 = 0.687598 loss)
I0511 20:32:43.777418 27330 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0511 20:42:44.561925 27330 solver.cpp:228] Iteration 4300, loss = 1.28075
I0511 20:42:44.562253 27330 solver.cpp:244]     Train net output #0: loss = 1.28075 (* 1 = 1.28075 loss)
I0511 20:42:44.562266 27330 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0511 20:52:55.534524 27330 solver.cpp:228] Iteration 4400, loss = 1.27654
I0511 20:52:55.534945 27330 solver.cpp:244]     Train net output #0: loss = 1.27654 (* 1 = 1.27654 loss)
I0511 20:52:55.534965 27330 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0511 21:03:02.295578 27330 solver.cpp:228] Iteration 4500, loss = 1.68054
I0511 21:03:02.295939 27330 solver.cpp:244]     Train net output #0: loss = 1.68054 (* 1 = 1.68054 loss)
I0511 21:03:02.295954 27330 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0511 21:13:15.148530 27330 solver.cpp:228] Iteration 4600, loss = 0.850498
I0511 21:13:15.148864 27330 solver.cpp:244]     Train net output #0: loss = 0.850499 (* 1 = 0.850499 loss)
I0511 21:13:15.148876 27330 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0511 21:23:21.192148 27330 solver.cpp:228] Iteration 4700, loss = 0.914635
I0511 21:23:21.192601 27330 solver.cpp:244]     Train net output #0: loss = 0.914635 (* 1 = 0.914635 loss)
I0511 21:23:21.192626 27330 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0511 21:33:08.775838 27330 solver.cpp:228] Iteration 4800, loss = 0.958597
I0511 21:33:08.776144 27330 solver.cpp:244]     Train net output #0: loss = 0.958597 (* 1 = 0.958597 loss)
I0511 21:33:08.776160 27330 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0511 21:43:24.472368 27330 solver.cpp:228] Iteration 4900, loss = 1.35109
I0511 21:43:24.472704 27330 solver.cpp:244]     Train net output #0: loss = 1.35109 (* 1 = 1.35109 loss)
I0511 21:43:24.472719 27330 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0511 21:53:04.576225 27330 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_5000.caffemodel
I0511 21:53:05.033782 27330 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_5000.solverstate
I0511 21:53:11.834313 27330 solver.cpp:228] Iteration 5000, loss = 1.06322
I0511 21:53:11.834358 27330 solver.cpp:244]     Train net output #0: loss = 1.06322 (* 1 = 1.06322 loss)
I0511 21:53:11.834369 27330 sgd_solver.cpp:106] Iteration 5000, lr = 0.0001
I0511 22:03:09.062860 27330 solver.cpp:228] Iteration 5100, loss = 0.649758
I0511 22:03:09.063318 27330 solver.cpp:244]     Train net output #0: loss = 0.649758 (* 1 = 0.649758 loss)
I0511 22:03:09.063344 27330 sgd_solver.cpp:106] Iteration 5100, lr = 0.0001
I0511 22:12:57.617616 27330 solver.cpp:228] Iteration 5200, loss = 0.782795
I0511 22:12:57.617842 27330 solver.cpp:244]     Train net output #0: loss = 0.782795 (* 1 = 0.782795 loss)
I0511 22:12:57.617858 27330 sgd_solver.cpp:106] Iteration 5200, lr = 0.0001
I0511 22:23:09.639251 27330 solver.cpp:228] Iteration 5300, loss = 1.6354
I0511 22:23:09.639658 27330 solver.cpp:244]     Train net output #0: loss = 1.6354 (* 1 = 1.6354 loss)
I0511 22:23:09.639672 27330 sgd_solver.cpp:106] Iteration 5300, lr = 0.0001
I0511 22:33:07.917745 27330 solver.cpp:228] Iteration 5400, loss = 1.21295
I0511 22:33:07.918192 27330 solver.cpp:244]     Train net output #0: loss = 1.21295 (* 1 = 1.21295 loss)
I0511 22:33:07.918226 27330 sgd_solver.cpp:106] Iteration 5400, lr = 0.0001
I0511 22:42:50.928002 27330 solver.cpp:228] Iteration 5500, loss = 1.15352
I0511 22:42:50.928334 27330 solver.cpp:244]     Train net output #0: loss = 1.15352 (* 1 = 1.15352 loss)
I0511 22:42:50.928350 27330 sgd_solver.cpp:106] Iteration 5500, lr = 0.0001
I0511 22:52:42.711231 27330 solver.cpp:228] Iteration 5600, loss = 0.959136
I0511 22:52:42.711612 27330 solver.cpp:244]     Train net output #0: loss = 0.959136 (* 1 = 0.959136 loss)
I0511 22:52:42.711628 27330 sgd_solver.cpp:106] Iteration 5600, lr = 0.0001
I0511 23:02:41.476483 27330 solver.cpp:228] Iteration 5700, loss = 0.98724
I0511 23:02:41.479009 27330 solver.cpp:244]     Train net output #0: loss = 0.98724 (* 1 = 0.98724 loss)
I0511 23:02:41.479024 27330 sgd_solver.cpp:106] Iteration 5700, lr = 0.0001
I0511 23:12:34.335182 27330 solver.cpp:228] Iteration 5800, loss = 0.993629
I0511 23:12:34.335692 27330 solver.cpp:244]     Train net output #0: loss = 0.993629 (* 1 = 0.993629 loss)
I0511 23:12:34.335713 27330 sgd_solver.cpp:106] Iteration 5800, lr = 0.0001
I0511 23:22:16.387215 27330 solver.cpp:228] Iteration 5900, loss = 0.935981
I0511 23:22:16.387578 27330 solver.cpp:244]     Train net output #0: loss = 0.935981 (* 1 = 0.935981 loss)
I0511 23:22:16.387591 27330 sgd_solver.cpp:106] Iteration 5900, lr = 0.0001
I0511 23:32:24.806043 27330 solver.cpp:228] Iteration 6000, loss = 0.825925
I0511 23:32:24.806428 27330 solver.cpp:244]     Train net output #0: loss = 0.825925 (* 1 = 0.825925 loss)
I0511 23:32:24.806443 27330 sgd_solver.cpp:106] Iteration 6000, lr = 0.0001
I0511 23:42:06.886214 27330 solver.cpp:228] Iteration 6100, loss = 0.862059
I0511 23:42:06.886565 27330 solver.cpp:244]     Train net output #0: loss = 0.86206 (* 1 = 0.86206 loss)
I0511 23:42:06.886582 27330 sgd_solver.cpp:106] Iteration 6100, lr = 0.0001
I0511 23:52:01.923277 27330 solver.cpp:228] Iteration 6200, loss = 0.986987
I0511 23:52:01.923638 27330 solver.cpp:244]     Train net output #0: loss = 0.986987 (* 1 = 0.986987 loss)
I0511 23:52:01.923657 27330 sgd_solver.cpp:106] Iteration 6200, lr = 0.0001
I0512 00:01:48.600673 27330 solver.cpp:228] Iteration 6300, loss = 0.934799
I0512 00:01:48.601147 27330 solver.cpp:244]     Train net output #0: loss = 0.934799 (* 1 = 0.934799 loss)
I0512 00:01:48.601172 27330 sgd_solver.cpp:106] Iteration 6300, lr = 0.0001
I0512 00:11:36.440129 27330 solver.cpp:228] Iteration 6400, loss = 0.882147
I0512 00:11:36.440600 27330 solver.cpp:244]     Train net output #0: loss = 0.882147 (* 1 = 0.882147 loss)
I0512 00:11:36.440624 27330 sgd_solver.cpp:106] Iteration 6400, lr = 0.0001
I0512 00:21:37.610141 27330 solver.cpp:228] Iteration 6500, loss = 0.850957
I0512 00:21:37.610513 27330 solver.cpp:244]     Train net output #0: loss = 0.850957 (* 1 = 0.850957 loss)
I0512 00:21:37.610528 27330 sgd_solver.cpp:106] Iteration 6500, lr = 0.0001
I0512 00:24:29.972944 27330 solver.cpp:337] Iteration 6530, Testing net (#0)
I0512 00:24:29.973289 27330 net.cpp:685] Ignoring source layer ratemap
I0512 00:24:29.973300 27330 net.cpp:685] Ignoring source layer amsFeatures
I0512 00:27:22.609771 27330 solver.cpp:404]     Test net output #0: loss = 0.761356 (* 1 = 0.761356 loss)
I0512 00:34:19.010920 27330 solver.cpp:228] Iteration 6600, loss = 0.967651
I0512 00:34:19.011284 27330 solver.cpp:244]     Train net output #0: loss = 0.967651 (* 1 = 0.967651 loss)
I0512 00:34:19.011297 27330 sgd_solver.cpp:106] Iteration 6600, lr = 0.0001
I0512 00:44:23.748744 27330 solver.cpp:228] Iteration 6700, loss = 0.88169
I0512 00:44:23.749181 27330 solver.cpp:244]     Train net output #0: loss = 0.881691 (* 1 = 0.881691 loss)
I0512 00:44:23.749194 27330 sgd_solver.cpp:106] Iteration 6700, lr = 0.0001
I0512 00:54:18.192190 27330 solver.cpp:228] Iteration 6800, loss = 0.499054
I0512 00:54:18.192631 27330 solver.cpp:244]     Train net output #0: loss = 0.499054 (* 1 = 0.499054 loss)
I0512 00:54:18.192656 27330 sgd_solver.cpp:106] Iteration 6800, lr = 0.0001
I0512 01:03:48.251879 27330 solver.cpp:228] Iteration 6900, loss = 0.750498
I0512 01:03:48.252250 27330 solver.cpp:244]     Train net output #0: loss = 0.750499 (* 1 = 0.750499 loss)
I0512 01:03:48.252264 27330 sgd_solver.cpp:106] Iteration 6900, lr = 0.0001
I0512 01:13:39.374194 27330 solver.cpp:228] Iteration 7000, loss = 0.599876
I0512 01:13:39.374562 27330 solver.cpp:244]     Train net output #0: loss = 0.599876 (* 1 = 0.599876 loss)
I0512 01:13:39.374578 27330 sgd_solver.cpp:106] Iteration 7000, lr = 0.0001
I0512 01:23:29.481170 27330 solver.cpp:228] Iteration 7100, loss = 1.6685
I0512 01:23:29.481591 27330 solver.cpp:244]     Train net output #0: loss = 1.6685 (* 1 = 1.6685 loss)
I0512 01:23:29.481617 27330 sgd_solver.cpp:106] Iteration 7100, lr = 0.0001
I0512 01:32:18.109367 27330 solver.cpp:228] Iteration 7200, loss = 0.679165
I0512 01:32:18.109843 27330 solver.cpp:244]     Train net output #0: loss = 0.679165 (* 1 = 0.679165 loss)
I0512 01:32:18.109868 27330 sgd_solver.cpp:106] Iteration 7200, lr = 0.0001
I0512 01:40:32.040848 27330 solver.cpp:228] Iteration 7300, loss = 1.28662
I0512 01:40:32.041260 27330 solver.cpp:244]     Train net output #0: loss = 1.28663 (* 1 = 1.28663 loss)
I0512 01:40:32.041280 27330 sgd_solver.cpp:106] Iteration 7300, lr = 0.0001
I0512 01:48:57.280174 27330 solver.cpp:228] Iteration 7400, loss = 1.1207
I0512 01:48:57.280521 27330 solver.cpp:244]     Train net output #0: loss = 1.1207 (* 1 = 1.1207 loss)
I0512 01:48:57.280541 27330 sgd_solver.cpp:106] Iteration 7400, lr = 0.0001
I0512 01:57:17.598824 27330 solver.cpp:228] Iteration 7500, loss = 0.712915
I0512 01:57:17.599272 27330 solver.cpp:244]     Train net output #0: loss = 0.712915 (* 1 = 0.712915 loss)
I0512 01:57:17.599290 27330 sgd_solver.cpp:106] Iteration 7500, lr = 0.0001
I0512 02:05:55.446588 27330 solver.cpp:228] Iteration 7600, loss = 0.580653
I0512 02:05:55.446979 27330 solver.cpp:244]     Train net output #0: loss = 0.580654 (* 1 = 0.580654 loss)
I0512 02:05:55.446998 27330 sgd_solver.cpp:106] Iteration 7600, lr = 0.0001
I0512 02:14:31.947862 27330 solver.cpp:228] Iteration 7700, loss = 0.51221
I0512 02:14:31.948204 27330 solver.cpp:244]     Train net output #0: loss = 0.51221 (* 1 = 0.51221 loss)
I0512 02:14:31.948215 27330 sgd_solver.cpp:106] Iteration 7700, lr = 0.0001
I0512 02:22:55.838346 27330 solver.cpp:228] Iteration 7800, loss = 0.93089
I0512 02:22:55.838652 27330 solver.cpp:244]     Train net output #0: loss = 0.93089 (* 1 = 0.93089 loss)
I0512 02:22:55.838665 27330 sgd_solver.cpp:106] Iteration 7800, lr = 0.0001
I0512 02:31:32.263116 27330 solver.cpp:228] Iteration 7900, loss = 0.795355
I0512 02:31:32.263504 27330 solver.cpp:244]     Train net output #0: loss = 0.795355 (* 1 = 0.795355 loss)
I0512 02:31:32.263523 27330 sgd_solver.cpp:106] Iteration 7900, lr = 0.0001
I0512 02:39:58.356817 27330 solver.cpp:228] Iteration 8000, loss = 0.627836
I0512 02:39:58.357216 27330 solver.cpp:244]     Train net output #0: loss = 0.627837 (* 1 = 0.627837 loss)
I0512 02:39:58.357237 27330 sgd_solver.cpp:106] Iteration 8000, lr = 0.0001
I0512 02:48:27.350947 27330 solver.cpp:228] Iteration 8100, loss = 0.938706
I0512 02:48:27.351367 27330 solver.cpp:244]     Train net output #0: loss = 0.938706 (* 1 = 0.938706 loss)
I0512 02:48:27.351388 27330 sgd_solver.cpp:106] Iteration 8100, lr = 0.0001
I0512 02:57:41.569903 27330 solver.cpp:228] Iteration 8200, loss = 0.704749
I0512 02:57:41.570231 27330 solver.cpp:244]     Train net output #0: loss = 0.704749 (* 1 = 0.704749 loss)
I0512 02:57:41.570246 27330 sgd_solver.cpp:106] Iteration 8200, lr = 0.0001
I0512 03:07:29.266041 27330 solver.cpp:228] Iteration 8300, loss = 1.22183
I0512 03:07:29.266439 27330 solver.cpp:244]     Train net output #0: loss = 1.22183 (* 1 = 1.22183 loss)
I0512 03:07:29.266461 27330 sgd_solver.cpp:106] Iteration 8300, lr = 0.0001
I0512 03:17:18.366519 27330 solver.cpp:228] Iteration 8400, loss = 0.530917
I0512 03:17:18.366874 27330 solver.cpp:244]     Train net output #0: loss = 0.530918 (* 1 = 0.530918 loss)
I0512 03:17:18.366894 27330 sgd_solver.cpp:106] Iteration 8400, lr = 0.0001
I0512 03:27:13.178400 27330 solver.cpp:228] Iteration 8500, loss = 0.590152
I0512 03:27:13.178779 27330 solver.cpp:244]     Train net output #0: loss = 0.590152 (* 1 = 0.590152 loss)
I0512 03:27:13.178792 27330 sgd_solver.cpp:106] Iteration 8500, lr = 0.0001
I0512 03:37:23.306272 27330 solver.cpp:228] Iteration 8600, loss = 0.822734
I0512 03:37:23.306582 27330 solver.cpp:244]     Train net output #0: loss = 0.822735 (* 1 = 0.822735 loss)
I0512 03:37:23.306607 27330 sgd_solver.cpp:106] Iteration 8600, lr = 0.0001
I0512 03:47:13.302736 27330 solver.cpp:228] Iteration 8700, loss = 0.63663
I0512 03:47:13.303120 27330 solver.cpp:244]     Train net output #0: loss = 0.63663 (* 1 = 0.63663 loss)
I0512 03:47:13.303133 27330 sgd_solver.cpp:106] Iteration 8700, lr = 0.0001
I0512 03:57:11.901510 27330 solver.cpp:228] Iteration 8800, loss = 1.16353
I0512 03:57:11.901883 27330 solver.cpp:244]     Train net output #0: loss = 1.16353 (* 1 = 1.16353 loss)
I0512 03:57:11.901904 27330 sgd_solver.cpp:106] Iteration 8800, lr = 0.0001
I0512 04:07:13.948580 27330 solver.cpp:228] Iteration 8900, loss = 0.764794
I0512 04:07:13.948946 27330 solver.cpp:244]     Train net output #0: loss = 0.764794 (* 1 = 0.764794 loss)
I0512 04:07:13.948966 27330 sgd_solver.cpp:106] Iteration 8900, lr = 0.0001
I0512 04:16:58.367341 27330 solver.cpp:228] Iteration 9000, loss = 0.927109
I0512 04:16:58.368716 27330 solver.cpp:244]     Train net output #0: loss = 0.927109 (* 1 = 0.927109 loss)
I0512 04:16:58.368741 27330 sgd_solver.cpp:106] Iteration 9000, lr = 0.0001
I0512 04:26:42.625552 27330 solver.cpp:228] Iteration 9100, loss = 1.42926
I0512 04:26:42.625900 27330 solver.cpp:244]     Train net output #0: loss = 1.42926 (* 1 = 1.42926 loss)
I0512 04:26:42.625912 27330 sgd_solver.cpp:106] Iteration 9100, lr = 0.0001
I0512 04:36:37.782109 27330 solver.cpp:228] Iteration 9200, loss = 0.897857
I0512 04:36:37.782451 27330 solver.cpp:244]     Train net output #0: loss = 0.897857 (* 1 = 0.897857 loss)
I0512 04:36:37.782471 27330 sgd_solver.cpp:106] Iteration 9200, lr = 0.0001
I0512 04:46:16.798305 27330 solver.cpp:228] Iteration 9300, loss = 0.396086
I0512 04:46:16.798743 27330 solver.cpp:244]     Train net output #0: loss = 0.396086 (* 1 = 0.396086 loss)
I0512 04:46:16.798763 27330 sgd_solver.cpp:106] Iteration 9300, lr = 0.0001
I0512 04:56:05.187997 27330 solver.cpp:228] Iteration 9400, loss = 0.920346
I0512 04:56:05.188359 27330 solver.cpp:244]     Train net output #0: loss = 0.920347 (* 1 = 0.920347 loss)
I0512 04:56:05.188383 27330 sgd_solver.cpp:106] Iteration 9400, lr = 0.0001
I0512 05:06:04.479898 27330 solver.cpp:228] Iteration 9500, loss = 0.590621
I0512 05:06:04.480268 27330 solver.cpp:244]     Train net output #0: loss = 0.590621 (* 1 = 0.590621 loss)
I0512 05:06:04.480293 27330 sgd_solver.cpp:106] Iteration 9500, lr = 0.0001
I0512 05:15:56.035446 27330 solver.cpp:228] Iteration 9600, loss = 0.552343
I0512 05:15:56.035884 27330 solver.cpp:244]     Train net output #0: loss = 0.552343 (* 1 = 0.552343 loss)
I0512 05:15:56.035905 27330 sgd_solver.cpp:106] Iteration 9600, lr = 0.0001
I0512 05:25:53.429296 27330 solver.cpp:228] Iteration 9700, loss = 0.581965
I0512 05:25:53.429683 27330 solver.cpp:244]     Train net output #0: loss = 0.581965 (* 1 = 0.581965 loss)
I0512 05:25:53.429697 27330 sgd_solver.cpp:106] Iteration 9700, lr = 0.0001
I0512 05:35:20.084666 27330 solver.cpp:337] Iteration 9795, Testing net (#0)
I0512 05:35:20.085053 27330 net.cpp:685] Ignoring source layer ratemap
I0512 05:35:20.085067 27330 net.cpp:685] Ignoring source layer amsFeatures
I0512 05:38:12.612560 27330 solver.cpp:404]     Test net output #0: loss = 0.633048 (* 1 = 0.633048 loss)
I0512 05:38:51.296288 27330 solver.cpp:228] Iteration 9800, loss = 0.981901
I0512 05:38:51.296680 27330 solver.cpp:244]     Train net output #0: loss = 0.981901 (* 1 = 0.981901 loss)
I0512 05:38:51.296705 27330 sgd_solver.cpp:106] Iteration 9800, lr = 0.0001
I0512 05:48:18.269117 27330 solver.cpp:228] Iteration 9900, loss = 0.75697
I0512 05:48:18.271215 27330 solver.cpp:244]     Train net output #0: loss = 0.75697 (* 1 = 0.75697 loss)
I0512 05:48:18.271226 27330 sgd_solver.cpp:106] Iteration 9900, lr = 0.0001
I0512 05:58:04.151196 27330 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_10000.caffemodel
I0512 05:58:04.335999 27330 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_10000.solverstate
I0512 05:58:10.223109 27330 solver.cpp:228] Iteration 10000, loss = 0.506544
I0512 05:58:10.223188 27330 solver.cpp:244]     Train net output #0: loss = 0.506544 (* 1 = 0.506544 loss)
I0512 05:58:10.223201 27330 sgd_solver.cpp:106] Iteration 10000, lr = 0.0001
I0512 06:07:59.255859 27330 solver.cpp:228] Iteration 10100, loss = 0.735852
I0512 06:07:59.256232 27330 solver.cpp:244]     Train net output #0: loss = 0.735853 (* 1 = 0.735853 loss)
I0512 06:07:59.256247 27330 sgd_solver.cpp:106] Iteration 10100, lr = 0.0001
I0512 06:17:46.442471 27330 solver.cpp:228] Iteration 10200, loss = 0.699407
I0512 06:17:46.455262 27330 solver.cpp:244]     Train net output #0: loss = 0.699407 (* 1 = 0.699407 loss)
I0512 06:17:46.455282 27330 sgd_solver.cpp:106] Iteration 10200, lr = 0.0001
I0512 06:27:20.301169 27330 solver.cpp:228] Iteration 10300, loss = 0.633501
I0512 06:27:20.301609 27330 solver.cpp:244]     Train net output #0: loss = 0.633501 (* 1 = 0.633501 loss)
I0512 06:27:20.301635 27330 sgd_solver.cpp:106] Iteration 10300, lr = 0.0001
I0512 06:36:35.138037 27330 solver.cpp:228] Iteration 10400, loss = 0.767734
I0512 06:36:35.138396 27330 solver.cpp:244]     Train net output #0: loss = 0.767734 (* 1 = 0.767734 loss)
I0512 06:36:35.138411 27330 sgd_solver.cpp:106] Iteration 10400, lr = 0.0001
I0512 06:45:48.623347 27330 solver.cpp:228] Iteration 10500, loss = 0.417017
I0512 06:45:48.623801 27330 solver.cpp:244]     Train net output #0: loss = 0.417017 (* 1 = 0.417017 loss)
I0512 06:45:48.623821 27330 sgd_solver.cpp:106] Iteration 10500, lr = 0.0001
I0512 06:54:17.318542 27330 solver.cpp:228] Iteration 10600, loss = 0.626102
I0512 06:54:17.318850 27330 solver.cpp:244]     Train net output #0: loss = 0.626103 (* 1 = 0.626103 loss)
I0512 06:54:17.318863 27330 sgd_solver.cpp:106] Iteration 10600, lr = 0.0001
I0512 07:02:38.489403 27330 solver.cpp:228] Iteration 10700, loss = 0.878607
I0512 07:02:38.489886 27330 solver.cpp:244]     Train net output #0: loss = 0.878607 (* 1 = 0.878607 loss)
I0512 07:02:38.489910 27330 sgd_solver.cpp:106] Iteration 10700, lr = 0.0001
I0512 07:11:05.795645 27330 solver.cpp:228] Iteration 10800, loss = 0.836974
I0512 07:11:05.796120 27330 solver.cpp:244]     Train net output #0: loss = 0.836974 (* 1 = 0.836974 loss)
I0512 07:11:05.796145 27330 sgd_solver.cpp:106] Iteration 10800, lr = 0.0001
I0512 07:19:27.240742 27330 solver.cpp:228] Iteration 10900, loss = 0.776028
I0512 07:19:27.241108 27330 solver.cpp:244]     Train net output #0: loss = 0.776029 (* 1 = 0.776029 loss)
I0512 07:19:27.241122 27330 sgd_solver.cpp:106] Iteration 10900, lr = 0.0001
I0512 07:27:46.448205 27330 solver.cpp:228] Iteration 11000, loss = 0.792435
I0512 07:27:46.448653 27330 solver.cpp:244]     Train net output #0: loss = 0.792435 (* 1 = 0.792435 loss)
I0512 07:27:46.448678 27330 sgd_solver.cpp:106] Iteration 11000, lr = 0.0001
I0512 07:36:14.162019 27330 solver.cpp:228] Iteration 11100, loss = 0.525038
I0512 07:36:14.162472 27330 solver.cpp:244]     Train net output #0: loss = 0.525038 (* 1 = 0.525038 loss)
I0512 07:36:14.162497 27330 sgd_solver.cpp:106] Iteration 11100, lr = 0.0001
I0512 07:45:10.273542 27330 solver.cpp:228] Iteration 11200, loss = 0.566269
I0512 07:45:10.273946 27330 solver.cpp:244]     Train net output #0: loss = 0.566269 (* 1 = 0.566269 loss)
I0512 07:45:10.273967 27330 sgd_solver.cpp:106] Iteration 11200, lr = 0.0001
I0512 07:54:58.233827 27330 solver.cpp:228] Iteration 11300, loss = 0.853948
I0512 07:54:58.234180 27330 solver.cpp:244]     Train net output #0: loss = 0.853949 (* 1 = 0.853949 loss)
I0512 07:54:58.234195 27330 sgd_solver.cpp:106] Iteration 11300, lr = 0.0001
I0512 08:04:49.745748 27330 solver.cpp:228] Iteration 11400, loss = 0.874617
I0512 08:04:49.746142 27330 solver.cpp:244]     Train net output #0: loss = 0.874618 (* 1 = 0.874618 loss)
I0512 08:04:49.746156 27330 sgd_solver.cpp:106] Iteration 11400, lr = 0.0001
I0512 08:14:45.597621 27330 solver.cpp:228] Iteration 11500, loss = 0.38058
I0512 08:14:45.597987 27330 solver.cpp:244]     Train net output #0: loss = 0.38058 (* 1 = 0.38058 loss)
I0512 08:14:45.598001 27330 sgd_solver.cpp:106] Iteration 11500, lr = 0.0001
I0512 08:24:33.732470 27330 solver.cpp:228] Iteration 11600, loss = 1.0641
I0512 08:24:33.732847 27330 solver.cpp:244]     Train net output #0: loss = 1.0641 (* 1 = 1.0641 loss)
I0512 08:24:33.732861 27330 sgd_solver.cpp:106] Iteration 11600, lr = 0.0001
I0512 08:34:19.296223 27330 solver.cpp:228] Iteration 11700, loss = 1.00912
I0512 08:34:19.296625 27330 solver.cpp:244]     Train net output #0: loss = 1.00912 (* 1 = 1.00912 loss)
I0512 08:34:19.296653 27330 sgd_solver.cpp:106] Iteration 11700, lr = 0.0001
I0512 08:44:08.262609 27330 solver.cpp:228] Iteration 11800, loss = 0.265263
I0512 08:44:08.263061 27330 solver.cpp:244]     Train net output #0: loss = 0.265263 (* 1 = 0.265263 loss)
I0512 08:44:08.263084 27330 sgd_solver.cpp:106] Iteration 11800, lr = 0.0001
I0512 08:53:58.508432 27330 solver.cpp:228] Iteration 11900, loss = 0.991506
I0512 08:53:58.508787 27330 solver.cpp:244]     Train net output #0: loss = 0.991506 (* 1 = 0.991506 loss)
I0512 08:53:58.508801 27330 sgd_solver.cpp:106] Iteration 11900, lr = 0.0001
I0512 09:03:59.211369 27330 solver.cpp:228] Iteration 12000, loss = 0.493637
I0512 09:03:59.211735 27330 solver.cpp:244]     Train net output #0: loss = 0.493637 (* 1 = 0.493637 loss)
I0512 09:03:59.211750 27330 sgd_solver.cpp:106] Iteration 12000, lr = 0.0001
I0512 09:13:35.169255 27330 solver.cpp:228] Iteration 12100, loss = 0.835821
I0512 09:13:35.169646 27330 solver.cpp:244]     Train net output #0: loss = 0.835821 (* 1 = 0.835821 loss)
I0512 09:13:35.169659 27330 sgd_solver.cpp:106] Iteration 12100, lr = 0.0001
I0512 09:23:13.193816 27330 solver.cpp:228] Iteration 12200, loss = 0.505908
I0512 09:23:13.194311 27330 solver.cpp:244]     Train net output #0: loss = 0.505908 (* 1 = 0.505908 loss)
I0512 09:23:13.194332 27330 sgd_solver.cpp:106] Iteration 12200, lr = 0.0001
I0512 09:32:43.694716 27330 solver.cpp:228] Iteration 12300, loss = 0.540078
I0512 09:32:43.695185 27330 solver.cpp:244]     Train net output #0: loss = 0.540078 (* 1 = 0.540078 loss)
I0512 09:32:43.695199 27330 sgd_solver.cpp:106] Iteration 12300, lr = 0.0001
I0512 09:42:21.232985 27330 solver.cpp:228] Iteration 12400, loss = 0.491191
I0512 09:42:21.233345 27330 solver.cpp:244]     Train net output #0: loss = 0.491191 (* 1 = 0.491191 loss)
I0512 09:42:21.233360 27330 sgd_solver.cpp:106] Iteration 12400, lr = 0.0001
I0512 09:52:12.021314 27330 solver.cpp:228] Iteration 12500, loss = 0.655641
I0512 09:52:12.021702 27330 solver.cpp:244]     Train net output #0: loss = 0.655641 (* 1 = 0.655641 loss)
I0512 09:52:12.021714 27330 sgd_solver.cpp:106] Iteration 12500, lr = 0.0001
I0512 10:02:06.247452 27330 solver.cpp:228] Iteration 12600, loss = 0.621166
I0512 10:02:06.247907 27330 solver.cpp:244]     Train net output #0: loss = 0.621166 (* 1 = 0.621166 loss)
I0512 10:02:06.247932 27330 sgd_solver.cpp:106] Iteration 12600, lr = 0.0001
I0512 10:11:49.163781 27330 solver.cpp:228] Iteration 12700, loss = 0.860161
I0512 10:11:49.164191 27330 solver.cpp:244]     Train net output #0: loss = 0.860161 (* 1 = 0.860161 loss)
I0512 10:11:49.164216 27330 sgd_solver.cpp:106] Iteration 12700, lr = 0.0001
I0512 10:21:37.852406 27330 solver.cpp:228] Iteration 12800, loss = 0.546823
I0512 10:21:37.852771 27330 solver.cpp:244]     Train net output #0: loss = 0.546823 (* 1 = 0.546823 loss)
I0512 10:21:37.852784 27330 sgd_solver.cpp:106] Iteration 12800, lr = 0.0001
I0512 10:31:42.850677 27330 solver.cpp:228] Iteration 12900, loss = 0.793561
I0512 10:31:42.851217 27330 solver.cpp:244]     Train net output #0: loss = 0.793561 (* 1 = 0.793561 loss)
I0512 10:31:42.851241 27330 sgd_solver.cpp:106] Iteration 12900, lr = 0.0001
I0512 10:41:25.265671 27330 solver.cpp:228] Iteration 13000, loss = 0.615031
I0512 10:41:25.266048 27330 solver.cpp:244]     Train net output #0: loss = 0.615031 (* 1 = 0.615031 loss)
I0512 10:41:25.266063 27330 sgd_solver.cpp:106] Iteration 13000, lr = 0.0001
I0512 10:47:13.334924 27330 solver.cpp:337] Iteration 13060, Testing net (#0)
I0512 10:47:13.335309 27330 net.cpp:685] Ignoring source layer ratemap
I0512 10:47:13.335327 27330 net.cpp:685] Ignoring source layer amsFeatures
I0512 10:50:05.831965 27330 solver.cpp:404]     Test net output #0: loss = 0.595725 (* 1 = 0.595725 loss)
I0512 10:54:03.155102 27330 solver.cpp:228] Iteration 13100, loss = 0.687405
I0512 10:54:03.155534 27330 solver.cpp:244]     Train net output #0: loss = 0.687404 (* 1 = 0.687404 loss)
I0512 10:54:03.155547 27330 sgd_solver.cpp:106] Iteration 13100, lr = 0.0001
I0512 11:03:31.961324 27330 solver.cpp:228] Iteration 13200, loss = 0.695434
I0512 11:03:31.961774 27330 solver.cpp:244]     Train net output #0: loss = 0.695434 (* 1 = 0.695434 loss)
I0512 11:03:31.961789 27330 sgd_solver.cpp:106] Iteration 13200, lr = 0.0001
I0512 11:13:27.657080 27330 solver.cpp:228] Iteration 13300, loss = 0.944105
I0512 11:13:27.657493 27330 solver.cpp:244]     Train net output #0: loss = 0.944105 (* 1 = 0.944105 loss)
I0512 11:13:27.657517 27330 sgd_solver.cpp:106] Iteration 13300, lr = 0.0001
I0512 11:22:50.775352 27330 solver.cpp:228] Iteration 13400, loss = 0.529561
I0512 11:22:50.775794 27330 solver.cpp:244]     Train net output #0: loss = 0.529561 (* 1 = 0.529561 loss)
I0512 11:22:50.775817 27330 sgd_solver.cpp:106] Iteration 13400, lr = 0.0001
I0512 11:32:16.658687 27330 solver.cpp:228] Iteration 13500, loss = 0.73301
I0512 11:32:16.659081 27330 solver.cpp:244]     Train net output #0: loss = 0.73301 (* 1 = 0.73301 loss)
I0512 11:32:16.659111 27330 sgd_solver.cpp:106] Iteration 13500, lr = 0.0001
I0512 11:40:59.680009 27330 solver.cpp:228] Iteration 13600, loss = 0.82927
I0512 11:40:59.680539 27330 solver.cpp:244]     Train net output #0: loss = 0.829269 (* 1 = 0.829269 loss)
I0512 11:40:59.680563 27330 sgd_solver.cpp:106] Iteration 13600, lr = 0.0001
I0512 11:50:02.705633 27330 solver.cpp:228] Iteration 13700, loss = 0.921532
I0512 11:50:02.705986 27330 solver.cpp:244]     Train net output #0: loss = 0.921532 (* 1 = 0.921532 loss)
I0512 11:50:02.705998 27330 sgd_solver.cpp:106] Iteration 13700, lr = 0.0001
I0512 11:58:45.196249 27330 solver.cpp:228] Iteration 13800, loss = 0.606224
I0512 11:58:45.196681 27330 solver.cpp:244]     Train net output #0: loss = 0.606223 (* 1 = 0.606223 loss)
I0512 11:58:45.196707 27330 sgd_solver.cpp:106] Iteration 13800, lr = 0.0001
I0512 12:08:34.876039 27330 solver.cpp:228] Iteration 13900, loss = 0.298205
I0512 12:08:34.876379 27330 solver.cpp:244]     Train net output #0: loss = 0.298204 (* 1 = 0.298204 loss)
I0512 12:08:34.876392 27330 sgd_solver.cpp:106] Iteration 13900, lr = 0.0001
I0512 12:18:47.365043 27330 solver.cpp:228] Iteration 14000, loss = 0.531911
I0512 12:18:47.365398 27330 solver.cpp:244]     Train net output #0: loss = 0.531911 (* 1 = 0.531911 loss)
I0512 12:18:47.365413 27330 sgd_solver.cpp:106] Iteration 14000, lr = 0.0001
I0512 12:28:36.807364 27330 solver.cpp:228] Iteration 14100, loss = 0.49894
I0512 12:28:36.807696 27330 solver.cpp:244]     Train net output #0: loss = 0.49894 (* 1 = 0.49894 loss)
I0512 12:28:36.807713 27330 sgd_solver.cpp:106] Iteration 14100, lr = 0.0001
I0512 12:39:02.505895 27330 solver.cpp:228] Iteration 14200, loss = 0.452797
I0512 12:39:02.506245 27330 solver.cpp:244]     Train net output #0: loss = 0.452797 (* 1 = 0.452797 loss)
I0512 12:39:02.506263 27330 sgd_solver.cpp:106] Iteration 14200, lr = 0.0001
I0512 12:48:56.939499 27330 solver.cpp:228] Iteration 14300, loss = 0.609908
I0512 12:48:56.939913 27330 solver.cpp:244]     Train net output #0: loss = 0.609908 (* 1 = 0.609908 loss)
I0512 12:48:56.939929 27330 sgd_solver.cpp:106] Iteration 14300, lr = 0.0001
I0512 12:58:48.550983 27330 solver.cpp:228] Iteration 14400, loss = 0.686059
I0512 12:58:48.551355 27330 solver.cpp:244]     Train net output #0: loss = 0.686058 (* 1 = 0.686058 loss)
I0512 12:58:48.551370 27330 sgd_solver.cpp:106] Iteration 14400, lr = 0.0001
I0512 13:08:52.788357 27330 solver.cpp:228] Iteration 14500, loss = 0.419667
I0512 13:08:52.788708 27330 solver.cpp:244]     Train net output #0: loss = 0.419667 (* 1 = 0.419667 loss)
I0512 13:08:52.788725 27330 sgd_solver.cpp:106] Iteration 14500, lr = 0.0001
I0512 13:18:57.124450 27330 solver.cpp:228] Iteration 14600, loss = 0.62077
I0512 13:18:57.124811 27330 solver.cpp:244]     Train net output #0: loss = 0.62077 (* 1 = 0.62077 loss)
I0512 13:18:57.124835 27330 sgd_solver.cpp:106] Iteration 14600, lr = 0.0001
I0512 13:28:58.560436 27330 solver.cpp:228] Iteration 14700, loss = 0.38599
I0512 13:28:58.560811 27330 solver.cpp:244]     Train net output #0: loss = 0.38599 (* 1 = 0.38599 loss)
I0512 13:28:58.560825 27330 sgd_solver.cpp:106] Iteration 14700, lr = 0.0001
I0512 13:38:48.707664 27330 solver.cpp:228] Iteration 14800, loss = 0.536029
I0512 13:38:48.708009 27330 solver.cpp:244]     Train net output #0: loss = 0.536029 (* 1 = 0.536029 loss)
I0512 13:38:48.708024 27330 sgd_solver.cpp:106] Iteration 14800, lr = 0.0001
I0512 13:48:31.953821 27330 solver.cpp:228] Iteration 14900, loss = 0.623722
I0512 13:48:31.954210 27330 solver.cpp:244]     Train net output #0: loss = 0.623722 (* 1 = 0.623722 loss)
I0512 13:48:31.954224 27330 sgd_solver.cpp:106] Iteration 14900, lr = 0.0001
I0512 13:58:15.596349 27330 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_15000.caffemodel
I0512 13:58:15.774817 27330 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_15000.solverstate
I0512 13:58:21.732017 27330 solver.cpp:228] Iteration 15000, loss = 0.431146
I0512 13:58:21.732074 27330 solver.cpp:244]     Train net output #0: loss = 0.431146 (* 1 = 0.431146 loss)
I0512 13:58:21.732085 27330 sgd_solver.cpp:106] Iteration 15000, lr = 0.0001
I0512 14:07:57.989437 27330 solver.cpp:228] Iteration 15100, loss = 0.57272
I0512 14:07:57.989845 27330 solver.cpp:244]     Train net output #0: loss = 0.57272 (* 1 = 0.57272 loss)
I0512 14:07:57.989858 27330 sgd_solver.cpp:106] Iteration 15100, lr = 0.0001
I0512 14:17:52.396196 27330 solver.cpp:228] Iteration 15200, loss = 0.498196
I0512 14:17:52.396595 27330 solver.cpp:244]     Train net output #0: loss = 0.498196 (* 1 = 0.498196 loss)
I0512 14:17:52.396610 27330 sgd_solver.cpp:106] Iteration 15200, lr = 0.0001
I0512 14:27:44.816259 27330 solver.cpp:228] Iteration 15300, loss = 0.397301
I0512 14:27:44.816611 27330 solver.cpp:244]     Train net output #0: loss = 0.397301 (* 1 = 0.397301 loss)
I0512 14:27:44.816627 27330 sgd_solver.cpp:106] Iteration 15300, lr = 0.0001
I0512 14:37:43.235054 27330 solver.cpp:228] Iteration 15400, loss = 0.379441
I0512 14:37:43.235438 27330 solver.cpp:244]     Train net output #0: loss = 0.379441 (* 1 = 0.379441 loss)
I0512 14:37:43.235455 27330 sgd_solver.cpp:106] Iteration 15400, lr = 0.0001
I0512 14:47:53.271039 27330 solver.cpp:228] Iteration 15500, loss = 0.57195
I0512 14:47:53.271378 27330 solver.cpp:244]     Train net output #0: loss = 0.57195 (* 1 = 0.57195 loss)
I0512 14:47:53.271396 27330 sgd_solver.cpp:106] Iteration 15500, lr = 0.0001
I0512 14:57:50.152262 27330 solver.cpp:228] Iteration 15600, loss = 0.531147
I0512 14:57:50.152642 27330 solver.cpp:244]     Train net output #0: loss = 0.531146 (* 1 = 0.531146 loss)
I0512 14:57:50.152657 27330 sgd_solver.cpp:106] Iteration 15600, lr = 0.0001
I0512 15:07:16.832128 27330 solver.cpp:228] Iteration 15700, loss = 0.557293
I0512 15:07:16.832572 27330 solver.cpp:244]     Train net output #0: loss = 0.557292 (* 1 = 0.557292 loss)
I0512 15:07:16.832597 27330 sgd_solver.cpp:106] Iteration 15700, lr = 0.0001
I0512 15:16:35.266219 27330 solver.cpp:228] Iteration 15800, loss = 0.627087
I0512 15:16:35.266656 27330 solver.cpp:244]     Train net output #0: loss = 0.627087 (* 1 = 0.627087 loss)
I0512 15:16:35.266676 27330 sgd_solver.cpp:106] Iteration 15800, lr = 0.0001
I0512 15:26:07.395032 27330 solver.cpp:228] Iteration 15900, loss = 0.406192
I0512 15:26:07.395421 27330 solver.cpp:244]     Train net output #0: loss = 0.406192 (* 1 = 0.406192 loss)
I0512 15:26:07.395442 27330 sgd_solver.cpp:106] Iteration 15900, lr = 0.0001
I0512 15:35:23.551985 27330 solver.cpp:228] Iteration 16000, loss = 0.679337
I0512 15:35:23.552371 27330 solver.cpp:244]     Train net output #0: loss = 0.679337 (* 1 = 0.679337 loss)
I0512 15:35:23.552383 27330 sgd_solver.cpp:106] Iteration 16000, lr = 0.0001
I0512 15:44:23.150002 27330 solver.cpp:228] Iteration 16100, loss = 0.694437
I0512 15:44:23.150447 27330 solver.cpp:244]     Train net output #0: loss = 0.694436 (* 1 = 0.694436 loss)
I0512 15:44:23.150467 27330 sgd_solver.cpp:106] Iteration 16100, lr = 0.0001
I0512 15:53:35.924084 27330 solver.cpp:228] Iteration 16200, loss = 0.830644
I0512 15:53:35.924499 27330 solver.cpp:244]     Train net output #0: loss = 0.830644 (* 1 = 0.830644 loss)
I0512 15:53:35.924518 27330 sgd_solver.cpp:106] Iteration 16200, lr = 0.0001
I0512 16:02:32.439141 27330 solver.cpp:228] Iteration 16300, loss = 0.493712
I0512 16:02:32.439532 27330 solver.cpp:244]     Train net output #0: loss = 0.493712 (* 1 = 0.493712 loss)
I0512 16:02:32.439551 27330 sgd_solver.cpp:106] Iteration 16300, lr = 0.0001
I0512 16:04:55.545287 27330 solver.cpp:337] Iteration 16325, Testing net (#0)
I0512 16:04:55.545680 27330 net.cpp:685] Ignoring source layer ratemap
I0512 16:04:55.545694 27330 net.cpp:685] Ignoring source layer amsFeatures
I0512 16:07:47.373101 27330 solver.cpp:404]     Test net output #0: loss = 0.567355 (* 1 = 0.567355 loss)
I0512 16:14:39.567566 27330 solver.cpp:228] Iteration 16400, loss = 0.417518
I0512 16:14:39.567977 27330 solver.cpp:244]     Train net output #0: loss = 0.417518 (* 1 = 0.417518 loss)
I0512 16:14:39.568006 27330 sgd_solver.cpp:106] Iteration 16400, lr = 0.0001
I0512 16:23:44.698113 27330 solver.cpp:228] Iteration 16500, loss = 0.410963
I0512 16:23:44.699296 27330 solver.cpp:244]     Train net output #0: loss = 0.410963 (* 1 = 0.410963 loss)
I0512 16:23:44.699311 27330 sgd_solver.cpp:106] Iteration 16500, lr = 0.0001
I0512 16:32:47.483228 27330 solver.cpp:228] Iteration 16600, loss = 0.65088
I0512 16:32:47.483657 27330 solver.cpp:244]     Train net output #0: loss = 0.65088 (* 1 = 0.65088 loss)
I0512 16:32:47.483677 27330 sgd_solver.cpp:106] Iteration 16600, lr = 0.0001
I0512 16:41:50.979491 27330 solver.cpp:228] Iteration 16700, loss = 0.899817
I0512 16:41:50.979845 27330 solver.cpp:244]     Train net output #0: loss = 0.899817 (* 1 = 0.899817 loss)
I0512 16:41:50.979856 27330 sgd_solver.cpp:106] Iteration 16700, lr = 0.0001
I0512 16:51:03.986639 27330 solver.cpp:228] Iteration 16800, loss = 0.516075
I0512 16:51:03.987015 27330 solver.cpp:244]     Train net output #0: loss = 0.516074 (* 1 = 0.516074 loss)
I0512 16:51:03.987038 27330 sgd_solver.cpp:106] Iteration 16800, lr = 0.0001
I0512 17:00:27.690017 27330 solver.cpp:228] Iteration 16900, loss = 0.841093
I0512 17:00:27.690366 27330 solver.cpp:244]     Train net output #0: loss = 0.841092 (* 1 = 0.841092 loss)
I0512 17:00:27.690385 27330 sgd_solver.cpp:106] Iteration 16900, lr = 0.0001
I0512 17:09:57.310621 27330 solver.cpp:228] Iteration 17000, loss = 0.551872
I0512 17:09:57.310982 27330 solver.cpp:244]     Train net output #0: loss = 0.551872 (* 1 = 0.551872 loss)
I0512 17:09:57.311002 27330 sgd_solver.cpp:106] Iteration 17000, lr = 0.0001
I0512 17:19:21.803333 27330 solver.cpp:228] Iteration 17100, loss = 0.803392
I0512 17:19:21.803692 27330 solver.cpp:244]     Train net output #0: loss = 0.803392 (* 1 = 0.803392 loss)
I0512 17:19:21.803720 27330 sgd_solver.cpp:106] Iteration 17100, lr = 0.0001
I0512 17:28:56.269623 27330 solver.cpp:228] Iteration 17200, loss = 0.374397
I0512 17:28:56.270005 27330 solver.cpp:244]     Train net output #0: loss = 0.374397 (* 1 = 0.374397 loss)
I0512 17:28:56.270018 27330 sgd_solver.cpp:106] Iteration 17200, lr = 0.0001
I0512 17:38:19.284346 27330 solver.cpp:228] Iteration 17300, loss = 0.415736
I0512 17:38:19.284734 27330 solver.cpp:244]     Train net output #0: loss = 0.415736 (* 1 = 0.415736 loss)
I0512 17:38:19.284754 27330 sgd_solver.cpp:106] Iteration 17300, lr = 0.0001
I0512 17:47:48.486929 27330 solver.cpp:228] Iteration 17400, loss = 0.563227
I0512 17:47:48.487365 27330 solver.cpp:244]     Train net output #0: loss = 0.563227 (* 1 = 0.563227 loss)
I0512 17:47:48.487383 27330 sgd_solver.cpp:106] Iteration 17400, lr = 0.0001
I0512 17:57:27.176308 27330 solver.cpp:228] Iteration 17500, loss = 0.23894
I0512 17:57:27.176769 27330 solver.cpp:244]     Train net output #0: loss = 0.238939 (* 1 = 0.238939 loss)
I0512 17:57:27.176795 27330 sgd_solver.cpp:106] Iteration 17500, lr = 0.0001
I0512 18:06:57.803737 27330 solver.cpp:228] Iteration 17600, loss = 0.84228
I0512 18:06:57.804132 27330 solver.cpp:244]     Train net output #0: loss = 0.84228 (* 1 = 0.84228 loss)
I0512 18:06:57.804152 27330 sgd_solver.cpp:106] Iteration 17600, lr = 0.0001
I0512 18:16:19.755818 27330 solver.cpp:228] Iteration 17700, loss = 0.576222
I0512 18:16:19.756222 27330 solver.cpp:244]     Train net output #0: loss = 0.576222 (* 1 = 0.576222 loss)
I0512 18:16:19.756242 27330 sgd_solver.cpp:106] Iteration 17700, lr = 0.0001
I0512 18:25:38.545413 27330 solver.cpp:228] Iteration 17800, loss = 0.398099
I0512 18:25:38.545797 27330 solver.cpp:244]     Train net output #0: loss = 0.398099 (* 1 = 0.398099 loss)
I0512 18:25:38.545817 27330 sgd_solver.cpp:106] Iteration 17800, lr = 0.0001
I0512 18:35:05.876107 27330 solver.cpp:228] Iteration 17900, loss = 0.491105
I0512 18:35:05.876559 27330 solver.cpp:244]     Train net output #0: loss = 0.491105 (* 1 = 0.491105 loss)
I0512 18:35:05.876579 27330 sgd_solver.cpp:106] Iteration 17900, lr = 0.0001
I0512 18:44:17.283535 27330 solver.cpp:228] Iteration 18000, loss = 0.596
I0512 18:44:17.283912 27330 solver.cpp:244]     Train net output #0: loss = 0.596 (* 1 = 0.596 loss)
I0512 18:44:17.283923 27330 sgd_solver.cpp:106] Iteration 18000, lr = 0.0001
I0512 18:53:28.337131 27330 solver.cpp:228] Iteration 18100, loss = 0.600515
I0512 18:53:28.337533 27330 solver.cpp:244]     Train net output #0: loss = 0.600515 (* 1 = 0.600515 loss)
I0512 18:53:28.337554 27330 sgd_solver.cpp:106] Iteration 18100, lr = 0.0001
I0512 19:02:51.421344 27330 solver.cpp:228] Iteration 18200, loss = 1.0677
I0512 19:02:51.421798 27330 solver.cpp:244]     Train net output #0: loss = 1.0677 (* 1 = 1.0677 loss)
I0512 19:02:51.421819 27330 sgd_solver.cpp:106] Iteration 18200, lr = 0.0001
I0512 19:12:04.387039 27330 solver.cpp:228] Iteration 18300, loss = 0.597185
I0512 19:12:04.387440 27330 solver.cpp:244]     Train net output #0: loss = 0.597185 (* 1 = 0.597185 loss)
I0512 19:12:04.387455 27330 sgd_solver.cpp:106] Iteration 18300, lr = 0.0001
I0512 19:21:54.689790 27330 solver.cpp:228] Iteration 18400, loss = 0.405465
I0512 19:21:54.690204 27330 solver.cpp:244]     Train net output #0: loss = 0.405465 (* 1 = 0.405465 loss)
I0512 19:21:54.690230 27330 sgd_solver.cpp:106] Iteration 18400, lr = 0.0001
I0512 19:31:36.644938 27330 solver.cpp:228] Iteration 18500, loss = 0.564004
I0512 19:31:36.645318 27330 solver.cpp:244]     Train net output #0: loss = 0.564004 (* 1 = 0.564004 loss)
I0512 19:31:36.645330 27330 sgd_solver.cpp:106] Iteration 18500, lr = 0.0001
I0512 19:41:18.646517 27330 solver.cpp:228] Iteration 18600, loss = 0.302619
I0512 19:41:18.646791 27330 solver.cpp:244]     Train net output #0: loss = 0.302619 (* 1 = 0.302619 loss)
I0512 19:41:18.646805 27330 sgd_solver.cpp:106] Iteration 18600, lr = 0.0001
I0512 19:51:01.695130 27330 solver.cpp:228] Iteration 18700, loss = 0.572819
I0512 19:51:01.695510 27330 solver.cpp:244]     Train net output #0: loss = 0.572819 (* 1 = 0.572819 loss)
I0512 19:51:01.695523 27330 sgd_solver.cpp:106] Iteration 18700, lr = 0.0001
I0512 20:00:41.845383 27330 solver.cpp:228] Iteration 18800, loss = 0.387901
I0512 20:00:41.845782 27330 solver.cpp:244]     Train net output #0: loss = 0.387901 (* 1 = 0.387901 loss)
I0512 20:00:41.845795 27330 sgd_solver.cpp:106] Iteration 18800, lr = 0.0001
I0512 20:10:11.647838 27330 solver.cpp:228] Iteration 18900, loss = 0.589237
I0512 20:10:11.648186 27330 solver.cpp:244]     Train net output #0: loss = 0.589236 (* 1 = 0.589236 loss)
I0512 20:10:11.648200 27330 sgd_solver.cpp:106] Iteration 18900, lr = 0.0001
I0512 20:19:07.596185 27330 solver.cpp:228] Iteration 19000, loss = 0.293034
I0512 20:19:07.596516 27330 solver.cpp:244]     Train net output #0: loss = 0.293034 (* 1 = 0.293034 loss)
I0512 20:19:07.596529 27330 sgd_solver.cpp:106] Iteration 19000, lr = 0.0001
I0512 20:27:55.692607 27330 solver.cpp:228] Iteration 19100, loss = 0.48774
I0512 20:27:55.692939 27330 solver.cpp:244]     Train net output #0: loss = 0.48774 (* 1 = 0.48774 loss)
I0512 20:27:55.692952 27330 sgd_solver.cpp:106] Iteration 19100, lr = 0.0001
I0512 20:36:35.210870 27330 solver.cpp:228] Iteration 19200, loss = 0.605139
I0512 20:36:35.211282 27330 solver.cpp:244]     Train net output #0: loss = 0.605139 (* 1 = 0.605139 loss)
I0512 20:36:35.211308 27330 sgd_solver.cpp:106] Iteration 19200, lr = 0.0001
I0512 20:45:27.258751 27330 solver.cpp:228] Iteration 19300, loss = 0.535907
I0512 20:45:27.259081 27330 solver.cpp:244]     Train net output #0: loss = 0.535907 (* 1 = 0.535907 loss)
I0512 20:45:27.259094 27330 sgd_solver.cpp:106] Iteration 19300, lr = 0.0001
I0512 20:54:51.090811 27330 solver.cpp:228] Iteration 19400, loss = 0.742063
I0512 20:54:51.091214 27330 solver.cpp:244]     Train net output #0: loss = 0.742063 (* 1 = 0.742063 loss)
I0512 20:54:51.091235 27330 sgd_solver.cpp:106] Iteration 19400, lr = 0.0001
I0512 21:04:46.059972 27330 solver.cpp:228] Iteration 19500, loss = 0.456391
I0512 21:04:46.060294 27330 solver.cpp:244]     Train net output #0: loss = 0.45639 (* 1 = 0.45639 loss)
I0512 21:04:46.060308 27330 sgd_solver.cpp:106] Iteration 19500, lr = 0.0001
I0512 21:13:25.087688 27330 solver.cpp:337] Iteration 19590, Testing net (#0)
I0512 21:13:25.088052 27330 net.cpp:685] Ignoring source layer ratemap
I0512 21:13:25.088063 27330 net.cpp:685] Ignoring source layer amsFeatures
I0512 21:16:17.980314 27330 solver.cpp:404]     Test net output #0: loss = 0.58527 (* 1 = 0.58527 loss)
I0512 21:17:21.742131 27330 solver.cpp:228] Iteration 19600, loss = 0.628261
I0512 21:17:21.742480 27330 solver.cpp:244]     Train net output #0: loss = 0.628261 (* 1 = 0.628261 loss)
I0512 21:17:21.742492 27330 sgd_solver.cpp:106] Iteration 19600, lr = 0.0001
I0512 21:26:51.663156 27330 solver.cpp:228] Iteration 19700, loss = 1.32547
I0512 21:26:51.663611 27330 solver.cpp:244]     Train net output #0: loss = 1.32547 (* 1 = 1.32547 loss)
I0512 21:26:51.663631 27330 sgd_solver.cpp:106] Iteration 19700, lr = 0.0001
I0512 21:36:21.139331 27330 solver.cpp:228] Iteration 19800, loss = 0.617617
I0512 21:36:21.139719 27330 solver.cpp:244]     Train net output #0: loss = 0.617617 (* 1 = 0.617617 loss)
I0512 21:36:21.139739 27330 sgd_solver.cpp:106] Iteration 19800, lr = 0.0001
I0512 21:46:11.083434 27330 solver.cpp:228] Iteration 19900, loss = 0.261792
I0512 21:46:11.083786 27330 solver.cpp:244]     Train net output #0: loss = 0.261792 (* 1 = 0.261792 loss)
I0512 21:46:11.083799 27330 sgd_solver.cpp:106] Iteration 19900, lr = 0.0001
I0512 21:55:54.085784 27330 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_20000.caffemodel
I0512 21:55:54.271245 27330 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_20000.solverstate
I0512 21:56:01.170680 27330 solver.cpp:228] Iteration 20000, loss = 0.357244
I0512 21:56:01.170732 27330 solver.cpp:244]     Train net output #0: loss = 0.357244 (* 1 = 0.357244 loss)
I0512 21:56:01.170743 27330 sgd_solver.cpp:106] Iteration 20000, lr = 0.0001
I0512 22:05:49.809224 27330 solver.cpp:228] Iteration 20100, loss = 0.307197
I0512 22:05:49.809645 27330 solver.cpp:244]     Train net output #0: loss = 0.307197 (* 1 = 0.307197 loss)
I0512 22:05:49.809665 27330 sgd_solver.cpp:106] Iteration 20100, lr = 0.0001
I0512 22:15:27.606598 27330 solver.cpp:228] Iteration 20200, loss = 0.315415
I0512 22:15:27.606922 27330 solver.cpp:244]     Train net output #0: loss = 0.315415 (* 1 = 0.315415 loss)
I0512 22:15:27.606936 27330 sgd_solver.cpp:106] Iteration 20200, lr = 0.0001
I0512 22:25:09.321149 27330 solver.cpp:228] Iteration 20300, loss = 0.621864
I0512 22:25:09.321506 27330 solver.cpp:244]     Train net output #0: loss = 0.621863 (* 1 = 0.621863 loss)
I0512 22:25:09.321526 27330 sgd_solver.cpp:106] Iteration 20300, lr = 0.0001
I0512 22:35:01.642427 27330 solver.cpp:228] Iteration 20400, loss = 0.473814
I0512 22:35:01.642819 27330 solver.cpp:244]     Train net output #0: loss = 0.473813 (* 1 = 0.473813 loss)
I0512 22:35:01.642840 27330 sgd_solver.cpp:106] Iteration 20400, lr = 0.0001
I0512 22:44:36.839684 27330 solver.cpp:228] Iteration 20500, loss = 0.772775
I0512 22:44:36.840045 27330 solver.cpp:244]     Train net output #0: loss = 0.772775 (* 1 = 0.772775 loss)
I0512 22:44:36.840071 27330 sgd_solver.cpp:106] Iteration 20500, lr = 0.0001
I0512 22:54:13.625365 27330 solver.cpp:228] Iteration 20600, loss = 0.458407
I0512 22:54:13.625870 27330 solver.cpp:244]     Train net output #0: loss = 0.458406 (* 1 = 0.458406 loss)
I0512 22:54:13.625895 27330 sgd_solver.cpp:106] Iteration 20600, lr = 0.0001
I0512 23:03:57.799002 27330 solver.cpp:228] Iteration 20700, loss = 0.317676
I0512 23:03:57.799402 27330 solver.cpp:244]     Train net output #0: loss = 0.317676 (* 1 = 0.317676 loss)
I0512 23:03:57.799423 27330 sgd_solver.cpp:106] Iteration 20700, lr = 0.0001
I0512 23:13:28.742808 27330 solver.cpp:228] Iteration 20800, loss = 0.350024
I0512 23:13:28.743186 27330 solver.cpp:244]     Train net output #0: loss = 0.350024 (* 1 = 0.350024 loss)
I0512 23:13:28.743216 27330 sgd_solver.cpp:106] Iteration 20800, lr = 0.0001
I0512 23:23:09.306056 27330 solver.cpp:228] Iteration 20900, loss = 0.463228
I0512 23:23:09.306460 27330 solver.cpp:244]     Train net output #0: loss = 0.463228 (* 1 = 0.463228 loss)
I0512 23:23:09.306480 27330 sgd_solver.cpp:106] Iteration 20900, lr = 0.0001
I0512 23:32:33.743711 27330 solver.cpp:228] Iteration 21000, loss = 0.504079
I0512 23:32:33.744135 27330 solver.cpp:244]     Train net output #0: loss = 0.504079 (* 1 = 0.504079 loss)
I0512 23:32:33.744155 27330 sgd_solver.cpp:106] Iteration 21000, lr = 0.0001
I0512 23:42:28.433059 27330 solver.cpp:228] Iteration 21100, loss = 0.862243
I0512 23:42:28.433462 27330 solver.cpp:244]     Train net output #0: loss = 0.862243 (* 1 = 0.862243 loss)
I0512 23:42:28.433483 27330 sgd_solver.cpp:106] Iteration 21100, lr = 0.0001
I0512 23:52:22.012383 27330 solver.cpp:228] Iteration 21200, loss = 0.44849
I0512 23:52:22.012759 27330 solver.cpp:244]     Train net output #0: loss = 0.44849 (* 1 = 0.44849 loss)
I0512 23:52:22.012774 27330 sgd_solver.cpp:106] Iteration 21200, lr = 0.0001
I0513 00:01:44.312074 27330 solver.cpp:228] Iteration 21300, loss = 0.765557
I0513 00:01:44.312487 27330 solver.cpp:244]     Train net output #0: loss = 0.765557 (* 1 = 0.765557 loss)
I0513 00:01:44.312508 27330 sgd_solver.cpp:106] Iteration 21300, lr = 0.0001
I0513 00:10:58.347941 27330 solver.cpp:228] Iteration 21400, loss = 0.525255
I0513 00:10:58.348361 27330 solver.cpp:244]     Train net output #0: loss = 0.525255 (* 1 = 0.525255 loss)
I0513 00:10:58.348387 27330 sgd_solver.cpp:106] Iteration 21400, lr = 0.0001
I0513 00:20:10.867084 27330 solver.cpp:228] Iteration 21500, loss = 0.388194
I0513 00:20:10.867501 27330 solver.cpp:244]     Train net output #0: loss = 0.388194 (* 1 = 0.388194 loss)
I0513 00:20:10.867522 27330 sgd_solver.cpp:106] Iteration 21500, lr = 0.0001
I0513 00:29:20.278201 27330 solver.cpp:228] Iteration 21600, loss = 0.310109
I0513 00:29:20.278592 27330 solver.cpp:244]     Train net output #0: loss = 0.310109 (* 1 = 0.310109 loss)
I0513 00:29:20.278612 27330 sgd_solver.cpp:106] Iteration 21600, lr = 0.0001
I0513 00:38:29.692708 27330 solver.cpp:228] Iteration 21700, loss = 0.280319
I0513 00:38:29.693145 27330 solver.cpp:244]     Train net output #0: loss = 0.280319 (* 1 = 0.280319 loss)
I0513 00:38:29.693164 27330 sgd_solver.cpp:106] Iteration 21700, lr = 0.0001
I0513 00:47:29.851858 27330 solver.cpp:228] Iteration 21800, loss = 0.453176
I0513 00:47:29.852290 27330 solver.cpp:244]     Train net output #0: loss = 0.453176 (* 1 = 0.453176 loss)
I0513 00:47:29.852310 27330 sgd_solver.cpp:106] Iteration 21800, lr = 0.0001
I0513 00:56:33.855425 27330 solver.cpp:228] Iteration 21900, loss = 0.529451
I0513 00:56:33.855850 27330 solver.cpp:244]     Train net output #0: loss = 0.52945 (* 1 = 0.52945 loss)
I0513 00:56:33.855870 27330 sgd_solver.cpp:106] Iteration 21900, lr = 0.0001
I0513 01:05:45.192034 27330 solver.cpp:228] Iteration 22000, loss = 0.557146
I0513 01:05:45.192462 27330 solver.cpp:244]     Train net output #0: loss = 0.557145 (* 1 = 0.557145 loss)
I0513 01:05:45.192482 27330 sgd_solver.cpp:106] Iteration 22000, lr = 0.0001
I0513 01:14:46.549408 27330 solver.cpp:228] Iteration 22100, loss = 0.407709
I0513 01:14:46.549809 27330 solver.cpp:244]     Train net output #0: loss = 0.407709 (* 1 = 0.407709 loss)
I0513 01:14:46.549830 27330 sgd_solver.cpp:106] Iteration 22100, lr = 0.0001
I0513 01:23:53.036844 27330 solver.cpp:228] Iteration 22200, loss = 0.528446
I0513 01:23:53.037248 27330 solver.cpp:244]     Train net output #0: loss = 0.528446 (* 1 = 0.528446 loss)
I0513 01:23:53.037262 27330 sgd_solver.cpp:106] Iteration 22200, lr = 0.0001
I0513 01:32:47.055644 27330 solver.cpp:228] Iteration 22300, loss = 0.523947
I0513 01:32:47.056018 27330 solver.cpp:244]     Train net output #0: loss = 0.523947 (* 1 = 0.523947 loss)
I0513 01:32:47.056030 27330 sgd_solver.cpp:106] Iteration 22300, lr = 0.0001
I0513 01:41:56.405200 27330 solver.cpp:228] Iteration 22400, loss = 0.672368
I0513 01:41:56.405598 27330 solver.cpp:244]     Train net output #0: loss = 0.672368 (* 1 = 0.672368 loss)
I0513 01:41:56.405619 27330 sgd_solver.cpp:106] Iteration 22400, lr = 0.0001
I0513 01:51:06.418597 27330 solver.cpp:228] Iteration 22500, loss = 0.797161
I0513 01:51:06.418982 27330 solver.cpp:244]     Train net output #0: loss = 0.797161 (* 1 = 0.797161 loss)
I0513 01:51:06.419003 27330 sgd_solver.cpp:106] Iteration 22500, lr = 0.0001
I0513 02:00:24.850162 27330 solver.cpp:228] Iteration 22600, loss = 0.398779
I0513 02:00:24.850579 27330 solver.cpp:244]     Train net output #0: loss = 0.398779 (* 1 = 0.398779 loss)
I0513 02:00:24.850602 27330 sgd_solver.cpp:106] Iteration 22600, lr = 0.0001
I0513 02:10:01.090754 27330 solver.cpp:228] Iteration 22700, loss = 0.600493
I0513 02:10:01.091145 27330 solver.cpp:244]     Train net output #0: loss = 0.600493 (* 1 = 0.600493 loss)
I0513 02:10:01.091187 27330 sgd_solver.cpp:106] Iteration 22700, lr = 0.0001
I0513 02:19:27.985157 27330 solver.cpp:228] Iteration 22800, loss = 0.276606
I0513 02:19:27.985553 27330 solver.cpp:244]     Train net output #0: loss = 0.276606 (* 1 = 0.276606 loss)
I0513 02:19:27.985574 27330 sgd_solver.cpp:106] Iteration 22800, lr = 0.0001
I0513 02:24:27.076278 27330 solver.cpp:337] Iteration 22855, Testing net (#0)
I0513 02:24:27.076664 27330 net.cpp:685] Ignoring source layer ratemap
I0513 02:24:27.076678 27330 net.cpp:685] Ignoring source layer amsFeatures
I0513 02:27:19.469230 27330 solver.cpp:404]     Test net output #0: loss = 0.596415 (* 1 = 0.596415 loss)
I0513 02:31:32.502653 27330 solver.cpp:228] Iteration 22900, loss = 0.408495
I0513 02:31:32.503036 27330 solver.cpp:244]     Train net output #0: loss = 0.408495 (* 1 = 0.408495 loss)
I0513 02:31:32.503057 27330 sgd_solver.cpp:106] Iteration 22900, lr = 0.0001
I0513 02:41:16.008352 27330 solver.cpp:228] Iteration 23000, loss = 0.435646
I0513 02:41:16.008671 27330 solver.cpp:244]     Train net output #0: loss = 0.435646 (* 1 = 0.435646 loss)
I0513 02:41:16.008683 27330 sgd_solver.cpp:106] Iteration 23000, lr = 0.0001
I0513 02:51:04.073402 27330 solver.cpp:228] Iteration 23100, loss = 0.299614
I0513 02:51:04.073823 27330 solver.cpp:244]     Train net output #0: loss = 0.299614 (* 1 = 0.299614 loss)
I0513 02:51:04.073837 27330 sgd_solver.cpp:106] Iteration 23100, lr = 0.0001
I0513 03:00:30.690665 27330 solver.cpp:228] Iteration 23200, loss = 0.56991
I0513 03:00:30.691048 27330 solver.cpp:244]     Train net output #0: loss = 0.56991 (* 1 = 0.56991 loss)
I0513 03:00:30.691068 27330 sgd_solver.cpp:106] Iteration 23200, lr = 0.0001
I0513 03:10:18.451021 27330 solver.cpp:228] Iteration 23300, loss = 0.549546
I0513 03:10:18.451428 27330 solver.cpp:244]     Train net output #0: loss = 0.549546 (* 1 = 0.549546 loss)
I0513 03:10:18.451468 27330 sgd_solver.cpp:106] Iteration 23300, lr = 0.0001
I0513 03:19:51.553834 27330 solver.cpp:228] Iteration 23400, loss = 0.504559
I0513 03:19:51.554183 27330 solver.cpp:244]     Train net output #0: loss = 0.504559 (* 1 = 0.504559 loss)
I0513 03:19:51.554198 27330 sgd_solver.cpp:106] Iteration 23400, lr = 0.0001
I0513 03:29:28.130426 27330 solver.cpp:228] Iteration 23500, loss = 0.424265
I0513 03:29:28.130727 27330 solver.cpp:244]     Train net output #0: loss = 0.424266 (* 1 = 0.424266 loss)
I0513 03:29:28.130740 27330 sgd_solver.cpp:106] Iteration 23500, lr = 0.0001
I0513 03:38:49.243067 27330 solver.cpp:228] Iteration 23600, loss = 0.387006
I0513 03:38:49.243469 27330 solver.cpp:244]     Train net output #0: loss = 0.387006 (* 1 = 0.387006 loss)
I0513 03:38:49.243497 27330 sgd_solver.cpp:106] Iteration 23600, lr = 0.0001
I0513 03:48:02.150362 27330 solver.cpp:228] Iteration 23700, loss = 0.562859
I0513 03:48:02.150746 27330 solver.cpp:244]     Train net output #0: loss = 0.562859 (* 1 = 0.562859 loss)
I0513 03:48:02.150759 27330 sgd_solver.cpp:106] Iteration 23700, lr = 0.0001
I0513 03:57:27.509711 27330 solver.cpp:228] Iteration 23800, loss = 0.645997
I0513 03:57:27.510099 27330 solver.cpp:244]     Train net output #0: loss = 0.645997 (* 1 = 0.645997 loss)
I0513 03:57:27.510128 27330 sgd_solver.cpp:106] Iteration 23800, lr = 0.0001
I0513 04:06:19.834970 27330 solver.cpp:228] Iteration 23900, loss = 0.305447
I0513 04:06:19.835449 27330 solver.cpp:244]     Train net output #0: loss = 0.305447 (* 1 = 0.305447 loss)
I0513 04:06:19.835470 27330 sgd_solver.cpp:106] Iteration 23900, lr = 0.0001
I0513 04:15:31.740789 27330 solver.cpp:228] Iteration 24000, loss = 0.313449
I0513 04:15:31.741304 27330 solver.cpp:244]     Train net output #0: loss = 0.313449 (* 1 = 0.313449 loss)
I0513 04:15:31.741328 27330 sgd_solver.cpp:106] Iteration 24000, lr = 0.0001
I0513 04:24:56.885495 27330 solver.cpp:228] Iteration 24100, loss = 0.404042
I0513 04:24:56.885897 27330 solver.cpp:244]     Train net output #0: loss = 0.404042 (* 1 = 0.404042 loss)
I0513 04:24:56.885915 27330 sgd_solver.cpp:106] Iteration 24100, lr = 0.0001
I0513 04:34:21.328446 27330 solver.cpp:228] Iteration 24200, loss = 0.329242
I0513 04:34:21.328821 27330 solver.cpp:244]     Train net output #0: loss = 0.329242 (* 1 = 0.329242 loss)
I0513 04:34:21.328835 27330 sgd_solver.cpp:106] Iteration 24200, lr = 0.0001
I0513 04:43:09.783058 27330 solver.cpp:228] Iteration 24300, loss = 0.3747
I0513 04:43:09.783459 27330 solver.cpp:244]     Train net output #0: loss = 0.3747 (* 1 = 0.3747 loss)
I0513 04:43:09.783475 27330 sgd_solver.cpp:106] Iteration 24300, lr = 0.0001
I0513 04:52:11.994021 27330 solver.cpp:228] Iteration 24400, loss = 0.536872
I0513 04:52:11.994407 27330 solver.cpp:244]     Train net output #0: loss = 0.536872 (* 1 = 0.536872 loss)
I0513 04:52:11.994423 27330 sgd_solver.cpp:106] Iteration 24400, lr = 0.0001
I0513 05:01:50.129861 27330 solver.cpp:228] Iteration 24500, loss = 0.476637
I0513 05:01:50.130283 27330 solver.cpp:244]     Train net output #0: loss = 0.476637 (* 1 = 0.476637 loss)
I0513 05:01:50.130316 27330 sgd_solver.cpp:106] Iteration 24500, lr = 0.0001
I0513 05:11:24.367787 27330 solver.cpp:228] Iteration 24600, loss = 0.227433
I0513 05:11:24.368193 27330 solver.cpp:244]     Train net output #0: loss = 0.227433 (* 1 = 0.227433 loss)
I0513 05:11:24.368208 27330 sgd_solver.cpp:106] Iteration 24600, lr = 0.0001
I0513 05:20:51.525879 27330 solver.cpp:228] Iteration 24700, loss = 0.837501
I0513 05:20:51.526228 27330 solver.cpp:244]     Train net output #0: loss = 0.837501 (* 1 = 0.837501 loss)
I0513 05:20:51.526242 27330 sgd_solver.cpp:106] Iteration 24700, lr = 0.0001
I0513 05:29:52.230499 27330 solver.cpp:228] Iteration 24800, loss = 0.735543
I0513 05:29:52.230901 27330 solver.cpp:244]     Train net output #0: loss = 0.735543 (* 1 = 0.735543 loss)
I0513 05:29:52.230913 27330 sgd_solver.cpp:106] Iteration 24800, lr = 0.0001
I0513 05:39:30.670052 27330 solver.cpp:228] Iteration 24900, loss = 0.702349
I0513 05:39:30.670481 27330 solver.cpp:244]     Train net output #0: loss = 0.702349 (* 1 = 0.702349 loss)
I0513 05:39:30.670497 27330 sgd_solver.cpp:106] Iteration 24900, lr = 0.0001
I0513 05:48:57.945993 27330 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_25000.caffemodel
I0513 05:48:58.131865 27330 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_25000.solverstate
I0513 05:49:03.748878 27330 solver.cpp:228] Iteration 25000, loss = 0.510811
I0513 05:49:03.748942 27330 solver.cpp:244]     Train net output #0: loss = 0.510811 (* 1 = 0.510811 loss)
I0513 05:49:03.748955 27330 sgd_solver.cpp:106] Iteration 25000, lr = 0.0001
I0513 05:58:04.847250 27330 solver.cpp:228] Iteration 25100, loss = 0.662733
I0513 05:58:04.847718 27330 solver.cpp:244]     Train net output #0: loss = 0.662733 (* 1 = 0.662733 loss)
I0513 05:58:04.847743 27330 sgd_solver.cpp:106] Iteration 25100, lr = 0.0001
I0513 06:07:35.295755 27330 solver.cpp:228] Iteration 25200, loss = 0.646091
I0513 06:07:35.296221 27330 solver.cpp:244]     Train net output #0: loss = 0.646091 (* 1 = 0.646091 loss)
I0513 06:07:35.296246 27330 sgd_solver.cpp:106] Iteration 25200, lr = 0.0001
I0513 06:16:30.718355 27330 solver.cpp:228] Iteration 25300, loss = 0.522904
I0513 06:16:30.718762 27330 solver.cpp:244]     Train net output #0: loss = 0.522904 (* 1 = 0.522904 loss)
I0513 06:16:30.718787 27330 sgd_solver.cpp:106] Iteration 25300, lr = 0.0001
I0513 06:25:02.268863 27330 solver.cpp:228] Iteration 25400, loss = 0.416067
I0513 06:25:02.269273 27330 solver.cpp:244]     Train net output #0: loss = 0.416067 (* 1 = 0.416067 loss)
I0513 06:25:02.269292 27330 sgd_solver.cpp:106] Iteration 25400, lr = 0.0001
I0513 06:33:25.978338 27330 solver.cpp:228] Iteration 25500, loss = 0.408186
I0513 06:33:25.978762 27330 solver.cpp:244]     Train net output #0: loss = 0.408186 (* 1 = 0.408186 loss)
I0513 06:33:25.978785 27330 sgd_solver.cpp:106] Iteration 25500, lr = 0.0001
I0513 06:42:05.507905 27330 solver.cpp:228] Iteration 25600, loss = 0.510907
I0513 06:42:05.508340 27330 solver.cpp:244]     Train net output #0: loss = 0.510907 (* 1 = 0.510907 loss)
I0513 06:42:05.508365 27330 sgd_solver.cpp:106] Iteration 25600, lr = 0.0001
I0513 06:50:41.695368 27330 solver.cpp:228] Iteration 25700, loss = 0.569416
I0513 06:50:41.695822 27330 solver.cpp:244]     Train net output #0: loss = 0.569416 (* 1 = 0.569416 loss)
I0513 06:50:41.695853 27330 sgd_solver.cpp:106] Iteration 25700, lr = 0.0001
I0513 06:59:05.104697 27330 solver.cpp:228] Iteration 25800, loss = 0.291133
I0513 06:59:05.105155 27330 solver.cpp:244]     Train net output #0: loss = 0.291133 (* 1 = 0.291133 loss)
I0513 06:59:05.105180 27330 sgd_solver.cpp:106] Iteration 25800, lr = 0.0001
I0513 07:07:25.184715 27330 solver.cpp:228] Iteration 25900, loss = 0.568736
I0513 07:07:25.185128 27330 solver.cpp:244]     Train net output #0: loss = 0.568737 (* 1 = 0.568737 loss)
I0513 07:07:25.185153 27330 sgd_solver.cpp:106] Iteration 25900, lr = 0.0001
I0513 07:16:00.876716 27330 solver.cpp:228] Iteration 26000, loss = 0.217628
I0513 07:16:00.877147 27330 solver.cpp:244]     Train net output #0: loss = 0.217628 (* 1 = 0.217628 loss)
I0513 07:16:00.877163 27330 sgd_solver.cpp:106] Iteration 26000, lr = 0.0001
I0513 07:24:27.110596 27330 solver.cpp:228] Iteration 26100, loss = 0.358016
I0513 07:24:27.111062 27330 solver.cpp:244]     Train net output #0: loss = 0.358016 (* 1 = 0.358016 loss)
I0513 07:24:27.111091 27330 sgd_solver.cpp:106] Iteration 26100, lr = 0.0001
I0513 07:26:08.517244 27330 solver.cpp:337] Iteration 26120, Testing net (#0)
I0513 07:26:08.517648 27330 net.cpp:685] Ignoring source layer ratemap
I0513 07:26:08.517666 27330 net.cpp:685] Ignoring source layer amsFeatures
I0513 07:29:00.350211 27330 solver.cpp:404]     Test net output #0: loss = 0.588989 (* 1 = 0.588989 loss)
I0513 07:35:49.966265 27330 solver.cpp:228] Iteration 26200, loss = 0.356236
I0513 07:35:49.966629 27330 solver.cpp:244]     Train net output #0: loss = 0.356236 (* 1 = 0.356236 loss)
I0513 07:35:49.966656 27330 sgd_solver.cpp:106] Iteration 26200, lr = 0.0001
I0513 07:44:15.476208 27330 solver.cpp:228] Iteration 26300, loss = 0.377191
I0513 07:44:15.476599 27330 solver.cpp:244]     Train net output #0: loss = 0.377191 (* 1 = 0.377191 loss)
I0513 07:44:15.476624 27330 sgd_solver.cpp:106] Iteration 26300, lr = 0.0001
I0513 07:52:35.934551 27330 solver.cpp:228] Iteration 26400, loss = 0.5992
I0513 07:52:35.934953 27330 solver.cpp:244]     Train net output #0: loss = 0.5992 (* 1 = 0.5992 loss)
I0513 07:52:35.934978 27330 sgd_solver.cpp:106] Iteration 26400, lr = 0.0001
I0513 08:01:01.980628 27330 solver.cpp:228] Iteration 26500, loss = 0.495713
I0513 08:01:01.981071 27330 solver.cpp:244]     Train net output #0: loss = 0.495713 (* 1 = 0.495713 loss)
I0513 08:01:01.981086 27330 sgd_solver.cpp:106] Iteration 26500, lr = 0.0001
I0513 08:09:16.143028 27330 solver.cpp:228] Iteration 26600, loss = 0.316342
I0513 08:09:16.143425 27330 solver.cpp:244]     Train net output #0: loss = 0.316342 (* 1 = 0.316342 loss)
I0513 08:09:16.143450 27330 sgd_solver.cpp:106] Iteration 26600, lr = 0.0001
I0513 08:17:47.640987 27330 solver.cpp:228] Iteration 26700, loss = 0.497488
I0513 08:17:47.641402 27330 solver.cpp:244]     Train net output #0: loss = 0.497488 (* 1 = 0.497488 loss)
I0513 08:17:47.641427 27330 sgd_solver.cpp:106] Iteration 26700, lr = 0.0001
I0513 08:26:18.638470 27330 solver.cpp:228] Iteration 26800, loss = 0.286713
I0513 08:26:18.638912 27330 solver.cpp:244]     Train net output #0: loss = 0.286713 (* 1 = 0.286713 loss)
I0513 08:26:18.638937 27330 sgd_solver.cpp:106] Iteration 26800, lr = 0.0001
I0513 08:34:47.960151 27330 solver.cpp:228] Iteration 26900, loss = 0.627722
I0513 08:34:47.960567 27330 solver.cpp:244]     Train net output #0: loss = 0.627722 (* 1 = 0.627722 loss)
I0513 08:34:47.960592 27330 sgd_solver.cpp:106] Iteration 26900, lr = 0.0001
I0513 08:43:15.128195 27330 solver.cpp:228] Iteration 27000, loss = 0.452976
I0513 08:43:15.128650 27330 solver.cpp:244]     Train net output #0: loss = 0.452976 (* 1 = 0.452976 loss)
I0513 08:43:15.128671 27330 sgd_solver.cpp:106] Iteration 27000, lr = 0.0001
I0513 08:51:39.166441 27330 solver.cpp:228] Iteration 27100, loss = 0.342456
I0513 08:51:39.166893 27330 solver.cpp:244]     Train net output #0: loss = 0.342456 (* 1 = 0.342456 loss)
I0513 08:51:39.166914 27330 sgd_solver.cpp:106] Iteration 27100, lr = 0.0001
I0513 08:59:56.820624 27330 solver.cpp:228] Iteration 27200, loss = 0.22881
I0513 08:59:56.821081 27330 solver.cpp:244]     Train net output #0: loss = 0.22881 (* 1 = 0.22881 loss)
I0513 08:59:56.821105 27330 sgd_solver.cpp:106] Iteration 27200, lr = 0.0001
I0513 09:08:14.121872 27330 solver.cpp:228] Iteration 27300, loss = 0.270654
I0513 09:08:14.122323 27330 solver.cpp:244]     Train net output #0: loss = 0.270654 (* 1 = 0.270654 loss)
I0513 09:08:14.122349 27330 sgd_solver.cpp:106] Iteration 27300, lr = 0.0001
I0513 09:16:42.497948 27330 solver.cpp:228] Iteration 27400, loss = 0.519546
I0513 09:16:42.498368 27330 solver.cpp:244]     Train net output #0: loss = 0.519546 (* 1 = 0.519546 loss)
I0513 09:16:42.498379 27330 sgd_solver.cpp:106] Iteration 27400, lr = 0.0001
I0513 09:24:48.742954 27330 solver.cpp:228] Iteration 27500, loss = 0.627985
I0513 09:24:48.747239 27330 solver.cpp:244]     Train net output #0: loss = 0.627985 (* 1 = 0.627985 loss)
I0513 09:24:48.747268 27330 sgd_solver.cpp:106] Iteration 27500, lr = 0.0001
I0513 09:32:58.848549 27330 solver.cpp:228] Iteration 27600, loss = 0.246687
I0513 09:32:58.849038 27330 solver.cpp:244]     Train net output #0: loss = 0.246687 (* 1 = 0.246687 loss)
I0513 09:32:58.849062 27330 sgd_solver.cpp:106] Iteration 27600, lr = 0.0001
I0513 09:41:32.026417 27330 solver.cpp:228] Iteration 27700, loss = 0.312921
I0513 09:41:32.026824 27330 solver.cpp:244]     Train net output #0: loss = 0.312921 (* 1 = 0.312921 loss)
I0513 09:41:32.026840 27330 sgd_solver.cpp:106] Iteration 27700, lr = 0.0001
I0513 09:49:48.717928 27330 solver.cpp:228] Iteration 27800, loss = 0.896185
I0513 09:49:48.718474 27330 solver.cpp:244]     Train net output #0: loss = 0.896185 (* 1 = 0.896185 loss)
I0513 09:49:48.718497 27330 sgd_solver.cpp:106] Iteration 27800, lr = 0.0001
I0513 09:58:18.811375 27330 solver.cpp:228] Iteration 27900, loss = 0.241968
I0513 09:58:18.811817 27330 solver.cpp:244]     Train net output #0: loss = 0.241968 (* 1 = 0.241968 loss)
I0513 09:58:18.811842 27330 sgd_solver.cpp:106] Iteration 27900, lr = 0.0001
I0513 10:06:44.995105 27330 solver.cpp:228] Iteration 28000, loss = 0.582363
I0513 10:06:44.995496 27330 solver.cpp:244]     Train net output #0: loss = 0.582363 (* 1 = 0.582363 loss)
I0513 10:06:44.995510 27330 sgd_solver.cpp:106] Iteration 28000, lr = 0.0001
I0513 10:15:11.071838 27330 solver.cpp:228] Iteration 28100, loss = 0.457631
I0513 10:15:11.072165 27330 solver.cpp:244]     Train net output #0: loss = 0.457631 (* 1 = 0.457631 loss)
I0513 10:15:11.072190 27330 sgd_solver.cpp:106] Iteration 28100, lr = 0.0001
I0513 10:23:55.044116 27330 solver.cpp:228] Iteration 28200, loss = 0.40942
I0513 10:23:55.044533 27330 solver.cpp:244]     Train net output #0: loss = 0.40942 (* 1 = 0.40942 loss)
I0513 10:23:55.044549 27330 sgd_solver.cpp:106] Iteration 28200, lr = 0.0001
I0513 10:32:49.711575 27330 solver.cpp:228] Iteration 28300, loss = 0.400919
I0513 10:32:49.712008 27330 solver.cpp:244]     Train net output #0: loss = 0.400919 (* 1 = 0.400919 loss)
I0513 10:32:49.712033 27330 sgd_solver.cpp:106] Iteration 28300, lr = 0.0001
I0513 10:41:23.771832 27330 solver.cpp:228] Iteration 28400, loss = 0.393227
I0513 10:41:23.772223 27330 solver.cpp:244]     Train net output #0: loss = 0.393227 (* 1 = 0.393227 loss)
I0513 10:41:23.772255 27330 sgd_solver.cpp:106] Iteration 28400, lr = 0.0001
I0513 10:50:23.918926 27330 solver.cpp:228] Iteration 28500, loss = 0.218932
I0513 10:50:23.919317 27330 solver.cpp:244]     Train net output #0: loss = 0.218932 (* 1 = 0.218932 loss)
I0513 10:50:23.919330 27330 sgd_solver.cpp:106] Iteration 28500, lr = 0.0001
I0513 10:59:05.783887 27330 solver.cpp:228] Iteration 28600, loss = 0.602394
I0513 10:59:05.784328 27330 solver.cpp:244]     Train net output #0: loss = 0.602395 (* 1 = 0.602395 loss)
I0513 10:59:05.784353 27330 sgd_solver.cpp:106] Iteration 28600, lr = 0.0001
I0513 11:08:08.290825 27330 solver.cpp:228] Iteration 28700, loss = 0.390263
I0513 11:08:08.291303 27330 solver.cpp:244]     Train net output #0: loss = 0.390263 (* 1 = 0.390263 loss)
I0513 11:08:08.291327 27330 sgd_solver.cpp:106] Iteration 28700, lr = 0.0001
I0513 11:17:17.509584 27330 solver.cpp:228] Iteration 28800, loss = 0.413769
I0513 11:17:17.510051 27330 solver.cpp:244]     Train net output #0: loss = 0.413769 (* 1 = 0.413769 loss)
I0513 11:17:17.510076 27330 sgd_solver.cpp:106] Iteration 28800, lr = 0.0001
I0513 11:25:47.006039 27330 solver.cpp:228] Iteration 28900, loss = 0.196725
I0513 11:25:47.006466 27330 solver.cpp:244]     Train net output #0: loss = 0.196725 (* 1 = 0.196725 loss)
I0513 11:25:47.006487 27330 sgd_solver.cpp:106] Iteration 28900, lr = 0.0001
I0513 11:34:48.051378 27330 solver.cpp:228] Iteration 29000, loss = 0.230948
I0513 11:34:48.051841 27330 solver.cpp:244]     Train net output #0: loss = 0.230948 (* 1 = 0.230948 loss)
I0513 11:34:48.051867 27330 sgd_solver.cpp:106] Iteration 29000, lr = 0.0001
I0513 11:44:09.587240 27330 solver.cpp:228] Iteration 29100, loss = 0.204168
I0513 11:44:09.587746 27330 solver.cpp:244]     Train net output #0: loss = 0.204168 (* 1 = 0.204168 loss)
I0513 11:44:09.587770 27330 sgd_solver.cpp:106] Iteration 29100, lr = 0.0001
I0513 11:52:35.175354 27330 solver.cpp:228] Iteration 29200, loss = 0.295158
I0513 11:52:35.175833 27330 solver.cpp:244]     Train net output #0: loss = 0.295158 (* 1 = 0.295158 loss)
I0513 11:52:35.175858 27330 sgd_solver.cpp:106] Iteration 29200, lr = 0.0001
I0513 12:00:54.980700 27330 solver.cpp:228] Iteration 29300, loss = 0.397004
I0513 12:00:54.981125 27330 solver.cpp:244]     Train net output #0: loss = 0.397004 (* 1 = 0.397004 loss)
I0513 12:00:54.981150 27330 sgd_solver.cpp:106] Iteration 29300, lr = 0.0001
I0513 12:08:21.299017 27330 solver.cpp:337] Iteration 29385, Testing net (#0)
I0513 12:08:21.299432 27330 net.cpp:685] Ignoring source layer ratemap
I0513 12:08:21.299449 27330 net.cpp:685] Ignoring source layer amsFeatures
I0513 12:11:12.759757 27330 solver.cpp:404]     Test net output #0: loss = 0.623441 (* 1 = 0.623441 loss)
I0513 12:12:32.753525 27330 solver.cpp:228] Iteration 29400, loss = 0.330548
I0513 12:12:32.753993 27330 solver.cpp:244]     Train net output #0: loss = 0.330548 (* 1 = 0.330548 loss)
I0513 12:12:32.754012 27330 sgd_solver.cpp:106] Iteration 29400, lr = 0.0001
I0513 12:20:43.209991 27330 solver.cpp:228] Iteration 29500, loss = 0.247689
I0513 12:20:43.210422 27330 solver.cpp:244]     Train net output #0: loss = 0.247689 (* 1 = 0.247689 loss)
I0513 12:20:43.210445 27330 sgd_solver.cpp:106] Iteration 29500, lr = 0.0001
I0513 12:29:25.364255 27330 solver.cpp:228] Iteration 29600, loss = 0.641441
I0513 12:29:25.364717 27330 solver.cpp:244]     Train net output #0: loss = 0.641441 (* 1 = 0.641441 loss)
I0513 12:29:25.364742 27330 sgd_solver.cpp:106] Iteration 29600, lr = 0.0001
I0513 12:37:59.813014 27330 solver.cpp:228] Iteration 29700, loss = 0.3156
I0513 12:37:59.813402 27330 solver.cpp:244]     Train net output #0: loss = 0.3156 (* 1 = 0.3156 loss)
I0513 12:37:59.813427 27330 sgd_solver.cpp:106] Iteration 29700, lr = 0.0001
I0513 12:46:34.134318 27330 solver.cpp:228] Iteration 29800, loss = 0.414612
I0513 12:46:34.134709 27330 solver.cpp:244]     Train net output #0: loss = 0.414612 (* 1 = 0.414612 loss)
I0513 12:46:34.134742 27330 sgd_solver.cpp:106] Iteration 29800, lr = 0.0001
I0513 12:54:25.777225 27330 solver.cpp:228] Iteration 29900, loss = 0.267
I0513 12:54:25.777645 27330 solver.cpp:244]     Train net output #0: loss = 0.267 (* 1 = 0.267 loss)
I0513 12:54:25.777670 27330 sgd_solver.cpp:106] Iteration 29900, lr = 0.0001
I0513 13:02:53.651368 27330 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_30000.caffemodel
I0513 13:02:53.838579 27330 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_30000.solverstate
I0513 13:02:58.872933 27330 solver.cpp:228] Iteration 30000, loss = 0.214403
I0513 13:02:58.872984 27330 solver.cpp:244]     Train net output #0: loss = 0.214403 (* 1 = 0.214403 loss)
I0513 13:02:58.872997 27330 sgd_solver.cpp:106] Iteration 30000, lr = 1e-05
I0513 13:11:15.162009 27330 solver.cpp:228] Iteration 30100, loss = 0.38774
I0513 13:11:15.162448 27330 solver.cpp:244]     Train net output #0: loss = 0.38774 (* 1 = 0.38774 loss)
I0513 13:11:15.162473 27330 sgd_solver.cpp:106] Iteration 30100, lr = 1e-05
I0513 13:19:44.489011 27330 solver.cpp:228] Iteration 30200, loss = 0.208906
I0513 13:19:44.489456 27330 solver.cpp:244]     Train net output #0: loss = 0.208906 (* 1 = 0.208906 loss)
I0513 13:19:44.489481 27330 sgd_solver.cpp:106] Iteration 30200, lr = 1e-05
I0513 13:28:07.080102 27330 solver.cpp:228] Iteration 30300, loss = 0.325796
I0513 13:28:07.080534 27330 solver.cpp:244]     Train net output #0: loss = 0.325796 (* 1 = 0.325796 loss)
I0513 13:28:07.080559 27330 sgd_solver.cpp:106] Iteration 30300, lr = 1e-05
I0513 13:36:24.417722 27330 solver.cpp:228] Iteration 30400, loss = 0.257591
I0513 13:36:24.418216 27330 solver.cpp:244]     Train net output #0: loss = 0.257591 (* 1 = 0.257591 loss)
I0513 13:36:24.418237 27330 sgd_solver.cpp:106] Iteration 30400, lr = 1e-05
I0513 13:44:47.565233 27330 solver.cpp:228] Iteration 30500, loss = 0.447816
I0513 13:44:47.565670 27330 solver.cpp:244]     Train net output #0: loss = 0.447816 (* 1 = 0.447816 loss)
I0513 13:44:47.565695 27330 sgd_solver.cpp:106] Iteration 30500, lr = 1e-05
I0513 13:53:04.210768 27330 solver.cpp:228] Iteration 30600, loss = 0.252249
I0513 13:53:04.211202 27330 solver.cpp:244]     Train net output #0: loss = 0.252249 (* 1 = 0.252249 loss)
I0513 13:53:04.211227 27330 sgd_solver.cpp:106] Iteration 30600, lr = 1e-05
I0513 14:01:22.944500 27330 solver.cpp:228] Iteration 30700, loss = 0.202861
I0513 14:01:22.944917 27330 solver.cpp:244]     Train net output #0: loss = 0.202861 (* 1 = 0.202861 loss)
I0513 14:01:22.944942 27330 sgd_solver.cpp:106] Iteration 30700, lr = 1e-05
I0513 14:09:44.464929 27330 solver.cpp:228] Iteration 30800, loss = 0.269262
I0513 14:09:44.465445 27330 solver.cpp:244]     Train net output #0: loss = 0.269262 (* 1 = 0.269262 loss)
I0513 14:09:44.465476 27330 sgd_solver.cpp:106] Iteration 30800, lr = 1e-05
I0513 14:18:02.686987 27330 solver.cpp:228] Iteration 30900, loss = 0.159841
I0513 14:18:02.687417 27330 solver.cpp:244]     Train net output #0: loss = 0.159841 (* 1 = 0.159841 loss)
I0513 14:18:02.687436 27330 sgd_solver.cpp:106] Iteration 30900, lr = 1e-05
I0513 14:26:24.273589 27330 solver.cpp:228] Iteration 31000, loss = 0.241497
I0513 14:26:24.274045 27330 solver.cpp:244]     Train net output #0: loss = 0.241498 (* 1 = 0.241498 loss)
I0513 14:26:24.274066 27330 sgd_solver.cpp:106] Iteration 31000, lr = 1e-05
I0513 14:34:43.478859 27330 solver.cpp:228] Iteration 31100, loss = 0.381126
I0513 14:34:43.479274 27330 solver.cpp:244]     Train net output #0: loss = 0.381126 (* 1 = 0.381126 loss)
I0513 14:34:43.479295 27330 sgd_solver.cpp:106] Iteration 31100, lr = 1e-05
I0513 14:43:19.177086 27330 solver.cpp:228] Iteration 31200, loss = 0.293757
I0513 14:43:19.177510 27330 solver.cpp:244]     Train net output #0: loss = 0.293757 (* 1 = 0.293757 loss)
I0513 14:43:19.177534 27330 sgd_solver.cpp:106] Iteration 31200, lr = 1e-05
I0513 14:51:50.891315 27330 solver.cpp:228] Iteration 31300, loss = 0.278824
I0513 14:51:50.891737 27330 solver.cpp:244]     Train net output #0: loss = 0.278824 (* 1 = 0.278824 loss)
I0513 14:51:50.891762 27330 sgd_solver.cpp:106] Iteration 31300, lr = 1e-05
I0513 14:59:56.639338 27330 solver.cpp:228] Iteration 31400, loss = 0.151974
I0513 14:59:56.639742 27330 solver.cpp:244]     Train net output #0: loss = 0.151974 (* 1 = 0.151974 loss)
I0513 14:59:56.639767 27330 sgd_solver.cpp:106] Iteration 31400, lr = 1e-05
I0513 15:08:30.286768 27330 solver.cpp:228] Iteration 31500, loss = 0.667239
I0513 15:08:30.287214 27330 solver.cpp:244]     Train net output #0: loss = 0.667239 (* 1 = 0.667239 loss)
I0513 15:08:30.287235 27330 sgd_solver.cpp:106] Iteration 31500, lr = 1e-05
I0513 15:16:48.856832 27330 solver.cpp:228] Iteration 31600, loss = 0.112262
I0513 15:16:48.857267 27330 solver.cpp:244]     Train net output #0: loss = 0.112262 (* 1 = 0.112262 loss)
I0513 15:16:48.857301 27330 sgd_solver.cpp:106] Iteration 31600, lr = 1e-05
I0513 15:25:19.350564 27330 solver.cpp:228] Iteration 31700, loss = 0.316177
I0513 15:25:19.350986 27330 solver.cpp:244]     Train net output #0: loss = 0.316177 (* 1 = 0.316177 loss)
I0513 15:25:19.351012 27330 sgd_solver.cpp:106] Iteration 31700, lr = 1e-05
I0513 15:33:48.309437 27330 solver.cpp:228] Iteration 31800, loss = 0.430315
I0513 15:33:48.309922 27330 solver.cpp:244]     Train net output #0: loss = 0.430315 (* 1 = 0.430315 loss)
I0513 15:33:48.309950 27330 sgd_solver.cpp:106] Iteration 31800, lr = 1e-05
I0513 15:42:17.109244 27330 solver.cpp:228] Iteration 31900, loss = 0.364693
I0513 15:42:17.109629 27330 solver.cpp:244]     Train net output #0: loss = 0.364693 (* 1 = 0.364693 loss)
I0513 15:42:17.109642 27330 sgd_solver.cpp:106] Iteration 31900, lr = 1e-05
I0513 15:50:47.198293 27330 solver.cpp:228] Iteration 32000, loss = 0.211984
I0513 15:50:47.198712 27330 solver.cpp:244]     Train net output #0: loss = 0.211984 (* 1 = 0.211984 loss)
I0513 15:50:47.198736 27330 sgd_solver.cpp:106] Iteration 32000, lr = 1e-05
I0513 15:59:13.163636 27330 solver.cpp:228] Iteration 32100, loss = 0.345456
I0513 15:59:13.164073 27330 solver.cpp:244]     Train net output #0: loss = 0.345456 (* 1 = 0.345456 loss)
I0513 15:59:13.164098 27330 sgd_solver.cpp:106] Iteration 32100, lr = 1e-05
I0513 16:07:48.273377 27330 solver.cpp:228] Iteration 32200, loss = 0.212308
I0513 16:07:48.273872 27330 solver.cpp:244]     Train net output #0: loss = 0.212308 (* 1 = 0.212308 loss)
I0513 16:07:48.273893 27330 sgd_solver.cpp:106] Iteration 32200, lr = 1e-05
I0513 16:16:20.884572 27330 solver.cpp:228] Iteration 32300, loss = 0.449844
I0513 16:16:20.884984 27330 solver.cpp:244]     Train net output #0: loss = 0.449844 (* 1 = 0.449844 loss)
I0513 16:16:20.885007 27330 sgd_solver.cpp:106] Iteration 32300, lr = 1e-05
I0513 16:24:46.697441 27330 solver.cpp:228] Iteration 32400, loss = 0.313395
I0513 16:24:46.697914 27330 solver.cpp:244]     Train net output #0: loss = 0.313395 (* 1 = 0.313395 loss)
I0513 16:24:46.697934 27330 sgd_solver.cpp:106] Iteration 32400, lr = 1e-05
I0513 16:33:09.889384 27330 solver.cpp:228] Iteration 32500, loss = 0.219932
I0513 16:33:09.889792 27330 solver.cpp:244]     Train net output #0: loss = 0.219933 (* 1 = 0.219933 loss)
I0513 16:33:09.889821 27330 sgd_solver.cpp:106] Iteration 32500, lr = 1e-05
I0513 16:41:38.413940 27330 solver.cpp:228] Iteration 32600, loss = 0.24395
I0513 16:41:38.414387 27330 solver.cpp:244]     Train net output #0: loss = 0.243951 (* 1 = 0.243951 loss)
I0513 16:41:38.414412 27330 sgd_solver.cpp:106] Iteration 32600, lr = 1e-05
I0513 16:45:45.381585 27330 solver.cpp:337] Iteration 32650, Testing net (#0)
I0513 16:45:45.382004 27330 net.cpp:685] Ignoring source layer ratemap
I0513 16:45:45.382022 27330 net.cpp:685] Ignoring source layer amsFeatures
I0513 16:48:36.788375 27330 solver.cpp:404]     Test net output #0: loss = 0.581006 (* 1 = 0.581006 loss)
I0513 16:52:48.183672 27330 solver.cpp:228] Iteration 32700, loss = 0.418963
I0513 16:52:48.184072 27330 solver.cpp:244]     Train net output #0: loss = 0.418963 (* 1 = 0.418963 loss)
I0513 16:52:48.184097 27330 sgd_solver.cpp:106] Iteration 32700, lr = 1e-05
I0513 17:01:11.905323 27330 solver.cpp:228] Iteration 32800, loss = 0.403985
I0513 17:01:11.905756 27330 solver.cpp:244]     Train net output #0: loss = 0.403986 (* 1 = 0.403986 loss)
I0513 17:01:11.905769 27330 sgd_solver.cpp:106] Iteration 32800, lr = 1e-05
I0513 17:09:28.556174 27330 solver.cpp:228] Iteration 32900, loss = 0.289748
I0513 17:09:28.556624 27330 solver.cpp:244]     Train net output #0: loss = 0.289749 (* 1 = 0.289749 loss)
I0513 17:09:28.556658 27330 sgd_solver.cpp:106] Iteration 32900, lr = 1e-05
I0513 17:17:45.022049 27330 solver.cpp:228] Iteration 33000, loss = 0.332958
I0513 17:17:45.022497 27330 solver.cpp:244]     Train net output #0: loss = 0.332958 (* 1 = 0.332958 loss)
I0513 17:17:45.022517 27330 sgd_solver.cpp:106] Iteration 33000, lr = 1e-05
I0513 17:26:07.567188 27330 solver.cpp:228] Iteration 33100, loss = 0.312519
I0513 17:26:07.567658 27330 solver.cpp:244]     Train net output #0: loss = 0.312519 (* 1 = 0.312519 loss)
I0513 17:26:07.567679 27330 sgd_solver.cpp:106] Iteration 33100, lr = 1e-05
I0513 17:34:37.028340 27330 solver.cpp:228] Iteration 33200, loss = 0.232841
I0513 17:34:37.028816 27330 solver.cpp:244]     Train net output #0: loss = 0.232841 (* 1 = 0.232841 loss)
I0513 17:34:37.028841 27330 sgd_solver.cpp:106] Iteration 33200, lr = 1e-05
I0513 17:43:07.678462 27330 solver.cpp:228] Iteration 33300, loss = 0.3125
I0513 17:43:07.678920 27330 solver.cpp:244]     Train net output #0: loss = 0.3125 (* 1 = 0.3125 loss)
I0513 17:43:07.678941 27330 sgd_solver.cpp:106] Iteration 33300, lr = 1e-05
I0513 17:51:41.402109 27330 solver.cpp:228] Iteration 33400, loss = 0.285838
I0513 17:51:41.402575 27330 solver.cpp:244]     Train net output #0: loss = 0.285839 (* 1 = 0.285839 loss)
I0513 17:51:41.402600 27330 sgd_solver.cpp:106] Iteration 33400, lr = 1e-05
I0513 18:00:10.790329 27330 solver.cpp:228] Iteration 33500, loss = 0.424051
I0513 18:00:10.790750 27330 solver.cpp:244]     Train net output #0: loss = 0.424051 (* 1 = 0.424051 loss)
I0513 18:00:10.790773 27330 sgd_solver.cpp:106] Iteration 33500, lr = 1e-05
I0513 18:08:17.356492 27330 solver.cpp:228] Iteration 33600, loss = 0.406209
I0513 18:08:17.356868 27330 solver.cpp:244]     Train net output #0: loss = 0.40621 (* 1 = 0.40621 loss)
I0513 18:08:17.356884 27330 sgd_solver.cpp:106] Iteration 33600, lr = 1e-05
I0513 18:16:50.068087 27330 solver.cpp:228] Iteration 33700, loss = 0.246425
I0513 18:16:50.068493 27330 solver.cpp:244]     Train net output #0: loss = 0.246425 (* 1 = 0.246425 loss)
I0513 18:16:50.068506 27330 sgd_solver.cpp:106] Iteration 33700, lr = 1e-05
I0513 18:24:55.983539 27330 solver.cpp:228] Iteration 33800, loss = 0.240988
I0513 18:24:55.984007 27330 solver.cpp:244]     Train net output #0: loss = 0.240988 (* 1 = 0.240988 loss)
I0513 18:24:55.984028 27330 sgd_solver.cpp:106] Iteration 33800, lr = 1e-05
I0513 18:33:13.859035 27330 solver.cpp:228] Iteration 33900, loss = 0.449376
I0513 18:33:13.859462 27330 solver.cpp:244]     Train net output #0: loss = 0.449376 (* 1 = 0.449376 loss)
I0513 18:33:13.859483 27330 sgd_solver.cpp:106] Iteration 33900, lr = 1e-05
I0513 18:41:36.009130 27330 solver.cpp:228] Iteration 34000, loss = 0.297811
I0513 18:41:36.009573 27330 solver.cpp:244]     Train net output #0: loss = 0.297811 (* 1 = 0.297811 loss)
I0513 18:41:36.009598 27330 sgd_solver.cpp:106] Iteration 34000, lr = 1e-05
I0513 18:50:11.636551 27330 solver.cpp:228] Iteration 34100, loss = 0.518369
I0513 18:50:11.636983 27330 solver.cpp:244]     Train net output #0: loss = 0.518369 (* 1 = 0.518369 loss)
I0513 18:50:11.637006 27330 sgd_solver.cpp:106] Iteration 34100, lr = 1e-05
I0513 18:58:23.323380 27330 solver.cpp:228] Iteration 34200, loss = 0.375019
I0513 18:58:23.323779 27330 solver.cpp:244]     Train net output #0: loss = 0.375019 (* 1 = 0.375019 loss)
I0513 18:58:23.323796 27330 sgd_solver.cpp:106] Iteration 34200, lr = 1e-05
I0513 19:06:32.213299 27330 solver.cpp:228] Iteration 34300, loss = 0.235102
I0513 19:06:32.213752 27330 solver.cpp:244]     Train net output #0: loss = 0.235103 (* 1 = 0.235103 loss)
I0513 19:06:32.213773 27330 sgd_solver.cpp:106] Iteration 34300, lr = 1e-05
I0513 19:15:02.883561 27330 solver.cpp:228] Iteration 34400, loss = 0.22033
I0513 19:15:02.883994 27330 solver.cpp:244]     Train net output #0: loss = 0.22033 (* 1 = 0.22033 loss)
I0513 19:15:02.884019 27330 sgd_solver.cpp:106] Iteration 34400, lr = 1e-05
I0513 19:23:19.865942 27330 solver.cpp:228] Iteration 34500, loss = 0.513457
I0513 19:23:19.866358 27330 solver.cpp:244]     Train net output #0: loss = 0.513458 (* 1 = 0.513458 loss)
I0513 19:23:19.866381 27330 sgd_solver.cpp:106] Iteration 34500, lr = 1e-05
I0513 19:31:33.651614 27330 solver.cpp:228] Iteration 34600, loss = 0.273976
I0513 19:31:33.652073 27330 solver.cpp:244]     Train net output #0: loss = 0.273977 (* 1 = 0.273977 loss)
I0513 19:31:33.652094 27330 sgd_solver.cpp:106] Iteration 34600, lr = 1e-05
I0513 19:39:55.839004 27330 solver.cpp:228] Iteration 34700, loss = 0.417004
I0513 19:39:55.839463 27330 solver.cpp:244]     Train net output #0: loss = 0.417005 (* 1 = 0.417005 loss)
I0513 19:39:55.839488 27330 sgd_solver.cpp:106] Iteration 34700, lr = 1e-05
I0513 19:48:09.104923 27330 solver.cpp:228] Iteration 34800, loss = 0.243219
I0513 19:48:09.105379 27330 solver.cpp:244]     Train net output #0: loss = 0.243219 (* 1 = 0.243219 loss)
I0513 19:48:09.105401 27330 sgd_solver.cpp:106] Iteration 34800, lr = 1e-05
I0513 19:56:36.065845 27330 solver.cpp:228] Iteration 34900, loss = 0.27904
I0513 19:56:36.066254 27330 solver.cpp:244]     Train net output #0: loss = 0.27904 (* 1 = 0.27904 loss)
I0513 19:56:36.066279 27330 sgd_solver.cpp:106] Iteration 34900, lr = 1e-05
I0513 20:05:12.465917 27330 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_35000.caffemodel
I0513 20:05:12.655303 27330 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_35000.solverstate
I0513 20:05:17.542485 27330 solver.cpp:228] Iteration 35000, loss = 0.255857
I0513 20:05:17.542539 27330 solver.cpp:244]     Train net output #0: loss = 0.255857 (* 1 = 0.255857 loss)
I0513 20:05:17.542549 27330 sgd_solver.cpp:106] Iteration 35000, lr = 1e-05
I0513 20:13:32.471914 27330 solver.cpp:228] Iteration 35100, loss = 0.221195
I0513 20:13:32.472298 27330 solver.cpp:244]     Train net output #0: loss = 0.221195 (* 1 = 0.221195 loss)
I0513 20:13:32.472322 27330 sgd_solver.cpp:106] Iteration 35100, lr = 1e-05
I0513 20:21:57.203791 27330 solver.cpp:228] Iteration 35200, loss = 0.67769
I0513 20:21:57.204241 27330 solver.cpp:244]     Train net output #0: loss = 0.67769 (* 1 = 0.67769 loss)
I0513 20:21:57.204265 27330 sgd_solver.cpp:106] Iteration 35200, lr = 1e-05
I0513 20:30:18.565999 27330 solver.cpp:228] Iteration 35300, loss = 0.206698
I0513 20:30:18.566467 27330 solver.cpp:244]     Train net output #0: loss = 0.206698 (* 1 = 0.206698 loss)
I0513 20:30:18.566486 27330 sgd_solver.cpp:106] Iteration 35300, lr = 1e-05
I0513 20:38:34.668772 27330 solver.cpp:228] Iteration 35400, loss = 0.266994
I0513 20:38:34.669190 27330 solver.cpp:244]     Train net output #0: loss = 0.266995 (* 1 = 0.266995 loss)
I0513 20:38:34.669215 27330 sgd_solver.cpp:106] Iteration 35400, lr = 1e-05
I0513 20:47:13.887318 27330 solver.cpp:228] Iteration 35500, loss = 0.485027
I0513 20:47:13.887753 27330 solver.cpp:244]     Train net output #0: loss = 0.485027 (* 1 = 0.485027 loss)
I0513 20:47:13.887778 27330 sgd_solver.cpp:106] Iteration 35500, lr = 1e-05
I0513 20:55:38.793380 27330 solver.cpp:228] Iteration 35600, loss = 0.212769
I0513 20:55:38.793817 27330 solver.cpp:244]     Train net output #0: loss = 0.212769 (* 1 = 0.212769 loss)
I0513 20:55:38.793838 27330 sgd_solver.cpp:106] Iteration 35600, lr = 1e-05
I0513 21:03:58.375033 27330 solver.cpp:228] Iteration 35700, loss = 0.552298
I0513 21:03:58.375435 27330 solver.cpp:244]     Train net output #0: loss = 0.552299 (* 1 = 0.552299 loss)
I0513 21:03:58.375459 27330 sgd_solver.cpp:106] Iteration 35700, lr = 1e-05
I0513 21:12:25.552759 27330 solver.cpp:228] Iteration 35800, loss = 0.228446
I0513 21:12:25.553282 27330 solver.cpp:244]     Train net output #0: loss = 0.228446 (* 1 = 0.228446 loss)
I0513 21:12:25.553305 27330 sgd_solver.cpp:106] Iteration 35800, lr = 1e-05
I0513 21:20:56.354470 27330 solver.cpp:228] Iteration 35900, loss = 0.204181
I0513 21:20:56.354928 27330 solver.cpp:244]     Train net output #0: loss = 0.204182 (* 1 = 0.204182 loss)
I0513 21:20:56.354949 27330 sgd_solver.cpp:106] Iteration 35900, lr = 1e-05
I0513 21:22:09.061322 27330 solver.cpp:337] Iteration 35915, Testing net (#0)
I0513 21:22:09.061708 27330 net.cpp:685] Ignoring source layer ratemap
I0513 21:22:09.061722 27330 net.cpp:685] Ignoring source layer amsFeatures
I0513 21:25:00.365516 27330 solver.cpp:404]     Test net output #0: loss = 0.590952 (* 1 = 0.590952 loss)
I0513 21:32:01.253553 27330 solver.cpp:228] Iteration 36000, loss = 0.548058
I0513 21:32:01.253932 27330 solver.cpp:244]     Train net output #0: loss = 0.548058 (* 1 = 0.548058 loss)
I0513 21:32:01.253957 27330 sgd_solver.cpp:106] Iteration 36000, lr = 1e-05
I0513 21:40:22.534518 27330 solver.cpp:228] Iteration 36100, loss = 0.365092
I0513 21:40:22.534947 27330 solver.cpp:244]     Train net output #0: loss = 0.365093 (* 1 = 0.365093 loss)
I0513 21:40:22.534976 27330 sgd_solver.cpp:106] Iteration 36100, lr = 1e-05
I0513 21:48:45.288640 27330 solver.cpp:228] Iteration 36200, loss = 0.308385
I0513 21:48:45.289000 27330 solver.cpp:244]     Train net output #0: loss = 0.308385 (* 1 = 0.308385 loss)
I0513 21:48:45.289024 27330 sgd_solver.cpp:106] Iteration 36200, lr = 1e-05
I0513 21:57:06.618202 27330 solver.cpp:228] Iteration 36300, loss = 0.202748
I0513 21:57:06.618671 27330 solver.cpp:244]     Train net output #0: loss = 0.202749 (* 1 = 0.202749 loss)
I0513 21:57:06.618700 27330 sgd_solver.cpp:106] Iteration 36300, lr = 1e-05
I0513 22:05:23.790519 27330 solver.cpp:228] Iteration 36400, loss = 0.273786
I0513 22:05:23.791013 27330 solver.cpp:244]     Train net output #0: loss = 0.273786 (* 1 = 0.273786 loss)
I0513 22:05:23.791036 27330 sgd_solver.cpp:106] Iteration 36400, lr = 1e-05
I0513 22:13:49.357080 27330 solver.cpp:228] Iteration 36500, loss = 0.208772
I0513 22:13:49.357527 27330 solver.cpp:244]     Train net output #0: loss = 0.208773 (* 1 = 0.208773 loss)
I0513 22:13:49.357547 27330 sgd_solver.cpp:106] Iteration 36500, lr = 1e-05
I0513 22:22:11.618948 27330 solver.cpp:228] Iteration 36600, loss = 0.287267
I0513 22:22:11.619364 27330 solver.cpp:244]     Train net output #0: loss = 0.287268 (* 1 = 0.287268 loss)
I0513 22:22:11.619388 27330 sgd_solver.cpp:106] Iteration 36600, lr = 1e-05
I0513 22:30:47.174686 27330 solver.cpp:228] Iteration 36700, loss = 0.34576
I0513 22:30:47.175036 27330 solver.cpp:244]     Train net output #0: loss = 0.345761 (* 1 = 0.345761 loss)
I0513 22:30:47.175052 27330 sgd_solver.cpp:106] Iteration 36700, lr = 1e-05
I0513 22:39:02.011546 27330 solver.cpp:228] Iteration 36800, loss = 0.279222
I0513 22:39:02.012042 27330 solver.cpp:244]     Train net output #0: loss = 0.279222 (* 1 = 0.279222 loss)
I0513 22:39:02.012061 27330 sgd_solver.cpp:106] Iteration 36800, lr = 1e-05
I0513 22:47:32.387486 27330 solver.cpp:228] Iteration 36900, loss = 0.22501
I0513 22:47:32.387883 27330 solver.cpp:244]     Train net output #0: loss = 0.225011 (* 1 = 0.225011 loss)
I0513 22:47:32.387908 27330 sgd_solver.cpp:106] Iteration 36900, lr = 1e-05
I0513 22:55:50.166517 27330 solver.cpp:228] Iteration 37000, loss = 0.187888
I0513 22:55:50.166934 27330 solver.cpp:244]     Train net output #0: loss = 0.187889 (* 1 = 0.187889 loss)
I0513 22:55:50.166965 27330 sgd_solver.cpp:106] Iteration 37000, lr = 1e-05
I0513 23:04:06.078027 27330 solver.cpp:228] Iteration 37100, loss = 0.298249
I0513 23:04:06.078429 27330 solver.cpp:244]     Train net output #0: loss = 0.29825 (* 1 = 0.29825 loss)
I0513 23:04:06.078452 27330 sgd_solver.cpp:106] Iteration 37100, lr = 1e-05
I0513 23:12:18.732863 27330 solver.cpp:228] Iteration 37200, loss = 0.427151
I0513 23:12:18.733351 27330 solver.cpp:244]     Train net output #0: loss = 0.427152 (* 1 = 0.427152 loss)
I0513 23:12:18.733376 27330 sgd_solver.cpp:106] Iteration 37200, lr = 1e-05
I0513 23:20:36.973212 27330 solver.cpp:228] Iteration 37300, loss = 0.244669
I0513 23:20:36.973681 27330 solver.cpp:244]     Train net output #0: loss = 0.244669 (* 1 = 0.244669 loss)
I0513 23:20:36.973702 27330 sgd_solver.cpp:106] Iteration 37300, lr = 1e-05
I0513 23:29:07.489197 27330 solver.cpp:228] Iteration 37400, loss = 0.365302
I0513 23:29:07.489641 27330 solver.cpp:244]     Train net output #0: loss = 0.365302 (* 1 = 0.365302 loss)
I0513 23:29:07.489670 27330 sgd_solver.cpp:106] Iteration 37400, lr = 1e-05
I0513 23:37:33.214437 27330 solver.cpp:228] Iteration 37500, loss = 0.240954
I0513 23:37:33.214864 27330 solver.cpp:244]     Train net output #0: loss = 0.240954 (* 1 = 0.240954 loss)
I0513 23:37:33.214887 27330 sgd_solver.cpp:106] Iteration 37500, lr = 1e-05
I0513 23:46:00.711262 27330 solver.cpp:228] Iteration 37600, loss = 0.251927
I0513 23:46:00.711689 27330 solver.cpp:244]     Train net output #0: loss = 0.251927 (* 1 = 0.251927 loss)
I0513 23:46:00.711714 27330 sgd_solver.cpp:106] Iteration 37600, lr = 1e-05
I0513 23:54:16.490854 27330 solver.cpp:228] Iteration 37700, loss = 0.145189
I0513 23:54:16.491322 27330 solver.cpp:244]     Train net output #0: loss = 0.14519 (* 1 = 0.14519 loss)
I0513 23:54:16.491348 27330 sgd_solver.cpp:106] Iteration 37700, lr = 1e-05
I0514 00:02:45.996917 27330 solver.cpp:228] Iteration 37800, loss = 0.3199
I0514 00:02:45.997364 27330 solver.cpp:244]     Train net output #0: loss = 0.319901 (* 1 = 0.319901 loss)
I0514 00:02:45.997388 27330 sgd_solver.cpp:106] Iteration 37800, lr = 1e-05
I0514 00:11:07.795539 27330 solver.cpp:228] Iteration 37900, loss = 0.574496
I0514 00:11:07.795953 27330 solver.cpp:244]     Train net output #0: loss = 0.574496 (* 1 = 0.574496 loss)
I0514 00:11:07.795976 27330 sgd_solver.cpp:106] Iteration 37900, lr = 1e-05
I0514 00:19:34.265967 27330 solver.cpp:228] Iteration 38000, loss = 0.48341
I0514 00:19:34.266428 27330 solver.cpp:244]     Train net output #0: loss = 0.483411 (* 1 = 0.483411 loss)
I0514 00:19:34.266453 27330 sgd_solver.cpp:106] Iteration 38000, lr = 1e-05
I0514 00:27:55.274723 27330 solver.cpp:228] Iteration 38100, loss = 0.23264
I0514 00:27:55.275148 27330 solver.cpp:244]     Train net output #0: loss = 0.232641 (* 1 = 0.232641 loss)
I0514 00:27:55.275192 27330 sgd_solver.cpp:106] Iteration 38100, lr = 1e-05
I0514 00:36:12.926990 27330 solver.cpp:228] Iteration 38200, loss = 0.342135
I0514 00:36:12.927417 27330 solver.cpp:244]     Train net output #0: loss = 0.342136 (* 1 = 0.342136 loss)
I0514 00:36:12.927431 27330 sgd_solver.cpp:106] Iteration 38200, lr = 1e-05
I0514 00:44:59.452963 27330 solver.cpp:228] Iteration 38300, loss = 0.26841
I0514 00:44:59.453356 27330 solver.cpp:244]     Train net output #0: loss = 0.268411 (* 1 = 0.268411 loss)
I0514 00:44:59.453368 27330 sgd_solver.cpp:106] Iteration 38300, lr = 1e-05
I0514 00:53:08.075598 27330 solver.cpp:228] Iteration 38400, loss = 0.543658
I0514 00:53:08.076030 27330 solver.cpp:244]     Train net output #0: loss = 0.543658 (* 1 = 0.543658 loss)
I0514 00:53:08.076056 27330 sgd_solver.cpp:106] Iteration 38400, lr = 1e-05
I0514 01:01:40.245847 27330 solver.cpp:228] Iteration 38500, loss = 0.406921
I0514 01:01:40.246244 27330 solver.cpp:244]     Train net output #0: loss = 0.406922 (* 1 = 0.406922 loss)
I0514 01:01:40.246269 27330 sgd_solver.cpp:106] Iteration 38500, lr = 1e-05
I0514 01:10:15.404000 27330 solver.cpp:228] Iteration 38600, loss = 0.607659
I0514 01:10:15.404492 27330 solver.cpp:244]     Train net output #0: loss = 0.60766 (* 1 = 0.60766 loss)
I0514 01:10:15.404506 27330 sgd_solver.cpp:106] Iteration 38600, lr = 1e-05
I0514 01:18:39.314024 27330 solver.cpp:228] Iteration 38700, loss = 0.197718
I0514 01:18:39.314432 27330 solver.cpp:244]     Train net output #0: loss = 0.197719 (* 1 = 0.197719 loss)
I0514 01:18:39.314456 27330 sgd_solver.cpp:106] Iteration 38700, lr = 1e-05
I0514 01:27:00.960295 27330 solver.cpp:228] Iteration 38800, loss = 0.412401
I0514 01:27:00.960705 27330 solver.cpp:244]     Train net output #0: loss = 0.412402 (* 1 = 0.412402 loss)
I0514 01:27:00.960718 27330 sgd_solver.cpp:106] Iteration 38800, lr = 1e-05
I0514 01:35:19.361318 27330 solver.cpp:228] Iteration 38900, loss = 0.353083
I0514 01:35:19.361719 27330 solver.cpp:244]     Train net output #0: loss = 0.353084 (* 1 = 0.353084 loss)
I0514 01:35:19.361743 27330 sgd_solver.cpp:106] Iteration 38900, lr = 1e-05
I0514 01:43:44.999244 27330 solver.cpp:228] Iteration 39000, loss = 0.265759
I0514 01:43:44.999666 27330 solver.cpp:244]     Train net output #0: loss = 0.26576 (* 1 = 0.26576 loss)
I0514 01:43:44.999691 27330 sgd_solver.cpp:106] Iteration 39000, lr = 1e-05
I0514 01:52:12.901361 27330 solver.cpp:228] Iteration 39100, loss = 0.269901
I0514 01:52:12.901692 27330 solver.cpp:244]     Train net output #0: loss = 0.269902 (* 1 = 0.269902 loss)
I0514 01:52:12.901717 27330 sgd_solver.cpp:106] Iteration 39100, lr = 1e-05
I0514 01:58:43.058912 27330 solver.cpp:337] Iteration 39180, Testing net (#0)
I0514 01:58:43.059341 27330 net.cpp:685] Ignoring source layer ratemap
I0514 01:58:43.059355 27330 net.cpp:685] Ignoring source layer amsFeatures
I0514 02:01:34.339489 27330 solver.cpp:404]     Test net output #0: loss = 0.564764 (* 1 = 0.564764 loss)
I0514 02:03:25.003955 27330 solver.cpp:228] Iteration 39200, loss = 0.342807
I0514 02:03:25.004369 27330 solver.cpp:244]     Train net output #0: loss = 0.342808 (* 1 = 0.342808 loss)
I0514 02:03:25.004392 27330 sgd_solver.cpp:106] Iteration 39200, lr = 1e-05
I0514 02:11:54.506651 27330 solver.cpp:228] Iteration 39300, loss = 0.227876
I0514 02:11:54.507098 27330 solver.cpp:244]     Train net output #0: loss = 0.227877 (* 1 = 0.227877 loss)
I0514 02:11:54.507118 27330 sgd_solver.cpp:106] Iteration 39300, lr = 1e-05
I0514 02:20:16.542420 27330 solver.cpp:228] Iteration 39400, loss = 0.272407
I0514 02:20:16.542845 27330 solver.cpp:244]     Train net output #0: loss = 0.272408 (* 1 = 0.272408 loss)
I0514 02:20:16.542860 27330 sgd_solver.cpp:106] Iteration 39400, lr = 1e-05
I0514 02:28:39.006825 27330 solver.cpp:228] Iteration 39500, loss = 0.277033
I0514 02:28:39.007314 27330 solver.cpp:244]     Train net output #0: loss = 0.277034 (* 1 = 0.277034 loss)
I0514 02:28:39.007339 27330 sgd_solver.cpp:106] Iteration 39500, lr = 1e-05
I0514 02:37:05.119948 27330 solver.cpp:228] Iteration 39600, loss = 0.24499
I0514 02:37:05.120383 27330 solver.cpp:244]     Train net output #0: loss = 0.244991 (* 1 = 0.244991 loss)
I0514 02:37:05.120407 27330 sgd_solver.cpp:106] Iteration 39600, lr = 1e-05
I0514 02:45:18.649910 27330 solver.cpp:228] Iteration 39700, loss = 0.238732
I0514 02:45:18.650332 27330 solver.cpp:244]     Train net output #0: loss = 0.238733 (* 1 = 0.238733 loss)
I0514 02:45:18.650357 27330 sgd_solver.cpp:106] Iteration 39700, lr = 1e-05
I0514 02:53:44.434826 27330 solver.cpp:228] Iteration 39800, loss = 0.323601
I0514 02:53:44.435235 27330 solver.cpp:244]     Train net output #0: loss = 0.323602 (* 1 = 0.323602 loss)
I0514 02:53:44.435263 27330 sgd_solver.cpp:106] Iteration 39800, lr = 1e-05
I0514 03:01:59.864039 27330 solver.cpp:228] Iteration 39900, loss = 0.583807
I0514 03:01:59.864454 27330 solver.cpp:244]     Train net output #0: loss = 0.583808 (* 1 = 0.583808 loss)
I0514 03:01:59.864478 27330 sgd_solver.cpp:106] Iteration 39900, lr = 1e-05
I0514 03:10:24.510571 27330 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_40000.caffemodel
I0514 03:10:24.704275 27330 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_40000.solverstate
I0514 03:10:29.143664 27330 solver.cpp:228] Iteration 40000, loss = 0.842313
I0514 03:10:29.143709 27330 solver.cpp:244]     Train net output #0: loss = 0.842314 (* 1 = 0.842314 loss)
I0514 03:10:29.143718 27330 sgd_solver.cpp:106] Iteration 40000, lr = 1e-05
I0514 03:18:54.372772 27330 solver.cpp:228] Iteration 40100, loss = 0.471663
I0514 03:18:54.373201 27330 solver.cpp:244]     Train net output #0: loss = 0.471665 (* 1 = 0.471665 loss)
I0514 03:18:54.373225 27330 sgd_solver.cpp:106] Iteration 40100, lr = 1e-05
I0514 03:27:18.438556 27330 solver.cpp:228] Iteration 40200, loss = 0.451753
I0514 03:27:18.439008 27330 solver.cpp:244]     Train net output #0: loss = 0.451754 (* 1 = 0.451754 loss)
I0514 03:27:18.439028 27330 sgd_solver.cpp:106] Iteration 40200, lr = 1e-05
I0514 03:35:39.012956 27330 solver.cpp:228] Iteration 40300, loss = 0.285473
I0514 03:35:39.013388 27330 solver.cpp:244]     Train net output #0: loss = 0.285474 (* 1 = 0.285474 loss)
I0514 03:35:39.013412 27330 sgd_solver.cpp:106] Iteration 40300, lr = 1e-05
I0514 03:44:11.835228 27330 solver.cpp:228] Iteration 40400, loss = 0.616694
I0514 03:44:11.835681 27330 solver.cpp:244]     Train net output #0: loss = 0.616695 (* 1 = 0.616695 loss)
I0514 03:44:11.835701 27330 sgd_solver.cpp:106] Iteration 40400, lr = 1e-05
I0514 03:52:30.120244 27330 solver.cpp:228] Iteration 40500, loss = 0.173615
I0514 03:52:30.120671 27330 solver.cpp:244]     Train net output #0: loss = 0.173616 (* 1 = 0.173616 loss)
I0514 03:52:30.120692 27330 sgd_solver.cpp:106] Iteration 40500, lr = 1e-05
I0514 04:01:01.435096 27330 solver.cpp:228] Iteration 40600, loss = 0.302344
I0514 04:01:01.435511 27330 solver.cpp:244]     Train net output #0: loss = 0.302345 (* 1 = 0.302345 loss)
I0514 04:01:01.435535 27330 sgd_solver.cpp:106] Iteration 40600, lr = 1e-05
I0514 04:09:25.062860 27330 solver.cpp:228] Iteration 40700, loss = 0.343306
I0514 04:09:25.063309 27330 solver.cpp:244]     Train net output #0: loss = 0.343307 (* 1 = 0.343307 loss)
I0514 04:09:25.063333 27330 sgd_solver.cpp:106] Iteration 40700, lr = 1e-05
I0514 04:17:55.284071 27330 solver.cpp:228] Iteration 40800, loss = 0.321528
I0514 04:17:55.284482 27330 solver.cpp:244]     Train net output #0: loss = 0.32153 (* 1 = 0.32153 loss)
I0514 04:17:55.284507 27330 sgd_solver.cpp:106] Iteration 40800, lr = 1e-05
I0514 04:26:14.503206 27330 solver.cpp:228] Iteration 40900, loss = 0.22795
I0514 04:26:14.503592 27330 solver.cpp:244]     Train net output #0: loss = 0.227951 (* 1 = 0.227951 loss)
I0514 04:26:14.503617 27330 sgd_solver.cpp:106] Iteration 40900, lr = 1e-05
I0514 04:34:41.409871 27330 solver.cpp:228] Iteration 41000, loss = 0.446756
I0514 04:34:41.410316 27330 solver.cpp:244]     Train net output #0: loss = 0.446757 (* 1 = 0.446757 loss)
I0514 04:34:41.410341 27330 sgd_solver.cpp:106] Iteration 41000, lr = 1e-05
I0514 04:43:04.557327 27330 solver.cpp:228] Iteration 41100, loss = 0.324139
I0514 04:43:04.557792 27330 solver.cpp:244]     Train net output #0: loss = 0.32414 (* 1 = 0.32414 loss)
I0514 04:43:04.557816 27330 sgd_solver.cpp:106] Iteration 41100, lr = 1e-05
I0514 04:51:25.983726 27330 solver.cpp:228] Iteration 41200, loss = 0.46392
I0514 04:51:25.984133 27330 solver.cpp:244]     Train net output #0: loss = 0.463921 (* 1 = 0.463921 loss)
I0514 04:51:25.984156 27330 sgd_solver.cpp:106] Iteration 41200, lr = 1e-05
I0514 04:59:46.510195 27330 solver.cpp:228] Iteration 41300, loss = 0.240634
I0514 04:59:46.510606 27330 solver.cpp:244]     Train net output #0: loss = 0.240635 (* 1 = 0.240635 loss)
I0514 04:59:46.510637 27330 sgd_solver.cpp:106] Iteration 41300, lr = 1e-05
I0514 05:08:05.093520 27330 solver.cpp:228] Iteration 41400, loss = 0.233345
I0514 05:08:05.093997 27330 solver.cpp:244]     Train net output #0: loss = 0.233346 (* 1 = 0.233346 loss)
I0514 05:08:05.094018 27330 sgd_solver.cpp:106] Iteration 41400, lr = 1e-05
I0514 05:16:08.461055 27330 solver.cpp:228] Iteration 41500, loss = 0.447897
I0514 05:16:08.461464 27330 solver.cpp:244]     Train net output #0: loss = 0.447898 (* 1 = 0.447898 loss)
I0514 05:16:08.461488 27330 sgd_solver.cpp:106] Iteration 41500, lr = 1e-05
I0514 05:24:37.174913 27330 solver.cpp:228] Iteration 41600, loss = 0.317113
I0514 05:24:37.175371 27330 solver.cpp:244]     Train net output #0: loss = 0.317114 (* 1 = 0.317114 loss)
I0514 05:24:37.175395 27330 sgd_solver.cpp:106] Iteration 41600, lr = 1e-05
I0514 05:33:02.773344 27330 solver.cpp:228] Iteration 41700, loss = 0.552334
I0514 05:33:02.773810 27330 solver.cpp:244]     Train net output #0: loss = 0.552335 (* 1 = 0.552335 loss)
I0514 05:33:02.773841 27330 sgd_solver.cpp:106] Iteration 41700, lr = 1e-05
I0514 05:41:22.181056 27330 solver.cpp:228] Iteration 41800, loss = 0.399322
I0514 05:41:22.181471 27330 solver.cpp:244]     Train net output #0: loss = 0.399323 (* 1 = 0.399323 loss)
I0514 05:41:22.181495 27330 sgd_solver.cpp:106] Iteration 41800, lr = 1e-05
I0514 05:49:39.896893 27330 solver.cpp:228] Iteration 41900, loss = 0.291879
I0514 05:49:39.897321 27330 solver.cpp:244]     Train net output #0: loss = 0.29188 (* 1 = 0.29188 loss)
I0514 05:49:39.897346 27330 sgd_solver.cpp:106] Iteration 41900, lr = 1e-05
I0514 05:57:49.733989 27330 solver.cpp:228] Iteration 42000, loss = 0.30426
I0514 05:57:49.734429 27330 solver.cpp:244]     Train net output #0: loss = 0.304262 (* 1 = 0.304262 loss)
I0514 05:57:49.734454 27330 sgd_solver.cpp:106] Iteration 42000, lr = 1e-05
I0514 06:06:10.218268 27330 solver.cpp:228] Iteration 42100, loss = 0.39706
I0514 06:06:10.218613 27330 solver.cpp:244]     Train net output #0: loss = 0.397062 (* 1 = 0.397062 loss)
I0514 06:06:10.218629 27330 sgd_solver.cpp:106] Iteration 42100, lr = 1e-05
I0514 06:14:32.041051 27330 solver.cpp:228] Iteration 42200, loss = 0.477084
I0514 06:14:32.041484 27330 solver.cpp:244]     Train net output #0: loss = 0.477085 (* 1 = 0.477085 loss)
I0514 06:14:32.041510 27330 sgd_solver.cpp:106] Iteration 42200, lr = 1e-05
I0514 06:22:50.734910 27330 solver.cpp:228] Iteration 42300, loss = 0.313001
I0514 06:22:50.735368 27330 solver.cpp:244]     Train net output #0: loss = 0.313002 (* 1 = 0.313002 loss)
I0514 06:22:50.735389 27330 sgd_solver.cpp:106] Iteration 42300, lr = 1e-05
I0514 06:31:22.688487 27330 solver.cpp:228] Iteration 42400, loss = 0.183731
I0514 06:31:22.688949 27330 solver.cpp:244]     Train net output #0: loss = 0.183732 (* 1 = 0.183732 loss)
I0514 06:31:22.688978 27330 sgd_solver.cpp:106] Iteration 42400, lr = 1e-05
I0514 06:35:16.603224 27330 solver.cpp:337] Iteration 42445, Testing net (#0)
I0514 06:35:16.603644 27330 net.cpp:685] Ignoring source layer ratemap
I0514 06:35:16.603667 27330 net.cpp:685] Ignoring source layer amsFeatures
I0514 06:38:07.942973 27330 solver.cpp:404]     Test net output #0: loss = 0.580839 (* 1 = 0.580839 loss)
I0514 06:42:52.608706 27330 solver.cpp:228] Iteration 42500, loss = 0.193105
I0514 06:42:52.609158 27330 solver.cpp:244]     Train net output #0: loss = 0.193106 (* 1 = 0.193106 loss)
I0514 06:42:52.609179 27330 sgd_solver.cpp:106] Iteration 42500, lr = 1e-05
I0514 06:51:21.464767 27330 solver.cpp:228] Iteration 42600, loss = 0.245211
I0514 06:51:21.465170 27330 solver.cpp:244]     Train net output #0: loss = 0.245212 (* 1 = 0.245212 loss)
I0514 06:51:21.465195 27330 sgd_solver.cpp:106] Iteration 42600, lr = 1e-05
I0514 06:59:29.637063 27330 solver.cpp:228] Iteration 42700, loss = 0.155818
I0514 06:59:29.637439 27330 solver.cpp:244]     Train net output #0: loss = 0.15582 (* 1 = 0.15582 loss)
I0514 06:59:29.637465 27330 sgd_solver.cpp:106] Iteration 42700, lr = 1e-05
I0514 07:07:46.220618 27330 solver.cpp:228] Iteration 42800, loss = 0.262668
I0514 07:07:46.220954 27330 solver.cpp:244]     Train net output #0: loss = 0.262669 (* 1 = 0.262669 loss)
I0514 07:07:46.220970 27330 sgd_solver.cpp:106] Iteration 42800, lr = 1e-05
I0514 07:16:08.378459 27330 solver.cpp:228] Iteration 42900, loss = 0.258137
I0514 07:16:08.378923 27330 solver.cpp:244]     Train net output #0: loss = 0.258138 (* 1 = 0.258138 loss)
I0514 07:16:08.378944 27330 sgd_solver.cpp:106] Iteration 42900, lr = 1e-05
I0514 07:24:36.690961 27330 solver.cpp:228] Iteration 43000, loss = 0.23989
I0514 07:24:36.691370 27330 solver.cpp:244]     Train net output #0: loss = 0.239891 (* 1 = 0.239891 loss)
I0514 07:24:36.691395 27330 sgd_solver.cpp:106] Iteration 43000, lr = 1e-05
I0514 07:33:00.743897 27330 solver.cpp:228] Iteration 43100, loss = 0.244197
I0514 07:33:00.744349 27330 solver.cpp:244]     Train net output #0: loss = 0.244198 (* 1 = 0.244198 loss)
I0514 07:33:00.744369 27330 sgd_solver.cpp:106] Iteration 43100, lr = 1e-05
I0514 07:41:13.491503 27330 solver.cpp:228] Iteration 43200, loss = 0.353426
I0514 07:41:13.491955 27330 solver.cpp:244]     Train net output #0: loss = 0.353427 (* 1 = 0.353427 loss)
I0514 07:41:13.491978 27330 sgd_solver.cpp:106] Iteration 43200, lr = 1e-05
I0514 07:49:40.529805 27330 solver.cpp:228] Iteration 43300, loss = 0.461087
I0514 07:49:40.530225 27330 solver.cpp:244]     Train net output #0: loss = 0.461088 (* 1 = 0.461088 loss)
I0514 07:49:40.530253 27330 sgd_solver.cpp:106] Iteration 43300, lr = 1e-05
I0514 07:57:49.638895 27330 solver.cpp:228] Iteration 43400, loss = 0.448834
I0514 07:57:49.639358 27330 solver.cpp:244]     Train net output #0: loss = 0.448835 (* 1 = 0.448835 loss)
I0514 07:57:49.639381 27330 sgd_solver.cpp:106] Iteration 43400, lr = 1e-05
I0514 08:06:16.383683 27330 solver.cpp:228] Iteration 43500, loss = 0.315296
I0514 08:06:16.384130 27330 solver.cpp:244]     Train net output #0: loss = 0.315297 (* 1 = 0.315297 loss)
I0514 08:06:16.384150 27330 sgd_solver.cpp:106] Iteration 43500, lr = 1e-05
I0514 08:14:32.384920 27330 solver.cpp:228] Iteration 43600, loss = 0.217006
I0514 08:14:32.385224 27330 solver.cpp:244]     Train net output #0: loss = 0.217007 (* 1 = 0.217007 loss)
I0514 08:14:32.385241 27330 sgd_solver.cpp:106] Iteration 43600, lr = 1e-05
I0514 08:22:47.876538 27330 solver.cpp:228] Iteration 43700, loss = 0.231115
I0514 08:22:47.876970 27330 solver.cpp:244]     Train net output #0: loss = 0.231116 (* 1 = 0.231116 loss)
I0514 08:22:47.876999 27330 sgd_solver.cpp:106] Iteration 43700, lr = 1e-05
I0514 08:30:56.135160 27330 solver.cpp:228] Iteration 43800, loss = 0.43842
I0514 08:30:56.135478 27330 solver.cpp:244]     Train net output #0: loss = 0.438421 (* 1 = 0.438421 loss)
I0514 08:30:56.135489 27330 sgd_solver.cpp:106] Iteration 43800, lr = 1e-05
I0514 08:39:06.482182 27330 solver.cpp:228] Iteration 43900, loss = 0.482402
I0514 08:39:06.482558 27330 solver.cpp:244]     Train net output #0: loss = 0.482403 (* 1 = 0.482403 loss)
I0514 08:39:06.482583 27330 sgd_solver.cpp:106] Iteration 43900, lr = 1e-05
I0514 08:47:32.987118 27330 solver.cpp:228] Iteration 44000, loss = 0.416212
I0514 08:47:32.987566 27330 solver.cpp:244]     Train net output #0: loss = 0.416213 (* 1 = 0.416213 loss)
I0514 08:47:32.987591 27330 sgd_solver.cpp:106] Iteration 44000, lr = 1e-05
I0514 08:56:15.941043 27330 solver.cpp:228] Iteration 44100, loss = 0.211843
I0514 08:56:15.941445 27330 solver.cpp:244]     Train net output #0: loss = 0.211844 (* 1 = 0.211844 loss)
I0514 08:56:15.941478 27330 sgd_solver.cpp:106] Iteration 44100, lr = 1e-05
I0514 09:04:46.069499 27330 solver.cpp:228] Iteration 44200, loss = 0.308072
I0514 09:04:46.069970 27330 solver.cpp:244]     Train net output #0: loss = 0.308073 (* 1 = 0.308073 loss)
I0514 09:04:46.069995 27330 sgd_solver.cpp:106] Iteration 44200, lr = 1e-05
I0514 09:13:05.384310 27330 solver.cpp:228] Iteration 44300, loss = 0.306403
I0514 09:13:05.384763 27330 solver.cpp:244]     Train net output #0: loss = 0.306404 (* 1 = 0.306404 loss)
I0514 09:13:05.384789 27330 sgd_solver.cpp:106] Iteration 44300, lr = 1e-05
I0514 09:21:24.452224 27330 solver.cpp:228] Iteration 44400, loss = 0.457831
I0514 09:21:24.452636 27330 solver.cpp:244]     Train net output #0: loss = 0.457832 (* 1 = 0.457832 loss)
I0514 09:21:24.452647 27330 sgd_solver.cpp:106] Iteration 44400, lr = 1e-05
I0514 09:29:44.784920 27330 solver.cpp:228] Iteration 44500, loss = 0.224207
I0514 09:29:44.785333 27330 solver.cpp:244]     Train net output #0: loss = 0.224208 (* 1 = 0.224208 loss)
I0514 09:29:44.785357 27330 sgd_solver.cpp:106] Iteration 44500, lr = 1e-05
I0514 09:38:07.565518 27330 solver.cpp:228] Iteration 44600, loss = 0.265375
I0514 09:38:07.565997 27330 solver.cpp:244]     Train net output #0: loss = 0.265376 (* 1 = 0.265376 loss)
I0514 09:38:07.566017 27330 sgd_solver.cpp:106] Iteration 44600, lr = 1e-05
I0514 09:46:22.800348 27330 solver.cpp:228] Iteration 44700, loss = 0.362596
I0514 09:46:22.800766 27330 solver.cpp:244]     Train net output #0: loss = 0.362597 (* 1 = 0.362597 loss)
I0514 09:46:22.800791 27330 sgd_solver.cpp:106] Iteration 44700, lr = 1e-05
I0514 09:54:42.911428 27330 solver.cpp:228] Iteration 44800, loss = 0.473062
I0514 09:54:42.911934 27330 solver.cpp:244]     Train net output #0: loss = 0.473063 (* 1 = 0.473063 loss)
I0514 09:54:42.911954 27330 sgd_solver.cpp:106] Iteration 44800, lr = 1e-05
I0514 10:03:06.719676 27330 solver.cpp:228] Iteration 44900, loss = 0.650154
I0514 10:03:06.720038 27330 solver.cpp:244]     Train net output #0: loss = 0.650155 (* 1 = 0.650155 loss)
I0514 10:03:06.720062 27330 sgd_solver.cpp:106] Iteration 44900, lr = 1e-05
I0514 10:11:27.597246 27330 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_45000.caffemodel
I0514 10:11:27.767426 27330 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_45000.solverstate
I0514 10:11:33.593914 27330 solver.cpp:228] Iteration 45000, loss = 0.263991
I0514 10:11:33.593963 27330 solver.cpp:244]     Train net output #0: loss = 0.263992 (* 1 = 0.263992 loss)
I0514 10:11:33.593973 27330 sgd_solver.cpp:106] Iteration 45000, lr = 1e-05
I0514 10:20:08.490531 27330 solver.cpp:228] Iteration 45100, loss = 0.468309
I0514 10:20:08.490962 27330 solver.cpp:244]     Train net output #0: loss = 0.468311 (* 1 = 0.468311 loss)
I0514 10:20:08.490986 27330 sgd_solver.cpp:106] Iteration 45100, lr = 1e-05
I0514 10:28:27.452870 27330 solver.cpp:228] Iteration 45200, loss = 0.548771
I0514 10:28:27.453249 27330 solver.cpp:244]     Train net output #0: loss = 0.548772 (* 1 = 0.548772 loss)
I0514 10:28:27.453274 27330 sgd_solver.cpp:106] Iteration 45200, lr = 1e-05
I0514 10:36:40.931008 27330 solver.cpp:228] Iteration 45300, loss = 0.349602
I0514 10:36:40.931464 27330 solver.cpp:244]     Train net output #0: loss = 0.349603 (* 1 = 0.349603 loss)
I0514 10:36:40.931484 27330 sgd_solver.cpp:106] Iteration 45300, lr = 1e-05
I0514 10:45:01.827186 27330 solver.cpp:228] Iteration 45400, loss = 0.627677
I0514 10:45:01.827623 27330 solver.cpp:244]     Train net output #0: loss = 0.627678 (* 1 = 0.627678 loss)
I0514 10:45:01.827647 27330 sgd_solver.cpp:106] Iteration 45400, lr = 1e-05
I0514 10:53:18.800493 27330 solver.cpp:228] Iteration 45500, loss = 0.249101
I0514 10:53:18.800894 27330 solver.cpp:244]     Train net output #0: loss = 0.249102 (* 1 = 0.249102 loss)
I0514 10:53:18.800918 27330 sgd_solver.cpp:106] Iteration 45500, lr = 1e-05
I0514 11:01:45.577770 27330 solver.cpp:228] Iteration 45600, loss = 0.544592
I0514 11:01:45.578199 27330 solver.cpp:244]     Train net output #0: loss = 0.544594 (* 1 = 0.544594 loss)
I0514 11:01:45.578224 27330 sgd_solver.cpp:106] Iteration 45600, lr = 1e-05
I0514 11:09:57.431687 27330 solver.cpp:228] Iteration 45700, loss = 0.32229
I0514 11:09:57.432101 27330 solver.cpp:244]     Train net output #0: loss = 0.322291 (* 1 = 0.322291 loss)
I0514 11:09:57.432132 27330 sgd_solver.cpp:106] Iteration 45700, lr = 1e-05
I0514 11:10:49.901888 27330 solver.cpp:337] Iteration 45710, Testing net (#0)
I0514 11:10:49.902292 27330 net.cpp:685] Ignoring source layer ratemap
I0514 11:10:49.902310 27330 net.cpp:685] Ignoring source layer amsFeatures
I0514 11:13:41.212090 27330 solver.cpp:404]     Test net output #0: loss = 0.604276 (* 1 = 0.604276 loss)
I0514 11:21:21.798660 27330 solver.cpp:228] Iteration 45800, loss = 0.251732
I0514 11:21:21.799072 27330 solver.cpp:244]     Train net output #0: loss = 0.251733 (* 1 = 0.251733 loss)
I0514 11:21:21.799095 27330 sgd_solver.cpp:106] Iteration 45800, lr = 1e-05
I0514 11:29:54.662441 27330 solver.cpp:228] Iteration 45900, loss = 0.214335
I0514 11:29:54.662847 27330 solver.cpp:244]     Train net output #0: loss = 0.214336 (* 1 = 0.214336 loss)
I0514 11:29:54.662870 27330 sgd_solver.cpp:106] Iteration 45900, lr = 1e-05
I0514 11:38:30.207584 27330 solver.cpp:228] Iteration 46000, loss = 0.385088
I0514 11:38:30.207990 27330 solver.cpp:244]     Train net output #0: loss = 0.385089 (* 1 = 0.385089 loss)
I0514 11:38:30.208014 27330 sgd_solver.cpp:106] Iteration 46000, lr = 1e-05
I0514 11:46:51.074364 27330 solver.cpp:228] Iteration 46100, loss = 0.312029
I0514 11:46:51.087261 27330 solver.cpp:244]     Train net output #0: loss = 0.31203 (* 1 = 0.31203 loss)
I0514 11:46:51.087285 27330 sgd_solver.cpp:106] Iteration 46100, lr = 1e-05
I0514 11:55:17.923312 27330 solver.cpp:228] Iteration 46200, loss = 0.355963
I0514 11:55:17.923769 27330 solver.cpp:244]     Train net output #0: loss = 0.355965 (* 1 = 0.355965 loss)
I0514 11:55:17.923789 27330 sgd_solver.cpp:106] Iteration 46200, lr = 1e-05
I0514 12:03:39.971360 27330 solver.cpp:228] Iteration 46300, loss = 0.13731
I0514 12:03:39.971724 27330 solver.cpp:244]     Train net output #0: loss = 0.137311 (* 1 = 0.137311 loss)
I0514 12:03:39.971750 27330 sgd_solver.cpp:106] Iteration 46300, lr = 1e-05
I0514 12:11:57.862849 27330 solver.cpp:228] Iteration 46400, loss = 0.362473
I0514 12:11:57.863311 27330 solver.cpp:244]     Train net output #0: loss = 0.362474 (* 1 = 0.362474 loss)
I0514 12:11:57.863324 27330 sgd_solver.cpp:106] Iteration 46400, lr = 1e-05
I0514 12:20:32.293725 27330 solver.cpp:228] Iteration 46500, loss = 0.365196
I0514 12:20:32.294150 27330 solver.cpp:244]     Train net output #0: loss = 0.365197 (* 1 = 0.365197 loss)
I0514 12:20:32.294172 27330 sgd_solver.cpp:106] Iteration 46500, lr = 1e-05
I0514 12:28:50.232970 27330 solver.cpp:228] Iteration 46600, loss = 0.461667
I0514 12:28:50.233382 27330 solver.cpp:244]     Train net output #0: loss = 0.461668 (* 1 = 0.461668 loss)
I0514 12:28:50.233407 27330 sgd_solver.cpp:106] Iteration 46600, lr = 1e-05
I0514 12:37:18.967911 27330 solver.cpp:228] Iteration 46700, loss = 0.435923
I0514 12:37:18.968338 27330 solver.cpp:244]     Train net output #0: loss = 0.435924 (* 1 = 0.435924 loss)
I0514 12:37:18.968363 27330 sgd_solver.cpp:106] Iteration 46700, lr = 1e-05
I0514 12:45:36.301406 27330 solver.cpp:228] Iteration 46800, loss = 0.227395
I0514 12:45:36.301837 27330 solver.cpp:244]     Train net output #0: loss = 0.227396 (* 1 = 0.227396 loss)
I0514 12:45:36.301862 27330 sgd_solver.cpp:106] Iteration 46800, lr = 1e-05
I0514 12:53:50.695354 27330 solver.cpp:228] Iteration 46900, loss = 0.298748
I0514 12:53:50.695829 27330 solver.cpp:244]     Train net output #0: loss = 0.298749 (* 1 = 0.298749 loss)
I0514 12:53:50.695853 27330 sgd_solver.cpp:106] Iteration 46900, lr = 1e-05
I0514 13:02:26.832458 27330 solver.cpp:228] Iteration 47000, loss = 0.294832
I0514 13:02:26.832904 27330 solver.cpp:244]     Train net output #0: loss = 0.294834 (* 1 = 0.294834 loss)
I0514 13:02:26.832926 27330 sgd_solver.cpp:106] Iteration 47000, lr = 1e-05
I0514 13:10:39.245069 27330 solver.cpp:228] Iteration 47100, loss = 0.369288
I0514 13:10:39.245445 27330 solver.cpp:244]     Train net output #0: loss = 0.369289 (* 1 = 0.369289 loss)
I0514 13:10:39.245470 27330 sgd_solver.cpp:106] Iteration 47100, lr = 1e-05
I0514 13:19:02.693032 27330 solver.cpp:228] Iteration 47200, loss = 0.514139
I0514 13:19:02.693490 27330 solver.cpp:244]     Train net output #0: loss = 0.514141 (* 1 = 0.514141 loss)
I0514 13:19:02.693519 27330 sgd_solver.cpp:106] Iteration 47200, lr = 1e-05
I0514 13:27:52.570822 27330 solver.cpp:228] Iteration 47300, loss = 0.554418
I0514 13:27:52.571243 27330 solver.cpp:244]     Train net output #0: loss = 0.554419 (* 1 = 0.554419 loss)
I0514 13:27:52.571269 27330 sgd_solver.cpp:106] Iteration 47300, lr = 1e-05
I0514 13:36:23.668642 27330 solver.cpp:228] Iteration 47400, loss = 0.337355
I0514 13:36:23.669080 27330 solver.cpp:244]     Train net output #0: loss = 0.337357 (* 1 = 0.337357 loss)
I0514 13:36:23.669105 27330 sgd_solver.cpp:106] Iteration 47400, lr = 1e-05
I0514 13:44:54.738759 27330 solver.cpp:228] Iteration 47500, loss = 0.2684
I0514 13:44:54.739208 27330 solver.cpp:244]     Train net output #0: loss = 0.268401 (* 1 = 0.268401 loss)
I0514 13:44:54.739233 27330 sgd_solver.cpp:106] Iteration 47500, lr = 1e-05
I0514 13:53:31.391683 27330 solver.cpp:228] Iteration 47600, loss = 0.561543
I0514 13:53:31.392144 27330 solver.cpp:244]     Train net output #0: loss = 0.561545 (* 1 = 0.561545 loss)
I0514 13:53:31.392168 27330 sgd_solver.cpp:106] Iteration 47600, lr = 1e-05
I0514 14:02:29.967020 27330 solver.cpp:228] Iteration 47700, loss = 0.264902
I0514 14:02:29.967423 27330 solver.cpp:244]     Train net output #0: loss = 0.264903 (* 1 = 0.264903 loss)
I0514 14:02:29.967437 27330 sgd_solver.cpp:106] Iteration 47700, lr = 1e-05
I0514 14:11:12.455757 27330 solver.cpp:228] Iteration 47800, loss = 0.264093
I0514 14:11:12.456140 27330 solver.cpp:244]     Train net output #0: loss = 0.264095 (* 1 = 0.264095 loss)
I0514 14:11:12.456156 27330 sgd_solver.cpp:106] Iteration 47800, lr = 1e-05
I0514 14:20:07.040261 27330 solver.cpp:228] Iteration 47900, loss = 0.321399
I0514 14:20:07.040731 27330 solver.cpp:244]     Train net output #0: loss = 0.321401 (* 1 = 0.321401 loss)
I0514 14:20:07.040752 27330 sgd_solver.cpp:106] Iteration 47900, lr = 1e-05
I0514 14:28:47.635802 27330 solver.cpp:228] Iteration 48000, loss = 0.193217
I0514 14:28:47.636204 27330 solver.cpp:244]     Train net output #0: loss = 0.193218 (* 1 = 0.193218 loss)
I0514 14:28:47.636217 27330 sgd_solver.cpp:106] Iteration 48000, lr = 1e-05
I0514 14:38:40.685879 27330 solver.cpp:228] Iteration 48100, loss = 0.290079
I0514 14:38:40.686257 27330 solver.cpp:244]     Train net output #0: loss = 0.290081 (* 1 = 0.290081 loss)
I0514 14:38:40.686275 27330 sgd_solver.cpp:106] Iteration 48100, lr = 1e-05
I0514 14:48:39.194772 27330 solver.cpp:228] Iteration 48200, loss = 0.21496
I0514 14:48:39.195122 27330 solver.cpp:244]     Train net output #0: loss = 0.214962 (* 1 = 0.214962 loss)
I0514 14:48:39.195137 27330 sgd_solver.cpp:106] Iteration 48200, lr = 1e-05
I0514 14:58:27.146981 27330 solver.cpp:228] Iteration 48300, loss = 0.261311
I0514 14:58:27.147354 27330 solver.cpp:244]     Train net output #0: loss = 0.261313 (* 1 = 0.261313 loss)
I0514 14:58:27.147370 27330 sgd_solver.cpp:106] Iteration 48300, lr = 1e-05
I0514 15:08:11.834769 27330 solver.cpp:228] Iteration 48400, loss = 0.260151
I0514 15:08:11.835129 27330 solver.cpp:244]     Train net output #0: loss = 0.260153 (* 1 = 0.260153 loss)
I0514 15:08:11.835144 27330 sgd_solver.cpp:106] Iteration 48400, lr = 1e-05
I0514 15:18:07.160229 27330 solver.cpp:228] Iteration 48500, loss = 0.217422
I0514 15:18:07.160586 27330 solver.cpp:244]     Train net output #0: loss = 0.217423 (* 1 = 0.217423 loss)
I0514 15:18:07.160606 27330 sgd_solver.cpp:106] Iteration 48500, lr = 1e-05
I0514 15:27:59.962484 27330 solver.cpp:228] Iteration 48600, loss = 0.211156
I0514 15:27:59.962821 27330 solver.cpp:244]     Train net output #0: loss = 0.211157 (* 1 = 0.211157 loss)
I0514 15:27:59.962836 27330 sgd_solver.cpp:106] Iteration 48600, lr = 1e-05
I0514 15:38:13.154582 27330 solver.cpp:228] Iteration 48700, loss = 0.279576
I0514 15:38:13.154942 27330 solver.cpp:244]     Train net output #0: loss = 0.279577 (* 1 = 0.279577 loss)
I0514 15:38:13.154958 27330 sgd_solver.cpp:106] Iteration 48700, lr = 1e-05
I0514 15:48:02.616063 27330 solver.cpp:228] Iteration 48800, loss = 0.336727
I0514 15:48:02.616475 27330 solver.cpp:244]     Train net output #0: loss = 0.336729 (* 1 = 0.336729 loss)
I0514 15:48:02.616503 27330 sgd_solver.cpp:106] Iteration 48800, lr = 1e-05
I0514 15:58:10.063716 27330 solver.cpp:228] Iteration 48900, loss = 0.544931
I0514 15:58:10.064075 27330 solver.cpp:244]     Train net output #0: loss = 0.544933 (* 1 = 0.544933 loss)
I0514 15:58:10.064090 27330 sgd_solver.cpp:106] Iteration 48900, lr = 1e-05
I0514 16:05:32.972264 27330 solver.cpp:337] Iteration 48975, Testing net (#0)
I0514 16:05:32.972591 27330 net.cpp:685] Ignoring source layer ratemap
I0514 16:05:32.972601 27330 net.cpp:685] Ignoring source layer amsFeatures
I0514 16:08:25.423156 27330 solver.cpp:404]     Test net output #0: loss = 0.584917 (* 1 = 0.584917 loss)
I0514 16:11:04.384623 27330 solver.cpp:228] Iteration 49000, loss = 0.40698
I0514 16:11:04.385017 27330 solver.cpp:244]     Train net output #0: loss = 0.406982 (* 1 = 0.406982 loss)
I0514 16:11:04.385032 27330 sgd_solver.cpp:106] Iteration 49000, lr = 1e-05
I0514 16:21:03.399224 27330 solver.cpp:228] Iteration 49100, loss = 0.437858
I0514 16:21:03.399556 27330 solver.cpp:244]     Train net output #0: loss = 0.43786 (* 1 = 0.43786 loss)
I0514 16:21:03.399569 27330 sgd_solver.cpp:106] Iteration 49100, lr = 1e-05
I0514 16:30:38.525024 27330 solver.cpp:228] Iteration 49200, loss = 0.445447
I0514 16:30:38.525367 27330 solver.cpp:244]     Train net output #0: loss = 0.445449 (* 1 = 0.445449 loss)
I0514 16:30:38.525380 27330 sgd_solver.cpp:106] Iteration 49200, lr = 1e-05
I0514 16:40:15.412945 27330 solver.cpp:228] Iteration 49300, loss = 0.475488
I0514 16:40:15.413383 27330 solver.cpp:244]     Train net output #0: loss = 0.47549 (* 1 = 0.47549 loss)
I0514 16:40:15.413404 27330 sgd_solver.cpp:106] Iteration 49300, lr = 1e-05
I0514 16:50:14.838207 27330 solver.cpp:228] Iteration 49400, loss = 0.175494
I0514 16:50:14.838539 27330 solver.cpp:244]     Train net output #0: loss = 0.175495 (* 1 = 0.175495 loss)
I0514 16:50:14.838553 27330 sgd_solver.cpp:106] Iteration 49400, lr = 1e-05
I0514 17:00:22.913128 27330 solver.cpp:228] Iteration 49500, loss = 0.250957
I0514 17:00:22.913431 27330 solver.cpp:244]     Train net output #0: loss = 0.250959 (* 1 = 0.250959 loss)
I0514 17:00:22.913445 27330 sgd_solver.cpp:106] Iteration 49500, lr = 1e-05
I0514 17:10:08.768846 27330 solver.cpp:228] Iteration 49600, loss = 0.439591
I0514 17:10:08.769160 27330 solver.cpp:244]     Train net output #0: loss = 0.439593 (* 1 = 0.439593 loss)
I0514 17:10:08.769176 27330 sgd_solver.cpp:106] Iteration 49600, lr = 1e-05
I0514 17:20:08.105761 27330 solver.cpp:228] Iteration 49700, loss = 0.328539
I0514 17:20:08.106137 27330 solver.cpp:244]     Train net output #0: loss = 0.328541 (* 1 = 0.328541 loss)
I0514 17:20:08.106150 27330 sgd_solver.cpp:106] Iteration 49700, lr = 1e-05
I0514 17:30:04.423185 27330 solver.cpp:228] Iteration 49800, loss = 0.139401
I0514 17:30:04.423552 27330 solver.cpp:244]     Train net output #0: loss = 0.139402 (* 1 = 0.139402 loss)
I0514 17:30:04.423568 27330 sgd_solver.cpp:106] Iteration 49800, lr = 1e-05
I0514 17:39:51.895668 27330 solver.cpp:228] Iteration 49900, loss = 0.370924
I0514 17:39:51.896049 27330 solver.cpp:244]     Train net output #0: loss = 0.370926 (* 1 = 0.370926 loss)
I0514 17:39:51.896065 27330 sgd_solver.cpp:106] Iteration 49900, lr = 1e-05
I0514 17:48:45.767640 27330 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_50000.caffemodel
I0514 17:48:45.937362 27330 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_50000.solverstate
I0514 17:48:51.420639 27330 solver.cpp:228] Iteration 50000, loss = 0.42327
I0514 17:48:51.420680 27330 solver.cpp:244]     Train net output #0: loss = 0.423272 (* 1 = 0.423272 loss)
I0514 17:48:51.420691 27330 sgd_solver.cpp:106] Iteration 50000, lr = 1e-05
I0514 17:57:21.932893 27330 solver.cpp:228] Iteration 50100, loss = 0.395487
I0514 17:57:21.933287 27330 solver.cpp:244]     Train net output #0: loss = 0.395488 (* 1 = 0.395488 loss)
I0514 17:57:21.933316 27330 sgd_solver.cpp:106] Iteration 50100, lr = 1e-05
I0514 18:05:59.922139 27330 solver.cpp:228] Iteration 50200, loss = 0.280536
I0514 18:05:59.922587 27330 solver.cpp:244]     Train net output #0: loss = 0.280538 (* 1 = 0.280538 loss)
I0514 18:05:59.922612 27330 sgd_solver.cpp:106] Iteration 50200, lr = 1e-05
I0514 18:14:11.831449 27330 solver.cpp:228] Iteration 50300, loss = 0.280982
I0514 18:14:11.831871 27330 solver.cpp:244]     Train net output #0: loss = 0.280984 (* 1 = 0.280984 loss)
I0514 18:14:11.831895 27330 sgd_solver.cpp:106] Iteration 50300, lr = 1e-05
I0514 18:22:20.394224 27330 solver.cpp:228] Iteration 50400, loss = 0.194746
I0514 18:22:20.394630 27330 solver.cpp:244]     Train net output #0: loss = 0.194747 (* 1 = 0.194747 loss)
I0514 18:22:20.394655 27330 sgd_solver.cpp:106] Iteration 50400, lr = 1e-05
I0514 18:30:54.391695 27330 solver.cpp:228] Iteration 50500, loss = 0.382557
I0514 18:30:54.392144 27330 solver.cpp:244]     Train net output #0: loss = 0.382558 (* 1 = 0.382558 loss)
I0514 18:30:54.392165 27330 sgd_solver.cpp:106] Iteration 50500, lr = 1e-05
I0514 18:39:16.413944 27330 solver.cpp:228] Iteration 50600, loss = 0.32436
I0514 18:39:16.414388 27330 solver.cpp:244]     Train net output #0: loss = 0.324362 (* 1 = 0.324362 loss)
I0514 18:39:16.414412 27330 sgd_solver.cpp:106] Iteration 50600, lr = 1e-05
I0514 18:47:24.320757 27330 solver.cpp:228] Iteration 50700, loss = 0.280518
I0514 18:47:24.321204 27330 solver.cpp:244]     Train net output #0: loss = 0.28052 (* 1 = 0.28052 loss)
I0514 18:47:24.321225 27330 sgd_solver.cpp:106] Iteration 50700, lr = 1e-05
I0514 18:55:47.149451 27330 solver.cpp:228] Iteration 50800, loss = 0.416581
I0514 18:55:47.149878 27330 solver.cpp:244]     Train net output #0: loss = 0.416583 (* 1 = 0.416583 loss)
I0514 18:55:47.149901 27330 sgd_solver.cpp:106] Iteration 50800, lr = 1e-05
I0514 19:04:12.334945 27330 solver.cpp:228] Iteration 50900, loss = 0.549002
I0514 19:04:12.335386 27330 solver.cpp:244]     Train net output #0: loss = 0.549004 (* 1 = 0.549004 loss)
I0514 19:04:12.335410 27330 sgd_solver.cpp:106] Iteration 50900, lr = 1e-05
I0514 19:12:40.876080 27330 solver.cpp:228] Iteration 51000, loss = 0.359459
I0514 19:12:40.876523 27330 solver.cpp:244]     Train net output #0: loss = 0.359461 (* 1 = 0.359461 loss)
I0514 19:12:40.876546 27330 sgd_solver.cpp:106] Iteration 51000, lr = 1e-05
I0514 19:21:03.702198 27330 solver.cpp:228] Iteration 51100, loss = 0.155083
I0514 19:21:03.702608 27330 solver.cpp:244]     Train net output #0: loss = 0.155085 (* 1 = 0.155085 loss)
I0514 19:21:03.702632 27330 sgd_solver.cpp:106] Iteration 51100, lr = 1e-05
I0514 19:29:20.267478 27330 solver.cpp:228] Iteration 51200, loss = 0.332844
I0514 19:29:20.267954 27330 solver.cpp:244]     Train net output #0: loss = 0.332846 (* 1 = 0.332846 loss)
I0514 19:29:20.267976 27330 sgd_solver.cpp:106] Iteration 51200, lr = 1e-05
I0514 19:37:52.145925 27330 solver.cpp:228] Iteration 51300, loss = 0.199883
I0514 19:37:52.146363 27330 solver.cpp:244]     Train net output #0: loss = 0.199885 (* 1 = 0.199885 loss)
I0514 19:37:52.146385 27330 sgd_solver.cpp:106] Iteration 51300, lr = 1e-05
I0514 19:46:13.401530 27330 solver.cpp:228] Iteration 51400, loss = 0.252531
I0514 19:46:13.401968 27330 solver.cpp:244]     Train net output #0: loss = 0.252533 (* 1 = 0.252533 loss)
I0514 19:46:13.401991 27330 sgd_solver.cpp:106] Iteration 51400, lr = 1e-05
I0514 19:54:32.980888 27330 solver.cpp:228] Iteration 51500, loss = 0.511383
I0514 19:54:32.981412 27330 solver.cpp:244]     Train net output #0: loss = 0.511385 (* 1 = 0.511385 loss)
I0514 19:54:32.981436 27330 sgd_solver.cpp:106] Iteration 51500, lr = 1e-05
I0514 20:02:42.411674 27330 solver.cpp:228] Iteration 51600, loss = 0.26298
I0514 20:02:42.412106 27330 solver.cpp:244]     Train net output #0: loss = 0.262982 (* 1 = 0.262982 loss)
I0514 20:02:42.412129 27330 sgd_solver.cpp:106] Iteration 51600, lr = 1e-05
I0514 20:11:19.178143 27330 solver.cpp:228] Iteration 51700, loss = 0.208717
I0514 20:11:19.178576 27330 solver.cpp:244]     Train net output #0: loss = 0.208719 (* 1 = 0.208719 loss)
I0514 20:11:19.178601 27330 sgd_solver.cpp:106] Iteration 51700, lr = 1e-05
I0514 20:19:36.470043 27330 solver.cpp:228] Iteration 51800, loss = 0.303983
I0514 20:19:36.470454 27330 solver.cpp:244]     Train net output #0: loss = 0.303985 (* 1 = 0.303985 loss)
I0514 20:19:36.470479 27330 sgd_solver.cpp:106] Iteration 51800, lr = 1e-05
I0514 20:28:16.599972 27330 solver.cpp:228] Iteration 51900, loss = 0.276874
I0514 20:28:16.600379 27330 solver.cpp:244]     Train net output #0: loss = 0.276876 (* 1 = 0.276876 loss)
I0514 20:28:16.600409 27330 sgd_solver.cpp:106] Iteration 51900, lr = 1e-05
I0514 20:36:39.954807 27330 solver.cpp:228] Iteration 52000, loss = 0.540516
I0514 20:36:39.955143 27330 solver.cpp:244]     Train net output #0: loss = 0.540518 (* 1 = 0.540518 loss)
I0514 20:36:39.955154 27330 sgd_solver.cpp:106] Iteration 52000, lr = 1e-05
I0514 20:44:57.006391 27330 solver.cpp:228] Iteration 52100, loss = 0.301581
I0514 20:44:57.006800 27330 solver.cpp:244]     Train net output #0: loss = 0.301584 (* 1 = 0.301584 loss)
I0514 20:44:57.006825 27330 sgd_solver.cpp:106] Iteration 52100, lr = 1e-05
I0514 20:53:28.555368 27330 solver.cpp:228] Iteration 52200, loss = 0.308058
I0514 20:53:28.555837 27330 solver.cpp:244]     Train net output #0: loss = 0.30806 (* 1 = 0.30806 loss)
I0514 20:53:28.555858 27330 sgd_solver.cpp:106] Iteration 52200, lr = 1e-05
I0514 20:56:58.628762 27330 solver.cpp:337] Iteration 52240, Testing net (#0)
I0514 20:56:58.629163 27330 net.cpp:685] Ignoring source layer ratemap
I0514 20:56:58.629180 27330 net.cpp:685] Ignoring source layer amsFeatures
I0514 20:59:49.953306 27330 solver.cpp:404]     Test net output #0: loss = 0.578708 (* 1 = 0.578708 loss)
I0514 21:04:54.307891 27330 solver.cpp:228] Iteration 52300, loss = 0.551133
I0514 21:04:54.308295 27330 solver.cpp:244]     Train net output #0: loss = 0.551135 (* 1 = 0.551135 loss)
I0514 21:04:54.308323 27330 sgd_solver.cpp:106] Iteration 52300, lr = 1e-05
I0514 21:13:13.973070 27330 solver.cpp:228] Iteration 52400, loss = 0.447138
I0514 21:13:13.973412 27330 solver.cpp:244]     Train net output #0: loss = 0.44714 (* 1 = 0.44714 loss)
I0514 21:13:13.973425 27330 sgd_solver.cpp:106] Iteration 52400, lr = 1e-05
I0514 21:21:38.408115 27330 solver.cpp:228] Iteration 52500, loss = 0.244371
I0514 21:21:38.408556 27330 solver.cpp:244]     Train net output #0: loss = 0.244373 (* 1 = 0.244373 loss)
I0514 21:21:38.408581 27330 sgd_solver.cpp:106] Iteration 52500, lr = 1e-05
I0514 21:30:08.828375 27330 solver.cpp:228] Iteration 52600, loss = 0.330387
I0514 21:30:08.828790 27330 solver.cpp:244]     Train net output #0: loss = 0.330389 (* 1 = 0.330389 loss)
I0514 21:30:08.828810 27330 sgd_solver.cpp:106] Iteration 52600, lr = 1e-05
I0514 21:38:24.445591 27330 solver.cpp:228] Iteration 52700, loss = 0.368146
I0514 21:38:24.446053 27330 solver.cpp:244]     Train net output #0: loss = 0.368148 (* 1 = 0.368148 loss)
I0514 21:38:24.446080 27330 sgd_solver.cpp:106] Iteration 52700, lr = 1e-05
I0514 21:46:44.468798 27330 solver.cpp:228] Iteration 52800, loss = 0.29978
I0514 21:46:44.469233 27330 solver.cpp:244]     Train net output #0: loss = 0.299782 (* 1 = 0.299782 loss)
I0514 21:46:44.469256 27330 sgd_solver.cpp:106] Iteration 52800, lr = 1e-05
I0514 21:55:07.262605 27330 solver.cpp:228] Iteration 52900, loss = 0.195748
I0514 21:55:07.262986 27330 solver.cpp:244]     Train net output #0: loss = 0.19575 (* 1 = 0.19575 loss)
I0514 21:55:07.263002 27330 sgd_solver.cpp:106] Iteration 52900, lr = 1e-05
I0514 22:03:26.082901 27330 solver.cpp:228] Iteration 53000, loss = 0.487488
I0514 22:03:26.083329 27330 solver.cpp:244]     Train net output #0: loss = 0.48749 (* 1 = 0.48749 loss)
I0514 22:03:26.083354 27330 sgd_solver.cpp:106] Iteration 53000, lr = 1e-05
I0514 22:11:48.365571 27330 solver.cpp:228] Iteration 53100, loss = 0.767314
I0514 22:11:48.366050 27330 solver.cpp:244]     Train net output #0: loss = 0.767316 (* 1 = 0.767316 loss)
I0514 22:11:48.366075 27330 sgd_solver.cpp:106] Iteration 53100, lr = 1e-05
I0514 22:20:12.765962 27330 solver.cpp:228] Iteration 53200, loss = 0.361429
I0514 22:20:12.766377 27330 solver.cpp:244]     Train net output #0: loss = 0.361431 (* 1 = 0.361431 loss)
I0514 22:20:12.766402 27330 sgd_solver.cpp:106] Iteration 53200, lr = 1e-05
I0514 22:28:40.746085 27330 solver.cpp:228] Iteration 53300, loss = 0.209934
I0514 22:28:40.746485 27330 solver.cpp:244]     Train net output #0: loss = 0.209936 (* 1 = 0.209936 loss)
I0514 22:28:40.746515 27330 sgd_solver.cpp:106] Iteration 53300, lr = 1e-05
I0514 22:36:53.919134 27330 solver.cpp:228] Iteration 53400, loss = 0.347131
I0514 22:36:53.919589 27330 solver.cpp:244]     Train net output #0: loss = 0.347133 (* 1 = 0.347133 loss)
I0514 22:36:53.919615 27330 sgd_solver.cpp:106] Iteration 53400, lr = 1e-05
I0514 22:45:09.064198 27330 solver.cpp:228] Iteration 53500, loss = 0.323125
I0514 22:45:09.064637 27330 solver.cpp:244]     Train net output #0: loss = 0.323127 (* 1 = 0.323127 loss)
I0514 22:45:09.064661 27330 sgd_solver.cpp:106] Iteration 53500, lr = 1e-05
I0514 22:53:14.923653 27330 solver.cpp:228] Iteration 53600, loss = 0.37171
I0514 22:53:14.924036 27330 solver.cpp:244]     Train net output #0: loss = 0.371712 (* 1 = 0.371712 loss)
I0514 22:53:14.924060 27330 sgd_solver.cpp:106] Iteration 53600, lr = 1e-05
I0514 23:01:31.219774 27330 solver.cpp:228] Iteration 53700, loss = 0.273205
I0514 23:01:31.220196 27330 solver.cpp:244]     Train net output #0: loss = 0.273207 (* 1 = 0.273207 loss)
I0514 23:01:31.220219 27330 sgd_solver.cpp:106] Iteration 53700, lr = 1e-05
I0514 23:10:01.705634 27330 solver.cpp:228] Iteration 53800, loss = 0.293763
I0514 23:10:01.706045 27330 solver.cpp:244]     Train net output #0: loss = 0.293765 (* 1 = 0.293765 loss)
I0514 23:10:01.706064 27330 sgd_solver.cpp:106] Iteration 53800, lr = 1e-05
I0514 23:18:20.002223 27330 solver.cpp:228] Iteration 53900, loss = 0.531051
I0514 23:18:20.002648 27330 solver.cpp:244]     Train net output #0: loss = 0.531053 (* 1 = 0.531053 loss)
I0514 23:18:20.002673 27330 sgd_solver.cpp:106] Iteration 53900, lr = 1e-05
I0514 23:26:56.966259 27330 solver.cpp:228] Iteration 54000, loss = 0.727226
I0514 23:26:56.966697 27330 solver.cpp:244]     Train net output #0: loss = 0.727229 (* 1 = 0.727229 loss)
I0514 23:26:56.966722 27330 sgd_solver.cpp:106] Iteration 54000, lr = 1e-05
I0514 23:35:14.212334 27330 solver.cpp:228] Iteration 54100, loss = 0.565289
I0514 23:35:14.212772 27330 solver.cpp:244]     Train net output #0: loss = 0.565291 (* 1 = 0.565291 loss)
I0514 23:35:14.212796 27330 sgd_solver.cpp:106] Iteration 54100, lr = 1e-05
I0514 23:43:32.974392 27330 solver.cpp:228] Iteration 54200, loss = 0.402715
I0514 23:43:32.974810 27330 solver.cpp:244]     Train net output #0: loss = 0.402717 (* 1 = 0.402717 loss)
I0514 23:43:32.974824 27330 sgd_solver.cpp:106] Iteration 54200, lr = 1e-05
I0514 23:51:49.103483 27330 solver.cpp:228] Iteration 54300, loss = 0.332282
I0514 23:51:49.103914 27330 solver.cpp:244]     Train net output #0: loss = 0.332284 (* 1 = 0.332284 loss)
I0514 23:51:49.103937 27330 sgd_solver.cpp:106] Iteration 54300, lr = 1e-05
I0515 00:00:02.682302 27330 solver.cpp:228] Iteration 54400, loss = 0.437703
I0515 00:00:02.682749 27330 solver.cpp:244]     Train net output #0: loss = 0.437705 (* 1 = 0.437705 loss)
I0515 00:00:02.682772 27330 sgd_solver.cpp:106] Iteration 54400, lr = 1e-05
I0515 00:08:28.802840 27330 solver.cpp:228] Iteration 54500, loss = 0.208775
I0515 00:08:28.803336 27330 solver.cpp:244]     Train net output #0: loss = 0.208777 (* 1 = 0.208777 loss)
I0515 00:08:28.803361 27330 sgd_solver.cpp:106] Iteration 54500, lr = 1e-05
I0515 00:17:03.751658 27330 solver.cpp:228] Iteration 54600, loss = 0.597958
I0515 00:17:03.752069 27330 solver.cpp:244]     Train net output #0: loss = 0.59796 (* 1 = 0.59796 loss)
I0515 00:17:03.752099 27330 sgd_solver.cpp:106] Iteration 54600, lr = 1e-05
I0515 00:25:30.812197 27330 solver.cpp:228] Iteration 54700, loss = 0.402462
I0515 00:25:30.812609 27330 solver.cpp:244]     Train net output #0: loss = 0.402464 (* 1 = 0.402464 loss)
I0515 00:25:30.812621 27330 sgd_solver.cpp:106] Iteration 54700, lr = 1e-05
I0515 00:33:44.422291 27330 solver.cpp:228] Iteration 54800, loss = 0.254163
I0515 00:33:44.422701 27330 solver.cpp:244]     Train net output #0: loss = 0.254165 (* 1 = 0.254165 loss)
I0515 00:33:44.422725 27330 sgd_solver.cpp:106] Iteration 54800, lr = 1e-05
I0515 00:42:05.950675 27330 solver.cpp:228] Iteration 54900, loss = 0.205676
I0515 00:42:05.951103 27330 solver.cpp:244]     Train net output #0: loss = 0.205679 (* 1 = 0.205679 loss)
I0515 00:42:05.951115 27330 sgd_solver.cpp:106] Iteration 54900, lr = 1e-05
I0515 00:49:51.761142 27330 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_55000.caffemodel
I0515 00:49:51.939680 27330 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_55000.solverstate
I0515 00:49:57.667801 27330 solver.cpp:228] Iteration 55000, loss = 0.369998
I0515 00:49:57.667851 27330 solver.cpp:244]     Train net output #0: loss = 0.37 (* 1 = 0.37 loss)
I0515 00:49:57.667861 27330 sgd_solver.cpp:106] Iteration 55000, lr = 1e-05
I0515 00:58:04.638406 27330 solver.cpp:228] Iteration 55100, loss = 0.404858
I0515 00:58:04.638890 27330 solver.cpp:244]     Train net output #0: loss = 0.40486 (* 1 = 0.40486 loss)
I0515 00:58:04.638916 27330 sgd_solver.cpp:106] Iteration 55100, lr = 1e-05
I0515 01:06:17.768535 27330 solver.cpp:228] Iteration 55200, loss = 0.39768
I0515 01:06:17.768942 27330 solver.cpp:244]     Train net output #0: loss = 0.397682 (* 1 = 0.397682 loss)
I0515 01:06:17.768966 27330 sgd_solver.cpp:106] Iteration 55200, lr = 1e-05
I0515 01:14:42.723139 27330 solver.cpp:228] Iteration 55300, loss = 0.272625
I0515 01:14:42.723582 27330 solver.cpp:244]     Train net output #0: loss = 0.272628 (* 1 = 0.272628 loss)
I0515 01:14:42.723603 27330 sgd_solver.cpp:106] Iteration 55300, lr = 1e-05
I0515 01:23:13.004458 27330 solver.cpp:228] Iteration 55400, loss = 0.495647
I0515 01:23:13.004835 27330 solver.cpp:244]     Train net output #0: loss = 0.495649 (* 1 = 0.495649 loss)
I0515 01:23:13.004859 27330 sgd_solver.cpp:106] Iteration 55400, lr = 1e-05
I0515 01:31:39.687885 27330 solver.cpp:228] Iteration 55500, loss = 0.623438
I0515 01:31:39.688346 27330 solver.cpp:244]     Train net output #0: loss = 0.62344 (* 1 = 0.62344 loss)
I0515 01:31:39.688370 27330 sgd_solver.cpp:106] Iteration 55500, lr = 1e-05
I0515 01:32:02.103469 27330 solver.cpp:337] Iteration 55505, Testing net (#0)
I0515 01:32:02.103500 27330 net.cpp:685] Ignoring source layer ratemap
I0515 01:32:02.103507 27330 net.cpp:685] Ignoring source layer amsFeatures
I0515 01:34:53.409791 27330 solver.cpp:404]     Test net output #0: loss = 0.581906 (* 1 = 0.581906 loss)
I0515 01:42:58.237877 27330 solver.cpp:228] Iteration 55600, loss = 0.297562
I0515 01:42:58.238301 27330 solver.cpp:244]     Train net output #0: loss = 0.297565 (* 1 = 0.297565 loss)
I0515 01:42:58.238324 27330 sgd_solver.cpp:106] Iteration 55600, lr = 1e-05
I0515 01:51:26.131373 27330 solver.cpp:228] Iteration 55700, loss = 0.387225
I0515 01:51:26.131824 27330 solver.cpp:244]     Train net output #0: loss = 0.387227 (* 1 = 0.387227 loss)
I0515 01:51:26.131847 27330 sgd_solver.cpp:106] Iteration 55700, lr = 1e-05
I0515 01:59:54.272526 27330 solver.cpp:228] Iteration 55800, loss = 0.357337
I0515 01:59:54.272889 27330 solver.cpp:244]     Train net output #0: loss = 0.357339 (* 1 = 0.357339 loss)
I0515 01:59:54.272913 27330 sgd_solver.cpp:106] Iteration 55800, lr = 1e-05
I0515 02:08:15.439487 27330 solver.cpp:228] Iteration 55900, loss = 0.223508
I0515 02:08:15.439973 27330 solver.cpp:244]     Train net output #0: loss = 0.22351 (* 1 = 0.22351 loss)
I0515 02:08:15.439999 27330 sgd_solver.cpp:106] Iteration 55900, lr = 1e-05
I0515 02:16:41.388891 27330 solver.cpp:228] Iteration 56000, loss = 0.215427
I0515 02:16:41.389389 27330 solver.cpp:244]     Train net output #0: loss = 0.21543 (* 1 = 0.21543 loss)
I0515 02:16:41.389408 27330 sgd_solver.cpp:106] Iteration 56000, lr = 1e-05
I0515 02:24:53.698344 27330 solver.cpp:228] Iteration 56100, loss = 0.412735
I0515 02:24:53.698765 27330 solver.cpp:244]     Train net output #0: loss = 0.412737 (* 1 = 0.412737 loss)
I0515 02:24:53.698791 27330 sgd_solver.cpp:106] Iteration 56100, lr = 1e-05
I0515 02:33:10.144570 27330 solver.cpp:228] Iteration 56200, loss = 0.412979
I0515 02:33:10.145078 27330 solver.cpp:244]     Train net output #0: loss = 0.412982 (* 1 = 0.412982 loss)
I0515 02:33:10.145099 27330 sgd_solver.cpp:106] Iteration 56200, lr = 1e-05
I0515 02:41:52.004675 27330 solver.cpp:228] Iteration 56300, loss = 0.382334
I0515 02:41:52.005056 27330 solver.cpp:244]     Train net output #0: loss = 0.382337 (* 1 = 0.382337 loss)
I0515 02:41:52.005080 27330 sgd_solver.cpp:106] Iteration 56300, lr = 1e-05
I0515 02:50:03.849141 27330 solver.cpp:228] Iteration 56400, loss = 0.579944
I0515 02:50:03.849575 27330 solver.cpp:244]     Train net output #0: loss = 0.579946 (* 1 = 0.579946 loss)
I0515 02:50:03.849601 27330 sgd_solver.cpp:106] Iteration 56400, lr = 1e-05
I0515 02:58:26.325557 27330 solver.cpp:228] Iteration 56500, loss = 0.547012
I0515 02:58:26.325983 27330 solver.cpp:244]     Train net output #0: loss = 0.547014 (* 1 = 0.547014 loss)
I0515 02:58:26.326012 27330 sgd_solver.cpp:106] Iteration 56500, lr = 1e-05
I0515 03:06:46.701548 27330 solver.cpp:228] Iteration 56600, loss = 0.524534
I0515 03:06:46.701953 27330 solver.cpp:244]     Train net output #0: loss = 0.524536 (* 1 = 0.524536 loss)
I0515 03:06:46.701977 27330 sgd_solver.cpp:106] Iteration 56600, lr = 1e-05
I0515 03:15:16.425170 27330 solver.cpp:228] Iteration 56700, loss = 0.1505
I0515 03:15:16.425647 27330 solver.cpp:244]     Train net output #0: loss = 0.150503 (* 1 = 0.150503 loss)
I0515 03:15:16.425667 27330 sgd_solver.cpp:106] Iteration 56700, lr = 1e-05
I0515 03:23:51.502660 27330 solver.cpp:228] Iteration 56800, loss = 0.344172
I0515 03:23:51.503063 27330 solver.cpp:244]     Train net output #0: loss = 0.344175 (* 1 = 0.344175 loss)
I0515 03:23:51.503087 27330 sgd_solver.cpp:106] Iteration 56800, lr = 1e-05
I0515 03:32:13.081079 27330 solver.cpp:228] Iteration 56900, loss = 0.611969
I0515 03:32:13.081501 27330 solver.cpp:244]     Train net output #0: loss = 0.611971 (* 1 = 0.611971 loss)
I0515 03:32:13.081526 27330 sgd_solver.cpp:106] Iteration 56900, lr = 1e-05
I0515 03:40:48.248818 27330 solver.cpp:228] Iteration 57000, loss = 0.166083
I0515 03:40:48.249202 27330 solver.cpp:244]     Train net output #0: loss = 0.166086 (* 1 = 0.166086 loss)
I0515 03:40:48.249227 27330 sgd_solver.cpp:106] Iteration 57000, lr = 1e-05
I0515 03:49:21.864452 27330 solver.cpp:228] Iteration 57100, loss = 0.135142
I0515 03:49:21.864845 27330 solver.cpp:244]     Train net output #0: loss = 0.135145 (* 1 = 0.135145 loss)
I0515 03:49:21.864869 27330 sgd_solver.cpp:106] Iteration 57100, lr = 1e-05
I0515 03:57:54.070355 27330 solver.cpp:228] Iteration 57200, loss = 0.512813
I0515 03:57:54.070739 27330 solver.cpp:244]     Train net output #0: loss = 0.512815 (* 1 = 0.512815 loss)
I0515 03:57:54.070765 27330 sgd_solver.cpp:106] Iteration 57200, lr = 1e-05
I0515 04:06:18.888674 27330 solver.cpp:228] Iteration 57300, loss = 0.291644
I0515 04:06:18.889138 27330 solver.cpp:244]     Train net output #0: loss = 0.291647 (* 1 = 0.291647 loss)
I0515 04:06:18.889161 27330 sgd_solver.cpp:106] Iteration 57300, lr = 1e-05
I0515 04:14:49.168306 27330 solver.cpp:228] Iteration 57400, loss = 0.332692
I0515 04:14:49.168658 27330 solver.cpp:244]     Train net output #0: loss = 0.332695 (* 1 = 0.332695 loss)
I0515 04:14:49.168681 27330 sgd_solver.cpp:106] Iteration 57400, lr = 1e-05
I0515 04:23:06.275003 27330 solver.cpp:228] Iteration 57500, loss = 0.435739
I0515 04:23:06.275451 27330 solver.cpp:244]     Train net output #0: loss = 0.435741 (* 1 = 0.435741 loss)
I0515 04:23:06.275472 27330 sgd_solver.cpp:106] Iteration 57500, lr = 1e-05
I0515 04:31:20.795735 27330 solver.cpp:228] Iteration 57600, loss = 0.287167
I0515 04:31:20.796126 27330 solver.cpp:244]     Train net output #0: loss = 0.287169 (* 1 = 0.287169 loss)
I0515 04:31:20.796150 27330 sgd_solver.cpp:106] Iteration 57600, lr = 1e-05
I0515 04:39:49.308959 27330 solver.cpp:228] Iteration 57700, loss = 0.286114
I0515 04:39:49.309417 27330 solver.cpp:244]     Train net output #0: loss = 0.286116 (* 1 = 0.286116 loss)
I0515 04:39:49.309442 27330 sgd_solver.cpp:106] Iteration 57700, lr = 1e-05
I0515 04:48:19.862249 27330 solver.cpp:228] Iteration 57800, loss = 0.226416
I0515 04:48:19.862711 27330 solver.cpp:244]     Train net output #0: loss = 0.226418 (* 1 = 0.226418 loss)
I0515 04:48:19.862742 27330 sgd_solver.cpp:106] Iteration 57800, lr = 1e-05
I0515 04:56:49.882498 27330 solver.cpp:228] Iteration 57900, loss = 0.198833
I0515 04:56:49.882917 27330 solver.cpp:244]     Train net output #0: loss = 0.198835 (* 1 = 0.198835 loss)
I0515 04:56:49.882948 27330 sgd_solver.cpp:106] Iteration 57900, lr = 1e-05
I0515 05:05:12.419944 27330 solver.cpp:228] Iteration 58000, loss = 0.242614
I0515 05:05:12.420348 27330 solver.cpp:244]     Train net output #0: loss = 0.242616 (* 1 = 0.242616 loss)
I0515 05:05:12.420373 27330 sgd_solver.cpp:106] Iteration 58000, lr = 1e-05
I0515 05:13:28.367159 27330 solver.cpp:228] Iteration 58100, loss = 0.266152
I0515 05:13:28.367574 27330 solver.cpp:244]     Train net output #0: loss = 0.266154 (* 1 = 0.266154 loss)
I0515 05:13:28.367599 27330 sgd_solver.cpp:106] Iteration 58100, lr = 1e-05
I0515 05:21:53.001497 27330 solver.cpp:228] Iteration 58200, loss = 0.163745
I0515 05:21:53.001925 27330 solver.cpp:244]     Train net output #0: loss = 0.163747 (* 1 = 0.163747 loss)
I0515 05:21:53.001950 27330 sgd_solver.cpp:106] Iteration 58200, lr = 1e-05
I0515 05:30:06.604862 27330 solver.cpp:228] Iteration 58300, loss = 0.205141
I0515 05:30:06.605345 27330 solver.cpp:244]     Train net output #0: loss = 0.205143 (* 1 = 0.205143 loss)
I0515 05:30:06.605370 27330 sgd_solver.cpp:106] Iteration 58300, lr = 1e-05
I0515 05:38:24.312021 27330 solver.cpp:228] Iteration 58400, loss = 0.4187
I0515 05:38:24.312461 27330 solver.cpp:244]     Train net output #0: loss = 0.418702 (* 1 = 0.418702 loss)
I0515 05:38:24.312487 27330 sgd_solver.cpp:106] Iteration 58400, lr = 1e-05
I0515 05:46:43.130122 27330 solver.cpp:228] Iteration 58500, loss = 0.14143
I0515 05:46:43.130558 27330 solver.cpp:244]     Train net output #0: loss = 0.141432 (* 1 = 0.141432 loss)
I0515 05:46:43.130583 27330 sgd_solver.cpp:106] Iteration 58500, lr = 1e-05
I0515 05:54:48.268466 27330 solver.cpp:228] Iteration 58600, loss = 0.29652
I0515 05:54:48.268893 27330 solver.cpp:244]     Train net output #0: loss = 0.296523 (* 1 = 0.296523 loss)
I0515 05:54:48.268918 27330 sgd_solver.cpp:106] Iteration 58600, lr = 1e-05
I0515 06:03:12.818742 27330 solver.cpp:228] Iteration 58700, loss = 0.235495
I0515 06:03:12.819193 27330 solver.cpp:244]     Train net output #0: loss = 0.235498 (* 1 = 0.235498 loss)
I0515 06:03:12.819218 27330 sgd_solver.cpp:106] Iteration 58700, lr = 1e-05
I0515 06:08:49.132217 27330 solver.cpp:337] Iteration 58770, Testing net (#0)
I0515 06:08:49.132642 27330 net.cpp:685] Ignoring source layer ratemap
I0515 06:08:49.132663 27330 net.cpp:685] Ignoring source layer amsFeatures
I0515 06:11:40.430220 27330 solver.cpp:404]     Test net output #0: loss = 0.571146 (* 1 = 0.571146 loss)
I0515 06:14:20.438678 27330 solver.cpp:228] Iteration 58800, loss = 0.269795
I0515 06:14:20.439118 27330 solver.cpp:244]     Train net output #0: loss = 0.269798 (* 1 = 0.269798 loss)
I0515 06:14:20.439143 27330 sgd_solver.cpp:106] Iteration 58800, lr = 1e-05
I0515 06:22:35.376333 27330 solver.cpp:228] Iteration 58900, loss = 0.313695
I0515 06:22:35.376734 27330 solver.cpp:244]     Train net output #0: loss = 0.313697 (* 1 = 0.313697 loss)
I0515 06:22:35.376760 27330 sgd_solver.cpp:106] Iteration 58900, lr = 1e-05
I0515 06:30:58.942822 27330 solver.cpp:228] Iteration 59000, loss = 0.429917
I0515 06:30:58.943243 27330 solver.cpp:244]     Train net output #0: loss = 0.42992 (* 1 = 0.42992 loss)
I0515 06:30:58.943258 27330 sgd_solver.cpp:106] Iteration 59000, lr = 1e-05
I0515 06:39:16.582084 27330 solver.cpp:228] Iteration 59100, loss = 0.286732
I0515 06:39:16.866086 27330 solver.cpp:244]     Train net output #0: loss = 0.286734 (* 1 = 0.286734 loss)
I0515 06:39:16.866118 27330 sgd_solver.cpp:106] Iteration 59100, lr = 1e-05
I0515 06:47:36.238826 27330 solver.cpp:228] Iteration 59200, loss = 0.272555
I0515 06:47:36.239151 27330 solver.cpp:244]     Train net output #0: loss = 0.272557 (* 1 = 0.272557 loss)
I0515 06:47:36.239192 27330 sgd_solver.cpp:106] Iteration 59200, lr = 1e-05
I0515 06:56:01.750181 27330 solver.cpp:228] Iteration 59300, loss = 0.343477
I0515 06:56:01.750596 27330 solver.cpp:244]     Train net output #0: loss = 0.343479 (* 1 = 0.343479 loss)
I0515 06:56:01.750619 27330 sgd_solver.cpp:106] Iteration 59300, lr = 1e-05
I0515 07:04:26.111351 27330 solver.cpp:228] Iteration 59400, loss = 0.244902
I0515 07:04:26.111778 27330 solver.cpp:244]     Train net output #0: loss = 0.244905 (* 1 = 0.244905 loss)
I0515 07:04:26.111802 27330 sgd_solver.cpp:106] Iteration 59400, lr = 1e-05
I0515 07:12:44.294452 27330 solver.cpp:228] Iteration 59500, loss = 0.370002
I0515 07:12:44.294888 27330 solver.cpp:244]     Train net output #0: loss = 0.370005 (* 1 = 0.370005 loss)
I0515 07:12:44.294914 27330 sgd_solver.cpp:106] Iteration 59500, lr = 1e-05
I0515 07:21:10.833580 27330 solver.cpp:228] Iteration 59600, loss = 0.469369
I0515 07:21:10.834003 27330 solver.cpp:244]     Train net output #0: loss = 0.469371 (* 1 = 0.469371 loss)
I0515 07:21:10.834028 27330 sgd_solver.cpp:106] Iteration 59600, lr = 1e-05
I0515 07:29:13.433265 27330 solver.cpp:228] Iteration 59700, loss = 0.23317
I0515 07:29:13.433730 27330 solver.cpp:244]     Train net output #0: loss = 0.233172 (* 1 = 0.233172 loss)
I0515 07:29:13.433754 27330 sgd_solver.cpp:106] Iteration 59700, lr = 1e-05
I0515 07:37:25.210815 27330 solver.cpp:228] Iteration 59800, loss = 0.165263
I0515 07:37:25.211138 27330 solver.cpp:244]     Train net output #0: loss = 0.165266 (* 1 = 0.165266 loss)
I0515 07:37:25.211153 27330 sgd_solver.cpp:106] Iteration 59800, lr = 1e-05
I0515 07:45:47.476078 27330 solver.cpp:228] Iteration 59900, loss = 0.190145
I0515 07:45:47.476459 27330 solver.cpp:244]     Train net output #0: loss = 0.190148 (* 1 = 0.190148 loss)
I0515 07:45:47.476483 27330 sgd_solver.cpp:106] Iteration 59900, lr = 1e-05
I0515 07:54:00.535367 27330 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_60000.caffemodel
I0515 07:54:00.694973 27330 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_60000.solverstate
I0515 07:54:05.740180 27330 solver.cpp:228] Iteration 60000, loss = 0.196359
I0515 07:54:05.740231 27330 solver.cpp:244]     Train net output #0: loss = 0.196362 (* 1 = 0.196362 loss)
I0515 07:54:05.740242 27330 sgd_solver.cpp:106] Iteration 60000, lr = 1e-06
I0515 08:02:29.191555 27330 solver.cpp:228] Iteration 60100, loss = 0.274754
I0515 08:02:29.191967 27330 solver.cpp:244]     Train net output #0: loss = 0.274757 (* 1 = 0.274757 loss)
I0515 08:02:29.191990 27330 sgd_solver.cpp:106] Iteration 60100, lr = 1e-06
I0515 08:10:40.908161 27330 solver.cpp:228] Iteration 60200, loss = 0.273888
I0515 08:10:40.908607 27330 solver.cpp:244]     Train net output #0: loss = 0.27389 (* 1 = 0.27389 loss)
I0515 08:10:40.908632 27330 sgd_solver.cpp:106] Iteration 60200, lr = 1e-06
I0515 08:18:51.937214 27330 solver.cpp:228] Iteration 60300, loss = 0.300142
I0515 08:18:51.937685 27330 solver.cpp:244]     Train net output #0: loss = 0.300145 (* 1 = 0.300145 loss)
I0515 08:18:51.937705 27330 sgd_solver.cpp:106] Iteration 60300, lr = 1e-06
I0515 08:27:01.944337 27330 solver.cpp:228] Iteration 60400, loss = 0.234587
I0515 08:27:01.944756 27330 solver.cpp:244]     Train net output #0: loss = 0.23459 (* 1 = 0.23459 loss)
I0515 08:27:01.944782 27330 sgd_solver.cpp:106] Iteration 60400, lr = 1e-06
I0515 08:35:28.876617 27330 solver.cpp:228] Iteration 60500, loss = 0.36333
I0515 08:35:28.877084 27330 solver.cpp:244]     Train net output #0: loss = 0.363332 (* 1 = 0.363332 loss)
I0515 08:35:28.877109 27330 sgd_solver.cpp:106] Iteration 60500, lr = 1e-06
I0515 08:43:42.351158 27330 solver.cpp:228] Iteration 60600, loss = 0.257927
I0515 08:43:42.351593 27330 solver.cpp:244]     Train net output #0: loss = 0.25793 (* 1 = 0.25793 loss)
I0515 08:43:42.351619 27330 sgd_solver.cpp:106] Iteration 60600, lr = 1e-06
I0515 08:52:09.941921 27330 solver.cpp:228] Iteration 60700, loss = 0.345506
I0515 08:52:09.942361 27330 solver.cpp:244]     Train net output #0: loss = 0.345509 (* 1 = 0.345509 loss)
I0515 08:52:09.942389 27330 sgd_solver.cpp:106] Iteration 60700, lr = 1e-06
I0515 09:00:35.220260 27330 solver.cpp:228] Iteration 60800, loss = 0.17928
I0515 09:00:35.220639 27330 solver.cpp:244]     Train net output #0: loss = 0.179283 (* 1 = 0.179283 loss)
I0515 09:00:35.220652 27330 sgd_solver.cpp:106] Iteration 60800, lr = 1e-06
I0515 09:09:11.694445 27330 solver.cpp:228] Iteration 60900, loss = 0.286465
I0515 09:09:11.694864 27330 solver.cpp:244]     Train net output #0: loss = 0.286468 (* 1 = 0.286468 loss)
I0515 09:09:11.694890 27330 sgd_solver.cpp:106] Iteration 60900, lr = 1e-06
I0515 09:17:23.918988 27330 solver.cpp:228] Iteration 61000, loss = 0.669711
I0515 09:17:23.919440 27330 solver.cpp:244]     Train net output #0: loss = 0.669714 (* 1 = 0.669714 loss)
I0515 09:17:23.919464 27330 sgd_solver.cpp:106] Iteration 61000, lr = 1e-06
I0515 09:25:32.204277 27330 solver.cpp:228] Iteration 61100, loss = 0.262874
I0515 09:25:32.204685 27330 solver.cpp:244]     Train net output #0: loss = 0.262877 (* 1 = 0.262877 loss)
I0515 09:25:32.204710 27330 sgd_solver.cpp:106] Iteration 61100, lr = 1e-06
I0515 09:34:04.949497 27330 solver.cpp:228] Iteration 61200, loss = 0.378409
I0515 09:34:04.949903 27330 solver.cpp:244]     Train net output #0: loss = 0.378412 (* 1 = 0.378412 loss)
I0515 09:34:04.949928 27330 sgd_solver.cpp:106] Iteration 61200, lr = 1e-06
I0515 09:42:20.012483 27330 solver.cpp:228] Iteration 61300, loss = 0.256388
I0515 09:42:20.012929 27330 solver.cpp:244]     Train net output #0: loss = 0.25639 (* 1 = 0.25639 loss)
I0515 09:42:20.012954 27330 sgd_solver.cpp:106] Iteration 61300, lr = 1e-06
I0515 09:50:40.526634 27330 solver.cpp:228] Iteration 61400, loss = 0.571857
I0515 09:50:40.527050 27330 solver.cpp:244]     Train net output #0: loss = 0.57186 (* 1 = 0.57186 loss)
I0515 09:50:40.527076 27330 sgd_solver.cpp:106] Iteration 61400, lr = 1e-06
I0515 09:58:41.608182 27330 solver.cpp:228] Iteration 61500, loss = 0.288878
I0515 09:58:41.608649 27330 solver.cpp:244]     Train net output #0: loss = 0.288881 (* 1 = 0.288881 loss)
I0515 09:58:41.608669 27330 sgd_solver.cpp:106] Iteration 61500, lr = 1e-06
I0515 10:07:06.887435 27330 solver.cpp:228] Iteration 61600, loss = 0.318381
I0515 10:07:06.887838 27330 solver.cpp:244]     Train net output #0: loss = 0.318383 (* 1 = 0.318383 loss)
I0515 10:07:06.887862 27330 sgd_solver.cpp:106] Iteration 61600, lr = 1e-06
I0515 10:15:27.374912 27330 solver.cpp:228] Iteration 61700, loss = 0.467582
I0515 10:15:27.375332 27330 solver.cpp:244]     Train net output #0: loss = 0.467585 (* 1 = 0.467585 loss)
I0515 10:15:27.375365 27330 sgd_solver.cpp:106] Iteration 61700, lr = 1e-06
I0515 10:23:30.203250 27330 solver.cpp:228] Iteration 61800, loss = 0.163356
I0515 10:23:30.203698 27330 solver.cpp:244]     Train net output #0: loss = 0.163359 (* 1 = 0.163359 loss)
I0515 10:23:30.203722 27330 sgd_solver.cpp:106] Iteration 61800, lr = 1e-06
I0515 10:31:54.550609 27330 solver.cpp:228] Iteration 61900, loss = 0.53357
I0515 10:31:54.551057 27330 solver.cpp:244]     Train net output #0: loss = 0.533572 (* 1 = 0.533572 loss)
I0515 10:31:54.551077 27330 sgd_solver.cpp:106] Iteration 61900, lr = 1e-06
I0515 10:40:26.608852 27330 solver.cpp:228] Iteration 62000, loss = 0.179796
I0515 10:40:26.609254 27330 solver.cpp:244]     Train net output #0: loss = 0.179799 (* 1 = 0.179799 loss)
I0515 10:40:26.609278 27330 sgd_solver.cpp:106] Iteration 62000, lr = 1e-06
I0515 10:43:16.778352 27330 solver.cpp:337] Iteration 62035, Testing net (#0)
I0515 10:43:16.778739 27330 net.cpp:685] Ignoring source layer ratemap
I0515 10:43:16.778758 27330 net.cpp:685] Ignoring source layer amsFeatures
I0515 10:46:08.107854 27330 solver.cpp:404]     Test net output #0: loss = 0.573536 (* 1 = 0.573536 loss)
I0515 10:51:35.485894 27330 solver.cpp:228] Iteration 62100, loss = 0.602564
I0515 10:51:35.486306 27330 solver.cpp:244]     Train net output #0: loss = 0.602567 (* 1 = 0.602567 loss)
I0515 10:51:35.486330 27330 sgd_solver.cpp:106] Iteration 62100, lr = 1e-06
I0515 10:59:51.173816 27330 solver.cpp:228] Iteration 62200, loss = 0.440794
I0515 10:59:51.174217 27330 solver.cpp:244]     Train net output #0: loss = 0.440797 (* 1 = 0.440797 loss)
I0515 10:59:51.174247 27330 sgd_solver.cpp:106] Iteration 62200, lr = 1e-06
I0515 11:08:09.138423 27330 solver.cpp:228] Iteration 62300, loss = 0.290746
I0515 11:08:09.138883 27330 solver.cpp:244]     Train net output #0: loss = 0.290748 (* 1 = 0.290748 loss)
I0515 11:08:09.138908 27330 sgd_solver.cpp:106] Iteration 62300, lr = 1e-06
I0515 11:16:18.116660 27330 solver.cpp:228] Iteration 62400, loss = 0.244745
I0515 11:16:18.117034 27330 solver.cpp:244]     Train net output #0: loss = 0.244748 (* 1 = 0.244748 loss)
I0515 11:16:18.117058 27330 sgd_solver.cpp:106] Iteration 62400, lr = 1e-06
I0515 11:24:39.436969 27330 solver.cpp:228] Iteration 62500, loss = 0.307797
I0515 11:24:39.437430 27330 solver.cpp:244]     Train net output #0: loss = 0.307799 (* 1 = 0.307799 loss)
I0515 11:24:39.437451 27330 sgd_solver.cpp:106] Iteration 62500, lr = 1e-06
I0515 11:33:06.422842 27330 solver.cpp:228] Iteration 62600, loss = 0.309482
I0515 11:33:06.423274 27330 solver.cpp:244]     Train net output #0: loss = 0.309485 (* 1 = 0.309485 loss)
I0515 11:33:06.423297 27330 sgd_solver.cpp:106] Iteration 62600, lr = 1e-06
I0515 11:41:20.839334 27330 solver.cpp:228] Iteration 62700, loss = 0.240062
I0515 11:41:20.839758 27330 solver.cpp:244]     Train net output #0: loss = 0.240065 (* 1 = 0.240065 loss)
I0515 11:41:20.839787 27330 sgd_solver.cpp:106] Iteration 62700, lr = 1e-06
I0515 11:49:41.311600 27330 solver.cpp:228] Iteration 62800, loss = 0.410954
I0515 11:49:41.312011 27330 solver.cpp:244]     Train net output #0: loss = 0.410956 (* 1 = 0.410956 loss)
I0515 11:49:41.312036 27330 sgd_solver.cpp:106] Iteration 62800, lr = 1e-06
I0515 11:58:02.722293 27330 solver.cpp:228] Iteration 62900, loss = 0.653131
I0515 11:58:02.722789 27330 solver.cpp:244]     Train net output #0: loss = 0.653133 (* 1 = 0.653133 loss)
I0515 11:58:02.722813 27330 sgd_solver.cpp:106] Iteration 62900, lr = 1e-06
I0515 12:06:15.824777 27330 solver.cpp:228] Iteration 63000, loss = 0.481162
I0515 12:06:15.825234 27330 solver.cpp:244]     Train net output #0: loss = 0.481164 (* 1 = 0.481164 loss)
I0515 12:06:15.825254 27330 sgd_solver.cpp:106] Iteration 63000, lr = 1e-06
I0515 12:14:24.867468 27330 solver.cpp:228] Iteration 63100, loss = 0.242573
I0515 12:14:24.867872 27330 solver.cpp:244]     Train net output #0: loss = 0.242575 (* 1 = 0.242575 loss)
I0515 12:14:24.867902 27330 sgd_solver.cpp:106] Iteration 63100, lr = 1e-06
I0515 12:22:53.861768 27330 solver.cpp:228] Iteration 63200, loss = 0.370913
I0515 12:22:53.862231 27330 solver.cpp:244]     Train net output #0: loss = 0.370916 (* 1 = 0.370916 loss)
I0515 12:22:53.862254 27330 sgd_solver.cpp:106] Iteration 63200, lr = 1e-06
I0515 12:31:12.033017 27330 solver.cpp:228] Iteration 63300, loss = 0.257454
I0515 12:31:12.033409 27330 solver.cpp:244]     Train net output #0: loss = 0.257456 (* 1 = 0.257456 loss)
I0515 12:31:12.033434 27330 sgd_solver.cpp:106] Iteration 63300, lr = 1e-06
I0515 12:39:23.742738 27330 solver.cpp:228] Iteration 63400, loss = 0.403061
I0515 12:39:23.743155 27330 solver.cpp:244]     Train net output #0: loss = 0.403064 (* 1 = 0.403064 loss)
I0515 12:39:23.743192 27330 sgd_solver.cpp:106] Iteration 63400, lr = 1e-06
I0515 12:47:56.026664 27330 solver.cpp:228] Iteration 63500, loss = 0.321309
I0515 12:47:56.027035 27330 solver.cpp:244]     Train net output #0: loss = 0.321311 (* 1 = 0.321311 loss)
I0515 12:47:56.027060 27330 sgd_solver.cpp:106] Iteration 63500, lr = 1e-06
I0515 12:56:12.606665 27330 solver.cpp:228] Iteration 63600, loss = 0.337734
I0515 12:56:12.607146 27330 solver.cpp:244]     Train net output #0: loss = 0.337736 (* 1 = 0.337736 loss)
I0515 12:56:12.607213 27330 sgd_solver.cpp:106] Iteration 63600, lr = 1e-06
I0515 13:04:37.909692 27330 solver.cpp:228] Iteration 63700, loss = 0.346364
I0515 13:04:37.910065 27330 solver.cpp:244]     Train net output #0: loss = 0.346367 (* 1 = 0.346367 loss)
I0515 13:04:37.910090 27330 sgd_solver.cpp:106] Iteration 63700, lr = 1e-06
I0515 13:12:54.999707 27330 solver.cpp:228] Iteration 63800, loss = 0.415463
I0515 13:12:55.000116 27330 solver.cpp:244]     Train net output #0: loss = 0.415466 (* 1 = 0.415466 loss)
I0515 13:12:55.000145 27330 sgd_solver.cpp:106] Iteration 63800, lr = 1e-06
I0515 13:21:02.749879 27330 solver.cpp:228] Iteration 63900, loss = 0.491113
I0515 13:21:02.750349 27330 solver.cpp:244]     Train net output #0: loss = 0.491115 (* 1 = 0.491115 loss)
I0515 13:21:02.750368 27330 sgd_solver.cpp:106] Iteration 63900, lr = 1e-06
I0515 13:29:31.782986 27330 solver.cpp:228] Iteration 64000, loss = 0.347988
I0515 13:29:31.783416 27330 solver.cpp:244]     Train net output #0: loss = 0.34799 (* 1 = 0.34799 loss)
I0515 13:29:31.783440 27330 sgd_solver.cpp:106] Iteration 64000, lr = 1e-06
I0515 13:37:55.550773 27330 solver.cpp:228] Iteration 64100, loss = 0.327515
I0515 13:37:55.551204 27330 solver.cpp:244]     Train net output #0: loss = 0.327518 (* 1 = 0.327518 loss)
I0515 13:37:55.551237 27330 sgd_solver.cpp:106] Iteration 64100, lr = 1e-06
I0515 13:46:02.005919 27330 solver.cpp:228] Iteration 64200, loss = 0.385621
I0515 13:46:02.006340 27330 solver.cpp:244]     Train net output #0: loss = 0.385623 (* 1 = 0.385623 loss)
I0515 13:46:02.006366 27330 sgd_solver.cpp:106] Iteration 64200, lr = 1e-06
I0515 13:54:22.662574 27330 solver.cpp:228] Iteration 64300, loss = 0.301962
I0515 13:54:22.663022 27330 solver.cpp:244]     Train net output #0: loss = 0.301964 (* 1 = 0.301964 loss)
I0515 13:54:22.663043 27330 sgd_solver.cpp:106] Iteration 64300, lr = 1e-06
I0515 14:02:50.833017 27330 solver.cpp:228] Iteration 64400, loss = 0.215707
I0515 14:02:50.833420 27330 solver.cpp:244]     Train net output #0: loss = 0.21571 (* 1 = 0.21571 loss)
I0515 14:02:50.833451 27330 sgd_solver.cpp:106] Iteration 64400, lr = 1e-06
I0515 14:11:04.966493 27330 solver.cpp:228] Iteration 64500, loss = 0.228823
I0515 14:11:04.966956 27330 solver.cpp:244]     Train net output #0: loss = 0.228826 (* 1 = 0.228826 loss)
I0515 14:11:04.966986 27330 sgd_solver.cpp:106] Iteration 64500, lr = 1e-06
I0515 14:19:10.946018 27330 solver.cpp:228] Iteration 64600, loss = 0.155679
I0515 14:19:10.946451 27330 solver.cpp:244]     Train net output #0: loss = 0.155682 (* 1 = 0.155682 loss)
I0515 14:19:10.946475 27330 sgd_solver.cpp:106] Iteration 64600, lr = 1e-06
I0515 14:27:41.480832 27330 solver.cpp:228] Iteration 64700, loss = 0.316208
I0515 14:27:41.481308 27330 solver.cpp:244]     Train net output #0: loss = 0.316211 (* 1 = 0.316211 loss)
I0515 14:27:41.481330 27330 sgd_solver.cpp:106] Iteration 64700, lr = 1e-06
I0515 14:36:02.992915 27330 solver.cpp:228] Iteration 64800, loss = 0.276042
I0515 14:36:02.993343 27330 solver.cpp:244]     Train net output #0: loss = 0.276045 (* 1 = 0.276045 loss)
I0515 14:36:02.993368 27330 sgd_solver.cpp:106] Iteration 64800, lr = 1e-06
I0515 14:44:10.328344 27330 solver.cpp:228] Iteration 64900, loss = 0.402585
I0515 14:44:10.328815 27330 solver.cpp:244]     Train net output #0: loss = 0.402588 (* 1 = 0.402588 loss)
I0515 14:44:10.328836 27330 sgd_solver.cpp:106] Iteration 64900, lr = 1e-06
I0515 14:52:33.083995 27330 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_65000.caffemodel
I0515 14:52:33.282110 27330 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_65000.solverstate
I0515 14:52:38.922135 27330 solver.cpp:228] Iteration 65000, loss = 0.345115
I0515 14:52:38.922181 27330 solver.cpp:244]     Train net output #0: loss = 0.345117 (* 1 = 0.345117 loss)
I0515 14:52:38.922204 27330 sgd_solver.cpp:106] Iteration 65000, lr = 1e-06
I0515 15:01:07.191375 27330 solver.cpp:228] Iteration 65100, loss = 0.368133
I0515 15:01:07.191833 27330 solver.cpp:244]     Train net output #0: loss = 0.368136 (* 1 = 0.368136 loss)
I0515 15:01:07.191854 27330 sgd_solver.cpp:106] Iteration 65100, lr = 1e-06
I0515 15:09:27.611882 27330 solver.cpp:228] Iteration 65200, loss = 0.181796
I0515 15:09:27.612318 27330 solver.cpp:244]     Train net output #0: loss = 0.181799 (* 1 = 0.181799 loss)
I0515 15:09:27.612341 27330 sgd_solver.cpp:106] Iteration 65200, lr = 1e-06
I0515 15:17:56.148890 27330 solver.cpp:337] Iteration 65300, Testing net (#0)
I0515 15:17:56.149304 27330 net.cpp:685] Ignoring source layer ratemap
I0515 15:17:56.149322 27330 net.cpp:685] Ignoring source layer amsFeatures
I0515 15:20:47.450989 27330 solver.cpp:404]     Test net output #0: loss = 0.580003 (* 1 = 0.580003 loss)
I0515 15:20:52.031728 27330 solver.cpp:228] Iteration 65300, loss = 0.373659
I0515 15:20:52.031782 27330 solver.cpp:244]     Train net output #0: loss = 0.373662 (* 1 = 0.373662 loss)
I0515 15:20:52.031793 27330 sgd_solver.cpp:106] Iteration 65300, lr = 1e-06
I0515 15:28:54.547300 27330 solver.cpp:228] Iteration 65400, loss = 0.289238
I0515 15:28:54.547674 27330 solver.cpp:244]     Train net output #0: loss = 0.289241 (* 1 = 0.289241 loss)
I0515 15:28:54.547686 27330 sgd_solver.cpp:106] Iteration 65400, lr = 1e-06
I0515 15:37:10.516551 27330 solver.cpp:228] Iteration 65500, loss = 0.346736
I0515 15:37:10.516989 27330 solver.cpp:244]     Train net output #0: loss = 0.346739 (* 1 = 0.346739 loss)
I0515 15:37:10.517019 27330 sgd_solver.cpp:106] Iteration 65500, lr = 1e-06
I0515 15:45:23.378865 27330 solver.cpp:228] Iteration 65600, loss = 0.243854
I0515 15:45:23.379323 27330 solver.cpp:244]     Train net output #0: loss = 0.243857 (* 1 = 0.243857 loss)
I0515 15:45:23.379345 27330 sgd_solver.cpp:106] Iteration 65600, lr = 1e-06
I0515 15:53:37.603920 27330 solver.cpp:228] Iteration 65700, loss = 0.381547
I0515 15:53:37.604353 27330 solver.cpp:244]     Train net output #0: loss = 0.38155 (* 1 = 0.38155 loss)
I0515 15:53:37.604367 27330 sgd_solver.cpp:106] Iteration 65700, lr = 1e-06
I0515 16:02:04.371690 27330 solver.cpp:228] Iteration 65800, loss = 0.141547
I0515 16:02:04.372079 27330 solver.cpp:244]     Train net output #0: loss = 0.14155 (* 1 = 0.14155 loss)
I0515 16:02:04.372097 27330 sgd_solver.cpp:106] Iteration 65800, lr = 1e-06
I0515 16:10:41.455054 27330 solver.cpp:228] Iteration 65900, loss = 0.180907
I0515 16:10:41.455536 27330 solver.cpp:244]     Train net output #0: loss = 0.18091 (* 1 = 0.18091 loss)
I0515 16:10:41.455566 27330 sgd_solver.cpp:106] Iteration 65900, lr = 1e-06
I0515 16:19:07.575019 27330 solver.cpp:228] Iteration 66000, loss = 0.163936
I0515 16:19:07.575438 27330 solver.cpp:244]     Train net output #0: loss = 0.163939 (* 1 = 0.163939 loss)
I0515 16:19:07.575462 27330 sgd_solver.cpp:106] Iteration 66000, lr = 1e-06
I0515 16:27:30.459480 27330 solver.cpp:228] Iteration 66100, loss = 0.192255
I0515 16:27:30.459856 27330 solver.cpp:244]     Train net output #0: loss = 0.192258 (* 1 = 0.192258 loss)
I0515 16:27:30.459875 27330 sgd_solver.cpp:106] Iteration 66100, lr = 1e-06
I0515 16:35:53.551103 27330 solver.cpp:228] Iteration 66200, loss = 0.263135
I0515 16:35:53.551558 27330 solver.cpp:244]     Train net output #0: loss = 0.263137 (* 1 = 0.263137 loss)
I0515 16:35:53.551581 27330 sgd_solver.cpp:106] Iteration 66200, lr = 1e-06
I0515 16:44:27.862751 27330 solver.cpp:228] Iteration 66300, loss = 0.316344
I0515 16:44:27.863209 27330 solver.cpp:244]     Train net output #0: loss = 0.316346 (* 1 = 0.316346 loss)
I0515 16:44:27.863240 27330 sgd_solver.cpp:106] Iteration 66300, lr = 1e-06
I0515 16:52:41.009253 27330 solver.cpp:228] Iteration 66400, loss = 0.421275
I0515 16:52:41.009683 27330 solver.cpp:244]     Train net output #0: loss = 0.421278 (* 1 = 0.421278 loss)
I0515 16:52:41.009712 27330 sgd_solver.cpp:106] Iteration 66400, lr = 1e-06
I0515 17:00:43.657316 27330 solver.cpp:228] Iteration 66500, loss = 0.493245
I0515 17:00:43.657759 27330 solver.cpp:244]     Train net output #0: loss = 0.493247 (* 1 = 0.493247 loss)
I0515 17:00:43.657783 27330 sgd_solver.cpp:106] Iteration 66500, lr = 1e-06
I0515 17:09:09.469789 27330 solver.cpp:228] Iteration 66600, loss = 0.239175
I0515 17:09:09.470139 27330 solver.cpp:244]     Train net output #0: loss = 0.239178 (* 1 = 0.239178 loss)
I0515 17:09:09.470151 27330 sgd_solver.cpp:106] Iteration 66600, lr = 1e-06
I0515 17:17:30.132763 27330 solver.cpp:228] Iteration 66700, loss = 0.242957
I0515 17:17:30.133219 27330 solver.cpp:244]     Train net output #0: loss = 0.24296 (* 1 = 0.24296 loss)
I0515 17:17:30.133240 27330 sgd_solver.cpp:106] Iteration 66700, lr = 1e-06
I0515 17:25:51.958353 27330 solver.cpp:228] Iteration 66800, loss = 0.482733
I0515 17:25:51.958760 27330 solver.cpp:244]     Train net output #0: loss = 0.482736 (* 1 = 0.482736 loss)
I0515 17:25:51.958783 27330 sgd_solver.cpp:106] Iteration 66800, lr = 1e-06
I0515 17:34:14.156251 27330 solver.cpp:228] Iteration 66900, loss = 0.437887
I0515 17:34:14.156683 27330 solver.cpp:244]     Train net output #0: loss = 0.43789 (* 1 = 0.43789 loss)
I0515 17:34:14.156708 27330 sgd_solver.cpp:106] Iteration 66900, lr = 1e-06
I0515 17:42:40.172843 27330 solver.cpp:228] Iteration 67000, loss = 0.131098
I0515 17:42:40.173214 27330 solver.cpp:244]     Train net output #0: loss = 0.131101 (* 1 = 0.131101 loss)
I0515 17:42:40.173230 27330 sgd_solver.cpp:106] Iteration 67000, lr = 1e-06
I0515 17:51:06.003273 27330 solver.cpp:228] Iteration 67100, loss = 0.281994
I0515 17:51:06.003726 27330 solver.cpp:244]     Train net output #0: loss = 0.281996 (* 1 = 0.281996 loss)
I0515 17:51:06.003751 27330 sgd_solver.cpp:106] Iteration 67100, lr = 1e-06
I0515 17:59:27.013788 27330 solver.cpp:228] Iteration 67200, loss = 0.346676
I0515 17:59:27.014222 27330 solver.cpp:244]     Train net output #0: loss = 0.346679 (* 1 = 0.346679 loss)
I0515 17:59:27.014242 27330 sgd_solver.cpp:106] Iteration 67200, lr = 1e-06
I0515 18:07:51.038318 27330 solver.cpp:228] Iteration 67300, loss = 0.32097
I0515 18:07:51.038739 27330 solver.cpp:244]     Train net output #0: loss = 0.320972 (* 1 = 0.320972 loss)
I0515 18:07:51.038763 27330 sgd_solver.cpp:106] Iteration 67300, lr = 1e-06
I0515 18:15:48.728622 27330 solver.cpp:228] Iteration 67400, loss = 0.256034
I0515 18:15:48.728968 27330 solver.cpp:244]     Train net output #0: loss = 0.256036 (* 1 = 0.256036 loss)
I0515 18:15:48.728993 27330 sgd_solver.cpp:106] Iteration 67400, lr = 1e-06
I0515 18:24:04.240342 27330 solver.cpp:228] Iteration 67500, loss = 0.124941
I0515 18:24:04.240744 27330 solver.cpp:244]     Train net output #0: loss = 0.124943 (* 1 = 0.124943 loss)
I0515 18:24:04.240768 27330 sgd_solver.cpp:106] Iteration 67500, lr = 1e-06
I0515 18:32:25.265331 27330 solver.cpp:228] Iteration 67600, loss = 0.551125
I0515 18:32:25.265776 27330 solver.cpp:244]     Train net output #0: loss = 0.551127 (* 1 = 0.551127 loss)
I0515 18:32:25.265797 27330 sgd_solver.cpp:106] Iteration 67600, lr = 1e-06
I0515 18:40:40.377255 27330 solver.cpp:228] Iteration 67700, loss = 0.204997
I0515 18:40:40.377708 27330 solver.cpp:244]     Train net output #0: loss = 0.205 (* 1 = 0.205 loss)
I0515 18:40:40.377734 27330 sgd_solver.cpp:106] Iteration 67700, lr = 1e-06
I0515 18:49:05.975409 27330 solver.cpp:228] Iteration 67800, loss = 0.357753
I0515 18:49:05.975827 27330 solver.cpp:244]     Train net output #0: loss = 0.357756 (* 1 = 0.357756 loss)
I0515 18:49:05.975852 27330 sgd_solver.cpp:106] Iteration 67800, lr = 1e-06
I0515 18:57:38.103615 27330 solver.cpp:228] Iteration 67900, loss = 0.215838
I0515 18:57:38.104079 27330 solver.cpp:244]     Train net output #0: loss = 0.215841 (* 1 = 0.215841 loss)
I0515 18:57:38.104099 27330 sgd_solver.cpp:106] Iteration 67900, lr = 1e-06
I0515 19:05:55.449121 27330 solver.cpp:228] Iteration 68000, loss = 0.257013
I0515 19:05:55.449439 27330 solver.cpp:244]     Train net output #0: loss = 0.257015 (* 1 = 0.257015 loss)
I0515 19:05:55.449455 27330 sgd_solver.cpp:106] Iteration 68000, lr = 1e-06
I0515 19:14:04.605700 27330 solver.cpp:228] Iteration 68100, loss = 0.190535
I0515 19:14:04.606132 27330 solver.cpp:244]     Train net output #0: loss = 0.190537 (* 1 = 0.190537 loss)
I0515 19:14:04.606158 27330 sgd_solver.cpp:106] Iteration 68100, lr = 1e-06
I0515 19:22:11.264574 27330 solver.cpp:228] Iteration 68200, loss = 0.143151
I0515 19:22:11.264996 27330 solver.cpp:244]     Train net output #0: loss = 0.143153 (* 1 = 0.143153 loss)
I0515 19:22:11.265015 27330 sgd_solver.cpp:106] Iteration 68200, lr = 1e-06
I0515 19:30:33.706534 27330 solver.cpp:228] Iteration 68300, loss = 0.175831
I0515 19:30:33.706899 27330 solver.cpp:244]     Train net output #0: loss = 0.175834 (* 1 = 0.175834 loss)
I0515 19:30:33.706923 27330 sgd_solver.cpp:106] Iteration 68300, lr = 1e-06
I0515 19:38:53.580415 27330 solver.cpp:228] Iteration 68400, loss = 0.432966
I0515 19:38:53.580807 27330 solver.cpp:244]     Train net output #0: loss = 0.432969 (* 1 = 0.432969 loss)
I0515 19:38:53.580832 27330 sgd_solver.cpp:106] Iteration 68400, lr = 1e-06
I0515 19:47:17.386020 27330 solver.cpp:228] Iteration 68500, loss = 0.382111
I0515 19:47:17.386394 27330 solver.cpp:244]     Train net output #0: loss = 0.382113 (* 1 = 0.382113 loss)
I0515 19:47:17.386406 27330 sgd_solver.cpp:106] Iteration 68500, lr = 1e-06
I0515 19:52:42.835912 27330 solver.cpp:337] Iteration 68565, Testing net (#0)
I0515 19:52:42.836266 27330 net.cpp:685] Ignoring source layer ratemap
I0515 19:52:42.836273 27330 net.cpp:685] Ignoring source layer amsFeatures
I0515 19:55:34.109532 27330 solver.cpp:404]     Test net output #0: loss = 0.577591 (* 1 = 0.577591 loss)
I0515 19:58:31.963438 27330 solver.cpp:228] Iteration 68600, loss = 0.236227
I0515 19:58:31.963856 27330 solver.cpp:244]     Train net output #0: loss = 0.23623 (* 1 = 0.23623 loss)
I0515 19:58:31.963881 27330 sgd_solver.cpp:106] Iteration 68600, lr = 1e-06
I0515 20:07:04.691301 27330 solver.cpp:228] Iteration 68700, loss = 0.239278
I0515 20:07:04.691684 27330 solver.cpp:244]     Train net output #0: loss = 0.239281 (* 1 = 0.239281 loss)
I0515 20:07:04.691699 27330 sgd_solver.cpp:106] Iteration 68700, lr = 1e-06
I0515 20:15:26.015985 27330 solver.cpp:228] Iteration 68800, loss = 0.220253
I0515 20:15:26.016368 27330 solver.cpp:244]     Train net output #0: loss = 0.220256 (* 1 = 0.220256 loss)
I0515 20:15:26.016391 27330 sgd_solver.cpp:106] Iteration 68800, lr = 1e-06
I0515 20:23:52.423785 27330 solver.cpp:228] Iteration 68900, loss = 0.33877
I0515 20:23:52.424229 27330 solver.cpp:244]     Train net output #0: loss = 0.338772 (* 1 = 0.338772 loss)
I0515 20:23:52.424253 27330 sgd_solver.cpp:106] Iteration 68900, lr = 1e-06
I0515 20:32:16.728088 27330 solver.cpp:228] Iteration 69000, loss = 0.215296
I0515 20:32:16.728516 27330 solver.cpp:244]     Train net output #0: loss = 0.215298 (* 1 = 0.215298 loss)
I0515 20:32:16.728538 27330 sgd_solver.cpp:106] Iteration 69000, lr = 1e-06
I0515 20:40:38.769438 27330 solver.cpp:228] Iteration 69100, loss = 0.351373
I0515 20:40:38.769862 27330 solver.cpp:244]     Train net output #0: loss = 0.351376 (* 1 = 0.351376 loss)
I0515 20:40:38.769887 27330 sgd_solver.cpp:106] Iteration 69100, lr = 1e-06
I0515 20:48:59.824050 27330 solver.cpp:228] Iteration 69200, loss = 0.217535
I0515 20:48:59.824523 27330 solver.cpp:244]     Train net output #0: loss = 0.217538 (* 1 = 0.217538 loss)
I0515 20:48:59.824547 27330 sgd_solver.cpp:106] Iteration 69200, lr = 1e-06
I0515 20:57:21.232084 27330 solver.cpp:228] Iteration 69300, loss = 0.315673
I0515 20:57:21.232595 27330 solver.cpp:244]     Train net output #0: loss = 0.315675 (* 1 = 0.315675 loss)
I0515 20:57:21.232616 27330 sgd_solver.cpp:106] Iteration 69300, lr = 1e-06
I0515 21:05:57.430117 27330 solver.cpp:228] Iteration 69400, loss = 0.180847
I0515 21:05:57.430528 27330 solver.cpp:244]     Train net output #0: loss = 0.18085 (* 1 = 0.18085 loss)
I0515 21:05:57.430554 27330 sgd_solver.cpp:106] Iteration 69400, lr = 1e-06
I0515 21:14:12.769774 27330 solver.cpp:228] Iteration 69500, loss = 0.181126
I0515 21:14:12.770210 27330 solver.cpp:244]     Train net output #0: loss = 0.181129 (* 1 = 0.181129 loss)
I0515 21:14:12.770231 27330 sgd_solver.cpp:106] Iteration 69500, lr = 1e-06
I0515 21:22:47.936931 27330 solver.cpp:228] Iteration 69600, loss = 0.341862
I0515 21:22:47.937333 27330 solver.cpp:244]     Train net output #0: loss = 0.341865 (* 1 = 0.341865 loss)
I0515 21:22:47.937357 27330 sgd_solver.cpp:106] Iteration 69600, lr = 1e-06
I0515 21:31:00.897359 27330 solver.cpp:228] Iteration 69700, loss = 0.653147
I0515 21:31:00.897783 27330 solver.cpp:244]     Train net output #0: loss = 0.65315 (* 1 = 0.65315 loss)
I0515 21:31:00.897814 27330 sgd_solver.cpp:106] Iteration 69700, lr = 1e-06
I0515 21:39:28.351596 27330 solver.cpp:228] Iteration 69800, loss = 0.198912
I0515 21:39:28.351976 27330 solver.cpp:244]     Train net output #0: loss = 0.198915 (* 1 = 0.198915 loss)
I0515 21:39:28.352000 27330 sgd_solver.cpp:106] Iteration 69800, lr = 1e-06
I0515 21:47:43.671267 27330 solver.cpp:228] Iteration 69900, loss = 0.630056
I0515 21:47:43.671699 27330 solver.cpp:244]     Train net output #0: loss = 0.630059 (* 1 = 0.630059 loss)
I0515 21:47:43.671728 27330 sgd_solver.cpp:106] Iteration 69900, lr = 1e-06
I0515 21:55:52.399999 27330 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_70000.caffemodel
I0515 21:55:52.595690 27330 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_70000.solverstate
I0515 21:55:56.976613 27330 solver.cpp:228] Iteration 70000, loss = 0.248238
I0515 21:55:56.976675 27330 solver.cpp:244]     Train net output #0: loss = 0.248241 (* 1 = 0.248241 loss)
I0515 21:55:56.976686 27330 sgd_solver.cpp:106] Iteration 70000, lr = 1e-06
I0515 22:04:18.459689 27330 solver.cpp:228] Iteration 70100, loss = 0.268858
I0515 22:04:18.460108 27330 solver.cpp:244]     Train net output #0: loss = 0.268861 (* 1 = 0.268861 loss)
I0515 22:04:18.460141 27330 sgd_solver.cpp:106] Iteration 70100, lr = 1e-06
I0515 22:12:21.789901 27330 solver.cpp:228] Iteration 70200, loss = 0.249921
I0515 22:12:21.790313 27330 solver.cpp:244]     Train net output #0: loss = 0.249924 (* 1 = 0.249924 loss)
I0515 22:12:21.790336 27330 sgd_solver.cpp:106] Iteration 70200, lr = 1e-06
I0515 22:20:28.195679 27330 solver.cpp:228] Iteration 70300, loss = 0.331549
I0515 22:20:28.196118 27330 solver.cpp:244]     Train net output #0: loss = 0.331552 (* 1 = 0.331552 loss)
I0515 22:20:28.196143 27330 sgd_solver.cpp:106] Iteration 70300, lr = 1e-06
I0515 22:28:59.437245 27330 solver.cpp:228] Iteration 70400, loss = 0.60245
I0515 22:28:59.437661 27330 solver.cpp:244]     Train net output #0: loss = 0.602453 (* 1 = 0.602453 loss)
I0515 22:28:59.437685 27330 sgd_solver.cpp:106] Iteration 70400, lr = 1e-06
I0515 22:37:06.108505 27330 solver.cpp:228] Iteration 70500, loss = 0.221184
I0515 22:37:06.108927 27330 solver.cpp:244]     Train net output #0: loss = 0.221187 (* 1 = 0.221187 loss)
I0515 22:37:06.108950 27330 sgd_solver.cpp:106] Iteration 70500, lr = 1e-06
I0515 22:45:14.101094 27330 solver.cpp:228] Iteration 70600, loss = 0.240295
I0515 22:45:14.101521 27330 solver.cpp:244]     Train net output #0: loss = 0.240298 (* 1 = 0.240298 loss)
I0515 22:45:14.101547 27330 sgd_solver.cpp:106] Iteration 70600, lr = 1e-06
I0515 22:53:48.563699 27330 solver.cpp:228] Iteration 70700, loss = 0.327846
I0515 22:53:48.564112 27330 solver.cpp:244]     Train net output #0: loss = 0.327849 (* 1 = 0.327849 loss)
I0515 22:53:48.564136 27330 sgd_solver.cpp:106] Iteration 70700, lr = 1e-06
I0515 23:02:03.991974 27330 solver.cpp:228] Iteration 70800, loss = 0.342833
I0515 23:02:03.992413 27330 solver.cpp:244]     Train net output #0: loss = 0.342836 (* 1 = 0.342836 loss)
I0515 23:02:03.992437 27330 sgd_solver.cpp:106] Iteration 70800, lr = 1e-06
I0515 23:10:22.061269 27330 solver.cpp:228] Iteration 70900, loss = 0.379438
I0515 23:10:22.061653 27330 solver.cpp:244]     Train net output #0: loss = 0.379441 (* 1 = 0.379441 loss)
I0515 23:10:22.061677 27330 sgd_solver.cpp:106] Iteration 70900, lr = 1e-06
I0515 23:18:43.631598 27330 solver.cpp:228] Iteration 71000, loss = 0.465833
I0515 23:18:43.632050 27330 solver.cpp:244]     Train net output #0: loss = 0.465836 (* 1 = 0.465836 loss)
I0515 23:18:43.632072 27330 sgd_solver.cpp:106] Iteration 71000, lr = 1e-06
I0515 23:26:59.972280 27330 solver.cpp:228] Iteration 71100, loss = 0.201262
I0515 23:26:59.972606 27330 solver.cpp:244]     Train net output #0: loss = 0.201265 (* 1 = 0.201265 loss)
I0515 23:26:59.972620 27330 sgd_solver.cpp:106] Iteration 71100, lr = 1e-06
I0515 23:35:25.207540 27330 solver.cpp:228] Iteration 71200, loss = 0.240877
I0515 23:35:25.207942 27330 solver.cpp:244]     Train net output #0: loss = 0.24088 (* 1 = 0.24088 loss)
I0515 23:35:25.207967 27330 sgd_solver.cpp:106] Iteration 71200, lr = 1e-06
I0515 23:43:46.834271 27330 solver.cpp:228] Iteration 71300, loss = 0.165449
I0515 23:43:46.834724 27330 solver.cpp:244]     Train net output #0: loss = 0.165451 (* 1 = 0.165451 loss)
I0515 23:43:46.834749 27330 sgd_solver.cpp:106] Iteration 71300, lr = 1e-06
I0515 23:52:09.083015 27330 solver.cpp:228] Iteration 71400, loss = 0.191787
I0515 23:52:09.083436 27330 solver.cpp:244]     Train net output #0: loss = 0.191789 (* 1 = 0.191789 loss)
I0515 23:52:09.083461 27330 sgd_solver.cpp:106] Iteration 71400, lr = 1e-06
I0516 00:00:35.788383 27330 solver.cpp:228] Iteration 71500, loss = 0.180455
I0516 00:00:35.788802 27330 solver.cpp:244]     Train net output #0: loss = 0.180458 (* 1 = 0.180458 loss)
I0516 00:00:35.788827 27330 sgd_solver.cpp:106] Iteration 71500, lr = 1e-06
I0516 00:08:32.846434 27330 solver.cpp:228] Iteration 71600, loss = 0.412962
I0516 00:08:32.846894 27330 solver.cpp:244]     Train net output #0: loss = 0.412965 (* 1 = 0.412965 loss)
I0516 00:08:32.846918 27330 sgd_solver.cpp:106] Iteration 71600, lr = 1e-06
I0516 00:17:08.360088 27330 solver.cpp:228] Iteration 71700, loss = 0.67126
I0516 00:17:08.360540 27330 solver.cpp:244]     Train net output #0: loss = 0.671262 (* 1 = 0.671262 loss)
I0516 00:17:08.360565 27330 sgd_solver.cpp:106] Iteration 71700, lr = 1e-06
I0516 00:25:24.404651 27330 solver.cpp:228] Iteration 71800, loss = 0.693123
I0516 00:25:24.405050 27330 solver.cpp:244]     Train net output #0: loss = 0.693126 (* 1 = 0.693126 loss)
I0516 00:25:24.405079 27330 sgd_solver.cpp:106] Iteration 71800, lr = 1e-06
I0516 00:27:53.143220 27330 solver.cpp:337] Iteration 71830, Testing net (#0)
I0516 00:27:53.143525 27330 net.cpp:685] Ignoring source layer ratemap
I0516 00:27:53.143534 27330 net.cpp:685] Ignoring source layer amsFeatures
I0516 00:30:44.366119 27330 solver.cpp:404]     Test net output #0: loss = 0.581711 (* 1 = 0.581711 loss)
I0516 00:36:41.169337 27330 solver.cpp:228] Iteration 71900, loss = 0.368117
I0516 00:36:41.169750 27330 solver.cpp:244]     Train net output #0: loss = 0.368119 (* 1 = 0.368119 loss)
I0516 00:36:41.169776 27330 sgd_solver.cpp:106] Iteration 71900, lr = 1e-06
I0516 00:45:05.808882 27330 solver.cpp:228] Iteration 72000, loss = 0.368353
I0516 00:45:05.809332 27330 solver.cpp:244]     Train net output #0: loss = 0.368356 (* 1 = 0.368356 loss)
I0516 00:45:05.809356 27330 sgd_solver.cpp:106] Iteration 72000, lr = 1e-06
I0516 00:53:10.654578 27330 solver.cpp:228] Iteration 72100, loss = 0.2259
I0516 00:53:10.655062 27330 solver.cpp:244]     Train net output #0: loss = 0.225902 (* 1 = 0.225902 loss)
I0516 00:53:10.655084 27330 sgd_solver.cpp:106] Iteration 72100, lr = 1e-06
I0516 01:01:16.065654 27330 solver.cpp:228] Iteration 72200, loss = 0.266688
I0516 01:01:16.066071 27330 solver.cpp:244]     Train net output #0: loss = 0.266691 (* 1 = 0.266691 loss)
I0516 01:01:16.066094 27330 sgd_solver.cpp:106] Iteration 72200, lr = 1e-06
I0516 01:09:48.294529 27330 solver.cpp:228] Iteration 72300, loss = 0.24712
I0516 01:09:48.294916 27330 solver.cpp:244]     Train net output #0: loss = 0.247122 (* 1 = 0.247122 loss)
I0516 01:09:48.294941 27330 sgd_solver.cpp:106] Iteration 72300, lr = 1e-06
I0516 01:18:26.315400 27330 solver.cpp:228] Iteration 72400, loss = 0.435251
I0516 01:18:26.315832 27330 solver.cpp:244]     Train net output #0: loss = 0.435253 (* 1 = 0.435253 loss)
I0516 01:18:26.315856 27330 sgd_solver.cpp:106] Iteration 72400, lr = 1e-06
I0516 01:26:36.723497 27330 solver.cpp:228] Iteration 72500, loss = 0.286398
I0516 01:26:36.723927 27330 solver.cpp:244]     Train net output #0: loss = 0.286401 (* 1 = 0.286401 loss)
I0516 01:26:36.723953 27330 sgd_solver.cpp:106] Iteration 72500, lr = 1e-06
I0516 01:34:59.809329 27330 solver.cpp:228] Iteration 72600, loss = 0.279397
I0516 01:34:59.809765 27330 solver.cpp:244]     Train net output #0: loss = 0.2794 (* 1 = 0.2794 loss)
I0516 01:34:59.809797 27330 sgd_solver.cpp:106] Iteration 72600, lr = 1e-06
I0516 01:43:29.522563 27330 solver.cpp:228] Iteration 72700, loss = 0.346521
I0516 01:43:29.522991 27330 solver.cpp:244]     Train net output #0: loss = 0.346524 (* 1 = 0.346524 loss)
I0516 01:43:29.523006 27330 sgd_solver.cpp:106] Iteration 72700, lr = 1e-06
I0516 01:51:42.125000 27330 solver.cpp:228] Iteration 72800, loss = 0.157409
I0516 01:51:42.125412 27330 solver.cpp:244]     Train net output #0: loss = 0.157412 (* 1 = 0.157412 loss)
I0516 01:51:42.125437 27330 sgd_solver.cpp:106] Iteration 72800, lr = 1e-06
I0516 02:00:02.561039 27330 solver.cpp:228] Iteration 72900, loss = 0.382858
I0516 02:00:02.561477 27330 solver.cpp:244]     Train net output #0: loss = 0.38286 (* 1 = 0.38286 loss)
I0516 02:00:02.561499 27330 sgd_solver.cpp:106] Iteration 72900, lr = 1e-06
I0516 02:08:40.204282 27330 solver.cpp:228] Iteration 73000, loss = 0.187239
I0516 02:08:40.204658 27330 solver.cpp:244]     Train net output #0: loss = 0.187242 (* 1 = 0.187242 loss)
I0516 02:08:40.204684 27330 sgd_solver.cpp:106] Iteration 73000, lr = 1e-06
I0516 02:16:56.482775 27330 solver.cpp:228] Iteration 73100, loss = 0.221809
I0516 02:16:56.483220 27330 solver.cpp:244]     Train net output #0: loss = 0.221811 (* 1 = 0.221811 loss)
I0516 02:16:56.483245 27330 sgd_solver.cpp:106] Iteration 73100, lr = 1e-06
I0516 02:25:13.466739 27330 solver.cpp:228] Iteration 73200, loss = 0.628451
I0516 02:25:13.467209 27330 solver.cpp:244]     Train net output #0: loss = 0.628453 (* 1 = 0.628453 loss)
I0516 02:25:13.467239 27330 sgd_solver.cpp:106] Iteration 73200, lr = 1e-06
I0516 02:33:41.063472 27330 solver.cpp:228] Iteration 73300, loss = 0.226332
I0516 02:33:41.063835 27330 solver.cpp:244]     Train net output #0: loss = 0.226335 (* 1 = 0.226335 loss)
I0516 02:33:41.063848 27330 sgd_solver.cpp:106] Iteration 73300, lr = 1e-06
I0516 02:42:10.260965 27330 solver.cpp:228] Iteration 73400, loss = 0.22023
I0516 02:42:10.261394 27330 solver.cpp:244]     Train net output #0: loss = 0.220233 (* 1 = 0.220233 loss)
I0516 02:42:10.261418 27330 sgd_solver.cpp:106] Iteration 73400, lr = 1e-06
I0516 02:50:29.817490 27330 solver.cpp:228] Iteration 73500, loss = 0.389726
I0516 02:50:29.817960 27330 solver.cpp:244]     Train net output #0: loss = 0.389729 (* 1 = 0.389729 loss)
I0516 02:50:29.817981 27330 sgd_solver.cpp:106] Iteration 73500, lr = 1e-06
I0516 02:58:44.486651 27330 solver.cpp:228] Iteration 73600, loss = 0.148352
I0516 02:58:44.487038 27330 solver.cpp:244]     Train net output #0: loss = 0.148354 (* 1 = 0.148354 loss)
I0516 02:58:44.487063 27330 sgd_solver.cpp:106] Iteration 73600, lr = 1e-06
I0516 03:07:09.967809 27330 solver.cpp:228] Iteration 73700, loss = 0.362748
I0516 03:07:09.968277 27330 solver.cpp:244]     Train net output #0: loss = 0.36275 (* 1 = 0.36275 loss)
I0516 03:07:09.968302 27330 sgd_solver.cpp:106] Iteration 73700, lr = 1e-06
I0516 03:15:21.214751 27330 solver.cpp:228] Iteration 73800, loss = 0.168109
I0516 03:15:21.215224 27330 solver.cpp:244]     Train net output #0: loss = 0.168111 (* 1 = 0.168111 loss)
I0516 03:15:21.215250 27330 sgd_solver.cpp:106] Iteration 73800, lr = 1e-06
I0516 03:23:53.543089 27330 solver.cpp:228] Iteration 73900, loss = 0.21995
I0516 03:23:53.543481 27330 solver.cpp:244]     Train net output #0: loss = 0.219953 (* 1 = 0.219953 loss)
I0516 03:23:53.543506 27330 sgd_solver.cpp:106] Iteration 73900, lr = 1e-06
I0516 03:32:09.513566 27330 solver.cpp:228] Iteration 74000, loss = 0.516986
I0516 03:32:09.514010 27330 solver.cpp:244]     Train net output #0: loss = 0.516989 (* 1 = 0.516989 loss)
I0516 03:32:09.514031 27330 sgd_solver.cpp:106] Iteration 74000, lr = 1e-06
I0516 03:40:12.037994 27330 solver.cpp:228] Iteration 74100, loss = 0.288228
I0516 03:40:12.038410 27330 solver.cpp:244]     Train net output #0: loss = 0.288231 (* 1 = 0.288231 loss)
I0516 03:40:12.038435 27330 sgd_solver.cpp:106] Iteration 74100, lr = 1e-06
I0516 03:48:43.685215 27330 solver.cpp:228] Iteration 74200, loss = 0.164165
I0516 03:48:43.685624 27330 solver.cpp:244]     Train net output #0: loss = 0.164167 (* 1 = 0.164167 loss)
I0516 03:48:43.685649 27330 sgd_solver.cpp:106] Iteration 74200, lr = 1e-06
I0516 03:57:14.244532 27330 solver.cpp:228] Iteration 74300, loss = 0.186355
I0516 03:57:14.244949 27330 solver.cpp:244]     Train net output #0: loss = 0.186357 (* 1 = 0.186357 loss)
I0516 03:57:14.244976 27330 sgd_solver.cpp:106] Iteration 74300, lr = 1e-06
I0516 04:05:45.565839 27330 solver.cpp:228] Iteration 74400, loss = 0.253285
I0516 04:05:45.566277 27330 solver.cpp:244]     Train net output #0: loss = 0.253288 (* 1 = 0.253288 loss)
I0516 04:05:45.566301 27330 sgd_solver.cpp:106] Iteration 74400, lr = 1e-06
I0516 04:14:00.827767 27330 solver.cpp:228] Iteration 74500, loss = 0.291455
I0516 04:14:00.828230 27330 solver.cpp:244]     Train net output #0: loss = 0.291458 (* 1 = 0.291458 loss)
I0516 04:14:00.828255 27330 sgd_solver.cpp:106] Iteration 74500, lr = 1e-06
I0516 04:22:25.289412 27330 solver.cpp:228] Iteration 74600, loss = 0.514594
I0516 04:22:25.289821 27330 solver.cpp:244]     Train net output #0: loss = 0.514596 (* 1 = 0.514596 loss)
I0516 04:22:25.289845 27330 sgd_solver.cpp:106] Iteration 74600, lr = 1e-06
I0516 04:30:50.874721 27330 solver.cpp:228] Iteration 74700, loss = 0.195922
I0516 04:30:50.875195 27330 solver.cpp:244]     Train net output #0: loss = 0.195925 (* 1 = 0.195925 loss)
I0516 04:30:50.875221 27330 sgd_solver.cpp:106] Iteration 74700, lr = 1e-06
I0516 04:39:09.681767 27330 solver.cpp:228] Iteration 74800, loss = 0.38055
I0516 04:39:09.682205 27330 solver.cpp:244]     Train net output #0: loss = 0.380553 (* 1 = 0.380553 loss)
I0516 04:39:09.682229 27330 sgd_solver.cpp:106] Iteration 74800, lr = 1e-06
I0516 04:47:37.170263 27330 solver.cpp:228] Iteration 74900, loss = 0.254493
I0516 04:47:37.170650 27330 solver.cpp:244]     Train net output #0: loss = 0.254495 (* 1 = 0.254495 loss)
I0516 04:47:37.170675 27330 sgd_solver.cpp:106] Iteration 74900, lr = 1e-06
I0516 04:55:52.199174 27330 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_75000.caffemodel
I0516 04:55:52.393316 27330 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_75000.solverstate
I0516 04:55:57.620229 27330 solver.cpp:228] Iteration 75000, loss = 0.340006
I0516 04:55:57.620280 27330 solver.cpp:244]     Train net output #0: loss = 0.340008 (* 1 = 0.340008 loss)
I0516 04:55:57.620290 27330 sgd_solver.cpp:106] Iteration 75000, lr = 1e-06
I0516 05:03:49.564613 27330 solver.cpp:337] Iteration 75095, Testing net (#0)
I0516 05:03:49.564975 27330 net.cpp:685] Ignoring source layer ratemap
I0516 05:03:49.564982 27330 net.cpp:685] Ignoring source layer amsFeatures
I0516 05:06:40.805740 27330 solver.cpp:404]     Test net output #0: loss = 0.584175 (* 1 = 0.584175 loss)
I0516 05:07:08.189965 27330 solver.cpp:228] Iteration 75100, loss = 0.319164
I0516 05:07:08.190016 27330 solver.cpp:244]     Train net output #0: loss = 0.319166 (* 1 = 0.319166 loss)
I0516 05:07:08.190026 27330 sgd_solver.cpp:106] Iteration 75100, lr = 1e-06
I0516 05:15:16.290644 27330 solver.cpp:228] Iteration 75200, loss = 0.286199
I0516 05:15:16.291055 27330 solver.cpp:244]     Train net output #0: loss = 0.286202 (* 1 = 0.286202 loss)
I0516 05:15:16.291081 27330 sgd_solver.cpp:106] Iteration 75200, lr = 1e-06
I0516 05:23:44.479073 27330 solver.cpp:228] Iteration 75300, loss = 0.362512
I0516 05:23:44.479549 27330 solver.cpp:244]     Train net output #0: loss = 0.362515 (* 1 = 0.362515 loss)
I0516 05:23:44.479570 27330 sgd_solver.cpp:106] Iteration 75300, lr = 1e-06
I0516 05:32:00.422668 27330 solver.cpp:228] Iteration 75400, loss = 0.319523
I0516 05:32:00.423102 27330 solver.cpp:244]     Train net output #0: loss = 0.319525 (* 1 = 0.319525 loss)
I0516 05:32:00.423123 27330 sgd_solver.cpp:106] Iteration 75400, lr = 1e-06
I0516 05:40:25.790794 27330 solver.cpp:228] Iteration 75500, loss = 0.179407
I0516 05:40:25.791278 27330 solver.cpp:244]     Train net output #0: loss = 0.17941 (* 1 = 0.17941 loss)
I0516 05:40:25.791302 27330 sgd_solver.cpp:106] Iteration 75500, lr = 1e-06
I0516 05:48:47.803109 27330 solver.cpp:228] Iteration 75600, loss = 0.210636
I0516 05:48:47.803537 27330 solver.cpp:244]     Train net output #0: loss = 0.210638 (* 1 = 0.210638 loss)
I0516 05:48:47.803561 27330 sgd_solver.cpp:106] Iteration 75600, lr = 1e-06
I0516 05:57:04.384618 27330 solver.cpp:228] Iteration 75700, loss = 0.306942
I0516 05:57:04.385030 27330 solver.cpp:244]     Train net output #0: loss = 0.306944 (* 1 = 0.306944 loss)
I0516 05:57:04.385054 27330 sgd_solver.cpp:106] Iteration 75700, lr = 1e-06
I0516 06:05:30.503303 27330 solver.cpp:228] Iteration 75800, loss = 0.49317
I0516 06:05:30.503753 27330 solver.cpp:244]     Train net output #0: loss = 0.493173 (* 1 = 0.493173 loss)
I0516 06:05:30.503774 27330 sgd_solver.cpp:106] Iteration 75800, lr = 1e-06
I0516 06:14:02.396661 27330 solver.cpp:228] Iteration 75900, loss = 0.287661
I0516 06:14:02.397037 27330 solver.cpp:244]     Train net output #0: loss = 0.287663 (* 1 = 0.287663 loss)
I0516 06:14:02.397058 27330 sgd_solver.cpp:106] Iteration 75900, lr = 1e-06
I0516 06:22:30.812407 27330 solver.cpp:228] Iteration 76000, loss = 0.322255
I0516 06:22:30.812801 27330 solver.cpp:244]     Train net output #0: loss = 0.322258 (* 1 = 0.322258 loss)
I0516 06:22:30.812825 27330 sgd_solver.cpp:106] Iteration 76000, lr = 1e-06
I0516 06:30:47.808084 27330 solver.cpp:228] Iteration 76100, loss = 0.408876
I0516 06:30:47.808511 27330 solver.cpp:244]     Train net output #0: loss = 0.408879 (* 1 = 0.408879 loss)
I0516 06:30:47.808532 27330 sgd_solver.cpp:106] Iteration 76100, lr = 1e-06
I0516 06:39:11.013221 27330 solver.cpp:228] Iteration 76200, loss = 0.754949
I0516 06:39:11.398903 27330 solver.cpp:244]     Train net output #0: loss = 0.754951 (* 1 = 0.754951 loss)
I0516 06:39:11.398932 27330 sgd_solver.cpp:106] Iteration 76200, lr = 1e-06
I0516 06:47:35.757583 27330 solver.cpp:228] Iteration 76300, loss = 0.426834
I0516 06:47:35.758011 27330 solver.cpp:244]     Train net output #0: loss = 0.426836 (* 1 = 0.426836 loss)
I0516 06:47:35.758033 27330 sgd_solver.cpp:106] Iteration 76300, lr = 1e-06
I0516 06:55:52.853126 27330 solver.cpp:228] Iteration 76400, loss = 0.444884
I0516 06:55:52.853555 27330 solver.cpp:244]     Train net output #0: loss = 0.444886 (* 1 = 0.444886 loss)
I0516 06:55:52.853580 27330 sgd_solver.cpp:106] Iteration 76400, lr = 1e-06
I0516 07:04:09.945291 27330 solver.cpp:228] Iteration 76500, loss = 0.31856
I0516 07:04:09.945710 27330 solver.cpp:244]     Train net output #0: loss = 0.318562 (* 1 = 0.318562 loss)
I0516 07:04:09.945731 27330 sgd_solver.cpp:106] Iteration 76500, lr = 1e-06
I0516 07:12:18.963186 27330 solver.cpp:228] Iteration 76600, loss = 0.333984
I0516 07:12:18.963592 27330 solver.cpp:244]     Train net output #0: loss = 0.333987 (* 1 = 0.333987 loss)
I0516 07:12:18.963605 27330 sgd_solver.cpp:106] Iteration 76600, lr = 1e-06
I0516 07:20:52.886026 27330 solver.cpp:228] Iteration 76700, loss = 0.191745
I0516 07:20:52.886495 27330 solver.cpp:244]     Train net output #0: loss = 0.191747 (* 1 = 0.191747 loss)
I0516 07:20:52.886517 27330 sgd_solver.cpp:106] Iteration 76700, lr = 1e-06
I0516 07:29:14.805492 27330 solver.cpp:228] Iteration 76800, loss = 0.521362
I0516 07:29:14.805917 27330 solver.cpp:244]     Train net output #0: loss = 0.521364 (* 1 = 0.521364 loss)
I0516 07:29:14.805940 27330 sgd_solver.cpp:106] Iteration 76800, lr = 1e-06
I0516 07:37:13.686097 27330 solver.cpp:228] Iteration 76900, loss = 0.330274
I0516 07:37:13.686537 27330 solver.cpp:244]     Train net output #0: loss = 0.330277 (* 1 = 0.330277 loss)
I0516 07:37:13.686561 27330 sgd_solver.cpp:106] Iteration 76900, lr = 1e-06
I0516 07:45:35.864078 27330 solver.cpp:228] Iteration 77000, loss = 0.27971
I0516 07:45:35.864460 27330 solver.cpp:244]     Train net output #0: loss = 0.279712 (* 1 = 0.279712 loss)
I0516 07:45:35.864485 27330 sgd_solver.cpp:106] Iteration 77000, lr = 1e-06
I0516 07:53:58.224308 27330 solver.cpp:228] Iteration 77100, loss = 0.382703
I0516 07:53:58.224778 27330 solver.cpp:244]     Train net output #0: loss = 0.382705 (* 1 = 0.382705 loss)
I0516 07:53:58.224807 27330 sgd_solver.cpp:106] Iteration 77100, lr = 1e-06
I0516 08:02:14.794659 27330 solver.cpp:228] Iteration 77200, loss = 0.243025
I0516 08:02:14.795065 27330 solver.cpp:244]     Train net output #0: loss = 0.243027 (* 1 = 0.243027 loss)
I0516 08:02:14.795090 27330 sgd_solver.cpp:106] Iteration 77200, lr = 1e-06
I0516 08:10:24.169219 27330 solver.cpp:228] Iteration 77300, loss = 0.185604
I0516 08:10:24.169618 27330 solver.cpp:244]     Train net output #0: loss = 0.185606 (* 1 = 0.185606 loss)
I0516 08:10:24.169651 27330 sgd_solver.cpp:106] Iteration 77300, lr = 1e-06
I0516 08:18:45.747618 27330 solver.cpp:228] Iteration 77400, loss = 0.853221
I0516 08:18:45.747969 27330 solver.cpp:244]     Train net output #0: loss = 0.853223 (* 1 = 0.853223 loss)
I0516 08:18:45.747985 27330 sgd_solver.cpp:106] Iteration 77400, lr = 1e-06
I0516 08:27:14.911504 27330 solver.cpp:228] Iteration 77500, loss = 0.142875
I0516 08:27:14.911921 27330 solver.cpp:244]     Train net output #0: loss = 0.142877 (* 1 = 0.142877 loss)
I0516 08:27:14.911944 27330 sgd_solver.cpp:106] Iteration 77500, lr = 1e-06
I0516 08:35:30.443002 27330 solver.cpp:228] Iteration 77600, loss = 0.194484
I0516 08:35:30.443382 27330 solver.cpp:244]     Train net output #0: loss = 0.194486 (* 1 = 0.194486 loss)
I0516 08:35:30.443394 27330 sgd_solver.cpp:106] Iteration 77600, lr = 1e-06
I0516 08:43:50.031110 27330 solver.cpp:228] Iteration 77700, loss = 0.450754
I0516 08:43:50.031541 27330 solver.cpp:244]     Train net output #0: loss = 0.450756 (* 1 = 0.450756 loss)
I0516 08:43:50.031565 27330 sgd_solver.cpp:106] Iteration 77700, lr = 1e-06
I0516 08:52:10.805454 27330 solver.cpp:228] Iteration 77800, loss = 0.202618
I0516 08:52:10.805861 27330 solver.cpp:244]     Train net output #0: loss = 0.20262 (* 1 = 0.20262 loss)
I0516 08:52:10.805886 27330 sgd_solver.cpp:106] Iteration 77800, lr = 1e-06
I0516 09:00:43.122514 27330 solver.cpp:228] Iteration 77900, loss = 0.199918
I0516 09:00:43.122951 27330 solver.cpp:244]     Train net output #0: loss = 0.19992 (* 1 = 0.19992 loss)
I0516 09:00:43.122975 27330 sgd_solver.cpp:106] Iteration 77900, lr = 1e-06
I0516 09:09:18.280324 27330 solver.cpp:228] Iteration 78000, loss = 0.446494
I0516 09:09:18.280692 27330 solver.cpp:244]     Train net output #0: loss = 0.446496 (* 1 = 0.446496 loss)
I0516 09:09:18.280709 27330 sgd_solver.cpp:106] Iteration 78000, lr = 1e-06
I0516 09:17:36.737287 27330 solver.cpp:228] Iteration 78100, loss = 0.356464
I0516 09:17:36.737723 27330 solver.cpp:244]     Train net output #0: loss = 0.356466 (* 1 = 0.356466 loss)
I0516 09:17:36.737748 27330 sgd_solver.cpp:106] Iteration 78100, lr = 1e-06
I0516 09:26:16.156627 27330 solver.cpp:228] Iteration 78200, loss = 0.400701
I0516 09:26:16.157095 27330 solver.cpp:244]     Train net output #0: loss = 0.400703 (* 1 = 0.400703 loss)
I0516 09:26:16.157116 27330 sgd_solver.cpp:106] Iteration 78200, lr = 1e-06
I0516 09:34:35.957403 27330 solver.cpp:228] Iteration 78300, loss = 0.23913
I0516 09:34:35.957854 27330 solver.cpp:244]     Train net output #0: loss = 0.239132 (* 1 = 0.239132 loss)
I0516 09:34:35.957880 27330 sgd_solver.cpp:106] Iteration 78300, lr = 1e-06
I0516 09:39:35.163394 27330 solver.cpp:337] Iteration 78360, Testing net (#0)
I0516 09:39:35.163857 27330 net.cpp:685] Ignoring source layer ratemap
I0516 09:39:35.163878 27330 net.cpp:685] Ignoring source layer amsFeatures
I0516 09:42:26.448328 27330 solver.cpp:404]     Test net output #0: loss = 0.575058 (* 1 = 0.575058 loss)
I0516 09:45:47.333019 27330 solver.cpp:228] Iteration 78400, loss = 0.259082
I0516 09:45:47.333448 27330 solver.cpp:244]     Train net output #0: loss = 0.259084 (* 1 = 0.259084 loss)
I0516 09:45:47.333474 27330 sgd_solver.cpp:106] Iteration 78400, lr = 1e-06
I0516 09:54:17.564985 27330 solver.cpp:228] Iteration 78500, loss = 0.203989
I0516 09:54:17.565415 27330 solver.cpp:244]     Train net output #0: loss = 0.203991 (* 1 = 0.203991 loss)
I0516 09:54:17.565445 27330 sgd_solver.cpp:106] Iteration 78500, lr = 1e-06
I0516 10:02:39.484937 27330 solver.cpp:228] Iteration 78600, loss = 0.187742
I0516 10:02:39.485306 27330 solver.cpp:244]     Train net output #0: loss = 0.187744 (* 1 = 0.187744 loss)
I0516 10:02:39.485330 27330 sgd_solver.cpp:106] Iteration 78600, lr = 1e-06
I0516 10:11:06.131320 27330 solver.cpp:228] Iteration 78700, loss = 0.273101
I0516 10:11:06.131803 27330 solver.cpp:244]     Train net output #0: loss = 0.273103 (* 1 = 0.273103 loss)
I0516 10:11:06.131829 27330 sgd_solver.cpp:106] Iteration 78700, lr = 1e-06
I0516 10:19:27.077407 27330 solver.cpp:228] Iteration 78800, loss = 0.149482
I0516 10:19:27.077790 27330 solver.cpp:244]     Train net output #0: loss = 0.149484 (* 1 = 0.149484 loss)
I0516 10:19:27.077814 27330 sgd_solver.cpp:106] Iteration 78800, lr = 1e-06
I0516 10:27:48.562677 27330 solver.cpp:228] Iteration 78900, loss = 0.258806
I0516 10:27:48.563139 27330 solver.cpp:244]     Train net output #0: loss = 0.258808 (* 1 = 0.258808 loss)
I0516 10:27:48.563159 27330 sgd_solver.cpp:106] Iteration 78900, lr = 1e-06
I0516 10:36:04.015254 27330 solver.cpp:228] Iteration 79000, loss = 0.168591
I0516 10:36:04.015640 27330 solver.cpp:244]     Train net output #0: loss = 0.168593 (* 1 = 0.168593 loss)
I0516 10:36:04.015662 27330 sgd_solver.cpp:106] Iteration 79000, lr = 1e-06
I0516 10:44:30.651420 27330 solver.cpp:228] Iteration 79100, loss = 0.296128
I0516 10:44:30.651796 27330 solver.cpp:244]     Train net output #0: loss = 0.29613 (* 1 = 0.29613 loss)
I0516 10:44:30.651808 27330 sgd_solver.cpp:106] Iteration 79100, lr = 1e-06
I0516 10:52:54.906899 27330 solver.cpp:228] Iteration 79200, loss = 0.482384
I0516 10:52:54.907330 27330 solver.cpp:244]     Train net output #0: loss = 0.482385 (* 1 = 0.482385 loss)
I0516 10:52:54.907356 27330 sgd_solver.cpp:106] Iteration 79200, lr = 1e-06
I0516 11:01:08.513584 27330 solver.cpp:228] Iteration 79300, loss = 0.204112
I0516 11:01:08.514017 27330 solver.cpp:244]     Train net output #0: loss = 0.204114 (* 1 = 0.204114 loss)
I0516 11:01:08.514042 27330 sgd_solver.cpp:106] Iteration 79300, lr = 1e-06
I0516 11:09:26.265463 27330 solver.cpp:228] Iteration 79400, loss = 0.412806
I0516 11:09:26.265902 27330 solver.cpp:244]     Train net output #0: loss = 0.412808 (* 1 = 0.412808 loss)
I0516 11:09:26.265926 27330 sgd_solver.cpp:106] Iteration 79400, lr = 1e-06
I0516 11:17:33.509609 27330 solver.cpp:228] Iteration 79500, loss = 0.329323
I0516 11:17:33.510090 27330 solver.cpp:244]     Train net output #0: loss = 0.329325 (* 1 = 0.329325 loss)
I0516 11:17:33.510118 27330 sgd_solver.cpp:106] Iteration 79500, lr = 1e-06
I0516 11:25:50.534575 27330 solver.cpp:228] Iteration 79600, loss = 0.251617
I0516 11:25:50.535015 27330 solver.cpp:244]     Train net output #0: loss = 0.251619 (* 1 = 0.251619 loss)
I0516 11:25:50.535039 27330 sgd_solver.cpp:106] Iteration 79600, lr = 1e-06
I0516 11:34:06.654413 27330 solver.cpp:228] Iteration 79700, loss = 0.290639
I0516 11:34:06.654820 27330 solver.cpp:244]     Train net output #0: loss = 0.290641 (* 1 = 0.290641 loss)
I0516 11:34:06.654845 27330 sgd_solver.cpp:106] Iteration 79700, lr = 1e-06
I0516 11:42:26.968956 27330 solver.cpp:228] Iteration 79800, loss = 0.370849
I0516 11:42:26.969349 27330 solver.cpp:244]     Train net output #0: loss = 0.370851 (* 1 = 0.370851 loss)
I0516 11:42:26.969370 27330 sgd_solver.cpp:106] Iteration 79800, lr = 1e-06
I0516 11:50:46.773176 27330 solver.cpp:228] Iteration 79900, loss = 0.218756
I0516 11:50:46.773586 27330 solver.cpp:244]     Train net output #0: loss = 0.218758 (* 1 = 0.218758 loss)
I0516 11:50:46.773612 27330 sgd_solver.cpp:106] Iteration 79900, lr = 1e-06
I0516 11:59:17.896600 27330 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_80000.caffemodel
I0516 11:59:18.091658 27330 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_80000.solverstate
I0516 11:59:23.971738 27330 solver.cpp:228] Iteration 80000, loss = 0.219526
I0516 11:59:23.971783 27330 solver.cpp:244]     Train net output #0: loss = 0.219527 (* 1 = 0.219527 loss)
I0516 11:59:23.971793 27330 sgd_solver.cpp:106] Iteration 80000, lr = 1e-06
I0516 12:07:49.062634 27330 solver.cpp:228] Iteration 80100, loss = 0.208108
I0516 12:07:49.062974 27330 solver.cpp:244]     Train net output #0: loss = 0.208109 (* 1 = 0.208109 loss)
I0516 12:07:49.062988 27330 sgd_solver.cpp:106] Iteration 80100, lr = 1e-06
I0516 12:16:17.447185 27330 solver.cpp:228] Iteration 80200, loss = 0.18033
I0516 12:16:17.447576 27330 solver.cpp:244]     Train net output #0: loss = 0.180331 (* 1 = 0.180331 loss)
I0516 12:16:17.447600 27330 sgd_solver.cpp:106] Iteration 80200, lr = 1e-06
I0516 12:24:44.846588 27330 solver.cpp:228] Iteration 80300, loss = 0.342531
I0516 12:24:44.847064 27330 solver.cpp:244]     Train net output #0: loss = 0.342533 (* 1 = 0.342533 loss)
I0516 12:24:44.847095 27330 sgd_solver.cpp:106] Iteration 80300, lr = 1e-06
I0516 12:32:57.151485 27330 solver.cpp:228] Iteration 80400, loss = 0.331102
I0516 12:32:57.151867 27330 solver.cpp:244]     Train net output #0: loss = 0.331104 (* 1 = 0.331104 loss)
I0516 12:32:57.151892 27330 sgd_solver.cpp:106] Iteration 80400, lr = 1e-06
I0516 12:41:16.608822 27330 solver.cpp:228] Iteration 80500, loss = 0.416003
I0516 12:41:16.609279 27330 solver.cpp:244]     Train net output #0: loss = 0.416005 (* 1 = 0.416005 loss)
I0516 12:41:16.609303 27330 sgd_solver.cpp:106] Iteration 80500, lr = 1e-06
I0516 12:49:33.392866 27330 solver.cpp:228] Iteration 80600, loss = 0.309723
I0516 12:49:33.393277 27330 solver.cpp:244]     Train net output #0: loss = 0.309725 (* 1 = 0.309725 loss)
I0516 12:49:33.393302 27330 sgd_solver.cpp:106] Iteration 80600, lr = 1e-06
I0516 12:57:57.829979 27330 solver.cpp:228] Iteration 80700, loss = 0.588456
I0516 12:57:57.830404 27330 solver.cpp:244]     Train net output #0: loss = 0.588458 (* 1 = 0.588458 loss)
I0516 12:57:57.830430 27330 sgd_solver.cpp:106] Iteration 80700, lr = 1e-06
I0516 13:06:18.632119 27330 solver.cpp:228] Iteration 80800, loss = 0.276428
I0516 13:06:18.632536 27330 solver.cpp:244]     Train net output #0: loss = 0.27643 (* 1 = 0.27643 loss)
I0516 13:06:18.632565 27330 sgd_solver.cpp:106] Iteration 80800, lr = 1e-06
I0516 13:14:46.430981 27330 solver.cpp:228] Iteration 80900, loss = 0.327325
I0516 13:14:46.431434 27330 solver.cpp:244]     Train net output #0: loss = 0.327327 (* 1 = 0.327327 loss)
I0516 13:14:46.431454 27330 sgd_solver.cpp:106] Iteration 80900, lr = 1e-06
I0516 13:23:06.447880 27330 solver.cpp:228] Iteration 81000, loss = 0.141835
I0516 13:23:06.448309 27330 solver.cpp:244]     Train net output #0: loss = 0.141837 (* 1 = 0.141837 loss)
I0516 13:23:06.448339 27330 sgd_solver.cpp:106] Iteration 81000, lr = 1e-06
I0516 13:31:18.917349 27330 solver.cpp:228] Iteration 81100, loss = 0.380834
I0516 13:31:18.917783 27330 solver.cpp:244]     Train net output #0: loss = 0.380836 (* 1 = 0.380836 loss)
I0516 13:31:18.917803 27330 sgd_solver.cpp:106] Iteration 81100, lr = 1e-06
I0516 13:39:38.609923 27330 solver.cpp:228] Iteration 81200, loss = 0.3862
I0516 13:39:38.610337 27330 solver.cpp:244]     Train net output #0: loss = 0.386202 (* 1 = 0.386202 loss)
I0516 13:39:38.610362 27330 sgd_solver.cpp:106] Iteration 81200, lr = 1e-06
I0516 13:48:04.579740 27330 solver.cpp:228] Iteration 81300, loss = 0.151955
I0516 13:48:04.580104 27330 solver.cpp:244]     Train net output #0: loss = 0.151957 (* 1 = 0.151957 loss)
I0516 13:48:04.580116 27330 sgd_solver.cpp:106] Iteration 81300, lr = 1e-06
I0516 13:56:27.902297 27330 solver.cpp:228] Iteration 81400, loss = 0.152251
I0516 13:56:27.902655 27330 solver.cpp:244]     Train net output #0: loss = 0.152253 (* 1 = 0.152253 loss)
I0516 13:56:27.902667 27330 sgd_solver.cpp:106] Iteration 81400, lr = 1e-06
I0516 14:04:48.066498 27330 solver.cpp:228] Iteration 81500, loss = 0.247939
I0516 14:04:48.066915 27330 solver.cpp:244]     Train net output #0: loss = 0.247941 (* 1 = 0.247941 loss)
I0516 14:04:48.066939 27330 sgd_solver.cpp:106] Iteration 81500, lr = 1e-06
I0516 14:13:15.098531 27330 solver.cpp:228] Iteration 81600, loss = 0.243454
I0516 14:13:15.098978 27330 solver.cpp:244]     Train net output #0: loss = 0.243456 (* 1 = 0.243456 loss)
I0516 14:13:15.098999 27330 sgd_solver.cpp:106] Iteration 81600, lr = 1e-06
I0516 14:15:12.372407 27330 solver.cpp:337] Iteration 81625, Testing net (#0)
I0516 14:15:12.372809 27330 net.cpp:685] Ignoring source layer ratemap
I0516 14:15:12.372828 27330 net.cpp:685] Ignoring source layer amsFeatures
I0516 14:18:03.605841 27330 solver.cpp:404]     Test net output #0: loss = 0.574319 (* 1 = 0.574319 loss)
I0516 14:24:15.234639 27330 solver.cpp:228] Iteration 81700, loss = 0.551872
I0516 14:24:15.235072 27330 solver.cpp:244]     Train net output #0: loss = 0.551874 (* 1 = 0.551874 loss)
I0516 14:24:15.235097 27330 sgd_solver.cpp:106] Iteration 81700, lr = 1e-06
I0516 14:32:43.871690 27330 solver.cpp:228] Iteration 81800, loss = 0.576812
I0516 14:32:43.872139 27330 solver.cpp:244]     Train net output #0: loss = 0.576814 (* 1 = 0.576814 loss)
I0516 14:32:43.872164 27330 sgd_solver.cpp:106] Iteration 81800, lr = 1e-06
I0516 14:41:10.602979 27330 solver.cpp:228] Iteration 81900, loss = 0.192409
I0516 14:41:10.603405 27330 solver.cpp:244]     Train net output #0: loss = 0.192411 (* 1 = 0.192411 loss)
I0516 14:41:10.603430 27330 sgd_solver.cpp:106] Iteration 81900, lr = 1e-06
I0516 14:49:32.562142 27330 solver.cpp:228] Iteration 82000, loss = 0.333945
I0516 14:49:32.562546 27330 solver.cpp:244]     Train net output #0: loss = 0.333947 (* 1 = 0.333947 loss)
I0516 14:49:32.562572 27330 sgd_solver.cpp:106] Iteration 82000, lr = 1e-06
I0516 14:58:00.910907 27330 solver.cpp:228] Iteration 82100, loss = 0.538497
I0516 14:58:00.911329 27330 solver.cpp:244]     Train net output #0: loss = 0.538499 (* 1 = 0.538499 loss)
I0516 14:58:00.911353 27330 sgd_solver.cpp:106] Iteration 82100, lr = 1e-06
I0516 15:06:35.665230 27330 solver.cpp:228] Iteration 82200, loss = 0.537534
I0516 15:06:35.665657 27330 solver.cpp:244]     Train net output #0: loss = 0.537536 (* 1 = 0.537536 loss)
I0516 15:06:35.665683 27330 sgd_solver.cpp:106] Iteration 82200, lr = 1e-06
I0516 15:14:49.222745 27330 solver.cpp:228] Iteration 82300, loss = 0.209604
I0516 15:14:49.223191 27330 solver.cpp:244]     Train net output #0: loss = 0.209606 (* 1 = 0.209606 loss)
I0516 15:14:49.223217 27330 sgd_solver.cpp:106] Iteration 82300, lr = 1e-06
I0516 15:23:04.781297 27330 solver.cpp:228] Iteration 82400, loss = 0.406139
I0516 15:23:04.781764 27330 solver.cpp:244]     Train net output #0: loss = 0.406141 (* 1 = 0.406141 loss)
I0516 15:23:04.781792 27330 sgd_solver.cpp:106] Iteration 82400, lr = 1e-06
I0516 15:31:14.330418 27330 solver.cpp:228] Iteration 82500, loss = 0.436459
I0516 15:31:14.330849 27330 solver.cpp:244]     Train net output #0: loss = 0.436461 (* 1 = 0.436461 loss)
I0516 15:31:14.330873 27330 sgd_solver.cpp:106] Iteration 82500, lr = 1e-06
I0516 15:39:43.639885 27330 solver.cpp:228] Iteration 82600, loss = 0.320855
I0516 15:39:43.640297 27330 solver.cpp:244]     Train net output #0: loss = 0.320856 (* 1 = 0.320856 loss)
I0516 15:39:43.640322 27330 sgd_solver.cpp:106] Iteration 82600, lr = 1e-06
I0516 15:48:20.467273 27330 solver.cpp:228] Iteration 82700, loss = 0.198753
I0516 15:48:20.467741 27330 solver.cpp:244]     Train net output #0: loss = 0.198754 (* 1 = 0.198754 loss)
I0516 15:48:20.467761 27330 sgd_solver.cpp:106] Iteration 82700, lr = 1e-06
I0516 15:56:35.261829 27330 solver.cpp:228] Iteration 82800, loss = 0.269715
I0516 15:56:35.262231 27330 solver.cpp:244]     Train net output #0: loss = 0.269717 (* 1 = 0.269717 loss)
I0516 15:56:35.262256 27330 sgd_solver.cpp:106] Iteration 82800, lr = 1e-06
I0516 16:04:55.657248 27330 solver.cpp:228] Iteration 82900, loss = 0.312852
I0516 16:04:55.657649 27330 solver.cpp:244]     Train net output #0: loss = 0.312854 (* 1 = 0.312854 loss)
I0516 16:04:55.657680 27330 sgd_solver.cpp:106] Iteration 82900, lr = 1e-06
I0516 16:13:16.692589 27330 solver.cpp:228] Iteration 83000, loss = 0.191133
I0516 16:13:16.692998 27330 solver.cpp:244]     Train net output #0: loss = 0.191135 (* 1 = 0.191135 loss)
I0516 16:13:16.693028 27330 sgd_solver.cpp:106] Iteration 83000, lr = 1e-06
I0516 16:21:42.328398 27330 solver.cpp:228] Iteration 83100, loss = 0.149427
I0516 16:21:42.328846 27330 solver.cpp:244]     Train net output #0: loss = 0.149429 (* 1 = 0.149429 loss)
I0516 16:21:42.328867 27330 sgd_solver.cpp:106] Iteration 83100, lr = 1e-06
I0516 16:30:17.891285 27330 solver.cpp:228] Iteration 83200, loss = 0.398844
I0516 16:30:17.891706 27330 solver.cpp:244]     Train net output #0: loss = 0.398846 (* 1 = 0.398846 loss)
I0516 16:30:17.891731 27330 sgd_solver.cpp:106] Iteration 83200, lr = 1e-06
I0516 16:38:33.236690 27330 solver.cpp:228] Iteration 83300, loss = 0.526405
I0516 16:38:33.237205 27330 solver.cpp:244]     Train net output #0: loss = 0.526406 (* 1 = 0.526406 loss)
I0516 16:38:33.237233 27330 sgd_solver.cpp:106] Iteration 83300, lr = 1e-06
I0516 16:46:54.218124 27330 solver.cpp:228] Iteration 83400, loss = 0.285734
I0516 16:46:54.218534 27330 solver.cpp:244]     Train net output #0: loss = 0.285736 (* 1 = 0.285736 loss)
I0516 16:46:54.218559 27330 sgd_solver.cpp:106] Iteration 83400, lr = 1e-06
I0516 16:55:04.923676 27330 solver.cpp:228] Iteration 83500, loss = 0.32799
I0516 16:55:04.924082 27330 solver.cpp:244]     Train net output #0: loss = 0.327991 (* 1 = 0.327991 loss)
I0516 16:55:04.924108 27330 sgd_solver.cpp:106] Iteration 83500, lr = 1e-06
I0516 17:03:11.716325 27330 solver.cpp:228] Iteration 83600, loss = 0.340618
I0516 17:03:11.716667 27330 solver.cpp:244]     Train net output #0: loss = 0.34062 (* 1 = 0.34062 loss)
I0516 17:03:11.716691 27330 sgd_solver.cpp:106] Iteration 83600, lr = 1e-06
I0516 17:11:32.778813 27330 solver.cpp:228] Iteration 83700, loss = 0.286691
I0516 17:11:32.779273 27330 solver.cpp:244]     Train net output #0: loss = 0.286693 (* 1 = 0.286693 loss)
I0516 17:11:32.779297 27330 sgd_solver.cpp:106] Iteration 83700, lr = 1e-06
I0516 17:19:53.103760 27330 solver.cpp:228] Iteration 83800, loss = 0.224972
I0516 17:19:53.104154 27330 solver.cpp:244]     Train net output #0: loss = 0.224973 (* 1 = 0.224973 loss)
I0516 17:19:53.104178 27330 sgd_solver.cpp:106] Iteration 83800, lr = 1e-06
I0516 17:28:21.209139 27330 solver.cpp:228] Iteration 83900, loss = 0.300501
I0516 17:28:21.209573 27330 solver.cpp:244]     Train net output #0: loss = 0.300503 (* 1 = 0.300503 loss)
I0516 17:28:21.209589 27330 sgd_solver.cpp:106] Iteration 83900, lr = 1e-06
I0516 17:36:51.577448 27330 solver.cpp:228] Iteration 84000, loss = 0.235864
I0516 17:36:51.577759 27330 solver.cpp:244]     Train net output #0: loss = 0.235866 (* 1 = 0.235866 loss)
I0516 17:36:51.577783 27330 sgd_solver.cpp:106] Iteration 84000, lr = 1e-06
I0516 17:45:05.966492 27330 solver.cpp:228] Iteration 84100, loss = 0.123278
I0516 17:45:05.967011 27330 solver.cpp:244]     Train net output #0: loss = 0.12328 (* 1 = 0.12328 loss)
I0516 17:45:05.967036 27330 sgd_solver.cpp:106] Iteration 84100, lr = 1e-06
I0516 17:53:32.867266 27330 solver.cpp:228] Iteration 84200, loss = 0.156172
I0516 17:53:32.867700 27330 solver.cpp:244]     Train net output #0: loss = 0.156173 (* 1 = 0.156173 loss)
I0516 17:53:32.867720 27330 sgd_solver.cpp:106] Iteration 84200, lr = 1e-06
I0516 18:02:03.368625 27330 solver.cpp:228] Iteration 84300, loss = 0.340719
I0516 18:02:03.369027 27330 solver.cpp:244]     Train net output #0: loss = 0.340721 (* 1 = 0.340721 loss)
I0516 18:02:03.369051 27330 sgd_solver.cpp:106] Iteration 84300, lr = 1e-06
I0516 18:10:39.075630 27330 solver.cpp:228] Iteration 84400, loss = 0.294473
I0516 18:10:39.076004 27330 solver.cpp:244]     Train net output #0: loss = 0.294474 (* 1 = 0.294474 loss)
I0516 18:10:39.076030 27330 sgd_solver.cpp:106] Iteration 84400, lr = 1e-06
I0516 18:19:01.875879 27330 solver.cpp:228] Iteration 84500, loss = 0.439345
I0516 18:19:01.876315 27330 solver.cpp:244]     Train net output #0: loss = 0.439347 (* 1 = 0.439347 loss)
I0516 18:19:01.876339 27330 sgd_solver.cpp:106] Iteration 84500, lr = 1e-06
I0516 18:27:16.628201 27330 solver.cpp:228] Iteration 84600, loss = 0.262317
I0516 18:27:16.628610 27330 solver.cpp:244]     Train net output #0: loss = 0.262318 (* 1 = 0.262318 loss)
I0516 18:27:16.628635 27330 sgd_solver.cpp:106] Iteration 84600, lr = 1e-06
I0516 18:35:50.265858 27330 solver.cpp:228] Iteration 84700, loss = 0.214951
I0516 18:35:50.266258 27330 solver.cpp:244]     Train net output #0: loss = 0.214953 (* 1 = 0.214953 loss)
I0516 18:35:50.266271 27330 sgd_solver.cpp:106] Iteration 84700, lr = 1e-06
I0516 18:44:16.670557 27330 solver.cpp:228] Iteration 84800, loss = 0.536505
I0516 18:44:16.670964 27330 solver.cpp:244]     Train net output #0: loss = 0.536507 (* 1 = 0.536507 loss)
I0516 18:44:16.670981 27330 sgd_solver.cpp:106] Iteration 84800, lr = 1e-06
I0516 18:51:51.957535 27330 solver.cpp:337] Iteration 84890, Testing net (#0)
I0516 18:51:51.957944 27330 net.cpp:685] Ignoring source layer ratemap
I0516 18:51:51.957957 27330 net.cpp:685] Ignoring source layer amsFeatures
I0516 18:54:43.997251 27330 solver.cpp:404]     Test net output #0: loss = 0.580169 (* 1 = 0.580169 loss)
I0516 18:55:35.386271 27330 solver.cpp:228] Iteration 84900, loss = 0.460409
I0516 18:55:35.386682 27330 solver.cpp:244]     Train net output #0: loss = 0.46041 (* 1 = 0.46041 loss)
I0516 18:55:35.386706 27330 sgd_solver.cpp:106] Iteration 84900, lr = 1e-06
I0516 19:03:59.319149 27330 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_85000.caffemodel
I0516 19:03:59.521342 27330 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_85000.solverstate
I0516 19:04:04.978000 27330 solver.cpp:228] Iteration 85000, loss = 0.240281
I0516 19:04:04.978046 27330 solver.cpp:244]     Train net output #0: loss = 0.240283 (* 1 = 0.240283 loss)
I0516 19:04:04.978056 27330 sgd_solver.cpp:106] Iteration 85000, lr = 1e-06
I0516 19:12:41.605376 27330 solver.cpp:228] Iteration 85100, loss = 0.140447
I0516 19:12:41.605885 27330 solver.cpp:244]     Train net output #0: loss = 0.140449 (* 1 = 0.140449 loss)
I0516 19:12:41.605913 27330 sgd_solver.cpp:106] Iteration 85100, lr = 1e-06
I0516 19:21:17.517591 27330 solver.cpp:228] Iteration 85200, loss = 0.368625
I0516 19:21:17.518029 27330 solver.cpp:244]     Train net output #0: loss = 0.368627 (* 1 = 0.368627 loss)
I0516 19:21:17.518054 27330 sgd_solver.cpp:106] Iteration 85200, lr = 1e-06
I0516 19:29:52.193982 27330 solver.cpp:228] Iteration 85300, loss = 0.272565
I0516 19:29:52.194417 27330 solver.cpp:244]     Train net output #0: loss = 0.272567 (* 1 = 0.272567 loss)
I0516 19:29:52.194442 27330 sgd_solver.cpp:106] Iteration 85300, lr = 1e-06
I0516 19:38:20.810495 27330 solver.cpp:228] Iteration 85400, loss = 0.286689
I0516 19:38:20.810933 27330 solver.cpp:244]     Train net output #0: loss = 0.28669 (* 1 = 0.28669 loss)
I0516 19:38:20.810957 27330 sgd_solver.cpp:106] Iteration 85400, lr = 1e-06
I0516 19:46:56.098888 27330 solver.cpp:228] Iteration 85500, loss = 0.272047
I0516 19:46:56.099351 27330 solver.cpp:244]     Train net output #0: loss = 0.272048 (* 1 = 0.272048 loss)
I0516 19:46:56.099391 27330 sgd_solver.cpp:106] Iteration 85500, lr = 1e-06
I0516 19:55:22.259652 27330 solver.cpp:228] Iteration 85600, loss = 0.487202
I0516 19:55:22.260076 27330 solver.cpp:244]     Train net output #0: loss = 0.487204 (* 1 = 0.487204 loss)
I0516 19:55:22.260097 27330 sgd_solver.cpp:106] Iteration 85600, lr = 1e-06
I0516 20:03:44.544054 27330 solver.cpp:228] Iteration 85700, loss = 0.274298
I0516 20:03:44.544510 27330 solver.cpp:244]     Train net output #0: loss = 0.2743 (* 1 = 0.2743 loss)
I0516 20:03:44.544534 27330 sgd_solver.cpp:106] Iteration 85700, lr = 1e-06
I0516 20:12:06.617727 27330 solver.cpp:228] Iteration 85800, loss = 0.427222
I0516 20:12:06.618166 27330 solver.cpp:244]     Train net output #0: loss = 0.427224 (* 1 = 0.427224 loss)
I0516 20:12:06.618191 27330 sgd_solver.cpp:106] Iteration 85800, lr = 1e-06
I0516 20:20:18.747802 27330 solver.cpp:228] Iteration 85900, loss = 0.380801
I0516 20:20:18.748270 27330 solver.cpp:244]     Train net output #0: loss = 0.380803 (* 1 = 0.380803 loss)
I0516 20:20:18.748291 27330 sgd_solver.cpp:106] Iteration 85900, lr = 1e-06
I0516 20:28:33.090703 27330 solver.cpp:228] Iteration 86000, loss = 0.319578
I0516 20:28:33.091109 27330 solver.cpp:244]     Train net output #0: loss = 0.319579 (* 1 = 0.319579 loss)
I0516 20:28:33.091133 27330 sgd_solver.cpp:106] Iteration 86000, lr = 1e-06
I0516 20:37:09.004483 27330 solver.cpp:228] Iteration 86100, loss = 0.454314
I0516 20:37:09.004951 27330 solver.cpp:244]     Train net output #0: loss = 0.454315 (* 1 = 0.454315 loss)
I0516 20:37:09.004972 27330 sgd_solver.cpp:106] Iteration 86100, lr = 1e-06
I0516 20:45:37.015131 27330 solver.cpp:228] Iteration 86200, loss = 0.250981
I0516 20:45:37.015560 27330 solver.cpp:244]     Train net output #0: loss = 0.250983 (* 1 = 0.250983 loss)
I0516 20:45:37.015585 27330 sgd_solver.cpp:106] Iteration 86200, lr = 1e-06
I0516 20:54:05.533027 27330 solver.cpp:228] Iteration 86300, loss = 0.352508
I0516 20:54:05.533479 27330 solver.cpp:244]     Train net output #0: loss = 0.35251 (* 1 = 0.35251 loss)
I0516 20:54:05.533500 27330 sgd_solver.cpp:106] Iteration 86300, lr = 1e-06
I0516 21:02:34.301033 27330 solver.cpp:228] Iteration 86400, loss = 0.183586
I0516 21:02:34.301434 27330 solver.cpp:244]     Train net output #0: loss = 0.183588 (* 1 = 0.183588 loss)
I0516 21:02:34.301460 27330 sgd_solver.cpp:106] Iteration 86400, lr = 1e-06
I0516 21:11:10.112509 27330 solver.cpp:228] Iteration 86500, loss = 0.39505
I0516 21:11:10.113014 27330 solver.cpp:244]     Train net output #0: loss = 0.395051 (* 1 = 0.395051 loss)
I0516 21:11:10.113044 27330 sgd_solver.cpp:106] Iteration 86500, lr = 1e-06
I0516 21:19:13.954387 27330 solver.cpp:228] Iteration 86600, loss = 0.277793
I0516 21:19:13.954790 27330 solver.cpp:244]     Train net output #0: loss = 0.277794 (* 1 = 0.277794 loss)
I0516 21:19:13.954814 27330 sgd_solver.cpp:106] Iteration 86600, lr = 1e-06
I0516 21:27:39.800441 27330 solver.cpp:228] Iteration 86700, loss = 0.292146
I0516 21:27:39.800892 27330 solver.cpp:244]     Train net output #0: loss = 0.292147 (* 1 = 0.292147 loss)
I0516 21:27:39.800917 27330 sgd_solver.cpp:106] Iteration 86700, lr = 1e-06
I0516 21:36:03.726744 27330 solver.cpp:228] Iteration 86800, loss = 0.135175
I0516 21:36:03.727210 27330 solver.cpp:244]     Train net output #0: loss = 0.135176 (* 1 = 0.135176 loss)
I0516 21:36:03.727231 27330 sgd_solver.cpp:106] Iteration 86800, lr = 1e-06
I0516 21:44:15.461206 27330 solver.cpp:228] Iteration 86900, loss = 0.160589
I0516 21:44:15.461771 27330 solver.cpp:244]     Train net output #0: loss = 0.16059 (* 1 = 0.16059 loss)
I0516 21:44:15.461796 27330 sgd_solver.cpp:106] Iteration 86900, lr = 1e-06
I0516 21:52:29.728349 27330 solver.cpp:228] Iteration 87000, loss = 0.175344
I0516 21:52:29.728831 27330 solver.cpp:244]     Train net output #0: loss = 0.175345 (* 1 = 0.175345 loss)
I0516 21:52:29.728863 27330 sgd_solver.cpp:106] Iteration 87000, lr = 1e-06
I0516 22:00:47.287199 27330 solver.cpp:228] Iteration 87100, loss = 0.376138
I0516 22:00:47.287623 27330 solver.cpp:244]     Train net output #0: loss = 0.376139 (* 1 = 0.376139 loss)
I0516 22:00:47.287647 27330 sgd_solver.cpp:106] Iteration 87100, lr = 1e-06
I0516 22:09:09.105509 27330 solver.cpp:228] Iteration 87200, loss = 0.442276
I0516 22:09:09.105976 27330 solver.cpp:244]     Train net output #0: loss = 0.442277 (* 1 = 0.442277 loss)
I0516 22:09:09.106001 27330 sgd_solver.cpp:106] Iteration 87200, lr = 1e-06
I0516 22:17:41.045965 27330 solver.cpp:228] Iteration 87300, loss = 0.279087
I0516 22:17:41.046409 27330 solver.cpp:244]     Train net output #0: loss = 0.279089 (* 1 = 0.279089 loss)
I0516 22:17:41.046434 27330 sgd_solver.cpp:106] Iteration 87300, lr = 1e-06
I0516 22:25:54.129150 27330 solver.cpp:228] Iteration 87400, loss = 0.350319
I0516 22:25:54.129570 27330 solver.cpp:244]     Train net output #0: loss = 0.35032 (* 1 = 0.35032 loss)
I0516 22:25:54.129602 27330 sgd_solver.cpp:106] Iteration 87400, lr = 1e-06
I0516 22:33:55.022997 27330 solver.cpp:228] Iteration 87500, loss = 0.280049
I0516 22:33:55.023450 27330 solver.cpp:244]     Train net output #0: loss = 0.280051 (* 1 = 0.280051 loss)
I0516 22:33:55.023470 27330 sgd_solver.cpp:106] Iteration 87500, lr = 1e-06
I0516 22:42:08.310312 27330 solver.cpp:228] Iteration 87600, loss = 0.285906
I0516 22:42:08.310730 27330 solver.cpp:244]     Train net output #0: loss = 0.285907 (* 1 = 0.285907 loss)
I0516 22:42:08.310755 27330 sgd_solver.cpp:106] Iteration 87600, lr = 1e-06
I0516 22:50:39.768965 27330 solver.cpp:228] Iteration 87700, loss = 0.27223
I0516 22:50:39.769381 27330 solver.cpp:244]     Train net output #0: loss = 0.272231 (* 1 = 0.272231 loss)
I0516 22:50:39.769404 27330 sgd_solver.cpp:106] Iteration 87700, lr = 1e-06
I0516 22:59:05.289242 27330 solver.cpp:228] Iteration 87800, loss = 0.195625
I0516 22:59:05.289664 27330 solver.cpp:244]     Train net output #0: loss = 0.195627 (* 1 = 0.195627 loss)
I0516 22:59:05.289688 27330 sgd_solver.cpp:106] Iteration 87800, lr = 1e-06
I0516 23:07:21.007817 27330 solver.cpp:228] Iteration 87900, loss = 0.176164
I0516 23:07:21.008206 27330 solver.cpp:244]     Train net output #0: loss = 0.176165 (* 1 = 0.176165 loss)
I0516 23:07:21.008229 27330 sgd_solver.cpp:106] Iteration 87900, lr = 1e-06
I0516 23:15:42.824790 27330 solver.cpp:228] Iteration 88000, loss = 0.412354
I0516 23:15:42.825222 27330 solver.cpp:244]     Train net output #0: loss = 0.412355 (* 1 = 0.412355 loss)
I0516 23:15:42.825247 27330 sgd_solver.cpp:106] Iteration 88000, lr = 1e-06
I0516 23:24:04.394857 27330 solver.cpp:228] Iteration 88100, loss = 0.216188
I0516 23:24:04.395305 27330 solver.cpp:244]     Train net output #0: loss = 0.216189 (* 1 = 0.216189 loss)
I0516 23:24:04.395321 27330 sgd_solver.cpp:106] Iteration 88100, lr = 1e-06
I0516 23:28:37.540019 27330 solver.cpp:337] Iteration 88155, Testing net (#0)
I0516 23:28:37.540330 27330 net.cpp:685] Ignoring source layer ratemap
I0516 23:28:37.540348 27330 net.cpp:685] Ignoring source layer amsFeatures
I0516 23:31:29.125990 27330 solver.cpp:404]     Test net output #0: loss = 0.576087 (* 1 = 0.576087 loss)
I0516 23:35:11.605590 27330 solver.cpp:228] Iteration 88200, loss = 0.254994
I0516 23:35:11.605983 27330 solver.cpp:244]     Train net output #0: loss = 0.254995 (* 1 = 0.254995 loss)
I0516 23:35:11.606009 27330 sgd_solver.cpp:106] Iteration 88200, lr = 1e-06
I0516 23:43:36.096784 27330 solver.cpp:228] Iteration 88300, loss = 0.357149
I0516 23:43:36.097232 27330 solver.cpp:244]     Train net output #0: loss = 0.35715 (* 1 = 0.35715 loss)
I0516 23:43:36.097254 27330 sgd_solver.cpp:106] Iteration 88300, lr = 1e-06
I0516 23:51:56.290886 27330 solver.cpp:228] Iteration 88400, loss = 0.239379
I0516 23:51:56.291340 27330 solver.cpp:244]     Train net output #0: loss = 0.23938 (* 1 = 0.23938 loss)
I0516 23:51:56.291362 27330 sgd_solver.cpp:106] Iteration 88400, lr = 1e-06
I0517 00:00:21.457188 27330 solver.cpp:228] Iteration 88500, loss = 0.28416
I0517 00:00:21.457651 27330 solver.cpp:244]     Train net output #0: loss = 0.284161 (* 1 = 0.284161 loss)
I0517 00:00:21.457675 27330 sgd_solver.cpp:106] Iteration 88500, lr = 1e-06
I0517 00:08:52.405863 27330 solver.cpp:228] Iteration 88600, loss = 0.160981
I0517 00:08:52.406255 27330 solver.cpp:244]     Train net output #0: loss = 0.160982 (* 1 = 0.160982 loss)
I0517 00:08:52.406287 27330 sgd_solver.cpp:106] Iteration 88600, lr = 1e-06
I0517 00:16:58.940104 27330 solver.cpp:228] Iteration 88700, loss = 0.203123
I0517 00:16:58.940552 27330 solver.cpp:244]     Train net output #0: loss = 0.203124 (* 1 = 0.203124 loss)
I0517 00:16:58.940577 27330 sgd_solver.cpp:106] Iteration 88700, lr = 1e-06
I0517 00:25:15.703553 27330 solver.cpp:228] Iteration 88800, loss = 0.450425
I0517 00:25:15.703976 27330 solver.cpp:244]     Train net output #0: loss = 0.450426 (* 1 = 0.450426 loss)
I0517 00:25:15.704002 27330 sgd_solver.cpp:106] Iteration 88800, lr = 1e-06
I0517 00:33:38.314930 27330 solver.cpp:228] Iteration 88900, loss = 0.381285
I0517 00:33:38.315351 27330 solver.cpp:244]     Train net output #0: loss = 0.381286 (* 1 = 0.381286 loss)
I0517 00:33:38.315376 27330 sgd_solver.cpp:106] Iteration 88900, lr = 1e-06
I0517 00:42:10.720597 27330 solver.cpp:228] Iteration 89000, loss = 0.244807
I0517 00:42:10.721027 27330 solver.cpp:244]     Train net output #0: loss = 0.244808 (* 1 = 0.244808 loss)
I0517 00:42:10.721051 27330 sgd_solver.cpp:106] Iteration 89000, lr = 1e-06
I0517 00:50:38.627043 27330 solver.cpp:228] Iteration 89100, loss = 0.374217
I0517 00:50:38.627467 27330 solver.cpp:244]     Train net output #0: loss = 0.374218 (* 1 = 0.374218 loss)
I0517 00:50:38.627491 27330 sgd_solver.cpp:106] Iteration 89100, lr = 1e-06
I0517 00:58:49.909838 27330 solver.cpp:228] Iteration 89200, loss = 0.262787
I0517 00:58:49.910213 27330 solver.cpp:244]     Train net output #0: loss = 0.262788 (* 1 = 0.262788 loss)
I0517 00:58:49.910226 27330 sgd_solver.cpp:106] Iteration 89200, lr = 1e-06
I0517 01:07:07.318812 27330 solver.cpp:228] Iteration 89300, loss = 0.501569
I0517 01:07:07.319227 27330 solver.cpp:244]     Train net output #0: loss = 0.50157 (* 1 = 0.50157 loss)
I0517 01:07:07.319242 27330 sgd_solver.cpp:106] Iteration 89300, lr = 1e-06
I0517 01:15:35.498561 27330 solver.cpp:228] Iteration 89400, loss = 0.240273
I0517 01:15:35.498971 27330 solver.cpp:244]     Train net output #0: loss = 0.240274 (* 1 = 0.240274 loss)
I0517 01:15:35.498996 27330 sgd_solver.cpp:106] Iteration 89400, lr = 1e-06
I0517 01:23:57.866808 27330 solver.cpp:228] Iteration 89500, loss = 0.195863
I0517 01:23:57.867254 27330 solver.cpp:244]     Train net output #0: loss = 0.195864 (* 1 = 0.195864 loss)
I0517 01:23:57.867285 27330 sgd_solver.cpp:106] Iteration 89500, lr = 1e-06
I0517 01:32:14.475307 27330 solver.cpp:228] Iteration 89600, loss = 0.209837
I0517 01:32:14.475759 27330 solver.cpp:244]     Train net output #0: loss = 0.209838 (* 1 = 0.209838 loss)
I0517 01:32:14.475778 27330 sgd_solver.cpp:106] Iteration 89600, lr = 1e-06
I0517 01:40:26.108157 27330 solver.cpp:228] Iteration 89700, loss = 0.30203
I0517 01:40:26.108630 27330 solver.cpp:244]     Train net output #0: loss = 0.302031 (* 1 = 0.302031 loss)
I0517 01:40:26.108654 27330 sgd_solver.cpp:106] Iteration 89700, lr = 1e-06
I0517 01:48:44.027861 27330 solver.cpp:228] Iteration 89800, loss = 0.215294
I0517 01:48:44.028280 27330 solver.cpp:244]     Train net output #0: loss = 0.215295 (* 1 = 0.215295 loss)
I0517 01:48:44.028293 27330 sgd_solver.cpp:106] Iteration 89800, lr = 1e-06
I0517 01:57:07.886890 27330 solver.cpp:228] Iteration 89900, loss = 0.280374
I0517 01:57:07.887367 27330 solver.cpp:244]     Train net output #0: loss = 0.280375 (* 1 = 0.280375 loss)
I0517 01:57:07.887388 27330 sgd_solver.cpp:106] Iteration 89900, lr = 1e-06
I0517 02:05:35.687659 27330 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_90000.caffemodel
I0517 02:05:35.850658 27330 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_90000.solverstate
I0517 02:05:40.878561 27330 solver.cpp:228] Iteration 90000, loss = 0.545861
I0517 02:05:40.878610 27330 solver.cpp:244]     Train net output #0: loss = 0.545862 (* 1 = 0.545862 loss)
I0517 02:05:40.878624 27330 sgd_solver.cpp:106] Iteration 90000, lr = 1e-07
I0517 02:14:09.442359 27330 solver.cpp:228] Iteration 90100, loss = 0.248736
I0517 02:14:09.442803 27330 solver.cpp:244]     Train net output #0: loss = 0.248737 (* 1 = 0.248737 loss)
I0517 02:14:09.442831 27330 sgd_solver.cpp:106] Iteration 90100, lr = 1e-07
I0517 02:22:31.800006 27330 solver.cpp:228] Iteration 90200, loss = 0.306566
I0517 02:22:31.800400 27330 solver.cpp:244]     Train net output #0: loss = 0.306567 (* 1 = 0.306567 loss)
I0517 02:22:31.800411 27330 sgd_solver.cpp:106] Iteration 90200, lr = 1e-07
I0517 02:30:58.912642 27330 solver.cpp:228] Iteration 90300, loss = 0.44706
I0517 02:30:58.912982 27330 solver.cpp:244]     Train net output #0: loss = 0.447061 (* 1 = 0.447061 loss)
I0517 02:30:58.912995 27330 sgd_solver.cpp:106] Iteration 90300, lr = 1e-07
I0517 02:39:12.531477 27330 solver.cpp:228] Iteration 90400, loss = 0.254904
I0517 02:39:12.531829 27330 solver.cpp:244]     Train net output #0: loss = 0.254905 (* 1 = 0.254905 loss)
I0517 02:39:12.531850 27330 sgd_solver.cpp:106] Iteration 90400, lr = 1e-07
I0517 02:47:42.810858 27330 solver.cpp:228] Iteration 90500, loss = 0.299292
I0517 02:47:42.811301 27330 solver.cpp:244]     Train net output #0: loss = 0.299293 (* 1 = 0.299293 loss)
I0517 02:47:42.811326 27330 sgd_solver.cpp:106] Iteration 90500, lr = 1e-07
I0517 02:55:53.800928 27330 solver.cpp:228] Iteration 90600, loss = 0.161028
I0517 02:55:53.801322 27330 solver.cpp:244]     Train net output #0: loss = 0.16103 (* 1 = 0.16103 loss)
I0517 02:55:53.801347 27330 sgd_solver.cpp:106] Iteration 90600, lr = 1e-07
I0517 03:04:21.286592 27330 solver.cpp:228] Iteration 90700, loss = 0.388251
I0517 03:04:21.286965 27330 solver.cpp:244]     Train net output #0: loss = 0.388252 (* 1 = 0.388252 loss)
I0517 03:04:21.286990 27330 sgd_solver.cpp:106] Iteration 90700, lr = 1e-07
I0517 03:12:47.545042 27330 solver.cpp:228] Iteration 90800, loss = 0.538123
I0517 03:12:47.545500 27330 solver.cpp:244]     Train net output #0: loss = 0.538124 (* 1 = 0.538124 loss)
I0517 03:12:47.545522 27330 sgd_solver.cpp:106] Iteration 90800, lr = 1e-07
I0517 03:21:16.777712 27330 solver.cpp:228] Iteration 90900, loss = 0.299649
I0517 03:21:16.778087 27330 solver.cpp:244]     Train net output #0: loss = 0.299651 (* 1 = 0.299651 loss)
I0517 03:21:16.778101 27330 sgd_solver.cpp:106] Iteration 90900, lr = 1e-07
I0517 03:29:44.699182 27330 solver.cpp:228] Iteration 91000, loss = 0.335768
I0517 03:29:44.699556 27330 solver.cpp:244]     Train net output #0: loss = 0.335769 (* 1 = 0.335769 loss)
I0517 03:29:44.699569 27330 sgd_solver.cpp:106] Iteration 91000, lr = 1e-07
I0517 03:37:55.945387 27330 solver.cpp:228] Iteration 91100, loss = 0.260234
I0517 03:37:55.945852 27330 solver.cpp:244]     Train net output #0: loss = 0.260236 (* 1 = 0.260236 loss)
I0517 03:37:55.945881 27330 sgd_solver.cpp:106] Iteration 91100, lr = 1e-07
I0517 03:46:16.695030 27330 solver.cpp:228] Iteration 91200, loss = 0.299764
I0517 03:46:16.695492 27330 solver.cpp:244]     Train net output #0: loss = 0.299765 (* 1 = 0.299765 loss)
I0517 03:46:16.695513 27330 sgd_solver.cpp:106] Iteration 91200, lr = 1e-07
I0517 03:54:35.125782 27330 solver.cpp:228] Iteration 91300, loss = 0.160292
I0517 03:54:35.126212 27330 solver.cpp:244]     Train net output #0: loss = 0.160293 (* 1 = 0.160293 loss)
I0517 03:54:35.126238 27330 sgd_solver.cpp:106] Iteration 91300, lr = 1e-07
I0517 04:02:56.460132 27330 solver.cpp:228] Iteration 91400, loss = 0.387345
I0517 04:02:56.460592 27330 solver.cpp:244]     Train net output #0: loss = 0.387346 (* 1 = 0.387346 loss)
I0517 04:02:56.460625 27330 sgd_solver.cpp:106] Iteration 91400, lr = 1e-07
I0517 04:04:32.448827 27330 solver.cpp:337] Iteration 91420, Testing net (#0)
I0517 04:04:32.449256 27330 net.cpp:685] Ignoring source layer ratemap
I0517 04:04:32.449273 27330 net.cpp:685] Ignoring source layer amsFeatures
I0517 04:07:24.001824 27330 solver.cpp:404]     Test net output #0: loss = 0.580837 (* 1 = 0.580837 loss)
I0517 04:14:15.646368 27330 solver.cpp:228] Iteration 91500, loss = 0.5365
I0517 04:14:15.646780 27330 solver.cpp:244]     Train net output #0: loss = 0.536501 (* 1 = 0.536501 loss)
I0517 04:14:15.646805 27330 sgd_solver.cpp:106] Iteration 91500, lr = 1e-07
I0517 04:22:45.672158 27330 solver.cpp:228] Iteration 91600, loss = 0.465097
I0517 04:22:45.672590 27330 solver.cpp:244]     Train net output #0: loss = 0.465099 (* 1 = 0.465099 loss)
I0517 04:22:45.672617 27330 sgd_solver.cpp:106] Iteration 91600, lr = 1e-07
I0517 04:31:14.690419 27330 solver.cpp:228] Iteration 91700, loss = 0.40634
I0517 04:31:14.690884 27330 solver.cpp:244]     Train net output #0: loss = 0.406342 (* 1 = 0.406342 loss)
I0517 04:31:14.690907 27330 sgd_solver.cpp:106] Iteration 91700, lr = 1e-07
I0517 04:39:22.624131 27330 solver.cpp:228] Iteration 91800, loss = 0.271614
I0517 04:39:22.624519 27330 solver.cpp:244]     Train net output #0: loss = 0.271616 (* 1 = 0.271616 loss)
I0517 04:39:22.624547 27330 sgd_solver.cpp:106] Iteration 91800, lr = 1e-07
I0517 04:47:56.786185 27330 solver.cpp:228] Iteration 91900, loss = 0.244661
I0517 04:47:56.786684 27330 solver.cpp:244]     Train net output #0: loss = 0.244663 (* 1 = 0.244663 loss)
I0517 04:47:56.786716 27330 sgd_solver.cpp:106] Iteration 91900, lr = 1e-07
I0517 04:56:03.009873 27330 solver.cpp:228] Iteration 92000, loss = 0.457838
I0517 04:56:03.010310 27330 solver.cpp:244]     Train net output #0: loss = 0.45784 (* 1 = 0.45784 loss)
I0517 04:56:03.010336 27330 sgd_solver.cpp:106] Iteration 92000, lr = 1e-07
I0517 05:04:39.004619 27330 solver.cpp:228] Iteration 92100, loss = 0.185069
I0517 05:04:39.005026 27330 solver.cpp:244]     Train net output #0: loss = 0.18507 (* 1 = 0.18507 loss)
I0517 05:04:39.005053 27330 sgd_solver.cpp:106] Iteration 92100, lr = 1e-07
I0517 05:12:49.884218 27330 solver.cpp:228] Iteration 92200, loss = 0.454728
I0517 05:12:49.884651 27330 solver.cpp:244]     Train net output #0: loss = 0.45473 (* 1 = 0.45473 loss)
I0517 05:12:49.884678 27330 sgd_solver.cpp:106] Iteration 92200, lr = 1e-07
I0517 05:21:16.616152 27330 solver.cpp:228] Iteration 92300, loss = 0.327252
I0517 05:21:16.616601 27330 solver.cpp:244]     Train net output #0: loss = 0.327254 (* 1 = 0.327254 loss)
I0517 05:21:16.616626 27330 sgd_solver.cpp:106] Iteration 92300, lr = 1e-07
I0517 05:29:29.375617 27330 solver.cpp:228] Iteration 92400, loss = 0.411456
I0517 05:29:29.376004 27330 solver.cpp:244]     Train net output #0: loss = 0.411457 (* 1 = 0.411457 loss)
I0517 05:29:29.376029 27330 sgd_solver.cpp:106] Iteration 92400, lr = 1e-07
I0517 05:37:53.320868 27330 solver.cpp:228] Iteration 92500, loss = 0.105045
I0517 05:37:53.321337 27330 solver.cpp:244]     Train net output #0: loss = 0.105047 (* 1 = 0.105047 loss)
I0517 05:37:53.321359 27330 sgd_solver.cpp:106] Iteration 92500, lr = 1e-07
I0517 05:46:13.845106 27330 solver.cpp:228] Iteration 92600, loss = 0.211856
I0517 05:46:13.845518 27330 solver.cpp:244]     Train net output #0: loss = 0.211858 (* 1 = 0.211858 loss)
I0517 05:46:13.845543 27330 sgd_solver.cpp:106] Iteration 92600, lr = 1e-07
I0517 05:54:37.564592 27330 solver.cpp:228] Iteration 92700, loss = 0.334723
I0517 05:54:37.565060 27330 solver.cpp:244]     Train net output #0: loss = 0.334725 (* 1 = 0.334725 loss)
I0517 05:54:37.565083 27330 sgd_solver.cpp:106] Iteration 92700, lr = 1e-07
I0517 06:02:57.045958 27330 solver.cpp:228] Iteration 92800, loss = 0.210523
I0517 06:02:57.046411 27330 solver.cpp:244]     Train net output #0: loss = 0.210525 (* 1 = 0.210525 loss)
I0517 06:02:57.046432 27330 sgd_solver.cpp:106] Iteration 92800, lr = 1e-07
I0517 06:11:21.159796 27330 solver.cpp:228] Iteration 92900, loss = 0.370636
I0517 06:11:21.160125 27330 solver.cpp:244]     Train net output #0: loss = 0.370638 (* 1 = 0.370638 loss)
I0517 06:11:21.160151 27330 sgd_solver.cpp:106] Iteration 92900, lr = 1e-07
I0517 06:19:45.473942 27330 solver.cpp:228] Iteration 93000, loss = 0.379636
I0517 06:19:45.474398 27330 solver.cpp:244]     Train net output #0: loss = 0.379638 (* 1 = 0.379638 loss)
I0517 06:19:45.474422 27330 sgd_solver.cpp:106] Iteration 93000, lr = 1e-07
I0517 06:28:04.903930 27330 solver.cpp:228] Iteration 93100, loss = 0.279166
I0517 06:28:04.904383 27330 solver.cpp:244]     Train net output #0: loss = 0.279167 (* 1 = 0.279167 loss)
I0517 06:28:04.904405 27330 sgd_solver.cpp:106] Iteration 93100, lr = 1e-07
I0517 06:36:30.377243 27330 solver.cpp:228] Iteration 93200, loss = 0.167923
I0517 06:36:30.967937 27330 solver.cpp:244]     Train net output #0: loss = 0.167924 (* 1 = 0.167924 loss)
I0517 06:36:30.967962 27330 sgd_solver.cpp:106] Iteration 93200, lr = 1e-07
I0517 06:44:42.862036 27330 solver.cpp:228] Iteration 93300, loss = 0.277163
I0517 06:44:43.020334 27330 solver.cpp:244]     Train net output #0: loss = 0.277165 (* 1 = 0.277165 loss)
I0517 06:44:43.020362 27330 sgd_solver.cpp:106] Iteration 93300, lr = 1e-07
I0517 06:53:12.380640 27330 solver.cpp:228] Iteration 93400, loss = 0.373836
I0517 06:53:12.380986 27330 solver.cpp:244]     Train net output #0: loss = 0.373838 (* 1 = 0.373838 loss)
I0517 06:53:12.381000 27330 sgd_solver.cpp:106] Iteration 93400, lr = 1e-07
I0517 07:01:35.447825 27330 solver.cpp:228] Iteration 93500, loss = 0.206067
I0517 07:01:35.448225 27330 solver.cpp:244]     Train net output #0: loss = 0.206069 (* 1 = 0.206069 loss)
I0517 07:01:35.448251 27330 sgd_solver.cpp:106] Iteration 93500, lr = 1e-07
I0517 07:09:54.956277 27330 solver.cpp:228] Iteration 93600, loss = 0.353971
I0517 07:09:54.956687 27330 solver.cpp:244]     Train net output #0: loss = 0.353973 (* 1 = 0.353973 loss)
I0517 07:09:54.956718 27330 sgd_solver.cpp:106] Iteration 93600, lr = 1e-07
I0517 07:18:00.162317 27330 solver.cpp:228] Iteration 93700, loss = 0.486948
I0517 07:18:00.162760 27330 solver.cpp:244]     Train net output #0: loss = 0.48695 (* 1 = 0.48695 loss)
I0517 07:18:00.162786 27330 sgd_solver.cpp:106] Iteration 93700, lr = 1e-07
I0517 07:26:43.031286 27330 solver.cpp:228] Iteration 93800, loss = 0.171091
I0517 07:26:43.031659 27330 solver.cpp:244]     Train net output #0: loss = 0.171093 (* 1 = 0.171093 loss)
I0517 07:26:43.031684 27330 sgd_solver.cpp:106] Iteration 93800, lr = 1e-07
I0517 07:34:57.041901 27330 solver.cpp:228] Iteration 93900, loss = 0.339946
I0517 07:34:57.042366 27330 solver.cpp:244]     Train net output #0: loss = 0.339948 (* 1 = 0.339948 loss)
I0517 07:34:57.042404 27330 sgd_solver.cpp:106] Iteration 93900, lr = 1e-07
I0517 07:43:17.216644 27330 solver.cpp:228] Iteration 94000, loss = 0.241428
I0517 07:43:17.217097 27330 solver.cpp:244]     Train net output #0: loss = 0.24143 (* 1 = 0.24143 loss)
I0517 07:43:17.217118 27330 sgd_solver.cpp:106] Iteration 94000, lr = 1e-07
I0517 07:51:37.031010 27330 solver.cpp:228] Iteration 94100, loss = 0.308793
I0517 07:51:37.031445 27330 solver.cpp:244]     Train net output #0: loss = 0.308795 (* 1 = 0.308795 loss)
I0517 07:51:37.031476 27330 sgd_solver.cpp:106] Iteration 94100, lr = 1e-07
I0517 07:59:47.914063 27330 solver.cpp:228] Iteration 94200, loss = 0.26104
I0517 07:59:47.914528 27330 solver.cpp:244]     Train net output #0: loss = 0.261042 (* 1 = 0.261042 loss)
I0517 07:59:47.914549 27330 sgd_solver.cpp:106] Iteration 94200, lr = 1e-07
I0517 08:07:48.689611 27330 solver.cpp:228] Iteration 94300, loss = 0.294379
I0517 08:07:48.689991 27330 solver.cpp:244]     Train net output #0: loss = 0.294381 (* 1 = 0.294381 loss)
I0517 08:07:48.690008 27330 sgd_solver.cpp:106] Iteration 94300, lr = 1e-07
I0517 08:15:56.375756 27330 solver.cpp:228] Iteration 94400, loss = 0.454802
I0517 08:15:56.376171 27330 solver.cpp:244]     Train net output #0: loss = 0.454805 (* 1 = 0.454805 loss)
I0517 08:15:56.376196 27330 sgd_solver.cpp:106] Iteration 94400, lr = 1e-07
I0517 08:24:33.341702 27330 solver.cpp:228] Iteration 94500, loss = 0.181493
I0517 08:24:33.342144 27330 solver.cpp:244]     Train net output #0: loss = 0.181496 (* 1 = 0.181496 loss)
I0517 08:24:33.342165 27330 sgd_solver.cpp:106] Iteration 94500, lr = 1e-07
I0517 08:32:48.641795 27330 solver.cpp:228] Iteration 94600, loss = 0.184984
I0517 08:32:48.642251 27330 solver.cpp:244]     Train net output #0: loss = 0.184986 (* 1 = 0.184986 loss)
I0517 08:32:48.642287 27330 sgd_solver.cpp:106] Iteration 94600, lr = 1e-07
I0517 08:39:56.283860 27330 solver.cpp:337] Iteration 94685, Testing net (#0)
I0517 08:39:56.284319 27330 net.cpp:685] Ignoring source layer ratemap
I0517 08:39:56.284343 27330 net.cpp:685] Ignoring source layer amsFeatures
I0517 08:42:47.457970 27330 solver.cpp:404]     Test net output #0: loss = 0.582201 (* 1 = 0.582201 loss)
I0517 08:44:11.323542 27330 solver.cpp:228] Iteration 94700, loss = 0.32538
I0517 08:44:11.323932 27330 solver.cpp:244]     Train net output #0: loss = 0.325382 (* 1 = 0.325382 loss)
I0517 08:44:11.323957 27330 sgd_solver.cpp:106] Iteration 94700, lr = 1e-07
I0517 08:52:39.550616 27330 solver.cpp:228] Iteration 94800, loss = 0.495519
I0517 08:52:39.551055 27330 solver.cpp:244]     Train net output #0: loss = 0.495522 (* 1 = 0.495522 loss)
I0517 08:52:39.551081 27330 sgd_solver.cpp:106] Iteration 94800, lr = 1e-07
I0517 09:00:59.773999 27330 solver.cpp:228] Iteration 94900, loss = 0.251943
I0517 09:00:59.774327 27330 solver.cpp:244]     Train net output #0: loss = 0.251945 (* 1 = 0.251945 loss)
I0517 09:00:59.774350 27330 sgd_solver.cpp:106] Iteration 94900, lr = 1e-07
I0517 09:08:59.340416 27330 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_95000.caffemodel
I0517 09:08:59.500787 27330 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_95000.solverstate
I0517 09:09:04.760978 27330 solver.cpp:228] Iteration 95000, loss = 0.190716
I0517 09:09:04.761029 27330 solver.cpp:244]     Train net output #0: loss = 0.190718 (* 1 = 0.190718 loss)
I0517 09:09:04.761041 27330 sgd_solver.cpp:106] Iteration 95000, lr = 1e-07
I0517 09:17:40.936358 27330 solver.cpp:228] Iteration 95100, loss = 0.185796
I0517 09:17:40.936812 27330 solver.cpp:244]     Train net output #0: loss = 0.185798 (* 1 = 0.185798 loss)
I0517 09:17:40.936838 27330 sgd_solver.cpp:106] Iteration 95100, lr = 1e-07
I0517 09:25:48.379228 27330 solver.cpp:228] Iteration 95200, loss = 0.485125
I0517 09:25:48.379706 27330 solver.cpp:244]     Train net output #0: loss = 0.485127 (* 1 = 0.485127 loss)
I0517 09:25:48.379737 27330 sgd_solver.cpp:106] Iteration 95200, lr = 1e-07
I0517 09:34:16.909711 27330 solver.cpp:228] Iteration 95300, loss = 0.430108
I0517 09:34:16.910145 27330 solver.cpp:244]     Train net output #0: loss = 0.43011 (* 1 = 0.43011 loss)
I0517 09:34:16.910169 27330 sgd_solver.cpp:106] Iteration 95300, lr = 1e-07
I0517 09:42:33.344727 27330 solver.cpp:228] Iteration 95400, loss = 0.274013
I0517 09:42:33.345188 27330 solver.cpp:244]     Train net output #0: loss = 0.274015 (* 1 = 0.274015 loss)
I0517 09:42:33.345211 27330 sgd_solver.cpp:106] Iteration 95400, lr = 1e-07
I0517 09:50:52.409333 27330 solver.cpp:228] Iteration 95500, loss = 0.264749
I0517 09:50:52.409804 27330 solver.cpp:244]     Train net output #0: loss = 0.264752 (* 1 = 0.264752 loss)
I0517 09:50:52.409834 27330 sgd_solver.cpp:106] Iteration 95500, lr = 1e-07
I0517 09:59:18.537333 27330 solver.cpp:228] Iteration 95600, loss = 0.221039
I0517 09:59:18.537799 27330 solver.cpp:244]     Train net output #0: loss = 0.221041 (* 1 = 0.221041 loss)
I0517 09:59:18.537828 27330 sgd_solver.cpp:106] Iteration 95600, lr = 1e-07
I0517 10:07:23.226006 27330 solver.cpp:228] Iteration 95700, loss = 0.245755
I0517 10:07:23.226441 27330 solver.cpp:244]     Train net output #0: loss = 0.245757 (* 1 = 0.245757 loss)
I0517 10:07:23.226469 27330 sgd_solver.cpp:106] Iteration 95700, lr = 1e-07
I0517 10:15:48.040594 27330 solver.cpp:228] Iteration 95800, loss = 0.192504
I0517 10:15:48.041044 27330 solver.cpp:244]     Train net output #0: loss = 0.192506 (* 1 = 0.192506 loss)
I0517 10:15:48.041070 27330 sgd_solver.cpp:106] Iteration 95800, lr = 1e-07
I0517 10:24:11.065666 27330 solver.cpp:228] Iteration 95900, loss = 0.329753
I0517 10:24:11.066115 27330 solver.cpp:244]     Train net output #0: loss = 0.329755 (* 1 = 0.329755 loss)
I0517 10:24:11.066140 27330 sgd_solver.cpp:106] Iteration 95900, lr = 1e-07
I0517 10:32:28.928266 27330 solver.cpp:228] Iteration 96000, loss = 0.438581
I0517 10:32:28.928722 27330 solver.cpp:244]     Train net output #0: loss = 0.438584 (* 1 = 0.438584 loss)
I0517 10:32:28.928748 27330 sgd_solver.cpp:106] Iteration 96000, lr = 1e-07
I0517 10:40:35.782868 27330 solver.cpp:228] Iteration 96100, loss = 0.307732
I0517 10:40:35.783360 27330 solver.cpp:244]     Train net output #0: loss = 0.307734 (* 1 = 0.307734 loss)
I0517 10:40:35.783381 27330 sgd_solver.cpp:106] Iteration 96100, lr = 1e-07
I0517 10:48:56.002750 27330 solver.cpp:228] Iteration 96200, loss = 0.324745
I0517 10:48:56.003201 27330 solver.cpp:244]     Train net output #0: loss = 0.324747 (* 1 = 0.324747 loss)
I0517 10:48:56.003226 27330 sgd_solver.cpp:106] Iteration 96200, lr = 1e-07
I0517 10:57:20.865298 27330 solver.cpp:228] Iteration 96300, loss = 0.670626
I0517 10:57:20.865869 27330 solver.cpp:244]     Train net output #0: loss = 0.670628 (* 1 = 0.670628 loss)
I0517 10:57:20.865898 27330 sgd_solver.cpp:106] Iteration 96300, lr = 1e-07
I0517 11:05:45.608878 27330 solver.cpp:228] Iteration 96400, loss = 0.235196
I0517 11:05:45.609287 27330 solver.cpp:244]     Train net output #0: loss = 0.235198 (* 1 = 0.235198 loss)
I0517 11:05:45.609299 27330 sgd_solver.cpp:106] Iteration 96400, lr = 1e-07
I0517 11:14:03.160434 27330 solver.cpp:228] Iteration 96500, loss = 0.309982
I0517 11:14:03.160893 27330 solver.cpp:244]     Train net output #0: loss = 0.309984 (* 1 = 0.309984 loss)
I0517 11:14:03.160923 27330 sgd_solver.cpp:106] Iteration 96500, lr = 1e-07
I0517 11:22:27.144084 27330 solver.cpp:228] Iteration 96600, loss = 0.265049
I0517 11:22:27.144559 27330 solver.cpp:244]     Train net output #0: loss = 0.265051 (* 1 = 0.265051 loss)
I0517 11:22:27.144582 27330 sgd_solver.cpp:106] Iteration 96600, lr = 1e-07
I0517 11:30:54.158315 27330 solver.cpp:228] Iteration 96700, loss = 0.181464
I0517 11:30:54.158747 27330 solver.cpp:244]     Train net output #0: loss = 0.181466 (* 1 = 0.181466 loss)
I0517 11:30:54.158773 27330 sgd_solver.cpp:106] Iteration 96700, lr = 1e-07
I0517 11:39:08.432076 27330 solver.cpp:228] Iteration 96800, loss = 0.432377
I0517 11:39:08.432505 27330 solver.cpp:244]     Train net output #0: loss = 0.432379 (* 1 = 0.432379 loss)
I0517 11:39:08.432530 27330 sgd_solver.cpp:106] Iteration 96800, lr = 1e-07
I0517 11:47:25.278275 27330 solver.cpp:228] Iteration 96900, loss = 0.227328
I0517 11:47:25.278820 27330 solver.cpp:244]     Train net output #0: loss = 0.22733 (* 1 = 0.22733 loss)
I0517 11:47:25.278848 27330 sgd_solver.cpp:106] Iteration 96900, lr = 1e-07
I0517 11:55:32.128428 27330 solver.cpp:228] Iteration 97000, loss = 0.224158
I0517 11:55:32.128885 27330 solver.cpp:244]     Train net output #0: loss = 0.22416 (* 1 = 0.22416 loss)
I0517 11:55:32.128911 27330 sgd_solver.cpp:106] Iteration 97000, lr = 1e-07
I0517 12:04:09.794472 27330 solver.cpp:228] Iteration 97100, loss = 0.308004
I0517 12:04:09.794816 27330 solver.cpp:244]     Train net output #0: loss = 0.308006 (* 1 = 0.308006 loss)
I0517 12:04:09.794828 27330 sgd_solver.cpp:106] Iteration 97100, lr = 1e-07
I0517 12:12:15.798832 27330 solver.cpp:228] Iteration 97200, loss = 0.476027
I0517 12:12:15.799216 27330 solver.cpp:244]     Train net output #0: loss = 0.476029 (* 1 = 0.476029 loss)
I0517 12:12:15.799240 27330 sgd_solver.cpp:106] Iteration 97200, lr = 1e-07
I0517 12:20:35.206990 27330 solver.cpp:228] Iteration 97300, loss = 0.360721
I0517 12:20:35.207404 27330 solver.cpp:244]     Train net output #0: loss = 0.360723 (* 1 = 0.360723 loss)
I0517 12:20:35.207429 27330 sgd_solver.cpp:106] Iteration 97300, lr = 1e-07
I0517 12:29:01.398715 27330 solver.cpp:228] Iteration 97400, loss = 0.383972
I0517 12:29:01.399206 27330 solver.cpp:244]     Train net output #0: loss = 0.383974 (* 1 = 0.383974 loss)
I0517 12:29:01.399230 27330 sgd_solver.cpp:106] Iteration 97400, lr = 1e-07
I0517 12:37:21.522039 27330 solver.cpp:228] Iteration 97500, loss = 0.399954
I0517 12:37:21.522475 27330 solver.cpp:244]     Train net output #0: loss = 0.399956 (* 1 = 0.399956 loss)
I0517 12:37:21.522498 27330 sgd_solver.cpp:106] Iteration 97500, lr = 1e-07
I0517 12:45:47.166291 27330 solver.cpp:228] Iteration 97600, loss = 0.258398
I0517 12:45:47.166723 27330 solver.cpp:244]     Train net output #0: loss = 0.2584 (* 1 = 0.2584 loss)
I0517 12:45:47.166749 27330 sgd_solver.cpp:106] Iteration 97600, lr = 1e-07
I0517 12:54:03.014703 27330 solver.cpp:228] Iteration 97700, loss = 0.453574
I0517 12:54:03.015115 27330 solver.cpp:244]     Train net output #0: loss = 0.453576 (* 1 = 0.453576 loss)
I0517 12:54:03.015141 27330 sgd_solver.cpp:106] Iteration 97700, lr = 1e-07
I0517 13:02:21.684427 27330 solver.cpp:228] Iteration 97800, loss = 0.254373
I0517 13:02:21.684844 27330 solver.cpp:244]     Train net output #0: loss = 0.254375 (* 1 = 0.254375 loss)
I0517 13:02:21.684867 27330 sgd_solver.cpp:106] Iteration 97800, lr = 1e-07
I0517 13:10:45.376682 27330 solver.cpp:228] Iteration 97900, loss = 0.151879
I0517 13:10:45.377149 27330 solver.cpp:244]     Train net output #0: loss = 0.151881 (* 1 = 0.151881 loss)
I0517 13:10:45.377164 27330 sgd_solver.cpp:106] Iteration 97900, lr = 1e-07
I0517 13:15:03.484307 27330 solver.cpp:337] Iteration 97950, Testing net (#0)
I0517 13:15:03.484719 27330 net.cpp:685] Ignoring source layer ratemap
I0517 13:15:03.484732 27330 net.cpp:685] Ignoring source layer amsFeatures
I0517 13:17:54.841701 27330 solver.cpp:404]     Test net output #0: loss = 0.582182 (* 1 = 0.582182 loss)
I0517 13:22:02.057885 27330 solver.cpp:228] Iteration 98000, loss = 0.202095
I0517 13:22:02.058281 27330 solver.cpp:244]     Train net output #0: loss = 0.202097 (* 1 = 0.202097 loss)
I0517 13:22:02.058296 27330 sgd_solver.cpp:106] Iteration 98000, lr = 1e-07
I0517 13:30:20.576112 27330 solver.cpp:228] Iteration 98100, loss = 0.191485
I0517 13:30:20.576591 27330 solver.cpp:244]     Train net output #0: loss = 0.191487 (* 1 = 0.191487 loss)
I0517 13:30:20.576616 27330 sgd_solver.cpp:106] Iteration 98100, lr = 1e-07
I0517 13:38:35.755501 27330 solver.cpp:228] Iteration 98200, loss = 0.165561
I0517 13:38:38.786440 27330 solver.cpp:244]     Train net output #0: loss = 0.165563 (* 1 = 0.165563 loss)
I0517 13:38:38.786463 27330 sgd_solver.cpp:106] Iteration 98200, lr = 1e-07
I0517 13:47:02.430420 27330 solver.cpp:228] Iteration 98300, loss = 0.231585
I0517 13:47:02.430891 27330 solver.cpp:244]     Train net output #0: loss = 0.231586 (* 1 = 0.231586 loss)
I0517 13:47:02.430923 27330 sgd_solver.cpp:106] Iteration 98300, lr = 1e-07
I0517 13:55:18.232316 27330 solver.cpp:228] Iteration 98400, loss = 0.310018
I0517 13:55:18.339586 27330 solver.cpp:244]     Train net output #0: loss = 0.31002 (* 1 = 0.31002 loss)
I0517 13:55:18.339619 27330 sgd_solver.cpp:106] Iteration 98400, lr = 1e-07
I0517 14:03:46.303689 27330 solver.cpp:228] Iteration 98500, loss = 0.269744
I0517 14:03:46.869745 27330 solver.cpp:244]     Train net output #0: loss = 0.269746 (* 1 = 0.269746 loss)
I0517 14:03:46.869776 27330 sgd_solver.cpp:106] Iteration 98500, lr = 1e-07
I0517 14:12:15.275495 27330 solver.cpp:228] Iteration 98600, loss = 0.357681
I0517 14:12:15.275915 27330 solver.cpp:244]     Train net output #0: loss = 0.357683 (* 1 = 0.357683 loss)
I0517 14:12:15.275929 27330 sgd_solver.cpp:106] Iteration 98600, lr = 1e-07
I0517 14:20:15.918043 27330 solver.cpp:228] Iteration 98700, loss = 0.250934
I0517 14:20:15.918462 27330 solver.cpp:244]     Train net output #0: loss = 0.250935 (* 1 = 0.250935 loss)
I0517 14:20:15.918493 27330 sgd_solver.cpp:106] Iteration 98700, lr = 1e-07
I0517 14:28:23.913733 27330 solver.cpp:228] Iteration 98800, loss = 0.183656
I0517 14:28:26.676731 27330 solver.cpp:244]     Train net output #0: loss = 0.183658 (* 1 = 0.183658 loss)
I0517 14:28:26.676764 27330 sgd_solver.cpp:106] Iteration 98800, lr = 1e-07
I0517 14:36:51.173292 27330 solver.cpp:228] Iteration 98900, loss = 0.418222
I0517 14:36:51.501982 27330 solver.cpp:244]     Train net output #0: loss = 0.418224 (* 1 = 0.418224 loss)
I0517 14:36:51.502012 27330 sgd_solver.cpp:106] Iteration 98900, lr = 1e-07
I0517 14:45:02.784756 27330 solver.cpp:228] Iteration 99000, loss = 0.367199
I0517 14:45:02.785130 27330 solver.cpp:244]     Train net output #0: loss = 0.3672 (* 1 = 0.3672 loss)
I0517 14:45:02.785153 27330 sgd_solver.cpp:106] Iteration 99000, lr = 1e-07
I0517 14:53:23.967285 27330 solver.cpp:228] Iteration 99100, loss = 0.145302
I0517 14:53:24.669145 27330 solver.cpp:244]     Train net output #0: loss = 0.145304 (* 1 = 0.145304 loss)
I0517 14:53:24.669169 27330 sgd_solver.cpp:106] Iteration 99100, lr = 1e-07
I0517 15:01:41.284019 27330 solver.cpp:228] Iteration 99200, loss = 0.333905
I0517 15:01:41.393102 27330 solver.cpp:244]     Train net output #0: loss = 0.333907 (* 1 = 0.333907 loss)
I0517 15:01:41.393124 27330 sgd_solver.cpp:106] Iteration 99200, lr = 1e-07
I0517 15:09:53.613559 27330 solver.cpp:228] Iteration 99300, loss = 0.360088
I0517 15:09:54.679132 27330 solver.cpp:244]     Train net output #0: loss = 0.36009 (* 1 = 0.36009 loss)
I0517 15:09:54.679178 27330 sgd_solver.cpp:106] Iteration 99300, lr = 1e-07
I0517 15:18:22.034095 27330 solver.cpp:228] Iteration 99400, loss = 0.44853
I0517 15:18:22.034577 27330 solver.cpp:244]     Train net output #0: loss = 0.448531 (* 1 = 0.448531 loss)
I0517 15:18:22.034607 27330 sgd_solver.cpp:106] Iteration 99400, lr = 1e-07
I0517 15:26:38.994248 27330 solver.cpp:228] Iteration 99500, loss = 0.173978
I0517 15:26:38.994685 27330 solver.cpp:244]     Train net output #0: loss = 0.173979 (* 1 = 0.173979 loss)
I0517 15:26:38.994711 27330 sgd_solver.cpp:106] Iteration 99500, lr = 1e-07
I0517 15:35:06.211544 27330 solver.cpp:228] Iteration 99600, loss = 0.337536
I0517 15:35:06.211935 27330 solver.cpp:244]     Train net output #0: loss = 0.337538 (* 1 = 0.337538 loss)
I0517 15:35:06.211962 27330 sgd_solver.cpp:106] Iteration 99600, lr = 1e-07
I0517 15:43:20.171895 27330 solver.cpp:228] Iteration 99700, loss = 0.377193
I0517 15:43:20.172338 27330 solver.cpp:244]     Train net output #0: loss = 0.377195 (* 1 = 0.377195 loss)
I0517 15:43:20.172360 27330 sgd_solver.cpp:106] Iteration 99700, lr = 1e-07
I0517 15:51:36.349879 27330 solver.cpp:228] Iteration 99800, loss = 0.2558
I0517 15:51:36.350322 27330 solver.cpp:244]     Train net output #0: loss = 0.255802 (* 1 = 0.255802 loss)
I0517 15:51:36.350347 27330 sgd_solver.cpp:106] Iteration 99800, lr = 1e-07
I0517 16:00:06.107234 27330 solver.cpp:228] Iteration 99900, loss = 0.450205
I0517 16:00:06.244822 27330 solver.cpp:244]     Train net output #0: loss = 0.450207 (* 1 = 0.450207 loss)
I0517 16:00:06.244839 27330 sgd_solver.cpp:106] Iteration 99900, lr = 1e-07
I0517 16:08:01.009986 27330 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_100000.caffemodel
I0517 16:08:01.209081 27330 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/24/te_iter_100000.solverstate
I0517 16:08:06.497171 27330 solver.cpp:317] Iteration 100000, loss = 0.356134
I0517 16:08:06.497231 27330 solver.cpp:322] Optimization Done.
I0517 16:08:06.497237 27330 caffe.cpp:222] Optimization Done.
