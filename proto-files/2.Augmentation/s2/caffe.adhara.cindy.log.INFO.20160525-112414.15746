Log file created at: 2016/05/25 11:24:14
Running on machine: adhara
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0525 11:24:14.344027 15746 caffe.cpp:185] Using GPUs 0
I0525 11:24:14.353008 15746 caffe.cpp:190] GPU 0: GeForce GTX 580
I0525 11:24:14.489181 15746 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1065
test_interval: 3265
base_lr: 0.0001
display: 100
max_iter: 100000
lr_policy: "step"
gamma: 0.1
momentum: 0.99
weight_decay: 0.0005
stepsize: 30000
snapshot: 3000
snapshot_prefix: "/mnt/raid/dnn/cindy/modelfiles/s2/te"
solver_mode: GPU
device_id: 0
net: "/mnt/antares_raid/home/cindy/adhara/experiments/s2/train_val.prototxt"
snapshot_after_train: true
I0525 11:24:14.489449 15746 solver.cpp:91] Creating training net from net file: /mnt/antares_raid/home/cindy/adhara/experiments/s2/train_val.prototxt
I0525 11:24:14.490931 15746 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0525 11:24:14.491201 15746 net.cpp:49] Initializing net from parameters: 
name: "SoundNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "amsFeatures"
  top: "ratemap"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/mnt/antares_raid/home/cindy/adhara/experiments/twoears_data_train.txt"
    batch_size: 128
  }
}
layer {
  name: "ratemap"
  type: "Python"
  bottom: "ratemap"
  top: "ratemap"
  include {
    phase: TRAIN
  }
  python_param {
    module: "nideep.layers.jitterlayer"
    layer: "JitterLayer"
    param_str: "{\'min_shift_f\':-8,\'max_shift_f\':8,\'min_shift_t\':-40,\'max_shift_t\':40}"
  }
}
layer {
  name: "amsFeatures"
  type: "Python"
  bottom: "amsFeatures"
  top: "amsFeatures"
  include {
    phase: TRAIN
  }
  python_param {
    module: "nideep.layers.jitterlayer"
    layer: "JitterLayer"
    param_str: "{\'min_shift_f\':-8,\'max_shift_f\':8,\'min_shift_t\':-40,\'max_shift_t\':40}"
  }
}
layer {
  name: "conv1_a"
  type: "Convolution"
  bottom: "amsFeatures"
  top: "conv1_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 6
  }
}
layer {
  name: "relu1_a"
  type: "ReLU"
  bottom: "conv1_a"
  top: "conv1_a"
}
layer {
  name: "conv2_a"
  type: "Convolution"
  bottom: "conv1_a"
  top: "conv2_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "pool2_a"
  type: "Pooling"
  bottom: "conv2_a"
  top: "pool2_a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "relu2_a"
  type: "ReLU"
  bottom: "pool2_a"
  top: "pool2_a"
}
layer {
  name: "ip2_a"
  type: "InnerProduct"
  bottom: "pool2_a"
  top: "ip2_a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_r"
  type: "Convolution"
  bottom: "ratemap"
  top: "conv1_r"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 6
  }
}
layer {
  name: "relu1_r"
  type: "ReLU"
  bottom: "conv1_r"
  top: "conv1_r"
}
layer {
  name: "conv2_r"
  type: "Convolution"
  bottom: "conv1_r"
  top: "conv2_r"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "pool2_r"
  type: "Pooling"
  bottom: "conv2_r"
  top: "pool2_r"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "relu2_r"
  type: "ReLU"
  bottom: "pool2_r"
  top: "pool2_r"
}
layer {
  name: "ip2_r"
  type: "InnerProduct"
  bottom: "pool2_r"
  top: "ip2_r"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "concat_ar"
  type: "Concat"
  bottom: "ip2_a"
  bottom: "ip2_r"
  top: "ip2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "dropip2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SigmoidCrossEntropyLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 11:24:14.492539 15746 layer_factory.hpp:77] Creating layer data
I0525 11:24:14.492586 15746 net.cpp:91] Creating Layer data
I0525 11:24:14.492619 15746 net.cpp:399] data -> amsFeatures
I0525 11:24:14.492691 15746 net.cpp:399] data -> ratemap
I0525 11:24:14.492720 15746 net.cpp:399] data -> label
I0525 11:24:14.492753 15746 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /mnt/antares_raid/home/cindy/adhara/experiments/twoears_data_train.txt
I0525 11:24:14.493324 15746 hdf5_data_layer.cpp:93] Number of HDF5 files: 5
I0525 11:24:14.495903 15746 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0525 11:24:19.530319 15746 net.cpp:141] Setting up data
I0525 11:24:19.530369 15746 net.cpp:148] Top shape: 128 9 16 63 (1161216)
I0525 11:24:19.530377 15746 net.cpp:148] Top shape: 128 1 16 63 (129024)
I0525 11:24:19.530385 15746 net.cpp:148] Top shape: 128 1 11 1 (1408)
I0525 11:24:19.530390 15746 net.cpp:156] Memory required for data: 5166592
I0525 11:24:19.530405 15746 layer_factory.hpp:77] Creating layer ratemap
I0525 11:24:20.079596 15746 net.cpp:91] Creating Layer ratemap
I0525 11:24:20.079638 15746 net.cpp:425] ratemap <- ratemap
I0525 11:24:20.079660 15746 net.cpp:386] ratemap -> ratemap (in-place)
I0525 11:24:20.080786 15746 net.cpp:141] Setting up ratemap
I0525 11:24:20.080811 15746 net.cpp:148] Top shape: 128 1 16 63 (129024)
I0525 11:24:20.080821 15746 net.cpp:156] Memory required for data: 5682688
I0525 11:24:20.080832 15746 layer_factory.hpp:77] Creating layer amsFeatures
I0525 11:24:20.080873 15746 net.cpp:91] Creating Layer amsFeatures
I0525 11:24:20.080884 15746 net.cpp:425] amsFeatures <- amsFeatures
I0525 11:24:20.080895 15746 net.cpp:386] amsFeatures -> amsFeatures (in-place)
I0525 11:24:20.084100 15746 net.cpp:141] Setting up amsFeatures
I0525 11:24:20.084122 15746 net.cpp:148] Top shape: 128 9 16 63 (1161216)
I0525 11:24:20.084131 15746 net.cpp:156] Memory required for data: 10327552
I0525 11:24:20.084138 15746 layer_factory.hpp:77] Creating layer conv1_a
I0525 11:24:20.084169 15746 net.cpp:91] Creating Layer conv1_a
I0525 11:24:20.084178 15746 net.cpp:425] conv1_a <- amsFeatures
I0525 11:24:20.084190 15746 net.cpp:399] conv1_a -> conv1_a
I0525 11:24:20.087026 15746 net.cpp:141] Setting up conv1_a
I0525 11:24:20.087049 15746 net.cpp:148] Top shape: 128 128 9 58 (8552448)
I0525 11:24:20.087057 15746 net.cpp:156] Memory required for data: 44537344
I0525 11:24:20.087082 15746 layer_factory.hpp:77] Creating layer relu1_a
I0525 11:24:20.087096 15746 net.cpp:91] Creating Layer relu1_a
I0525 11:24:20.087105 15746 net.cpp:425] relu1_a <- conv1_a
I0525 11:24:20.087116 15746 net.cpp:386] relu1_a -> conv1_a (in-place)
I0525 11:24:20.087131 15746 net.cpp:141] Setting up relu1_a
I0525 11:24:20.087141 15746 net.cpp:148] Top shape: 128 128 9 58 (8552448)
I0525 11:24:20.087147 15746 net.cpp:156] Memory required for data: 78747136
I0525 11:24:20.087154 15746 layer_factory.hpp:77] Creating layer conv2_a
I0525 11:24:20.087180 15746 net.cpp:91] Creating Layer conv2_a
I0525 11:24:20.087189 15746 net.cpp:425] conv2_a <- conv1_a
I0525 11:24:20.087204 15746 net.cpp:399] conv2_a -> conv2_a
I0525 11:24:20.089592 15746 net.cpp:141] Setting up conv2_a
I0525 11:24:20.089614 15746 net.cpp:148] Top shape: 128 128 7 56 (6422528)
I0525 11:24:20.089623 15746 net.cpp:156] Memory required for data: 104437248
I0525 11:24:20.089637 15746 layer_factory.hpp:77] Creating layer pool2_a
I0525 11:24:20.089653 15746 net.cpp:91] Creating Layer pool2_a
I0525 11:24:20.089660 15746 net.cpp:425] pool2_a <- conv2_a
I0525 11:24:20.089671 15746 net.cpp:399] pool2_a -> pool2_a
I0525 11:24:20.089733 15746 net.cpp:141] Setting up pool2_a
I0525 11:24:20.089746 15746 net.cpp:148] Top shape: 128 128 4 28 (1835008)
I0525 11:24:20.089753 15746 net.cpp:156] Memory required for data: 111777280
I0525 11:24:20.089761 15746 layer_factory.hpp:77] Creating layer relu2_a
I0525 11:24:20.089771 15746 net.cpp:91] Creating Layer relu2_a
I0525 11:24:20.089778 15746 net.cpp:425] relu2_a <- pool2_a
I0525 11:24:20.089787 15746 net.cpp:386] relu2_a -> pool2_a (in-place)
I0525 11:24:20.089798 15746 net.cpp:141] Setting up relu2_a
I0525 11:24:20.089807 15746 net.cpp:148] Top shape: 128 128 4 28 (1835008)
I0525 11:24:20.089814 15746 net.cpp:156] Memory required for data: 119117312
I0525 11:24:20.089820 15746 layer_factory.hpp:77] Creating layer ip2_a
I0525 11:24:20.089841 15746 net.cpp:91] Creating Layer ip2_a
I0525 11:24:20.089849 15746 net.cpp:425] ip2_a <- pool2_a
I0525 11:24:20.089860 15746 net.cpp:399] ip2_a -> ip2_a
I0525 11:24:20.132553 15746 net.cpp:141] Setting up ip2_a
I0525 11:24:20.132581 15746 net.cpp:148] Top shape: 128 256 (32768)
I0525 11:24:20.132589 15746 net.cpp:156] Memory required for data: 119248384
I0525 11:24:20.132606 15746 layer_factory.hpp:77] Creating layer conv1_r
I0525 11:24:20.132627 15746 net.cpp:91] Creating Layer conv1_r
I0525 11:24:20.132635 15746 net.cpp:425] conv1_r <- ratemap
I0525 11:24:20.132648 15746 net.cpp:399] conv1_r -> conv1_r
I0525 11:24:20.133687 15746 net.cpp:141] Setting up conv1_r
I0525 11:24:20.133708 15746 net.cpp:148] Top shape: 128 128 9 58 (8552448)
I0525 11:24:20.133715 15746 net.cpp:156] Memory required for data: 153458176
I0525 11:24:20.133726 15746 layer_factory.hpp:77] Creating layer relu1_r
I0525 11:24:20.133738 15746 net.cpp:91] Creating Layer relu1_r
I0525 11:24:20.133746 15746 net.cpp:425] relu1_r <- conv1_r
I0525 11:24:20.133755 15746 net.cpp:386] relu1_r -> conv1_r (in-place)
I0525 11:24:20.133769 15746 net.cpp:141] Setting up relu1_r
I0525 11:24:20.133776 15746 net.cpp:148] Top shape: 128 128 9 58 (8552448)
I0525 11:24:20.133782 15746 net.cpp:156] Memory required for data: 187667968
I0525 11:24:20.133790 15746 layer_factory.hpp:77] Creating layer conv2_r
I0525 11:24:20.133806 15746 net.cpp:91] Creating Layer conv2_r
I0525 11:24:20.133813 15746 net.cpp:425] conv2_r <- conv1_r
I0525 11:24:20.133826 15746 net.cpp:399] conv2_r -> conv2_r
I0525 11:24:20.136103 15746 net.cpp:141] Setting up conv2_r
I0525 11:24:20.136124 15746 net.cpp:148] Top shape: 128 128 7 56 (6422528)
I0525 11:24:20.136132 15746 net.cpp:156] Memory required for data: 213358080
I0525 11:24:20.136148 15746 layer_factory.hpp:77] Creating layer pool2_r
I0525 11:24:20.136162 15746 net.cpp:91] Creating Layer pool2_r
I0525 11:24:20.136169 15746 net.cpp:425] pool2_r <- conv2_r
I0525 11:24:20.136179 15746 net.cpp:399] pool2_r -> pool2_r
I0525 11:24:20.136229 15746 net.cpp:141] Setting up pool2_r
I0525 11:24:20.136240 15746 net.cpp:148] Top shape: 128 128 4 28 (1835008)
I0525 11:24:20.136247 15746 net.cpp:156] Memory required for data: 220698112
I0525 11:24:20.136255 15746 layer_factory.hpp:77] Creating layer relu2_r
I0525 11:24:20.136265 15746 net.cpp:91] Creating Layer relu2_r
I0525 11:24:20.136274 15746 net.cpp:425] relu2_r <- pool2_r
I0525 11:24:20.136282 15746 net.cpp:386] relu2_r -> pool2_r (in-place)
I0525 11:24:20.136294 15746 net.cpp:141] Setting up relu2_r
I0525 11:24:20.136302 15746 net.cpp:148] Top shape: 128 128 4 28 (1835008)
I0525 11:24:20.136308 15746 net.cpp:156] Memory required for data: 228038144
I0525 11:24:20.136315 15746 layer_factory.hpp:77] Creating layer ip2_r
I0525 11:24:20.136332 15746 net.cpp:91] Creating Layer ip2_r
I0525 11:24:20.136339 15746 net.cpp:425] ip2_r <- pool2_r
I0525 11:24:20.136350 15746 net.cpp:399] ip2_r -> ip2_r
I0525 11:24:20.178968 15746 net.cpp:141] Setting up ip2_r
I0525 11:24:20.178997 15746 net.cpp:148] Top shape: 128 256 (32768)
I0525 11:24:20.179003 15746 net.cpp:156] Memory required for data: 228169216
I0525 11:24:20.179016 15746 layer_factory.hpp:77] Creating layer concat_ar
I0525 11:24:20.179039 15746 net.cpp:91] Creating Layer concat_ar
I0525 11:24:20.179047 15746 net.cpp:425] concat_ar <- ip2_a
I0525 11:24:20.179056 15746 net.cpp:425] concat_ar <- ip2_r
I0525 11:24:20.179065 15746 net.cpp:399] concat_ar -> ip2
I0525 11:24:20.179097 15746 net.cpp:141] Setting up concat_ar
I0525 11:24:20.179107 15746 net.cpp:148] Top shape: 128 512 (65536)
I0525 11:24:20.179114 15746 net.cpp:156] Memory required for data: 228431360
I0525 11:24:20.179123 15746 layer_factory.hpp:77] Creating layer relu2
I0525 11:24:20.179138 15746 net.cpp:91] Creating Layer relu2
I0525 11:24:20.179146 15746 net.cpp:425] relu2 <- ip2
I0525 11:24:20.179157 15746 net.cpp:386] relu2 -> ip2 (in-place)
I0525 11:24:20.179175 15746 net.cpp:141] Setting up relu2
I0525 11:24:20.179184 15746 net.cpp:148] Top shape: 128 512 (65536)
I0525 11:24:20.179191 15746 net.cpp:156] Memory required for data: 228693504
I0525 11:24:20.179198 15746 layer_factory.hpp:77] Creating layer dropip2
I0525 11:24:20.179215 15746 net.cpp:91] Creating Layer dropip2
I0525 11:24:20.179222 15746 net.cpp:425] dropip2 <- ip2
I0525 11:24:20.179234 15746 net.cpp:386] dropip2 -> ip2 (in-place)
I0525 11:24:20.179270 15746 net.cpp:141] Setting up dropip2
I0525 11:24:20.179280 15746 net.cpp:148] Top shape: 128 512 (65536)
I0525 11:24:20.179286 15746 net.cpp:156] Memory required for data: 228955648
I0525 11:24:20.179292 15746 layer_factory.hpp:77] Creating layer ip3
I0525 11:24:20.179304 15746 net.cpp:91] Creating Layer ip3
I0525 11:24:20.179311 15746 net.cpp:425] ip3 <- ip2
I0525 11:24:20.179322 15746 net.cpp:399] ip3 -> ip3
I0525 11:24:20.179512 15746 net.cpp:141] Setting up ip3
I0525 11:24:20.179529 15746 net.cpp:148] Top shape: 128 11 (1408)
I0525 11:24:20.179536 15746 net.cpp:156] Memory required for data: 228961280
I0525 11:24:20.179546 15746 layer_factory.hpp:77] Creating layer loss
I0525 11:24:20.179565 15746 net.cpp:91] Creating Layer loss
I0525 11:24:20.179572 15746 net.cpp:425] loss <- ip3
I0525 11:24:20.179584 15746 net.cpp:425] loss <- label
I0525 11:24:20.179595 15746 net.cpp:399] loss -> loss
I0525 11:24:20.179644 15746 net.cpp:141] Setting up loss
I0525 11:24:20.179659 15746 net.cpp:148] Top shape: (1)
I0525 11:24:20.179666 15746 net.cpp:151]     with loss weight 1
I0525 11:24:20.179705 15746 net.cpp:156] Memory required for data: 228961284
I0525 11:24:20.179713 15746 net.cpp:217] loss needs backward computation.
I0525 11:24:20.179725 15746 net.cpp:217] ip3 needs backward computation.
I0525 11:24:20.179733 15746 net.cpp:217] dropip2 needs backward computation.
I0525 11:24:20.179738 15746 net.cpp:217] relu2 needs backward computation.
I0525 11:24:20.179744 15746 net.cpp:217] concat_ar needs backward computation.
I0525 11:24:20.179751 15746 net.cpp:217] ip2_r needs backward computation.
I0525 11:24:20.179759 15746 net.cpp:217] relu2_r needs backward computation.
I0525 11:24:20.179764 15746 net.cpp:217] pool2_r needs backward computation.
I0525 11:24:20.179770 15746 net.cpp:217] conv2_r needs backward computation.
I0525 11:24:20.179777 15746 net.cpp:217] relu1_r needs backward computation.
I0525 11:24:20.179785 15746 net.cpp:217] conv1_r needs backward computation.
I0525 11:24:20.179795 15746 net.cpp:217] ip2_a needs backward computation.
I0525 11:24:20.179801 15746 net.cpp:217] relu2_a needs backward computation.
I0525 11:24:20.179808 15746 net.cpp:217] pool2_a needs backward computation.
I0525 11:24:20.179814 15746 net.cpp:217] conv2_a needs backward computation.
I0525 11:24:20.179821 15746 net.cpp:217] relu1_a needs backward computation.
I0525 11:24:20.179828 15746 net.cpp:217] conv1_a needs backward computation.
I0525 11:24:20.179838 15746 net.cpp:219] amsFeatures does not need backward computation.
I0525 11:24:20.179846 15746 net.cpp:219] ratemap does not need backward computation.
I0525 11:24:20.179853 15746 net.cpp:219] data does not need backward computation.
I0525 11:24:20.179859 15746 net.cpp:261] This network produces output loss
I0525 11:24:20.179880 15746 net.cpp:274] Network initialization done.
I0525 11:24:20.180867 15746 solver.cpp:181] Creating test net (#0) specified by net file: /mnt/antares_raid/home/cindy/adhara/experiments/s2/train_val.prototxt
I0525 11:24:20.180932 15746 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0525 11:24:20.180944 15746 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer ratemap
I0525 11:24:20.180953 15746 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer amsFeatures
I0525 11:24:20.181171 15746 net.cpp:49] Initializing net from parameters: 
name: "SoundNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "amsFeatures"
  top: "ratemap"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/mnt/antares_raid/home/cindy/adhara/experiments/twoears_data_test.txt"
    batch_size: 128
  }
}
layer {
  name: "conv1_a"
  type: "Convolution"
  bottom: "amsFeatures"
  top: "conv1_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 6
  }
}
layer {
  name: "relu1_a"
  type: "ReLU"
  bottom: "conv1_a"
  top: "conv1_a"
}
layer {
  name: "conv2_a"
  type: "Convolution"
  bottom: "conv1_a"
  top: "conv2_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "pool2_a"
  type: "Pooling"
  bottom: "conv2_a"
  top: "pool2_a"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "relu2_a"
  type: "ReLU"
  bottom: "pool2_a"
  top: "pool2_a"
}
layer {
  name: "ip2_a"
  type: "InnerProduct"
  bottom: "pool2_a"
  top: "ip2_a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_r"
  type: "Convolution"
  bottom: "ratemap"
  top: "conv1_r"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 8
    kernel_w: 6
  }
}
layer {
  name: "relu1_r"
  type: "ReLU"
  bottom: "conv1_r"
  top: "conv1_r"
}
layer {
  name: "conv2_r"
  type: "Convolution"
  bottom: "conv1_r"
  top: "conv2_r"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    kernel_h: 3
    kernel_w: 3
  }
}
layer {
  name: "pool2_r"
  type: "Pooling"
  bottom: "conv2_r"
  top: "pool2_r"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "relu2_r"
  type: "ReLU"
  bottom: "pool2_r"
  top: "pool2_r"
}
layer {
  name: "ip2_r"
  type: "InnerProduct"
  bottom: "pool2_r"
  top: "ip2_r"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "concat_ar"
  type: "Concat"
  bottom: "ip2_a"
  bottom: "ip2_r"
  top: "ip2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "dropip2"
  type: "Dropout"
  bottom: "ip2"
  top: "ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 11
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SigmoidCrossEntropyLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0525 11:24:20.181972 15746 layer_factory.hpp:77] Creating layer data
I0525 11:24:20.181988 15746 net.cpp:91] Creating Layer data
I0525 11:24:20.181996 15746 net.cpp:399] data -> amsFeatures
I0525 11:24:20.182009 15746 net.cpp:399] data -> ratemap
I0525 11:24:20.182020 15746 net.cpp:399] data -> label
I0525 11:24:20.182030 15746 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /mnt/antares_raid/home/cindy/adhara/experiments/twoears_data_test.txt
I0525 11:24:20.182418 15746 hdf5_data_layer.cpp:93] Number of HDF5 files: 2
I0525 11:24:26.537595 15746 net.cpp:141] Setting up data
I0525 11:24:26.537636 15746 net.cpp:148] Top shape: 128 9 16 63 (1161216)
I0525 11:24:26.537644 15746 net.cpp:148] Top shape: 128 1 16 63 (129024)
I0525 11:24:26.537652 15746 net.cpp:148] Top shape: 128 1 11 1 (1408)
I0525 11:24:26.537657 15746 net.cpp:156] Memory required for data: 5166592
I0525 11:24:26.537669 15746 layer_factory.hpp:77] Creating layer conv1_a
I0525 11:24:26.537704 15746 net.cpp:91] Creating Layer conv1_a
I0525 11:24:26.537711 15746 net.cpp:425] conv1_a <- amsFeatures
I0525 11:24:26.537721 15746 net.cpp:399] conv1_a -> conv1_a
I0525 11:24:26.538451 15746 net.cpp:141] Setting up conv1_a
I0525 11:24:26.538465 15746 net.cpp:148] Top shape: 128 128 9 58 (8552448)
I0525 11:24:26.538470 15746 net.cpp:156] Memory required for data: 39376384
I0525 11:24:26.538485 15746 layer_factory.hpp:77] Creating layer relu1_a
I0525 11:24:26.538496 15746 net.cpp:91] Creating Layer relu1_a
I0525 11:24:26.538501 15746 net.cpp:425] relu1_a <- conv1_a
I0525 11:24:26.538508 15746 net.cpp:386] relu1_a -> conv1_a (in-place)
I0525 11:24:26.538517 15746 net.cpp:141] Setting up relu1_a
I0525 11:24:26.538524 15746 net.cpp:148] Top shape: 128 128 9 58 (8552448)
I0525 11:24:26.538529 15746 net.cpp:156] Memory required for data: 73586176
I0525 11:24:26.538534 15746 layer_factory.hpp:77] Creating layer conv2_a
I0525 11:24:26.538543 15746 net.cpp:91] Creating Layer conv2_a
I0525 11:24:26.538548 15746 net.cpp:425] conv2_a <- conv1_a
I0525 11:24:26.538555 15746 net.cpp:399] conv2_a -> conv2_a
I0525 11:24:26.540391 15746 net.cpp:141] Setting up conv2_a
I0525 11:24:26.540408 15746 net.cpp:148] Top shape: 128 128 7 56 (6422528)
I0525 11:24:26.540415 15746 net.cpp:156] Memory required for data: 99276288
I0525 11:24:26.540426 15746 layer_factory.hpp:77] Creating layer pool2_a
I0525 11:24:26.540436 15746 net.cpp:91] Creating Layer pool2_a
I0525 11:24:26.540443 15746 net.cpp:425] pool2_a <- conv2_a
I0525 11:24:26.540451 15746 net.cpp:399] pool2_a -> pool2_a
I0525 11:24:26.540483 15746 net.cpp:141] Setting up pool2_a
I0525 11:24:26.540493 15746 net.cpp:148] Top shape: 128 128 4 28 (1835008)
I0525 11:24:26.540498 15746 net.cpp:156] Memory required for data: 106616320
I0525 11:24:26.540503 15746 layer_factory.hpp:77] Creating layer relu2_a
I0525 11:24:26.540510 15746 net.cpp:91] Creating Layer relu2_a
I0525 11:24:26.540515 15746 net.cpp:425] relu2_a <- pool2_a
I0525 11:24:26.540521 15746 net.cpp:386] relu2_a -> pool2_a (in-place)
I0525 11:24:26.540529 15746 net.cpp:141] Setting up relu2_a
I0525 11:24:26.540536 15746 net.cpp:148] Top shape: 128 128 4 28 (1835008)
I0525 11:24:26.540541 15746 net.cpp:156] Memory required for data: 113956352
I0525 11:24:26.540545 15746 layer_factory.hpp:77] Creating layer ip2_a
I0525 11:24:26.540555 15746 net.cpp:91] Creating Layer ip2_a
I0525 11:24:26.540560 15746 net.cpp:425] ip2_a <- pool2_a
I0525 11:24:26.540566 15746 net.cpp:399] ip2_a -> ip2_a
I0525 11:24:26.573084 15746 net.cpp:141] Setting up ip2_a
I0525 11:24:26.573106 15746 net.cpp:148] Top shape: 128 256 (32768)
I0525 11:24:26.573112 15746 net.cpp:156] Memory required for data: 114087424
I0525 11:24:26.573124 15746 layer_factory.hpp:77] Creating layer conv1_r
I0525 11:24:26.573140 15746 net.cpp:91] Creating Layer conv1_r
I0525 11:24:26.573146 15746 net.cpp:425] conv1_r <- ratemap
I0525 11:24:26.573154 15746 net.cpp:399] conv1_r -> conv1_r
I0525 11:24:26.573448 15746 net.cpp:141] Setting up conv1_r
I0525 11:24:26.573462 15746 net.cpp:148] Top shape: 128 128 9 58 (8552448)
I0525 11:24:26.573468 15746 net.cpp:156] Memory required for data: 148297216
I0525 11:24:26.573477 15746 layer_factory.hpp:77] Creating layer relu1_r
I0525 11:24:26.573487 15746 net.cpp:91] Creating Layer relu1_r
I0525 11:24:26.573494 15746 net.cpp:425] relu1_r <- conv1_r
I0525 11:24:26.573504 15746 net.cpp:386] relu1_r -> conv1_r (in-place)
I0525 11:24:26.573514 15746 net.cpp:141] Setting up relu1_r
I0525 11:24:26.573523 15746 net.cpp:148] Top shape: 128 128 9 58 (8552448)
I0525 11:24:26.573529 15746 net.cpp:156] Memory required for data: 182507008
I0525 11:24:26.573534 15746 layer_factory.hpp:77] Creating layer conv2_r
I0525 11:24:26.573547 15746 net.cpp:91] Creating Layer conv2_r
I0525 11:24:26.573554 15746 net.cpp:425] conv2_r <- conv1_r
I0525 11:24:26.573561 15746 net.cpp:399] conv2_r -> conv2_r
I0525 11:24:26.575429 15746 net.cpp:141] Setting up conv2_r
I0525 11:24:26.575446 15746 net.cpp:148] Top shape: 128 128 7 56 (6422528)
I0525 11:24:26.575453 15746 net.cpp:156] Memory required for data: 208197120
I0525 11:24:26.575462 15746 layer_factory.hpp:77] Creating layer pool2_r
I0525 11:24:26.575472 15746 net.cpp:91] Creating Layer pool2_r
I0525 11:24:26.575479 15746 net.cpp:425] pool2_r <- conv2_r
I0525 11:24:26.575490 15746 net.cpp:399] pool2_r -> pool2_r
I0525 11:24:26.575527 15746 net.cpp:141] Setting up pool2_r
I0525 11:24:26.575536 15746 net.cpp:148] Top shape: 128 128 4 28 (1835008)
I0525 11:24:26.575541 15746 net.cpp:156] Memory required for data: 215537152
I0525 11:24:26.575546 15746 layer_factory.hpp:77] Creating layer relu2_r
I0525 11:24:26.575552 15746 net.cpp:91] Creating Layer relu2_r
I0525 11:24:26.575557 15746 net.cpp:425] relu2_r <- pool2_r
I0525 11:24:26.575565 15746 net.cpp:386] relu2_r -> pool2_r (in-place)
I0525 11:24:26.575573 15746 net.cpp:141] Setting up relu2_r
I0525 11:24:26.575579 15746 net.cpp:148] Top shape: 128 128 4 28 (1835008)
I0525 11:24:26.575584 15746 net.cpp:156] Memory required for data: 222877184
I0525 11:24:26.575590 15746 layer_factory.hpp:77] Creating layer ip2_r
I0525 11:24:26.575601 15746 net.cpp:91] Creating Layer ip2_r
I0525 11:24:26.575606 15746 net.cpp:425] ip2_r <- pool2_r
I0525 11:24:26.575613 15746 net.cpp:399] ip2_r -> ip2_r
I0525 11:24:26.608091 15746 net.cpp:141] Setting up ip2_r
I0525 11:24:26.608114 15746 net.cpp:148] Top shape: 128 256 (32768)
I0525 11:24:26.608119 15746 net.cpp:156] Memory required for data: 223008256
I0525 11:24:26.608129 15746 layer_factory.hpp:77] Creating layer concat_ar
I0525 11:24:26.608139 15746 net.cpp:91] Creating Layer concat_ar
I0525 11:24:26.608146 15746 net.cpp:425] concat_ar <- ip2_a
I0525 11:24:26.608155 15746 net.cpp:425] concat_ar <- ip2_r
I0525 11:24:26.608163 15746 net.cpp:399] concat_ar -> ip2
I0525 11:24:26.608183 15746 net.cpp:141] Setting up concat_ar
I0525 11:24:26.608193 15746 net.cpp:148] Top shape: 128 512 (65536)
I0525 11:24:26.608198 15746 net.cpp:156] Memory required for data: 223270400
I0525 11:24:26.608204 15746 layer_factory.hpp:77] Creating layer relu2
I0525 11:24:26.608212 15746 net.cpp:91] Creating Layer relu2
I0525 11:24:26.608217 15746 net.cpp:425] relu2 <- ip2
I0525 11:24:26.608223 15746 net.cpp:386] relu2 -> ip2 (in-place)
I0525 11:24:26.608232 15746 net.cpp:141] Setting up relu2
I0525 11:24:26.608237 15746 net.cpp:148] Top shape: 128 512 (65536)
I0525 11:24:26.608242 15746 net.cpp:156] Memory required for data: 223532544
I0525 11:24:26.608247 15746 layer_factory.hpp:77] Creating layer dropip2
I0525 11:24:26.608258 15746 net.cpp:91] Creating Layer dropip2
I0525 11:24:26.608266 15746 net.cpp:425] dropip2 <- ip2
I0525 11:24:26.608273 15746 net.cpp:386] dropip2 -> ip2 (in-place)
I0525 11:24:26.608294 15746 net.cpp:141] Setting up dropip2
I0525 11:24:26.608301 15746 net.cpp:148] Top shape: 128 512 (65536)
I0525 11:24:26.608305 15746 net.cpp:156] Memory required for data: 223794688
I0525 11:24:26.608310 15746 layer_factory.hpp:77] Creating layer ip3
I0525 11:24:26.608321 15746 net.cpp:91] Creating Layer ip3
I0525 11:24:26.608326 15746 net.cpp:425] ip3 <- ip2
I0525 11:24:26.608336 15746 net.cpp:399] ip3 -> ip3
I0525 11:24:26.608487 15746 net.cpp:141] Setting up ip3
I0525 11:24:26.608496 15746 net.cpp:148] Top shape: 128 11 (1408)
I0525 11:24:26.608501 15746 net.cpp:156] Memory required for data: 223800320
I0525 11:24:26.608510 15746 layer_factory.hpp:77] Creating layer loss
I0525 11:24:26.608521 15746 net.cpp:91] Creating Layer loss
I0525 11:24:26.608526 15746 net.cpp:425] loss <- ip3
I0525 11:24:26.608532 15746 net.cpp:425] loss <- label
I0525 11:24:26.608539 15746 net.cpp:399] loss -> loss
I0525 11:24:26.608568 15746 net.cpp:141] Setting up loss
I0525 11:24:26.608577 15746 net.cpp:148] Top shape: (1)
I0525 11:24:26.608582 15746 net.cpp:151]     with loss weight 1
I0525 11:24:26.608602 15746 net.cpp:156] Memory required for data: 223800324
I0525 11:24:26.608606 15746 net.cpp:217] loss needs backward computation.
I0525 11:24:26.608611 15746 net.cpp:217] ip3 needs backward computation.
I0525 11:24:26.608616 15746 net.cpp:217] dropip2 needs backward computation.
I0525 11:24:26.608621 15746 net.cpp:217] relu2 needs backward computation.
I0525 11:24:26.608625 15746 net.cpp:217] concat_ar needs backward computation.
I0525 11:24:26.608630 15746 net.cpp:217] ip2_r needs backward computation.
I0525 11:24:26.608635 15746 net.cpp:217] relu2_r needs backward computation.
I0525 11:24:26.608640 15746 net.cpp:217] pool2_r needs backward computation.
I0525 11:24:26.608645 15746 net.cpp:217] conv2_r needs backward computation.
I0525 11:24:26.608650 15746 net.cpp:217] relu1_r needs backward computation.
I0525 11:24:26.608656 15746 net.cpp:217] conv1_r needs backward computation.
I0525 11:24:26.608661 15746 net.cpp:217] ip2_a needs backward computation.
I0525 11:24:26.608666 15746 net.cpp:217] relu2_a needs backward computation.
I0525 11:24:26.608671 15746 net.cpp:217] pool2_a needs backward computation.
I0525 11:24:26.608677 15746 net.cpp:217] conv2_a needs backward computation.
I0525 11:24:26.608682 15746 net.cpp:217] relu1_a needs backward computation.
I0525 11:24:26.608687 15746 net.cpp:217] conv1_a needs backward computation.
I0525 11:24:26.608693 15746 net.cpp:219] data does not need backward computation.
I0525 11:24:26.608697 15746 net.cpp:261] This network produces output loss
I0525 11:24:26.608713 15746 net.cpp:274] Network initialization done.
I0525 11:24:26.608808 15746 solver.cpp:60] Solver scaffolding done.
I0525 11:24:26.609246 15746 caffe.cpp:219] Starting Optimization
I0525 11:24:26.609266 15746 solver.cpp:279] Solving SoundNet
I0525 11:24:26.609272 15746 solver.cpp:280] Learning Rate Policy: step
I0525 11:24:26.610025 15746 solver.cpp:337] Iteration 0, Testing net (#0)
I0525 11:24:26.610041 15746 net.cpp:685] Ignoring source layer ratemap
I0525 11:24:26.610047 15746 net.cpp:685] Ignoring source layer amsFeatures
I0525 11:27:16.948487 15746 solver.cpp:404]     Test net output #0: loss = 7.55385 (* 1 = 7.55385 loss)
I0525 11:27:21.871515 15746 solver.cpp:228] Iteration 0, loss = 7.59891
I0525 11:27:21.871588 15746 solver.cpp:244]     Train net output #0: loss = 7.59891 (* 1 = 7.59891 loss)
I0525 11:27:21.871613 15746 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
I0525 11:35:54.753617 15746 solver.cpp:228] Iteration 100, loss = 3.48758
I0525 11:35:54.754331 15746 solver.cpp:244]     Train net output #0: loss = 3.48758 (* 1 = 3.48758 loss)
I0525 11:35:54.754364 15746 sgd_solver.cpp:106] Iteration 100, lr = 0.0001
I0525 11:44:13.353958 15746 solver.cpp:228] Iteration 200, loss = 3.53107
I0525 11:44:13.354436 15746 solver.cpp:244]     Train net output #0: loss = 3.53107 (* 1 = 3.53107 loss)
I0525 11:44:13.354461 15746 sgd_solver.cpp:106] Iteration 200, lr = 0.0001
I0525 11:52:37.803277 15746 solver.cpp:228] Iteration 300, loss = 3.28108
I0525 11:52:37.804044 15746 solver.cpp:244]     Train net output #0: loss = 3.28108 (* 1 = 3.28108 loss)
I0525 11:52:37.804069 15746 sgd_solver.cpp:106] Iteration 300, lr = 0.0001
I0525 12:01:01.904069 15746 solver.cpp:228] Iteration 400, loss = 3.04764
I0525 12:01:01.904770 15746 solver.cpp:244]     Train net output #0: loss = 3.04764 (* 1 = 3.04764 loss)
I0525 12:01:01.904791 15746 sgd_solver.cpp:106] Iteration 400, lr = 0.0001
I0525 12:09:13.394964 15746 solver.cpp:228] Iteration 500, loss = 3.10846
I0525 12:09:13.395455 15746 solver.cpp:244]     Train net output #0: loss = 3.10846 (* 1 = 3.10846 loss)
I0525 12:09:13.395476 15746 sgd_solver.cpp:106] Iteration 500, lr = 0.0001
I0525 12:17:35.399796 15746 solver.cpp:228] Iteration 600, loss = 3.41981
I0525 12:17:35.400501 15746 solver.cpp:244]     Train net output #0: loss = 3.41981 (* 1 = 3.41981 loss)
I0525 12:17:35.400521 15746 sgd_solver.cpp:106] Iteration 600, lr = 0.0001
I0525 12:25:46.176736 15746 solver.cpp:228] Iteration 700, loss = 2.9199
I0525 12:25:46.177374 15746 solver.cpp:244]     Train net output #0: loss = 2.9199 (* 1 = 2.9199 loss)
I0525 12:25:46.177397 15746 sgd_solver.cpp:106] Iteration 700, lr = 0.0001
I0525 12:34:17.504709 15746 solver.cpp:228] Iteration 800, loss = 3.01565
I0525 12:34:17.505435 15746 solver.cpp:244]     Train net output #0: loss = 3.01565 (* 1 = 3.01565 loss)
I0525 12:34:17.505463 15746 sgd_solver.cpp:106] Iteration 800, lr = 0.0001
I0525 12:42:06.569069 15746 solver.cpp:228] Iteration 900, loss = 3.26951
I0525 12:42:06.569748 15746 solver.cpp:244]     Train net output #0: loss = 3.26951 (* 1 = 3.26951 loss)
I0525 12:42:06.569772 15746 sgd_solver.cpp:106] Iteration 900, lr = 0.0001
I0525 12:49:54.864177 15746 solver.cpp:228] Iteration 1000, loss = 2.93071
I0525 12:49:54.864917 15746 solver.cpp:244]     Train net output #0: loss = 2.93071 (* 1 = 2.93071 loss)
I0525 12:49:54.864953 15746 sgd_solver.cpp:106] Iteration 1000, lr = 0.0001
I0525 12:58:05.829587 15746 solver.cpp:228] Iteration 1100, loss = 2.67298
I0525 12:58:05.830323 15746 solver.cpp:244]     Train net output #0: loss = 2.67298 (* 1 = 2.67298 loss)
I0525 12:58:05.830344 15746 sgd_solver.cpp:106] Iteration 1100, lr = 0.0001
I0525 13:06:07.612148 15746 solver.cpp:228] Iteration 1200, loss = 2.46135
I0525 13:06:07.612875 15746 solver.cpp:244]     Train net output #0: loss = 2.46135 (* 1 = 2.46135 loss)
I0525 13:06:07.612898 15746 sgd_solver.cpp:106] Iteration 1200, lr = 0.0001
I0525 13:14:19.775490 15746 solver.cpp:228] Iteration 1300, loss = 2.34559
I0525 13:14:19.776244 15746 solver.cpp:244]     Train net output #0: loss = 2.34559 (* 1 = 2.34559 loss)
I0525 13:14:19.776268 15746 sgd_solver.cpp:106] Iteration 1300, lr = 0.0001
I0525 13:22:26.054944 15746 solver.cpp:228] Iteration 1400, loss = 2.33256
I0525 13:22:26.055701 15746 solver.cpp:244]     Train net output #0: loss = 2.33256 (* 1 = 2.33256 loss)
I0525 13:22:26.055724 15746 sgd_solver.cpp:106] Iteration 1400, lr = 0.0001
I0525 13:30:21.325410 15746 solver.cpp:228] Iteration 1500, loss = 2.33977
I0525 13:30:21.326108 15746 solver.cpp:244]     Train net output #0: loss = 2.33977 (* 1 = 2.33977 loss)
I0525 13:30:21.326133 15746 sgd_solver.cpp:106] Iteration 1500, lr = 0.0001
I0525 13:38:34.906623 15746 solver.cpp:228] Iteration 1600, loss = 2.46856
I0525 13:38:34.907238 15746 solver.cpp:244]     Train net output #0: loss = 2.46856 (* 1 = 2.46856 loss)
I0525 13:38:34.907258 15746 sgd_solver.cpp:106] Iteration 1600, lr = 0.0001
I0525 13:46:51.902148 15746 solver.cpp:228] Iteration 1700, loss = 2.28473
I0525 13:46:51.904889 15746 solver.cpp:244]     Train net output #0: loss = 2.28473 (* 1 = 2.28473 loss)
I0525 13:46:51.904914 15746 sgd_solver.cpp:106] Iteration 1700, lr = 0.0001
I0525 13:54:59.579548 15746 solver.cpp:228] Iteration 1800, loss = 2.32586
I0525 13:54:59.580266 15746 solver.cpp:244]     Train net output #0: loss = 2.32586 (* 1 = 2.32586 loss)
I0525 13:54:59.580304 15746 sgd_solver.cpp:106] Iteration 1800, lr = 0.0001
I0525 14:03:00.766870 15746 solver.cpp:228] Iteration 1900, loss = 2.60376
I0525 14:03:00.767580 15746 solver.cpp:244]     Train net output #0: loss = 2.60376 (* 1 = 2.60376 loss)
I0525 14:03:00.767606 15746 sgd_solver.cpp:106] Iteration 1900, lr = 0.0001
I0525 14:10:49.285677 15746 solver.cpp:228] Iteration 2000, loss = 2.52658
I0525 14:10:49.286278 15746 solver.cpp:244]     Train net output #0: loss = 2.52658 (* 1 = 2.52658 loss)
I0525 14:10:49.286298 15746 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I0525 14:18:56.798187 15746 solver.cpp:228] Iteration 2100, loss = 2.53185
I0525 14:18:56.798740 15746 solver.cpp:244]     Train net output #0: loss = 2.53185 (* 1 = 2.53185 loss)
I0525 14:18:56.798765 15746 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I0525 14:27:00.077896 15746 solver.cpp:228] Iteration 2200, loss = 1.81953
I0525 14:27:00.078330 15746 solver.cpp:244]     Train net output #0: loss = 1.81953 (* 1 = 1.81953 loss)
I0525 14:27:00.078354 15746 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I0525 14:35:12.103960 15746 solver.cpp:228] Iteration 2300, loss = 1.72449
I0525 14:35:12.104454 15746 solver.cpp:244]     Train net output #0: loss = 1.72449 (* 1 = 1.72449 loss)
I0525 14:35:12.104477 15746 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I0525 14:43:25.736354 15746 solver.cpp:228] Iteration 2400, loss = 1.76319
I0525 14:43:25.736826 15746 solver.cpp:244]     Train net output #0: loss = 1.76319 (* 1 = 1.76319 loss)
I0525 14:43:25.736856 15746 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I0525 14:51:37.803035 15746 solver.cpp:228] Iteration 2500, loss = 1.72994
I0525 14:51:37.804553 15746 solver.cpp:244]     Train net output #0: loss = 1.72994 (* 1 = 1.72994 loss)
I0525 14:51:37.804582 15746 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0525 14:59:45.823228 15746 solver.cpp:228] Iteration 2600, loss = 2.22599
I0525 14:59:45.823705 15746 solver.cpp:244]     Train net output #0: loss = 2.22599 (* 1 = 2.22599 loss)
I0525 14:59:45.823729 15746 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0525 15:08:01.341447 15746 solver.cpp:228] Iteration 2700, loss = 2.04735
I0525 15:08:01.342144 15746 solver.cpp:244]     Train net output #0: loss = 2.04735 (* 1 = 2.04735 loss)
I0525 15:08:01.342170 15746 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0525 15:16:20.808523 15746 solver.cpp:228] Iteration 2800, loss = 2.12401
I0525 15:16:20.808959 15746 solver.cpp:244]     Train net output #0: loss = 2.12401 (* 1 = 2.12401 loss)
I0525 15:16:20.808982 15746 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0525 15:24:41.003566 15746 solver.cpp:228] Iteration 2900, loss = 2.14092
I0525 15:24:41.004014 15746 solver.cpp:244]     Train net output #0: loss = 2.14092 (* 1 = 2.14092 loss)
I0525 15:24:41.004039 15746 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0525 15:32:36.297832 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_3000.caffemodel
I0525 15:32:36.527448 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_3000.solverstate
I0525 15:32:41.976424 15746 solver.cpp:228] Iteration 3000, loss = 1.78424
I0525 15:32:41.976485 15746 solver.cpp:244]     Train net output #0: loss = 1.78424 (* 1 = 1.78424 loss)
I0525 15:32:41.976495 15746 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0525 15:40:41.785177 15746 solver.cpp:228] Iteration 3100, loss = 2.29371
I0525 15:40:41.785902 15746 solver.cpp:244]     Train net output #0: loss = 2.29371 (* 1 = 2.29371 loss)
I0525 15:40:41.785926 15746 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0525 15:48:49.200356 15746 solver.cpp:228] Iteration 3200, loss = 2.24782
I0525 15:48:49.202893 15746 solver.cpp:244]     Train net output #0: loss = 2.24782 (* 1 = 2.24782 loss)
I0525 15:48:49.202919 15746 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0525 15:54:10.264595 15746 solver.cpp:337] Iteration 3265, Testing net (#0)
I0525 15:54:10.265377 15746 net.cpp:685] Ignoring source layer ratemap
I0525 15:54:10.265395 15746 net.cpp:685] Ignoring source layer amsFeatures
I0525 15:57:00.826617 15746 solver.cpp:404]     Test net output #0: loss = 1.24282 (* 1 = 1.24282 loss)
I0525 15:59:58.761349 15746 solver.cpp:228] Iteration 3300, loss = 1.51795
I0525 15:59:58.761759 15746 solver.cpp:244]     Train net output #0: loss = 1.51795 (* 1 = 1.51795 loss)
I0525 15:59:58.761785 15746 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0525 16:08:09.803977 15746 solver.cpp:228] Iteration 3400, loss = 1.64809
I0525 16:08:09.804710 15746 solver.cpp:244]     Train net output #0: loss = 1.64809 (* 1 = 1.64809 loss)
I0525 16:08:09.804733 15746 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0525 16:16:21.914470 15746 solver.cpp:228] Iteration 3500, loss = 1.81845
I0525 16:16:21.915190 15746 solver.cpp:244]     Train net output #0: loss = 1.81845 (* 1 = 1.81845 loss)
I0525 16:16:21.915218 15746 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0525 16:24:19.559135 15746 solver.cpp:228] Iteration 3600, loss = 1.46022
I0525 16:24:19.559800 15746 solver.cpp:244]     Train net output #0: loss = 1.46022 (* 1 = 1.46022 loss)
I0525 16:24:19.559823 15746 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0525 16:32:30.476941 15746 solver.cpp:228] Iteration 3700, loss = 1.9494
I0525 16:32:30.477710 15746 solver.cpp:244]     Train net output #0: loss = 1.9494 (* 1 = 1.9494 loss)
I0525 16:32:30.477741 15746 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0525 16:40:40.556259 15746 solver.cpp:228] Iteration 3800, loss = 1.18828
I0525 16:40:40.556975 15746 solver.cpp:244]     Train net output #0: loss = 1.18828 (* 1 = 1.18828 loss)
I0525 16:40:40.557006 15746 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0525 16:48:41.927407 15746 solver.cpp:228] Iteration 3900, loss = 2.00014
I0525 16:48:41.928051 15746 solver.cpp:244]     Train net output #0: loss = 2.00014 (* 1 = 2.00014 loss)
I0525 16:48:41.928079 15746 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0525 16:56:50.621508 15746 solver.cpp:228] Iteration 4000, loss = 1.5408
I0525 16:56:50.622195 15746 solver.cpp:244]     Train net output #0: loss = 1.5408 (* 1 = 1.5408 loss)
I0525 16:56:50.622215 15746 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0525 17:05:10.025028 15746 solver.cpp:228] Iteration 4100, loss = 1.4729
I0525 17:05:10.025789 15746 solver.cpp:244]     Train net output #0: loss = 1.4729 (* 1 = 1.4729 loss)
I0525 17:05:10.025828 15746 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0525 17:13:17.075273 15746 solver.cpp:228] Iteration 4200, loss = 1.44081
I0525 17:13:17.075996 15746 solver.cpp:244]     Train net output #0: loss = 1.44081 (* 1 = 1.44081 loss)
I0525 17:13:17.076025 15746 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0525 17:21:21.399845 15746 solver.cpp:228] Iteration 4300, loss = 1.4185
I0525 17:21:21.400547 15746 solver.cpp:244]     Train net output #0: loss = 1.4185 (* 1 = 1.4185 loss)
I0525 17:21:21.400570 15746 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0525 17:29:16.565922 15746 solver.cpp:228] Iteration 4400, loss = 1.38709
I0525 17:29:16.566608 15746 solver.cpp:244]     Train net output #0: loss = 1.38709 (* 1 = 1.38709 loss)
I0525 17:29:16.566628 15746 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0525 17:37:20.168120 15746 solver.cpp:228] Iteration 4500, loss = 1.36138
I0525 17:37:20.168795 15746 solver.cpp:244]     Train net output #0: loss = 1.36138 (* 1 = 1.36138 loss)
I0525 17:37:20.168817 15746 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0525 17:45:40.148843 15746 solver.cpp:228] Iteration 4600, loss = 1.26172
I0525 17:45:40.149572 15746 solver.cpp:244]     Train net output #0: loss = 1.26172 (* 1 = 1.26172 loss)
I0525 17:45:40.149593 15746 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0525 17:53:51.116189 15746 solver.cpp:228] Iteration 4700, loss = 1.06656
I0525 17:53:51.116842 15746 solver.cpp:244]     Train net output #0: loss = 1.06656 (* 1 = 1.06656 loss)
I0525 17:53:51.116868 15746 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0525 18:01:54.185062 15746 solver.cpp:228] Iteration 4800, loss = 1.17309
I0525 18:01:54.185463 15746 solver.cpp:244]     Train net output #0: loss = 1.17309 (* 1 = 1.17309 loss)
I0525 18:01:54.185475 15746 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0525 18:10:13.140606 15746 solver.cpp:228] Iteration 4900, loss = 1.21329
I0525 18:10:13.141372 15746 solver.cpp:244]     Train net output #0: loss = 1.21329 (* 1 = 1.21329 loss)
I0525 18:10:13.141412 15746 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0525 18:18:32.475278 15746 solver.cpp:228] Iteration 5000, loss = 1.52837
I0525 18:18:32.476080 15746 solver.cpp:244]     Train net output #0: loss = 1.52837 (* 1 = 1.52837 loss)
I0525 18:18:32.476105 15746 sgd_solver.cpp:106] Iteration 5000, lr = 0.0001
I0525 18:26:39.125357 15746 solver.cpp:228] Iteration 5100, loss = 1.92284
I0525 18:26:39.126083 15746 solver.cpp:244]     Train net output #0: loss = 1.92284 (* 1 = 1.92284 loss)
I0525 18:26:39.126121 15746 sgd_solver.cpp:106] Iteration 5100, lr = 0.0001
I0525 18:34:53.092051 15746 solver.cpp:228] Iteration 5200, loss = 1.1736
I0525 18:34:53.092803 15746 solver.cpp:244]     Train net output #0: loss = 1.1736 (* 1 = 1.1736 loss)
I0525 18:34:53.092839 15746 sgd_solver.cpp:106] Iteration 5200, lr = 0.0001
I0525 18:43:04.238265 15746 solver.cpp:228] Iteration 5300, loss = 1.64849
I0525 18:43:04.238939 15746 solver.cpp:244]     Train net output #0: loss = 1.64849 (* 1 = 1.64849 loss)
I0525 18:43:04.238971 15746 sgd_solver.cpp:106] Iteration 5300, lr = 0.0001
I0525 18:51:19.819780 15746 solver.cpp:228] Iteration 5400, loss = 1.83555
I0525 18:51:19.820487 15746 solver.cpp:244]     Train net output #0: loss = 1.83555 (* 1 = 1.83555 loss)
I0525 18:51:19.820511 15746 sgd_solver.cpp:106] Iteration 5400, lr = 0.0001
I0525 18:59:32.717752 15746 solver.cpp:228] Iteration 5500, loss = 1.2564
I0525 18:59:32.718463 15746 solver.cpp:244]     Train net output #0: loss = 1.2564 (* 1 = 1.2564 loss)
I0525 18:59:32.718494 15746 sgd_solver.cpp:106] Iteration 5500, lr = 0.0001
I0525 19:07:56.387907 15746 solver.cpp:228] Iteration 5600, loss = 1.28256
I0525 19:07:56.388682 15746 solver.cpp:244]     Train net output #0: loss = 1.28256 (* 1 = 1.28256 loss)
I0525 19:07:56.388707 15746 sgd_solver.cpp:106] Iteration 5600, lr = 0.0001
I0525 19:16:08.583670 15746 solver.cpp:228] Iteration 5700, loss = 1.2017
I0525 19:16:08.584368 15746 solver.cpp:244]     Train net output #0: loss = 1.2017 (* 1 = 1.2017 loss)
I0525 19:16:08.584388 15746 sgd_solver.cpp:106] Iteration 5700, lr = 0.0001
I0525 19:24:14.948381 15746 solver.cpp:228] Iteration 5800, loss = 1.70468
I0525 19:24:14.949151 15746 solver.cpp:244]     Train net output #0: loss = 1.70468 (* 1 = 1.70468 loss)
I0525 19:24:14.949182 15746 sgd_solver.cpp:106] Iteration 5800, lr = 0.0001
I0525 19:32:33.627938 15746 solver.cpp:228] Iteration 5900, loss = 1.1964
I0525 19:32:33.628726 15746 solver.cpp:244]     Train net output #0: loss = 1.1964 (* 1 = 1.1964 loss)
I0525 19:32:33.628762 15746 sgd_solver.cpp:106] Iteration 5900, lr = 0.0001
I0525 19:40:32.578003 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_6000.caffemodel
I0525 19:40:32.885181 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_6000.solverstate
I0525 19:40:37.916888 15746 solver.cpp:228] Iteration 6000, loss = 1.18269
I0525 19:40:37.916962 15746 solver.cpp:244]     Train net output #0: loss = 1.18269 (* 1 = 1.18269 loss)
I0525 19:40:37.916975 15746 sgd_solver.cpp:106] Iteration 6000, lr = 0.0001
I0525 19:48:48.644799 15746 solver.cpp:228] Iteration 6100, loss = 1.37227
I0525 19:48:48.645594 15746 solver.cpp:244]     Train net output #0: loss = 1.37227 (* 1 = 1.37227 loss)
I0525 19:48:48.645633 15746 sgd_solver.cpp:106] Iteration 6100, lr = 0.0001
I0525 19:57:08.727615 15746 solver.cpp:228] Iteration 6200, loss = 1.15543
I0525 19:57:08.728427 15746 solver.cpp:244]     Train net output #0: loss = 1.15543 (* 1 = 1.15543 loss)
I0525 19:57:08.728462 15746 sgd_solver.cpp:106] Iteration 6200, lr = 0.0001
I0525 20:05:18.333999 15746 solver.cpp:228] Iteration 6300, loss = 1.43983
I0525 20:05:18.334774 15746 solver.cpp:244]     Train net output #0: loss = 1.43983 (* 1 = 1.43983 loss)
I0525 20:05:18.334810 15746 sgd_solver.cpp:106] Iteration 6300, lr = 0.0001
I0525 20:13:29.950167 15746 solver.cpp:228] Iteration 6400, loss = 1.40336
I0525 20:13:29.950835 15746 solver.cpp:244]     Train net output #0: loss = 1.40336 (* 1 = 1.40336 loss)
I0525 20:13:29.950850 15746 sgd_solver.cpp:106] Iteration 6400, lr = 0.0001
I0525 20:21:45.933851 15746 solver.cpp:228] Iteration 6500, loss = 1.0168
I0525 20:21:45.934531 15746 solver.cpp:244]     Train net output #0: loss = 1.0168 (* 1 = 1.0168 loss)
I0525 20:21:45.934562 15746 sgd_solver.cpp:106] Iteration 6500, lr = 0.0001
I0525 20:24:13.613168 15746 solver.cpp:337] Iteration 6530, Testing net (#0)
I0525 20:24:13.613615 15746 net.cpp:685] Ignoring source layer ratemap
I0525 20:24:13.613633 15746 net.cpp:685] Ignoring source layer amsFeatures
I0525 20:27:04.651352 15746 solver.cpp:404]     Test net output #0: loss = 0.828208 (* 1 = 0.828208 loss)
I0525 20:33:01.889241 15746 solver.cpp:228] Iteration 6600, loss = 1.22568
I0525 20:33:01.889945 15746 solver.cpp:244]     Train net output #0: loss = 1.22568 (* 1 = 1.22568 loss)
I0525 20:33:01.889966 15746 sgd_solver.cpp:106] Iteration 6600, lr = 0.0001
I0525 20:41:43.975626 15746 solver.cpp:228] Iteration 6700, loss = 1.44447
I0525 20:41:43.976372 15746 solver.cpp:244]     Train net output #0: loss = 1.44447 (* 1 = 1.44447 loss)
I0525 20:41:43.976397 15746 sgd_solver.cpp:106] Iteration 6700, lr = 0.0001
I0525 20:50:28.347980 15746 solver.cpp:228] Iteration 6800, loss = 1.01979
I0525 20:50:28.348675 15746 solver.cpp:244]     Train net output #0: loss = 1.01979 (* 1 = 1.01979 loss)
I0525 20:50:28.348695 15746 sgd_solver.cpp:106] Iteration 6800, lr = 0.0001
I0525 20:58:51.620254 15746 solver.cpp:228] Iteration 6900, loss = 0.958795
I0525 20:58:51.620978 15746 solver.cpp:244]     Train net output #0: loss = 0.958794 (* 1 = 0.958794 loss)
I0525 20:58:51.621002 15746 sgd_solver.cpp:106] Iteration 6900, lr = 0.0001
I0525 21:07:30.183629 15746 solver.cpp:228] Iteration 7000, loss = 1.4576
I0525 21:07:30.184320 15746 solver.cpp:244]     Train net output #0: loss = 1.4576 (* 1 = 1.4576 loss)
I0525 21:07:30.184341 15746 sgd_solver.cpp:106] Iteration 7000, lr = 0.0001
I0525 21:16:06.428951 15746 solver.cpp:228] Iteration 7100, loss = 1.05938
I0525 21:16:06.429651 15746 solver.cpp:244]     Train net output #0: loss = 1.05938 (* 1 = 1.05938 loss)
I0525 21:16:06.429684 15746 sgd_solver.cpp:106] Iteration 7100, lr = 0.0001
I0525 21:24:29.160877 15746 solver.cpp:228] Iteration 7200, loss = 1.05438
I0525 21:24:29.161594 15746 solver.cpp:244]     Train net output #0: loss = 1.05438 (* 1 = 1.05438 loss)
I0525 21:24:29.161614 15746 sgd_solver.cpp:106] Iteration 7200, lr = 0.0001
I0525 21:32:40.718121 15746 solver.cpp:228] Iteration 7300, loss = 1.2657
I0525 21:32:40.718824 15746 solver.cpp:244]     Train net output #0: loss = 1.2657 (* 1 = 1.2657 loss)
I0525 21:32:40.718844 15746 sgd_solver.cpp:106] Iteration 7300, lr = 0.0001
I0525 21:41:09.044312 15746 solver.cpp:228] Iteration 7400, loss = 1.20601
I0525 21:41:09.045095 15746 solver.cpp:244]     Train net output #0: loss = 1.20601 (* 1 = 1.20601 loss)
I0525 21:41:09.045136 15746 sgd_solver.cpp:106] Iteration 7400, lr = 0.0001
I0525 21:49:35.425678 15746 solver.cpp:228] Iteration 7500, loss = 1.15522
I0525 21:49:35.426486 15746 solver.cpp:244]     Train net output #0: loss = 1.15522 (* 1 = 1.15522 loss)
I0525 21:49:35.426511 15746 sgd_solver.cpp:106] Iteration 7500, lr = 0.0001
I0525 21:57:50.865290 15746 solver.cpp:228] Iteration 7600, loss = 1.62484
I0525 21:57:50.865964 15746 solver.cpp:244]     Train net output #0: loss = 1.62484 (* 1 = 1.62484 loss)
I0525 21:57:50.865985 15746 sgd_solver.cpp:106] Iteration 7600, lr = 0.0001
I0525 22:06:26.457559 15746 solver.cpp:228] Iteration 7700, loss = 0.946652
I0525 22:06:26.458200 15746 solver.cpp:244]     Train net output #0: loss = 0.946652 (* 1 = 0.946652 loss)
I0525 22:06:26.458214 15746 sgd_solver.cpp:106] Iteration 7700, lr = 0.0001
I0525 22:14:58.412989 15746 solver.cpp:228] Iteration 7800, loss = 1.35367
I0525 22:14:58.413882 15746 solver.cpp:244]     Train net output #0: loss = 1.35367 (* 1 = 1.35367 loss)
I0525 22:14:58.413902 15746 sgd_solver.cpp:106] Iteration 7800, lr = 0.0001
I0525 22:23:17.565608 15746 solver.cpp:228] Iteration 7900, loss = 1.27963
I0525 22:23:17.566251 15746 solver.cpp:244]     Train net output #0: loss = 1.27963 (* 1 = 1.27963 loss)
I0525 22:23:17.566270 15746 sgd_solver.cpp:106] Iteration 7900, lr = 0.0001
I0525 22:31:50.472548 15746 solver.cpp:228] Iteration 8000, loss = 0.836157
I0525 22:31:50.473239 15746 solver.cpp:244]     Train net output #0: loss = 0.836157 (* 1 = 0.836157 loss)
I0525 22:31:50.473274 15746 sgd_solver.cpp:106] Iteration 8000, lr = 0.0001
I0525 22:40:17.068402 15746 solver.cpp:228] Iteration 8100, loss = 1.28164
I0525 22:40:17.069118 15746 solver.cpp:244]     Train net output #0: loss = 1.28164 (* 1 = 1.28164 loss)
I0525 22:40:17.069157 15746 sgd_solver.cpp:106] Iteration 8100, lr = 0.0001
I0525 22:48:55.273741 15746 solver.cpp:228] Iteration 8200, loss = 1.08771
I0525 22:48:55.274509 15746 solver.cpp:244]     Train net output #0: loss = 1.08771 (* 1 = 1.08771 loss)
I0525 22:48:55.274533 15746 sgd_solver.cpp:106] Iteration 8200, lr = 0.0001
I0525 22:57:24.769021 15746 solver.cpp:228] Iteration 8300, loss = 1.34807
I0525 22:57:24.769743 15746 solver.cpp:244]     Train net output #0: loss = 1.34807 (* 1 = 1.34807 loss)
I0525 22:57:24.769786 15746 sgd_solver.cpp:106] Iteration 8300, lr = 0.0001
I0525 23:05:57.659373 15746 solver.cpp:228] Iteration 8400, loss = 0.888519
I0525 23:05:57.660099 15746 solver.cpp:244]     Train net output #0: loss = 0.888519 (* 1 = 0.888519 loss)
I0525 23:05:57.660125 15746 sgd_solver.cpp:106] Iteration 8400, lr = 0.0001
I0525 23:14:22.994035 15746 solver.cpp:228] Iteration 8500, loss = 0.95308
I0525 23:14:22.994696 15746 solver.cpp:244]     Train net output #0: loss = 0.95308 (* 1 = 0.95308 loss)
I0525 23:14:22.994716 15746 sgd_solver.cpp:106] Iteration 8500, lr = 0.0001
I0525 23:23:01.361522 15746 solver.cpp:228] Iteration 8600, loss = 1.87726
I0525 23:23:01.362217 15746 solver.cpp:244]     Train net output #0: loss = 1.87726 (* 1 = 1.87726 loss)
I0525 23:23:01.362242 15746 sgd_solver.cpp:106] Iteration 8600, lr = 0.0001
I0525 23:31:20.027750 15746 solver.cpp:228] Iteration 8700, loss = 1.02353
I0525 23:31:20.028409 15746 solver.cpp:244]     Train net output #0: loss = 1.02353 (* 1 = 1.02353 loss)
I0525 23:31:20.028439 15746 sgd_solver.cpp:106] Iteration 8700, lr = 0.0001
I0525 23:39:37.617066 15746 solver.cpp:228] Iteration 8800, loss = 0.757031
I0525 23:39:37.617769 15746 solver.cpp:244]     Train net output #0: loss = 0.757031 (* 1 = 0.757031 loss)
I0525 23:39:37.617799 15746 sgd_solver.cpp:106] Iteration 8800, lr = 0.0001
I0525 23:48:00.077422 15746 solver.cpp:228] Iteration 8900, loss = 1.15686
I0525 23:48:00.078217 15746 solver.cpp:244]     Train net output #0: loss = 1.15686 (* 1 = 1.15686 loss)
I0525 23:48:00.078258 15746 sgd_solver.cpp:106] Iteration 8900, lr = 0.0001
I0525 23:56:16.725134 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_9000.caffemodel
I0525 23:56:17.257206 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_9000.solverstate
I0525 23:56:22.938426 15746 solver.cpp:228] Iteration 9000, loss = 0.940843
I0525 23:56:22.938478 15746 solver.cpp:244]     Train net output #0: loss = 0.940843 (* 1 = 0.940843 loss)
I0525 23:56:22.938490 15746 sgd_solver.cpp:106] Iteration 9000, lr = 0.0001
I0526 00:04:39.337159 15746 solver.cpp:228] Iteration 9100, loss = 0.796644
I0526 00:04:39.337910 15746 solver.cpp:244]     Train net output #0: loss = 0.796644 (* 1 = 0.796644 loss)
I0526 00:04:39.337934 15746 sgd_solver.cpp:106] Iteration 9100, lr = 0.0001
I0526 00:13:05.658932 15746 solver.cpp:228] Iteration 9200, loss = 1.0523
I0526 00:13:05.659718 15746 solver.cpp:244]     Train net output #0: loss = 1.0523 (* 1 = 1.0523 loss)
I0526 00:13:05.659742 15746 sgd_solver.cpp:106] Iteration 9200, lr = 0.0001
I0526 00:21:25.188765 15746 solver.cpp:228] Iteration 9300, loss = 0.853152
I0526 00:21:25.189492 15746 solver.cpp:244]     Train net output #0: loss = 0.853152 (* 1 = 0.853152 loss)
I0526 00:21:25.189517 15746 sgd_solver.cpp:106] Iteration 9300, lr = 0.0001
I0526 00:29:22.421059 15746 solver.cpp:228] Iteration 9400, loss = 1.34932
I0526 00:29:22.421752 15746 solver.cpp:244]     Train net output #0: loss = 1.34932 (* 1 = 1.34932 loss)
I0526 00:29:22.421773 15746 sgd_solver.cpp:106] Iteration 9400, lr = 0.0001
I0526 00:37:49.677474 15746 solver.cpp:228] Iteration 9500, loss = 1.49216
I0526 00:37:49.678189 15746 solver.cpp:244]     Train net output #0: loss = 1.49216 (* 1 = 1.49216 loss)
I0526 00:37:49.678227 15746 sgd_solver.cpp:106] Iteration 9500, lr = 0.0001
I0526 00:46:10.115766 15746 solver.cpp:228] Iteration 9600, loss = 0.825415
I0526 00:46:10.116492 15746 solver.cpp:244]     Train net output #0: loss = 0.825415 (* 1 = 0.825415 loss)
I0526 00:46:10.116523 15746 sgd_solver.cpp:106] Iteration 9600, lr = 0.0001
I0526 00:54:30.219787 15746 solver.cpp:228] Iteration 9700, loss = 1.57302
I0526 00:54:30.220451 15746 solver.cpp:244]     Train net output #0: loss = 1.57302 (* 1 = 1.57302 loss)
I0526 00:54:30.220473 15746 sgd_solver.cpp:106] Iteration 9700, lr = 0.0001
I0526 01:02:29.119359 15746 solver.cpp:337] Iteration 9795, Testing net (#0)
I0526 01:02:29.120054 15746 net.cpp:685] Ignoring source layer ratemap
I0526 01:02:29.120069 15746 net.cpp:685] Ignoring source layer amsFeatures
I0526 01:05:19.832981 15746 solver.cpp:404]     Test net output #0: loss = 0.699284 (* 1 = 0.699284 loss)
I0526 01:05:44.990981 15746 solver.cpp:228] Iteration 9800, loss = 1.68969
I0526 01:05:44.991032 15746 solver.cpp:244]     Train net output #0: loss = 1.68969 (* 1 = 1.68969 loss)
I0526 01:05:44.991044 15746 sgd_solver.cpp:106] Iteration 9800, lr = 0.0001
I0526 01:14:01.209659 15746 solver.cpp:228] Iteration 9900, loss = 0.958674
I0526 01:14:01.210182 15746 solver.cpp:244]     Train net output #0: loss = 0.958674 (* 1 = 0.958674 loss)
I0526 01:14:01.210203 15746 sgd_solver.cpp:106] Iteration 9900, lr = 0.0001
I0526 01:22:18.252269 15746 solver.cpp:228] Iteration 10000, loss = 0.768158
I0526 01:22:18.253067 15746 solver.cpp:244]     Train net output #0: loss = 0.768158 (* 1 = 0.768158 loss)
I0526 01:22:18.253092 15746 sgd_solver.cpp:106] Iteration 10000, lr = 0.0001
I0526 01:30:26.819653 15746 solver.cpp:228] Iteration 10100, loss = 1.24539
I0526 01:30:26.820365 15746 solver.cpp:244]     Train net output #0: loss = 1.24539 (* 1 = 1.24539 loss)
I0526 01:30:26.820394 15746 sgd_solver.cpp:106] Iteration 10100, lr = 0.0001
I0526 01:38:43.758816 15746 solver.cpp:228] Iteration 10200, loss = 1.34952
I0526 01:38:43.759475 15746 solver.cpp:244]     Train net output #0: loss = 1.34952 (* 1 = 1.34952 loss)
I0526 01:38:43.759495 15746 sgd_solver.cpp:106] Iteration 10200, lr = 0.0001
I0526 01:47:05.094458 15746 solver.cpp:228] Iteration 10300, loss = 0.867163
I0526 01:47:05.095082 15746 solver.cpp:244]     Train net output #0: loss = 0.867162 (* 1 = 0.867162 loss)
I0526 01:47:05.095113 15746 sgd_solver.cpp:106] Iteration 10300, lr = 0.0001
I0526 01:55:26.405931 15746 solver.cpp:228] Iteration 10400, loss = 0.934559
I0526 01:55:26.406783 15746 solver.cpp:244]     Train net output #0: loss = 0.934558 (* 1 = 0.934558 loss)
I0526 01:55:26.406810 15746 sgd_solver.cpp:106] Iteration 10400, lr = 0.0001
I0526 02:03:40.291095 15746 solver.cpp:228] Iteration 10500, loss = 1.04941
I0526 02:03:40.291887 15746 solver.cpp:244]     Train net output #0: loss = 1.04941 (* 1 = 1.04941 loss)
I0526 02:03:40.291913 15746 sgd_solver.cpp:106] Iteration 10500, lr = 0.0001
I0526 02:12:05.714426 15746 solver.cpp:228] Iteration 10600, loss = 1.0297
I0526 02:12:05.715152 15746 solver.cpp:244]     Train net output #0: loss = 1.0297 (* 1 = 1.0297 loss)
I0526 02:12:05.715214 15746 sgd_solver.cpp:106] Iteration 10600, lr = 0.0001
I0526 02:20:15.181318 15746 solver.cpp:228] Iteration 10700, loss = 0.991885
I0526 02:20:15.182021 15746 solver.cpp:244]     Train net output #0: loss = 0.991885 (* 1 = 0.991885 loss)
I0526 02:20:15.182042 15746 sgd_solver.cpp:106] Iteration 10700, lr = 0.0001
I0526 02:28:28.400307 15746 solver.cpp:228] Iteration 10800, loss = 0.742024
I0526 02:28:28.400985 15746 solver.cpp:244]     Train net output #0: loss = 0.742024 (* 1 = 0.742024 loss)
I0526 02:28:28.401015 15746 sgd_solver.cpp:106] Iteration 10800, lr = 0.0001
I0526 02:36:34.567266 15746 solver.cpp:228] Iteration 10900, loss = 0.746784
I0526 02:36:34.567931 15746 solver.cpp:244]     Train net output #0: loss = 0.746783 (* 1 = 0.746783 loss)
I0526 02:36:34.567952 15746 sgd_solver.cpp:106] Iteration 10900, lr = 0.0001
I0526 02:44:42.342527 15746 solver.cpp:228] Iteration 11000, loss = 1.11956
I0526 02:44:42.343250 15746 solver.cpp:244]     Train net output #0: loss = 1.11956 (* 1 = 1.11956 loss)
I0526 02:44:42.343281 15746 sgd_solver.cpp:106] Iteration 11000, lr = 0.0001
I0526 02:52:48.921412 15746 solver.cpp:228] Iteration 11100, loss = 0.851474
I0526 02:52:48.922106 15746 solver.cpp:244]     Train net output #0: loss = 0.851474 (* 1 = 0.851474 loss)
I0526 02:52:48.922134 15746 sgd_solver.cpp:106] Iteration 11100, lr = 0.0001
I0526 03:01:12.721618 15746 solver.cpp:228] Iteration 11200, loss = 0.982767
I0526 03:01:12.722322 15746 solver.cpp:244]     Train net output #0: loss = 0.982767 (* 1 = 0.982767 loss)
I0526 03:01:12.722342 15746 sgd_solver.cpp:106] Iteration 11200, lr = 0.0001
I0526 03:09:27.632215 15746 solver.cpp:228] Iteration 11300, loss = 1.22387
I0526 03:09:27.632891 15746 solver.cpp:244]     Train net output #0: loss = 1.22387 (* 1 = 1.22387 loss)
I0526 03:09:27.632912 15746 sgd_solver.cpp:106] Iteration 11300, lr = 0.0001
I0526 03:17:53.124495 15746 solver.cpp:228] Iteration 11400, loss = 0.846366
I0526 03:17:53.125169 15746 solver.cpp:244]     Train net output #0: loss = 0.846366 (* 1 = 0.846366 loss)
I0526 03:17:53.125190 15746 sgd_solver.cpp:106] Iteration 11400, lr = 0.0001
I0526 03:26:01.371007 15746 solver.cpp:228] Iteration 11500, loss = 0.908255
I0526 03:26:01.371744 15746 solver.cpp:244]     Train net output #0: loss = 0.908255 (* 1 = 0.908255 loss)
I0526 03:26:01.371778 15746 sgd_solver.cpp:106] Iteration 11500, lr = 0.0001
I0526 03:34:15.716102 15746 solver.cpp:228] Iteration 11600, loss = 1.09743
I0526 03:34:15.716838 15746 solver.cpp:244]     Train net output #0: loss = 1.09743 (* 1 = 1.09743 loss)
I0526 03:34:15.716859 15746 sgd_solver.cpp:106] Iteration 11600, lr = 0.0001
I0526 03:42:36.725553 15746 solver.cpp:228] Iteration 11700, loss = 1.39232
I0526 03:42:36.726208 15746 solver.cpp:244]     Train net output #0: loss = 1.39232 (* 1 = 1.39232 loss)
I0526 03:42:36.726238 15746 sgd_solver.cpp:106] Iteration 11700, lr = 0.0001
I0526 03:50:56.748334 15746 solver.cpp:228] Iteration 11800, loss = 1.03625
I0526 03:50:56.749094 15746 solver.cpp:244]     Train net output #0: loss = 1.03625 (* 1 = 1.03625 loss)
I0526 03:50:56.749114 15746 sgd_solver.cpp:106] Iteration 11800, lr = 0.0001
I0526 03:59:20.417258 15746 solver.cpp:228] Iteration 11900, loss = 1.06431
I0526 03:59:20.417917 15746 solver.cpp:244]     Train net output #0: loss = 1.06431 (* 1 = 1.06431 loss)
I0526 03:59:20.417937 15746 sgd_solver.cpp:106] Iteration 11900, lr = 0.0001
I0526 04:07:55.246572 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_12000.caffemodel
I0526 04:07:55.496701 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_12000.solverstate
I0526 04:08:00.281946 15746 solver.cpp:228] Iteration 12000, loss = 0.809845
I0526 04:08:00.281996 15746 solver.cpp:244]     Train net output #0: loss = 0.809845 (* 1 = 0.809845 loss)
I0526 04:08:00.282006 15746 sgd_solver.cpp:106] Iteration 12000, lr = 0.0001
I0526 04:16:24.494390 15746 solver.cpp:228] Iteration 12100, loss = 1.05593
I0526 04:16:24.495034 15746 solver.cpp:244]     Train net output #0: loss = 1.05593 (* 1 = 1.05593 loss)
I0526 04:16:24.495049 15746 sgd_solver.cpp:106] Iteration 12100, lr = 0.0001
I0526 04:24:54.461606 15746 solver.cpp:228] Iteration 12200, loss = 1.11158
I0526 04:24:54.462354 15746 solver.cpp:244]     Train net output #0: loss = 1.11158 (* 1 = 1.11158 loss)
I0526 04:24:54.462374 15746 sgd_solver.cpp:106] Iteration 12200, lr = 0.0001
I0526 04:33:11.021580 15746 solver.cpp:228] Iteration 12300, loss = 0.901034
I0526 04:33:11.022204 15746 solver.cpp:244]     Train net output #0: loss = 0.901034 (* 1 = 0.901034 loss)
I0526 04:33:11.022219 15746 sgd_solver.cpp:106] Iteration 12300, lr = 0.0001
I0526 04:41:13.673621 15746 solver.cpp:228] Iteration 12400, loss = 1.39846
I0526 04:41:13.674260 15746 solver.cpp:244]     Train net output #0: loss = 1.39846 (* 1 = 1.39846 loss)
I0526 04:41:13.674289 15746 sgd_solver.cpp:106] Iteration 12400, lr = 0.0001
I0526 04:49:22.289093 15746 solver.cpp:228] Iteration 12500, loss = 1.00927
I0526 04:49:22.289731 15746 solver.cpp:244]     Train net output #0: loss = 1.00927 (* 1 = 1.00927 loss)
I0526 04:49:22.289752 15746 sgd_solver.cpp:106] Iteration 12500, lr = 0.0001
I0526 04:57:44.557886 15746 solver.cpp:228] Iteration 12600, loss = 1.0617
I0526 04:57:44.558702 15746 solver.cpp:244]     Train net output #0: loss = 1.06169 (* 1 = 1.06169 loss)
I0526 04:57:44.558732 15746 sgd_solver.cpp:106] Iteration 12600, lr = 0.0001
I0526 05:06:09.120218 15746 solver.cpp:228] Iteration 12700, loss = 0.922473
I0526 05:06:09.120976 15746 solver.cpp:244]     Train net output #0: loss = 0.922472 (* 1 = 0.922472 loss)
I0526 05:06:09.121009 15746 sgd_solver.cpp:106] Iteration 12700, lr = 0.0001
I0526 05:14:20.077956 15746 solver.cpp:228] Iteration 12800, loss = 1.1336
I0526 05:14:20.078627 15746 solver.cpp:244]     Train net output #0: loss = 1.13359 (* 1 = 1.13359 loss)
I0526 05:14:20.078647 15746 sgd_solver.cpp:106] Iteration 12800, lr = 0.0001
I0526 05:22:55.626669 15746 solver.cpp:228] Iteration 12900, loss = 0.867923
I0526 05:22:55.627451 15746 solver.cpp:244]     Train net output #0: loss = 0.867923 (* 1 = 0.867923 loss)
I0526 05:22:55.627485 15746 sgd_solver.cpp:106] Iteration 12900, lr = 0.0001
I0526 05:31:28.344211 15746 solver.cpp:228] Iteration 13000, loss = 1.17163
I0526 05:31:28.345010 15746 solver.cpp:244]     Train net output #0: loss = 1.17163 (* 1 = 1.17163 loss)
I0526 05:31:28.345046 15746 sgd_solver.cpp:106] Iteration 13000, lr = 0.0001
I0526 05:36:27.474364 15746 solver.cpp:337] Iteration 13060, Testing net (#0)
I0526 05:36:27.474805 15746 net.cpp:685] Ignoring source layer ratemap
I0526 05:36:27.474819 15746 net.cpp:685] Ignoring source layer amsFeatures
I0526 05:39:18.490170 15746 solver.cpp:404]     Test net output #0: loss = 0.647355 (* 1 = 0.647355 loss)
I0526 05:42:57.312939 15746 solver.cpp:228] Iteration 13100, loss = 1.04239
I0526 05:42:57.313403 15746 solver.cpp:244]     Train net output #0: loss = 1.04239 (* 1 = 1.04239 loss)
I0526 05:42:57.313424 15746 sgd_solver.cpp:106] Iteration 13100, lr = 0.0001
I0526 05:51:39.800323 15746 solver.cpp:228] Iteration 13200, loss = 0.649344
I0526 05:51:39.801023 15746 solver.cpp:244]     Train net output #0: loss = 0.649344 (* 1 = 0.649344 loss)
I0526 05:51:39.801044 15746 sgd_solver.cpp:106] Iteration 13200, lr = 0.0001
I0526 05:59:47.176266 15746 solver.cpp:228] Iteration 13300, loss = 0.519692
I0526 05:59:47.176949 15746 solver.cpp:244]     Train net output #0: loss = 0.519691 (* 1 = 0.519691 loss)
I0526 05:59:47.176969 15746 sgd_solver.cpp:106] Iteration 13300, lr = 0.0001
I0526 06:08:16.634855 15746 solver.cpp:228] Iteration 13400, loss = 0.722344
I0526 06:08:16.635619 15746 solver.cpp:244]     Train net output #0: loss = 0.722344 (* 1 = 0.722344 loss)
I0526 06:08:16.635644 15746 sgd_solver.cpp:106] Iteration 13400, lr = 0.0001
I0526 06:16:53.308642 15746 solver.cpp:228] Iteration 13500, loss = 0.543238
I0526 06:16:53.309407 15746 solver.cpp:244]     Train net output #0: loss = 0.543238 (* 1 = 0.543238 loss)
I0526 06:16:53.309447 15746 sgd_solver.cpp:106] Iteration 13500, lr = 0.0001
I0526 06:25:24.203480 15746 solver.cpp:228] Iteration 13600, loss = 0.85972
I0526 06:25:24.204330 15746 solver.cpp:244]     Train net output #0: loss = 0.859719 (* 1 = 0.859719 loss)
I0526 06:25:24.204391 15746 sgd_solver.cpp:106] Iteration 13600, lr = 0.0001
I0526 06:33:40.972880 15746 solver.cpp:228] Iteration 13700, loss = 1.17589
I0526 06:33:40.973506 15746 solver.cpp:244]     Train net output #0: loss = 1.17589 (* 1 = 1.17589 loss)
I0526 06:33:40.973541 15746 sgd_solver.cpp:106] Iteration 13700, lr = 0.0001
I0526 06:41:59.125368 15746 solver.cpp:228] Iteration 13800, loss = 0.785515
I0526 06:41:59.126040 15746 solver.cpp:244]     Train net output #0: loss = 0.785514 (* 1 = 0.785514 loss)
I0526 06:41:59.126071 15746 sgd_solver.cpp:106] Iteration 13800, lr = 0.0001
I0526 06:50:27.576325 15746 solver.cpp:228] Iteration 13900, loss = 0.527028
I0526 06:50:27.577102 15746 solver.cpp:244]     Train net output #0: loss = 0.527027 (* 1 = 0.527027 loss)
I0526 06:50:27.577127 15746 sgd_solver.cpp:106] Iteration 13900, lr = 0.0001
I0526 06:59:06.596613 15746 solver.cpp:228] Iteration 14000, loss = 0.987508
I0526 06:59:06.597287 15746 solver.cpp:244]     Train net output #0: loss = 0.987507 (* 1 = 0.987507 loss)
I0526 06:59:06.597307 15746 sgd_solver.cpp:106] Iteration 14000, lr = 0.0001
I0526 07:07:31.803421 15746 solver.cpp:228] Iteration 14100, loss = 1.58021
I0526 07:07:31.804154 15746 solver.cpp:244]     Train net output #0: loss = 1.58021 (* 1 = 1.58021 loss)
I0526 07:07:31.804168 15746 sgd_solver.cpp:106] Iteration 14100, lr = 0.0001
I0526 07:15:57.991901 15746 solver.cpp:228] Iteration 14200, loss = 0.776046
I0526 07:15:57.992599 15746 solver.cpp:244]     Train net output #0: loss = 0.776045 (* 1 = 0.776045 loss)
I0526 07:15:57.992640 15746 sgd_solver.cpp:106] Iteration 14200, lr = 0.0001
I0526 07:24:47.335178 15746 solver.cpp:228] Iteration 14300, loss = 0.900787
I0526 07:24:47.335861 15746 solver.cpp:244]     Train net output #0: loss = 0.900786 (* 1 = 0.900786 loss)
I0526 07:24:47.335886 15746 sgd_solver.cpp:106] Iteration 14300, lr = 0.0001
I0526 07:33:14.771543 15746 solver.cpp:228] Iteration 14400, loss = 0.694589
I0526 07:33:14.772270 15746 solver.cpp:244]     Train net output #0: loss = 0.694589 (* 1 = 0.694589 loss)
I0526 07:33:14.772290 15746 sgd_solver.cpp:106] Iteration 14400, lr = 0.0001
I0526 07:41:52.550489 15746 solver.cpp:228] Iteration 14500, loss = 0.717569
I0526 07:41:52.551304 15746 solver.cpp:244]     Train net output #0: loss = 0.717569 (* 1 = 0.717569 loss)
I0526 07:41:52.551337 15746 sgd_solver.cpp:106] Iteration 14500, lr = 0.0001
I0526 07:50:36.714583 15746 solver.cpp:228] Iteration 14600, loss = 0.552826
I0526 07:50:36.715365 15746 solver.cpp:244]     Train net output #0: loss = 0.552825 (* 1 = 0.552825 loss)
I0526 07:50:36.715394 15746 sgd_solver.cpp:106] Iteration 14600, lr = 0.0001
I0526 07:59:06.706420 15746 solver.cpp:228] Iteration 14700, loss = 0.830789
I0526 07:59:06.707216 15746 solver.cpp:244]     Train net output #0: loss = 0.830788 (* 1 = 0.830788 loss)
I0526 07:59:06.707254 15746 sgd_solver.cpp:106] Iteration 14700, lr = 0.0001
I0526 08:07:52.063730 15746 solver.cpp:228] Iteration 14800, loss = 0.691742
I0526 08:07:52.064494 15746 solver.cpp:244]     Train net output #0: loss = 0.691742 (* 1 = 0.691742 loss)
I0526 08:07:52.064519 15746 sgd_solver.cpp:106] Iteration 14800, lr = 0.0001
I0526 08:16:24.781534 15746 solver.cpp:228] Iteration 14900, loss = 0.892738
I0526 08:16:24.782207 15746 solver.cpp:244]     Train net output #0: loss = 0.892737 (* 1 = 0.892737 loss)
I0526 08:16:24.782237 15746 sgd_solver.cpp:106] Iteration 14900, lr = 0.0001
I0526 08:24:48.663478 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_15000.caffemodel
I0526 08:24:48.855641 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_15000.solverstate
I0526 08:24:52.822309 15746 solver.cpp:228] Iteration 15000, loss = 0.450608
I0526 08:24:52.822381 15746 solver.cpp:244]     Train net output #0: loss = 0.450607 (* 1 = 0.450607 loss)
I0526 08:24:52.822391 15746 sgd_solver.cpp:106] Iteration 15000, lr = 0.0001
I0526 08:33:05.955529 15746 solver.cpp:228] Iteration 15100, loss = 1.1949
I0526 08:33:05.956292 15746 solver.cpp:244]     Train net output #0: loss = 1.1949 (* 1 = 1.1949 loss)
I0526 08:33:05.956326 15746 sgd_solver.cpp:106] Iteration 15100, lr = 0.0001
I0526 08:41:29.876971 15746 solver.cpp:228] Iteration 15200, loss = 1.1312
I0526 08:41:29.877882 15746 solver.cpp:244]     Train net output #0: loss = 1.1312 (* 1 = 1.1312 loss)
I0526 08:41:29.877907 15746 sgd_solver.cpp:106] Iteration 15200, lr = 0.0001
I0526 08:50:11.826059 15746 solver.cpp:228] Iteration 15300, loss = 0.802152
I0526 08:50:11.826731 15746 solver.cpp:244]     Train net output #0: loss = 0.802151 (* 1 = 0.802151 loss)
I0526 08:50:11.826762 15746 sgd_solver.cpp:106] Iteration 15300, lr = 0.0001
I0526 08:58:35.941489 15746 solver.cpp:228] Iteration 15400, loss = 0.805077
I0526 08:58:35.942183 15746 solver.cpp:244]     Train net output #0: loss = 0.805076 (* 1 = 0.805076 loss)
I0526 08:58:35.942205 15746 sgd_solver.cpp:106] Iteration 15400, lr = 0.0001
I0526 09:06:54.857636 15746 solver.cpp:228] Iteration 15500, loss = 1.09639
I0526 09:06:54.858377 15746 solver.cpp:244]     Train net output #0: loss = 1.09639 (* 1 = 1.09639 loss)
I0526 09:06:54.858402 15746 sgd_solver.cpp:106] Iteration 15500, lr = 0.0001
I0526 09:15:07.910490 15746 solver.cpp:228] Iteration 15600, loss = 0.763136
I0526 09:15:07.911208 15746 solver.cpp:244]     Train net output #0: loss = 0.763136 (* 1 = 0.763136 loss)
I0526 09:15:07.911231 15746 sgd_solver.cpp:106] Iteration 15600, lr = 0.0001
I0526 09:23:18.345237 15746 solver.cpp:228] Iteration 15700, loss = 0.637007
I0526 09:23:18.345906 15746 solver.cpp:244]     Train net output #0: loss = 0.637006 (* 1 = 0.637006 loss)
I0526 09:23:18.345938 15746 sgd_solver.cpp:106] Iteration 15700, lr = 0.0001
I0526 09:31:34.001850 15746 solver.cpp:228] Iteration 15800, loss = 0.938767
I0526 09:31:34.002508 15746 solver.cpp:244]     Train net output #0: loss = 0.938767 (* 1 = 0.938767 loss)
I0526 09:31:34.002521 15746 sgd_solver.cpp:106] Iteration 15800, lr = 0.0001
I0526 09:40:06.071516 15746 solver.cpp:228] Iteration 15900, loss = 0.912582
I0526 09:40:06.072114 15746 solver.cpp:244]     Train net output #0: loss = 0.912582 (* 1 = 0.912582 loss)
I0526 09:40:06.072134 15746 sgd_solver.cpp:106] Iteration 15900, lr = 0.0001
I0526 09:48:24.883208 15746 solver.cpp:228] Iteration 16000, loss = 0.790591
I0526 09:48:24.883906 15746 solver.cpp:244]     Train net output #0: loss = 0.790591 (* 1 = 0.790591 loss)
I0526 09:48:24.883920 15746 sgd_solver.cpp:106] Iteration 16000, lr = 0.0001
I0526 09:56:51.238822 15746 solver.cpp:228] Iteration 16100, loss = 0.715489
I0526 09:56:51.239531 15746 solver.cpp:244]     Train net output #0: loss = 0.715488 (* 1 = 0.715488 loss)
I0526 09:56:51.239550 15746 sgd_solver.cpp:106] Iteration 16100, lr = 0.0001
I0526 10:05:35.849581 15746 solver.cpp:228] Iteration 16200, loss = 0.687968
I0526 10:05:35.850229 15746 solver.cpp:244]     Train net output #0: loss = 0.687967 (* 1 = 0.687967 loss)
I0526 10:05:35.850249 15746 sgd_solver.cpp:106] Iteration 16200, lr = 0.0001
I0526 10:14:10.277012 15746 solver.cpp:228] Iteration 16300, loss = 0.747138
I0526 10:14:10.277706 15746 solver.cpp:244]     Train net output #0: loss = 0.747137 (* 1 = 0.747137 loss)
I0526 10:14:10.277725 15746 sgd_solver.cpp:106] Iteration 16300, lr = 0.0001
I0526 10:16:19.863453 15746 solver.cpp:337] Iteration 16325, Testing net (#0)
I0526 10:16:19.863955 15746 net.cpp:685] Ignoring source layer ratemap
I0526 10:16:19.863982 15746 net.cpp:685] Ignoring source layer amsFeatures
I0526 10:19:11.076081 15746 solver.cpp:404]     Test net output #0: loss = 0.64233 (* 1 = 0.64233 loss)
I0526 10:25:37.633788 15746 solver.cpp:228] Iteration 16400, loss = 0.697268
I0526 10:25:37.634260 15746 solver.cpp:244]     Train net output #0: loss = 0.697268 (* 1 = 0.697268 loss)
I0526 10:25:37.634284 15746 sgd_solver.cpp:106] Iteration 16400, lr = 0.0001
I0526 10:33:39.656805 15746 solver.cpp:228] Iteration 16500, loss = 1.00479
I0526 10:33:39.657505 15746 solver.cpp:244]     Train net output #0: loss = 1.00479 (* 1 = 1.00479 loss)
I0526 10:33:39.657526 15746 sgd_solver.cpp:106] Iteration 16500, lr = 0.0001
I0526 10:41:47.871644 15746 solver.cpp:228] Iteration 16600, loss = 0.743257
I0526 10:41:47.872493 15746 solver.cpp:244]     Train net output #0: loss = 0.743256 (* 1 = 0.743256 loss)
I0526 10:41:47.872519 15746 sgd_solver.cpp:106] Iteration 16600, lr = 0.0001
I0526 10:49:56.052652 15746 solver.cpp:228] Iteration 16700, loss = 1.07703
I0526 10:49:56.053350 15746 solver.cpp:244]     Train net output #0: loss = 1.07703 (* 1 = 1.07703 loss)
I0526 10:49:56.053371 15746 sgd_solver.cpp:106] Iteration 16700, lr = 0.0001
I0526 10:57:51.458943 15746 solver.cpp:228] Iteration 16800, loss = 0.807374
I0526 10:57:51.459653 15746 solver.cpp:244]     Train net output #0: loss = 0.807373 (* 1 = 0.807373 loss)
I0526 10:57:51.459678 15746 sgd_solver.cpp:106] Iteration 16800, lr = 0.0001
I0526 11:06:08.227797 15746 solver.cpp:228] Iteration 16900, loss = 0.761081
I0526 11:06:08.228376 15746 solver.cpp:244]     Train net output #0: loss = 0.761081 (* 1 = 0.761081 loss)
I0526 11:06:08.228399 15746 sgd_solver.cpp:106] Iteration 16900, lr = 0.0001
I0526 11:14:20.986081 15746 solver.cpp:228] Iteration 17000, loss = 0.790581
I0526 11:14:20.986851 15746 solver.cpp:244]     Train net output #0: loss = 0.79058 (* 1 = 0.79058 loss)
I0526 11:14:20.986873 15746 sgd_solver.cpp:106] Iteration 17000, lr = 0.0001
I0526 11:22:30.395181 15746 solver.cpp:228] Iteration 17100, loss = 1.25043
I0526 11:22:30.395941 15746 solver.cpp:244]     Train net output #0: loss = 1.25043 (* 1 = 1.25043 loss)
I0526 11:22:30.395964 15746 sgd_solver.cpp:106] Iteration 17100, lr = 0.0001
I0526 11:30:49.721945 15746 solver.cpp:228] Iteration 17200, loss = 0.935243
I0526 11:30:49.722718 15746 solver.cpp:244]     Train net output #0: loss = 0.935242 (* 1 = 0.935242 loss)
I0526 11:30:49.722743 15746 sgd_solver.cpp:106] Iteration 17200, lr = 0.0001
I0526 11:39:11.246913 15746 solver.cpp:228] Iteration 17300, loss = 0.77229
I0526 11:39:11.247534 15746 solver.cpp:244]     Train net output #0: loss = 0.772289 (* 1 = 0.772289 loss)
I0526 11:39:11.247562 15746 sgd_solver.cpp:106] Iteration 17300, lr = 0.0001
I0526 11:47:14.525449 15746 solver.cpp:228] Iteration 17400, loss = 0.603556
I0526 11:47:14.526175 15746 solver.cpp:244]     Train net output #0: loss = 0.603555 (* 1 = 0.603555 loss)
I0526 11:47:14.526201 15746 sgd_solver.cpp:106] Iteration 17400, lr = 0.0001
I0526 11:55:20.269074 15746 solver.cpp:228] Iteration 17500, loss = 0.432006
I0526 11:55:20.269736 15746 solver.cpp:244]     Train net output #0: loss = 0.432004 (* 1 = 0.432004 loss)
I0526 11:55:20.269760 15746 sgd_solver.cpp:106] Iteration 17500, lr = 0.0001
I0526 12:03:34.466645 15746 solver.cpp:228] Iteration 17600, loss = 0.80234
I0526 12:03:34.467373 15746 solver.cpp:244]     Train net output #0: loss = 0.802338 (* 1 = 0.802338 loss)
I0526 12:03:34.467397 15746 sgd_solver.cpp:106] Iteration 17600, lr = 0.0001
I0526 12:11:41.033664 15746 solver.cpp:228] Iteration 17700, loss = 0.455794
I0526 12:11:41.034369 15746 solver.cpp:244]     Train net output #0: loss = 0.455793 (* 1 = 0.455793 loss)
I0526 12:11:41.034412 15746 sgd_solver.cpp:106] Iteration 17700, lr = 0.0001
I0526 12:20:01.446751 15746 solver.cpp:228] Iteration 17800, loss = 1.06232
I0526 12:20:01.447604 15746 solver.cpp:244]     Train net output #0: loss = 1.06232 (* 1 = 1.06232 loss)
I0526 12:20:01.447633 15746 sgd_solver.cpp:106] Iteration 17800, lr = 0.0001
I0526 12:28:24.174289 15746 solver.cpp:228] Iteration 17900, loss = 0.652487
I0526 12:28:24.174765 15746 solver.cpp:244]     Train net output #0: loss = 0.652486 (* 1 = 0.652486 loss)
I0526 12:28:24.174798 15746 sgd_solver.cpp:106] Iteration 17900, lr = 0.0001
I0526 12:36:42.242456 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_18000.caffemodel
I0526 12:36:42.429682 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_18000.solverstate
I0526 12:36:47.374644 15746 solver.cpp:228] Iteration 18000, loss = 0.879402
I0526 12:36:47.374697 15746 solver.cpp:244]     Train net output #0: loss = 0.879401 (* 1 = 0.879401 loss)
I0526 12:36:47.374707 15746 sgd_solver.cpp:106] Iteration 18000, lr = 0.0001
I0526 12:44:58.288882 15746 solver.cpp:228] Iteration 18100, loss = 0.669581
I0526 12:44:58.289610 15746 solver.cpp:244]     Train net output #0: loss = 0.669579 (* 1 = 0.669579 loss)
I0526 12:44:58.289625 15746 sgd_solver.cpp:106] Iteration 18100, lr = 0.0001
I0526 12:53:19.901954 15746 solver.cpp:228] Iteration 18200, loss = 0.768347
I0526 12:53:19.902724 15746 solver.cpp:244]     Train net output #0: loss = 0.768346 (* 1 = 0.768346 loss)
I0526 12:53:19.902743 15746 sgd_solver.cpp:106] Iteration 18200, lr = 0.0001
I0526 13:01:31.991204 15746 solver.cpp:228] Iteration 18300, loss = 0.927615
I0526 13:01:31.991839 15746 solver.cpp:244]     Train net output #0: loss = 0.927614 (* 1 = 0.927614 loss)
I0526 13:01:31.991878 15746 sgd_solver.cpp:106] Iteration 18300, lr = 0.0001
I0526 13:09:37.649672 15746 solver.cpp:228] Iteration 18400, loss = 0.403639
I0526 13:09:37.650441 15746 solver.cpp:244]     Train net output #0: loss = 0.403637 (* 1 = 0.403637 loss)
I0526 13:09:37.650465 15746 sgd_solver.cpp:106] Iteration 18400, lr = 0.0001
I0526 13:18:00.626801 15746 solver.cpp:228] Iteration 18500, loss = 0.711489
I0526 13:18:00.627465 15746 solver.cpp:244]     Train net output #0: loss = 0.711488 (* 1 = 0.711488 loss)
I0526 13:18:00.627485 15746 sgd_solver.cpp:106] Iteration 18500, lr = 0.0001
I0526 13:25:58.596266 15746 solver.cpp:228] Iteration 18600, loss = 0.562539
I0526 13:25:58.596982 15746 solver.cpp:244]     Train net output #0: loss = 0.562538 (* 1 = 0.562538 loss)
I0526 13:25:58.597005 15746 sgd_solver.cpp:106] Iteration 18600, lr = 0.0001
I0526 13:34:08.715199 15746 solver.cpp:228] Iteration 18700, loss = 1.28553
I0526 13:34:08.715895 15746 solver.cpp:244]     Train net output #0: loss = 1.28552 (* 1 = 1.28552 loss)
I0526 13:34:08.715910 15746 sgd_solver.cpp:106] Iteration 18700, lr = 0.0001
I0526 13:41:59.051673 15746 solver.cpp:228] Iteration 18800, loss = 0.46116
I0526 13:41:59.052537 15746 solver.cpp:244]     Train net output #0: loss = 0.461159 (* 1 = 0.461159 loss)
I0526 13:41:59.052559 15746 sgd_solver.cpp:106] Iteration 18800, lr = 0.0001
I0526 13:49:48.834978 15746 solver.cpp:228] Iteration 18900, loss = 0.570517
I0526 13:49:48.835691 15746 solver.cpp:244]     Train net output #0: loss = 0.570515 (* 1 = 0.570515 loss)
I0526 13:49:48.835717 15746 sgd_solver.cpp:106] Iteration 18900, lr = 0.0001
I0526 13:57:37.376197 15746 solver.cpp:228] Iteration 19000, loss = 0.442564
I0526 13:57:37.377037 15746 solver.cpp:244]     Train net output #0: loss = 0.442563 (* 1 = 0.442563 loss)
I0526 13:57:37.377066 15746 sgd_solver.cpp:106] Iteration 19000, lr = 0.0001
I0526 14:05:25.975306 15746 solver.cpp:228] Iteration 19100, loss = 0.945725
I0526 14:05:25.976106 15746 solver.cpp:244]     Train net output #0: loss = 0.945724 (* 1 = 0.945724 loss)
I0526 14:05:25.976127 15746 sgd_solver.cpp:106] Iteration 19100, lr = 0.0001
I0526 14:13:20.841012 15746 solver.cpp:228] Iteration 19200, loss = 0.497505
I0526 14:13:20.841775 15746 solver.cpp:244]     Train net output #0: loss = 0.497504 (* 1 = 0.497504 loss)
I0526 14:13:20.841796 15746 sgd_solver.cpp:106] Iteration 19200, lr = 0.0001
I0526 14:21:16.017117 15746 solver.cpp:228] Iteration 19300, loss = 0.898463
I0526 14:21:16.019778 15746 solver.cpp:244]     Train net output #0: loss = 0.898462 (* 1 = 0.898462 loss)
I0526 14:21:16.019805 15746 sgd_solver.cpp:106] Iteration 19300, lr = 0.0001
I0526 14:29:13.915771 15746 solver.cpp:228] Iteration 19400, loss = 0.679304
I0526 14:29:13.916512 15746 solver.cpp:244]     Train net output #0: loss = 0.679302 (* 1 = 0.679302 loss)
I0526 14:29:13.916532 15746 sgd_solver.cpp:106] Iteration 19400, lr = 0.0001
I0526 14:36:55.371219 15746 solver.cpp:228] Iteration 19500, loss = 0.945057
I0526 14:36:55.371894 15746 solver.cpp:244]     Train net output #0: loss = 0.945055 (* 1 = 0.945055 loss)
I0526 14:36:55.371918 15746 sgd_solver.cpp:106] Iteration 19500, lr = 0.0001
I0526 14:44:18.175592 15746 solver.cpp:337] Iteration 19590, Testing net (#0)
I0526 14:44:18.176312 15746 net.cpp:685] Ignoring source layer ratemap
I0526 14:44:18.176337 15746 net.cpp:685] Ignoring source layer amsFeatures
I0526 14:47:08.153244 15746 solver.cpp:404]     Test net output #0: loss = 0.573558 (* 1 = 0.573558 loss)
I0526 14:48:00.686770 15746 solver.cpp:228] Iteration 19600, loss = 0.587026
I0526 14:48:00.687237 15746 solver.cpp:244]     Train net output #0: loss = 0.587024 (* 1 = 0.587024 loss)
I0526 14:48:00.687258 15746 sgd_solver.cpp:106] Iteration 19600, lr = 0.0001
I0526 14:55:55.220180 15746 solver.cpp:228] Iteration 19700, loss = 0.676066
I0526 14:55:55.220940 15746 solver.cpp:244]     Train net output #0: loss = 0.676065 (* 1 = 0.676065 loss)
I0526 14:55:55.220973 15746 sgd_solver.cpp:106] Iteration 19700, lr = 0.0001
I0526 15:03:53.406349 15746 solver.cpp:228] Iteration 19800, loss = 0.558386
I0526 15:03:53.407017 15746 solver.cpp:244]     Train net output #0: loss = 0.558384 (* 1 = 0.558384 loss)
I0526 15:03:53.407038 15746 sgd_solver.cpp:106] Iteration 19800, lr = 0.0001
I0526 15:11:48.112856 15746 solver.cpp:228] Iteration 19900, loss = 0.455518
I0526 15:11:48.113483 15746 solver.cpp:244]     Train net output #0: loss = 0.455517 (* 1 = 0.455517 loss)
I0526 15:11:48.113513 15746 sgd_solver.cpp:106] Iteration 19900, lr = 0.0001
I0526 15:19:36.096135 15746 solver.cpp:228] Iteration 20000, loss = 0.565503
I0526 15:19:36.096683 15746 solver.cpp:244]     Train net output #0: loss = 0.565501 (* 1 = 0.565501 loss)
I0526 15:19:36.096704 15746 sgd_solver.cpp:106] Iteration 20000, lr = 0.0001
I0526 15:27:40.500776 15746 solver.cpp:228] Iteration 20100, loss = 0.331726
I0526 15:27:40.501260 15746 solver.cpp:244]     Train net output #0: loss = 0.331725 (* 1 = 0.331725 loss)
I0526 15:27:40.501281 15746 sgd_solver.cpp:106] Iteration 20100, lr = 0.0001
I0526 15:35:44.306529 15746 solver.cpp:228] Iteration 20200, loss = 0.842007
I0526 15:35:44.307384 15746 solver.cpp:244]     Train net output #0: loss = 0.842006 (* 1 = 0.842006 loss)
I0526 15:35:44.307404 15746 sgd_solver.cpp:106] Iteration 20200, lr = 0.0001
I0526 15:43:21.842998 15746 solver.cpp:228] Iteration 20300, loss = 0.820257
I0526 15:43:21.843482 15746 solver.cpp:244]     Train net output #0: loss = 0.820256 (* 1 = 0.820256 loss)
I0526 15:43:21.843502 15746 sgd_solver.cpp:106] Iteration 20300, lr = 0.0001
I0526 15:51:28.676002 15746 solver.cpp:228] Iteration 20400, loss = 0.966192
I0526 15:51:28.676487 15746 solver.cpp:244]     Train net output #0: loss = 0.966191 (* 1 = 0.966191 loss)
I0526 15:51:28.676507 15746 sgd_solver.cpp:106] Iteration 20400, lr = 0.0001
I0526 15:59:23.984145 15746 solver.cpp:228] Iteration 20500, loss = 0.926738
I0526 15:59:23.984920 15746 solver.cpp:244]     Train net output #0: loss = 0.926737 (* 1 = 0.926737 loss)
I0526 15:59:23.984940 15746 sgd_solver.cpp:106] Iteration 20500, lr = 0.0001
I0526 16:07:06.208298 15746 solver.cpp:228] Iteration 20600, loss = 0.730929
I0526 16:07:06.208981 15746 solver.cpp:244]     Train net output #0: loss = 0.730928 (* 1 = 0.730928 loss)
I0526 16:07:06.209005 15746 sgd_solver.cpp:106] Iteration 20600, lr = 0.0001
I0526 16:14:58.001312 15746 solver.cpp:228] Iteration 20700, loss = 0.758563
I0526 16:14:58.001952 15746 solver.cpp:244]     Train net output #0: loss = 0.758562 (* 1 = 0.758562 loss)
I0526 16:14:58.001974 15746 sgd_solver.cpp:106] Iteration 20700, lr = 0.0001
I0526 16:22:54.252190 15746 solver.cpp:228] Iteration 20800, loss = 0.920109
I0526 16:22:54.252666 15746 solver.cpp:244]     Train net output #0: loss = 0.920108 (* 1 = 0.920108 loss)
I0526 16:22:54.252687 15746 sgd_solver.cpp:106] Iteration 20800, lr = 0.0001
I0526 16:30:52.136435 15746 solver.cpp:228] Iteration 20900, loss = 0.595237
I0526 16:30:52.136910 15746 solver.cpp:244]     Train net output #0: loss = 0.595236 (* 1 = 0.595236 loss)
I0526 16:30:52.136935 15746 sgd_solver.cpp:106] Iteration 20900, lr = 0.0001
I0526 16:38:41.854796 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_21000.caffemodel
I0526 16:38:42.042559 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_21000.solverstate
I0526 16:38:46.766175 15746 solver.cpp:228] Iteration 21000, loss = 0.595263
I0526 16:38:46.766227 15746 solver.cpp:244]     Train net output #0: loss = 0.595262 (* 1 = 0.595262 loss)
I0526 16:38:46.766237 15746 sgd_solver.cpp:106] Iteration 21000, lr = 0.0001
I0526 16:46:37.986475 15746 solver.cpp:228] Iteration 21100, loss = 0.755436
I0526 16:46:37.987292 15746 solver.cpp:244]     Train net output #0: loss = 0.755435 (* 1 = 0.755435 loss)
I0526 16:46:37.987313 15746 sgd_solver.cpp:106] Iteration 21100, lr = 0.0001
I0526 16:54:37.345263 15746 solver.cpp:228] Iteration 21200, loss = 0.619258
I0526 16:54:37.346068 15746 solver.cpp:244]     Train net output #0: loss = 0.619256 (* 1 = 0.619256 loss)
I0526 16:54:37.346091 15746 sgd_solver.cpp:106] Iteration 21200, lr = 0.0001
I0526 17:02:42.279120 15746 solver.cpp:228] Iteration 21300, loss = 0.882199
I0526 17:02:42.279606 15746 solver.cpp:244]     Train net output #0: loss = 0.882198 (* 1 = 0.882198 loss)
I0526 17:02:42.279634 15746 sgd_solver.cpp:106] Iteration 21300, lr = 0.0001
I0526 17:10:29.554635 15746 solver.cpp:228] Iteration 21400, loss = 0.712241
I0526 17:10:29.555301 15746 solver.cpp:244]     Train net output #0: loss = 0.712239 (* 1 = 0.712239 loss)
I0526 17:10:29.555315 15746 sgd_solver.cpp:106] Iteration 21400, lr = 0.0001
I0526 17:18:22.478585 15746 solver.cpp:228] Iteration 21500, loss = 0.969873
I0526 17:18:22.479377 15746 solver.cpp:244]     Train net output #0: loss = 0.969872 (* 1 = 0.969872 loss)
I0526 17:18:22.479396 15746 sgd_solver.cpp:106] Iteration 21500, lr = 0.0001
I0526 17:26:13.275571 15746 solver.cpp:228] Iteration 21600, loss = 0.869532
I0526 17:26:13.276226 15746 solver.cpp:244]     Train net output #0: loss = 0.869531 (* 1 = 0.869531 loss)
I0526 17:26:13.276249 15746 sgd_solver.cpp:106] Iteration 21600, lr = 0.0001
I0526 17:34:17.099105 15746 solver.cpp:228] Iteration 21700, loss = 0.643598
I0526 17:34:17.099773 15746 solver.cpp:244]     Train net output #0: loss = 0.643597 (* 1 = 0.643597 loss)
I0526 17:34:17.099794 15746 sgd_solver.cpp:106] Iteration 21700, lr = 0.0001
I0526 17:41:59.513520 15746 solver.cpp:228] Iteration 21800, loss = 0.786021
I0526 17:41:59.514191 15746 solver.cpp:244]     Train net output #0: loss = 0.78602 (* 1 = 0.78602 loss)
I0526 17:41:59.514225 15746 sgd_solver.cpp:106] Iteration 21800, lr = 0.0001
I0526 17:50:02.330668 15746 solver.cpp:228] Iteration 21900, loss = 0.672978
I0526 17:50:02.331156 15746 solver.cpp:244]     Train net output #0: loss = 0.672977 (* 1 = 0.672977 loss)
I0526 17:50:02.331202 15746 sgd_solver.cpp:106] Iteration 21900, lr = 0.0001
I0526 17:58:04.998462 15746 solver.cpp:228] Iteration 22000, loss = 0.703701
I0526 17:58:04.998996 15746 solver.cpp:244]     Train net output #0: loss = 0.7037 (* 1 = 0.7037 loss)
I0526 17:58:04.999017 15746 sgd_solver.cpp:106] Iteration 22000, lr = 0.0001
I0526 18:06:03.745465 15746 solver.cpp:228] Iteration 22100, loss = 0.662163
I0526 18:06:03.746245 15746 solver.cpp:244]     Train net output #0: loss = 0.662162 (* 1 = 0.662162 loss)
I0526 18:06:03.746274 15746 sgd_solver.cpp:106] Iteration 22100, lr = 0.0001
I0526 18:14:04.649147 15746 solver.cpp:228] Iteration 22200, loss = 0.517632
I0526 18:14:04.649989 15746 solver.cpp:244]     Train net output #0: loss = 0.517631 (* 1 = 0.517631 loss)
I0526 18:14:04.650020 15746 sgd_solver.cpp:106] Iteration 22200, lr = 0.0001
I0526 18:22:08.726955 15746 solver.cpp:228] Iteration 22300, loss = 0.826477
I0526 18:22:08.727656 15746 solver.cpp:244]     Train net output #0: loss = 0.826476 (* 1 = 0.826476 loss)
I0526 18:22:08.727676 15746 sgd_solver.cpp:106] Iteration 22300, lr = 0.0001
I0526 18:30:03.975136 15746 solver.cpp:228] Iteration 22400, loss = 0.491999
I0526 18:30:03.975793 15746 solver.cpp:244]     Train net output #0: loss = 0.491998 (* 1 = 0.491998 loss)
I0526 18:30:03.975817 15746 sgd_solver.cpp:106] Iteration 22400, lr = 0.0001
I0526 18:38:02.022009 15746 solver.cpp:228] Iteration 22500, loss = 0.826529
I0526 18:38:02.022706 15746 solver.cpp:244]     Train net output #0: loss = 0.826528 (* 1 = 0.826528 loss)
I0526 18:38:02.022743 15746 sgd_solver.cpp:106] Iteration 22500, lr = 0.0001
I0526 18:46:01.212077 15746 solver.cpp:228] Iteration 22600, loss = 0.867168
I0526 18:46:01.212728 15746 solver.cpp:244]     Train net output #0: loss = 0.867166 (* 1 = 0.867166 loss)
I0526 18:46:01.212756 15746 sgd_solver.cpp:106] Iteration 22600, lr = 0.0001
I0526 18:54:04.288146 15746 solver.cpp:228] Iteration 22700, loss = 0.495831
I0526 18:54:04.288827 15746 solver.cpp:244]     Train net output #0: loss = 0.495829 (* 1 = 0.495829 loss)
I0526 18:54:04.288859 15746 sgd_solver.cpp:106] Iteration 22700, lr = 0.0001
I0526 19:01:59.718669 15746 solver.cpp:228] Iteration 22800, loss = 0.540268
I0526 19:01:59.719388 15746 solver.cpp:244]     Train net output #0: loss = 0.540266 (* 1 = 0.540266 loss)
I0526 19:01:59.719409 15746 sgd_solver.cpp:106] Iteration 22800, lr = 0.0001
I0526 19:06:18.418864 15746 solver.cpp:337] Iteration 22855, Testing net (#0)
I0526 19:06:18.419302 15746 net.cpp:685] Ignoring source layer ratemap
I0526 19:06:18.419327 15746 net.cpp:685] Ignoring source layer amsFeatures
I0526 19:09:09.938696 15746 solver.cpp:404]     Test net output #0: loss = 0.558787 (* 1 = 0.558787 loss)
I0526 19:12:45.229797 15746 solver.cpp:228] Iteration 22900, loss = 0.635965
I0526 19:12:45.230090 15746 solver.cpp:244]     Train net output #0: loss = 0.635964 (* 1 = 0.635964 loss)
I0526 19:12:45.230101 15746 sgd_solver.cpp:106] Iteration 22900, lr = 0.0001
I0526 19:20:36.155302 15746 solver.cpp:228] Iteration 23000, loss = 0.687684
I0526 19:20:36.156149 15746 solver.cpp:244]     Train net output #0: loss = 0.687683 (* 1 = 0.687683 loss)
I0526 19:20:36.156184 15746 sgd_solver.cpp:106] Iteration 23000, lr = 0.0001
I0526 19:28:32.479632 15746 solver.cpp:228] Iteration 23100, loss = 0.861108
I0526 19:28:32.480388 15746 solver.cpp:244]     Train net output #0: loss = 0.861107 (* 1 = 0.861107 loss)
I0526 19:28:32.480409 15746 sgd_solver.cpp:106] Iteration 23100, lr = 0.0001
I0526 19:36:29.089943 15746 solver.cpp:228] Iteration 23200, loss = 0.295927
I0526 19:36:29.090710 15746 solver.cpp:244]     Train net output #0: loss = 0.295926 (* 1 = 0.295926 loss)
I0526 19:36:29.090730 15746 sgd_solver.cpp:106] Iteration 23200, lr = 0.0001
I0526 19:44:38.603852 15746 solver.cpp:228] Iteration 23300, loss = 0.4053
I0526 19:44:38.604537 15746 solver.cpp:244]     Train net output #0: loss = 0.405299 (* 1 = 0.405299 loss)
I0526 19:44:38.604562 15746 sgd_solver.cpp:106] Iteration 23300, lr = 0.0001
I0526 19:52:25.219342 15746 solver.cpp:228] Iteration 23400, loss = 0.86125
I0526 19:52:25.220093 15746 solver.cpp:244]     Train net output #0: loss = 0.861248 (* 1 = 0.861248 loss)
I0526 19:52:25.220118 15746 sgd_solver.cpp:106] Iteration 23400, lr = 0.0001
I0526 20:00:35.018746 15746 solver.cpp:228] Iteration 23500, loss = 0.868604
I0526 20:00:35.019449 15746 solver.cpp:244]     Train net output #0: loss = 0.868603 (* 1 = 0.868603 loss)
I0526 20:00:35.019474 15746 sgd_solver.cpp:106] Iteration 23500, lr = 0.0001
I0526 20:08:21.953411 15746 solver.cpp:228] Iteration 23600, loss = 0.736671
I0526 20:08:21.954198 15746 solver.cpp:244]     Train net output #0: loss = 0.73667 (* 1 = 0.73667 loss)
I0526 20:08:21.954226 15746 sgd_solver.cpp:106] Iteration 23600, lr = 0.0001
I0526 20:16:22.198108 15746 solver.cpp:228] Iteration 23700, loss = 1.16646
I0526 20:16:22.198874 15746 solver.cpp:244]     Train net output #0: loss = 1.16646 (* 1 = 1.16646 loss)
I0526 20:16:22.198915 15746 sgd_solver.cpp:106] Iteration 23700, lr = 0.0001
I0526 20:24:16.631786 15746 solver.cpp:228] Iteration 23800, loss = 0.522642
I0526 20:24:16.632619 15746 solver.cpp:244]     Train net output #0: loss = 0.522641 (* 1 = 0.522641 loss)
I0526 20:24:16.632640 15746 sgd_solver.cpp:106] Iteration 23800, lr = 0.0001
I0526 20:32:10.221529 15746 solver.cpp:228] Iteration 23900, loss = 0.769055
I0526 20:32:10.222345 15746 solver.cpp:244]     Train net output #0: loss = 0.769054 (* 1 = 0.769054 loss)
I0526 20:32:10.222398 15746 sgd_solver.cpp:106] Iteration 23900, lr = 0.0001
I0526 20:39:58.206518 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_24000.caffemodel
I0526 20:39:58.381556 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_24000.solverstate
I0526 20:40:00.911993 15746 solver.cpp:228] Iteration 24000, loss = 0.39264
I0526 20:40:00.912045 15746 solver.cpp:244]     Train net output #0: loss = 0.392639 (* 1 = 0.392639 loss)
I0526 20:40:00.912055 15746 sgd_solver.cpp:106] Iteration 24000, lr = 0.0001
I0526 20:48:07.735201 15746 solver.cpp:228] Iteration 24100, loss = 0.453084
I0526 20:48:07.735913 15746 solver.cpp:244]     Train net output #0: loss = 0.453083 (* 1 = 0.453083 loss)
I0526 20:48:07.735934 15746 sgd_solver.cpp:106] Iteration 24100, lr = 0.0001
I0526 20:56:03.384441 15746 solver.cpp:228] Iteration 24200, loss = 0.354735
I0526 20:56:03.385258 15746 solver.cpp:244]     Train net output #0: loss = 0.354733 (* 1 = 0.354733 loss)
I0526 20:56:03.385279 15746 sgd_solver.cpp:106] Iteration 24200, lr = 0.0001
I0526 21:04:01.348754 15746 solver.cpp:228] Iteration 24300, loss = 0.62235
I0526 21:04:01.349362 15746 solver.cpp:244]     Train net output #0: loss = 0.622348 (* 1 = 0.622348 loss)
I0526 21:04:01.349387 15746 sgd_solver.cpp:106] Iteration 24300, lr = 0.0001
I0526 21:11:57.356695 15746 solver.cpp:228] Iteration 24400, loss = 0.74924
I0526 21:11:57.357398 15746 solver.cpp:244]     Train net output #0: loss = 0.749239 (* 1 = 0.749239 loss)
I0526 21:11:57.357422 15746 sgd_solver.cpp:106] Iteration 24400, lr = 0.0001
I0526 21:20:08.196921 15746 solver.cpp:228] Iteration 24500, loss = 0.589939
I0526 21:20:08.197664 15746 solver.cpp:244]     Train net output #0: loss = 0.589937 (* 1 = 0.589937 loss)
I0526 21:20:08.197703 15746 sgd_solver.cpp:106] Iteration 24500, lr = 0.0001
I0526 21:28:09.872737 15746 solver.cpp:228] Iteration 24600, loss = 0.729662
I0526 21:28:09.873436 15746 solver.cpp:244]     Train net output #0: loss = 0.72966 (* 1 = 0.72966 loss)
I0526 21:28:09.873461 15746 sgd_solver.cpp:106] Iteration 24600, lr = 0.0001
I0526 21:36:38.414932 15746 solver.cpp:228] Iteration 24700, loss = 0.629806
I0526 21:36:38.415701 15746 solver.cpp:244]     Train net output #0: loss = 0.629804 (* 1 = 0.629804 loss)
I0526 21:36:38.415726 15746 sgd_solver.cpp:106] Iteration 24700, lr = 0.0001
I0526 21:44:52.898154 15746 solver.cpp:228] Iteration 24800, loss = 0.468456
I0526 21:44:52.898921 15746 solver.cpp:244]     Train net output #0: loss = 0.468454 (* 1 = 0.468454 loss)
I0526 21:44:52.898950 15746 sgd_solver.cpp:106] Iteration 24800, lr = 0.0001
I0526 21:53:09.448285 15746 solver.cpp:228] Iteration 24900, loss = 0.671251
I0526 21:53:09.449025 15746 solver.cpp:244]     Train net output #0: loss = 0.671249 (* 1 = 0.671249 loss)
I0526 21:53:09.449045 15746 sgd_solver.cpp:106] Iteration 24900, lr = 0.0001
I0526 22:01:34.429569 15746 solver.cpp:228] Iteration 25000, loss = 0.540006
I0526 22:01:34.430307 15746 solver.cpp:244]     Train net output #0: loss = 0.540005 (* 1 = 0.540005 loss)
I0526 22:01:34.430322 15746 sgd_solver.cpp:106] Iteration 25000, lr = 0.0001
I0526 22:09:54.449722 15746 solver.cpp:228] Iteration 25100, loss = 0.553256
I0526 22:09:54.450438 15746 solver.cpp:244]     Train net output #0: loss = 0.553254 (* 1 = 0.553254 loss)
I0526 22:09:54.450460 15746 sgd_solver.cpp:106] Iteration 25100, lr = 0.0001
I0526 22:18:33.814193 15746 solver.cpp:228] Iteration 25200, loss = 1.1232
I0526 22:18:33.814983 15746 solver.cpp:244]     Train net output #0: loss = 1.1232 (* 1 = 1.1232 loss)
I0526 22:18:33.815012 15746 sgd_solver.cpp:106] Iteration 25200, lr = 0.0001
I0526 22:26:54.469460 15746 solver.cpp:228] Iteration 25300, loss = 0.680243
I0526 22:26:54.470296 15746 solver.cpp:244]     Train net output #0: loss = 0.680242 (* 1 = 0.680242 loss)
I0526 22:26:54.470317 15746 sgd_solver.cpp:106] Iteration 25300, lr = 0.0001
I0526 22:35:04.728588 15746 solver.cpp:228] Iteration 25400, loss = 0.727925
I0526 22:35:04.729439 15746 solver.cpp:244]     Train net output #0: loss = 0.727923 (* 1 = 0.727923 loss)
I0526 22:35:04.729460 15746 sgd_solver.cpp:106] Iteration 25400, lr = 0.0001
I0526 22:43:39.217746 15746 solver.cpp:228] Iteration 25500, loss = 0.643259
I0526 22:43:39.218380 15746 solver.cpp:244]     Train net output #0: loss = 0.643257 (* 1 = 0.643257 loss)
I0526 22:43:39.218412 15746 sgd_solver.cpp:106] Iteration 25500, lr = 0.0001
I0526 22:52:04.570058 15746 solver.cpp:228] Iteration 25600, loss = 1.09504
I0526 22:52:04.570847 15746 solver.cpp:244]     Train net output #0: loss = 1.09504 (* 1 = 1.09504 loss)
I0526 22:52:04.570881 15746 sgd_solver.cpp:106] Iteration 25600, lr = 0.0001
I0526 23:00:03.209663 15746 solver.cpp:228] Iteration 25700, loss = 0.944131
I0526 23:00:03.210429 15746 solver.cpp:244]     Train net output #0: loss = 0.944129 (* 1 = 0.944129 loss)
I0526 23:00:03.210458 15746 sgd_solver.cpp:106] Iteration 25700, lr = 0.0001
I0526 23:08:04.426432 15746 solver.cpp:228] Iteration 25800, loss = 0.488674
I0526 23:08:04.427201 15746 solver.cpp:244]     Train net output #0: loss = 0.488672 (* 1 = 0.488672 loss)
I0526 23:08:04.427233 15746 sgd_solver.cpp:106] Iteration 25800, lr = 0.0001
I0526 23:16:16.537518 15746 solver.cpp:228] Iteration 25900, loss = 0.608406
I0526 23:16:16.538204 15746 solver.cpp:244]     Train net output #0: loss = 0.608404 (* 1 = 0.608404 loss)
I0526 23:16:16.538225 15746 sgd_solver.cpp:106] Iteration 25900, lr = 0.0001
I0526 23:24:41.968873 15746 solver.cpp:228] Iteration 26000, loss = 0.355149
I0526 23:24:41.969625 15746 solver.cpp:244]     Train net output #0: loss = 0.355148 (* 1 = 0.355148 loss)
I0526 23:24:41.969655 15746 sgd_solver.cpp:106] Iteration 26000, lr = 0.0001
I0526 23:33:00.293181 15746 solver.cpp:228] Iteration 26100, loss = 1.06077
I0526 23:33:00.293962 15746 solver.cpp:244]     Train net output #0: loss = 1.06077 (* 1 = 1.06077 loss)
I0526 23:33:00.293985 15746 sgd_solver.cpp:106] Iteration 26100, lr = 0.0001
I0526 23:34:41.118377 15746 solver.cpp:337] Iteration 26120, Testing net (#0)
I0526 23:34:41.118804 15746 net.cpp:685] Ignoring source layer ratemap
I0526 23:34:41.118820 15746 net.cpp:685] Ignoring source layer amsFeatures
I0526 23:37:30.990953 15746 solver.cpp:404]     Test net output #0: loss = 0.550458 (* 1 = 0.550458 loss)
I0526 23:43:52.893908 15746 solver.cpp:228] Iteration 26200, loss = 0.685818
I0526 23:43:52.894646 15746 solver.cpp:244]     Train net output #0: loss = 0.685816 (* 1 = 0.685816 loss)
I0526 23:43:52.894677 15746 sgd_solver.cpp:106] Iteration 26200, lr = 0.0001
I0526 23:52:16.899006 15746 solver.cpp:228] Iteration 26300, loss = 0.637472
I0526 23:52:16.899610 15746 solver.cpp:244]     Train net output #0: loss = 0.63747 (* 1 = 0.63747 loss)
I0526 23:52:16.899631 15746 sgd_solver.cpp:106] Iteration 26300, lr = 0.0001
I0527 00:00:47.036897 15746 solver.cpp:228] Iteration 26400, loss = 0.611635
I0527 00:00:47.037653 15746 solver.cpp:244]     Train net output #0: loss = 0.611633 (* 1 = 0.611633 loss)
I0527 00:00:47.037677 15746 sgd_solver.cpp:106] Iteration 26400, lr = 0.0001
I0527 00:09:12.362471 15746 solver.cpp:228] Iteration 26500, loss = 0.524111
I0527 00:09:12.363181 15746 solver.cpp:244]     Train net output #0: loss = 0.524109 (* 1 = 0.524109 loss)
I0527 00:09:12.363206 15746 sgd_solver.cpp:106] Iteration 26500, lr = 0.0001
I0527 00:17:46.374619 15746 solver.cpp:228] Iteration 26600, loss = 0.521938
I0527 00:17:46.375438 15746 solver.cpp:244]     Train net output #0: loss = 0.521936 (* 1 = 0.521936 loss)
I0527 00:17:46.375469 15746 sgd_solver.cpp:106] Iteration 26600, lr = 0.0001
I0527 00:26:14.188015 15746 solver.cpp:228] Iteration 26700, loss = 0.591945
I0527 00:26:14.188719 15746 solver.cpp:244]     Train net output #0: loss = 0.591944 (* 1 = 0.591944 loss)
I0527 00:26:14.188740 15746 sgd_solver.cpp:106] Iteration 26700, lr = 0.0001
I0527 00:34:34.405182 15746 solver.cpp:228] Iteration 26800, loss = 0.674778
I0527 00:34:34.405959 15746 solver.cpp:244]     Train net output #0: loss = 0.674776 (* 1 = 0.674776 loss)
I0527 00:34:34.405995 15746 sgd_solver.cpp:106] Iteration 26800, lr = 0.0001
I0527 00:42:43.696126 15746 solver.cpp:228] Iteration 26900, loss = 0.83732
I0527 00:42:43.696844 15746 solver.cpp:244]     Train net output #0: loss = 0.837318 (* 1 = 0.837318 loss)
I0527 00:42:43.696872 15746 sgd_solver.cpp:106] Iteration 26900, lr = 0.0001
I0527 00:51:02.576294 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_27000.caffemodel
I0527 00:51:02.756554 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_27000.solverstate
I0527 00:51:07.205946 15746 solver.cpp:228] Iteration 27000, loss = 0.884638
I0527 00:51:07.206006 15746 solver.cpp:244]     Train net output #0: loss = 0.884636 (* 1 = 0.884636 loss)
I0527 00:51:07.206015 15746 sgd_solver.cpp:106] Iteration 27000, lr = 0.0001
I0527 00:59:27.929042 15746 solver.cpp:228] Iteration 27100, loss = 0.643553
I0527 00:59:27.929808 15746 solver.cpp:244]     Train net output #0: loss = 0.643551 (* 1 = 0.643551 loss)
I0527 00:59:27.929832 15746 sgd_solver.cpp:106] Iteration 27100, lr = 0.0001
I0527 01:07:37.532024 15746 solver.cpp:228] Iteration 27200, loss = 0.5265
I0527 01:07:37.532873 15746 solver.cpp:244]     Train net output #0: loss = 0.526498 (* 1 = 0.526498 loss)
I0527 01:07:37.532907 15746 sgd_solver.cpp:106] Iteration 27200, lr = 0.0001
I0527 01:15:53.341330 15746 solver.cpp:228] Iteration 27300, loss = 0.372537
I0527 01:15:53.341990 15746 solver.cpp:244]     Train net output #0: loss = 0.372535 (* 1 = 0.372535 loss)
I0527 01:15:53.342010 15746 sgd_solver.cpp:106] Iteration 27300, lr = 0.0001
I0527 01:24:18.209111 15746 solver.cpp:228] Iteration 27400, loss = 0.421336
I0527 01:24:18.209909 15746 solver.cpp:244]     Train net output #0: loss = 0.421334 (* 1 = 0.421334 loss)
I0527 01:24:18.209930 15746 sgd_solver.cpp:106] Iteration 27400, lr = 0.0001
I0527 01:32:31.191740 15746 solver.cpp:228] Iteration 27500, loss = 0.559852
I0527 01:32:31.192482 15746 solver.cpp:244]     Train net output #0: loss = 0.55985 (* 1 = 0.55985 loss)
I0527 01:32:31.192517 15746 sgd_solver.cpp:106] Iteration 27500, lr = 0.0001
I0527 01:40:49.998152 15746 solver.cpp:228] Iteration 27600, loss = 0.403545
I0527 01:40:49.998867 15746 solver.cpp:244]     Train net output #0: loss = 0.403543 (* 1 = 0.403543 loss)
I0527 01:40:49.998895 15746 sgd_solver.cpp:106] Iteration 27600, lr = 0.0001
I0527 01:49:17.260020 15746 solver.cpp:228] Iteration 27700, loss = 0.91297
I0527 01:49:17.260642 15746 solver.cpp:244]     Train net output #0: loss = 0.912968 (* 1 = 0.912968 loss)
I0527 01:49:17.260654 15746 sgd_solver.cpp:106] Iteration 27700, lr = 0.0001
I0527 01:57:32.574208 15746 solver.cpp:228] Iteration 27800, loss = 0.852132
I0527 01:57:32.574847 15746 solver.cpp:244]     Train net output #0: loss = 0.85213 (* 1 = 0.85213 loss)
I0527 01:57:32.574877 15746 sgd_solver.cpp:106] Iteration 27800, lr = 0.0001
I0527 02:05:48.816442 15746 solver.cpp:228] Iteration 27900, loss = 0.655841
I0527 02:05:48.817170 15746 solver.cpp:244]     Train net output #0: loss = 0.655839 (* 1 = 0.655839 loss)
I0527 02:05:48.817198 15746 sgd_solver.cpp:106] Iteration 27900, lr = 0.0001
I0527 02:13:57.169909 15746 solver.cpp:228] Iteration 28000, loss = 0.528379
I0527 02:13:57.170644 15746 solver.cpp:244]     Train net output #0: loss = 0.528377 (* 1 = 0.528377 loss)
I0527 02:13:57.170681 15746 sgd_solver.cpp:106] Iteration 28000, lr = 0.0001
I0527 02:22:24.508826 15746 solver.cpp:228] Iteration 28100, loss = 0.554708
I0527 02:22:24.509573 15746 solver.cpp:244]     Train net output #0: loss = 0.554706 (* 1 = 0.554706 loss)
I0527 02:22:24.509593 15746 sgd_solver.cpp:106] Iteration 28100, lr = 0.0001
I0527 02:30:44.915629 15746 solver.cpp:228] Iteration 28200, loss = 0.698213
I0527 02:30:44.916424 15746 solver.cpp:244]     Train net output #0: loss = 0.698211 (* 1 = 0.698211 loss)
I0527 02:30:44.916458 15746 sgd_solver.cpp:106] Iteration 28200, lr = 0.0001
I0527 02:39:05.809226 15746 solver.cpp:228] Iteration 28300, loss = 0.487299
I0527 02:39:05.809914 15746 solver.cpp:244]     Train net output #0: loss = 0.487297 (* 1 = 0.487297 loss)
I0527 02:39:05.809943 15746 sgd_solver.cpp:106] Iteration 28300, lr = 0.0001
I0527 02:47:17.969925 15746 solver.cpp:228] Iteration 28400, loss = 0.42939
I0527 02:47:17.970618 15746 solver.cpp:244]     Train net output #0: loss = 0.429388 (* 1 = 0.429388 loss)
I0527 02:47:17.970646 15746 sgd_solver.cpp:106] Iteration 28400, lr = 0.0001
I0527 02:55:46.969576 15746 solver.cpp:228] Iteration 28500, loss = 0.551235
I0527 02:55:46.970175 15746 solver.cpp:244]     Train net output #0: loss = 0.551233 (* 1 = 0.551233 loss)
I0527 02:55:46.970188 15746 sgd_solver.cpp:106] Iteration 28500, lr = 0.0001
I0527 03:04:29.722761 15746 solver.cpp:228] Iteration 28600, loss = 0.506226
I0527 03:04:29.723431 15746 solver.cpp:244]     Train net output #0: loss = 0.506223 (* 1 = 0.506223 loss)
I0527 03:04:29.723467 15746 sgd_solver.cpp:106] Iteration 28600, lr = 0.0001
I0527 03:12:42.322233 15746 solver.cpp:228] Iteration 28700, loss = 0.373588
I0527 03:12:42.322953 15746 solver.cpp:244]     Train net output #0: loss = 0.373586 (* 1 = 0.373586 loss)
I0527 03:12:42.322988 15746 sgd_solver.cpp:106] Iteration 28700, lr = 0.0001
I0527 03:20:43.873261 15746 solver.cpp:228] Iteration 28800, loss = 0.517976
I0527 03:20:43.873913 15746 solver.cpp:244]     Train net output #0: loss = 0.517974 (* 1 = 0.517974 loss)
I0527 03:20:43.873934 15746 sgd_solver.cpp:106] Iteration 28800, lr = 0.0001
I0527 03:29:09.691217 15746 solver.cpp:228] Iteration 28900, loss = 0.476383
I0527 03:29:09.691937 15746 solver.cpp:244]     Train net output #0: loss = 0.476381 (* 1 = 0.476381 loss)
I0527 03:29:09.691972 15746 sgd_solver.cpp:106] Iteration 28900, lr = 0.0001
I0527 03:37:15.309692 15746 solver.cpp:228] Iteration 29000, loss = 0.519267
I0527 03:37:15.310386 15746 solver.cpp:244]     Train net output #0: loss = 0.519265 (* 1 = 0.519265 loss)
I0527 03:37:15.310411 15746 sgd_solver.cpp:106] Iteration 29000, lr = 0.0001
I0527 03:45:26.579566 15746 solver.cpp:228] Iteration 29100, loss = 0.442332
I0527 03:45:26.580238 15746 solver.cpp:244]     Train net output #0: loss = 0.44233 (* 1 = 0.44233 loss)
I0527 03:45:26.580271 15746 sgd_solver.cpp:106] Iteration 29100, lr = 0.0001
I0527 03:53:44.460680 15746 solver.cpp:228] Iteration 29200, loss = 0.382239
I0527 03:53:44.461323 15746 solver.cpp:244]     Train net output #0: loss = 0.382237 (* 1 = 0.382237 loss)
I0527 03:53:44.461351 15746 sgd_solver.cpp:106] Iteration 29200, lr = 0.0001
I0527 04:01:43.146512 15746 solver.cpp:228] Iteration 29300, loss = 0.635029
I0527 04:01:43.147220 15746 solver.cpp:244]     Train net output #0: loss = 0.635028 (* 1 = 0.635028 loss)
I0527 04:01:43.147253 15746 sgd_solver.cpp:106] Iteration 29300, lr = 0.0001
I0527 04:08:32.417783 15746 solver.cpp:337] Iteration 29385, Testing net (#0)
I0527 04:08:32.418490 15746 net.cpp:685] Ignoring source layer ratemap
I0527 04:08:32.418509 15746 net.cpp:685] Ignoring source layer amsFeatures
I0527 04:11:22.388017 15746 solver.cpp:404]     Test net output #0: loss = 0.561536 (* 1 = 0.561536 loss)
I0527 04:12:37.850669 15746 solver.cpp:228] Iteration 29400, loss = 0.783644
I0527 04:12:37.851157 15746 solver.cpp:244]     Train net output #0: loss = 0.783642 (* 1 = 0.783642 loss)
I0527 04:12:37.851222 15746 sgd_solver.cpp:106] Iteration 29400, lr = 0.0001
I0527 04:20:33.064446 15746 solver.cpp:228] Iteration 29500, loss = 0.774745
I0527 04:20:33.065138 15746 solver.cpp:244]     Train net output #0: loss = 0.774744 (* 1 = 0.774744 loss)
I0527 04:20:33.065160 15746 sgd_solver.cpp:106] Iteration 29500, lr = 0.0001
I0527 04:28:26.330010 15746 solver.cpp:228] Iteration 29600, loss = 0.482241
I0527 04:28:26.330763 15746 solver.cpp:244]     Train net output #0: loss = 0.48224 (* 1 = 0.48224 loss)
I0527 04:28:26.330796 15746 sgd_solver.cpp:106] Iteration 29600, lr = 0.0001
I0527 04:36:27.083791 15746 solver.cpp:228] Iteration 29700, loss = 0.562701
I0527 04:36:27.084539 15746 solver.cpp:244]     Train net output #0: loss = 0.5627 (* 1 = 0.5627 loss)
I0527 04:36:27.084563 15746 sgd_solver.cpp:106] Iteration 29700, lr = 0.0001
I0527 04:44:19.392662 15746 solver.cpp:228] Iteration 29800, loss = 1.22131
I0527 04:44:19.393431 15746 solver.cpp:244]     Train net output #0: loss = 1.22131 (* 1 = 1.22131 loss)
I0527 04:44:19.393471 15746 sgd_solver.cpp:106] Iteration 29800, lr = 0.0001
I0527 04:52:13.417845 15746 solver.cpp:228] Iteration 29900, loss = 0.379245
I0527 04:52:13.418555 15746 solver.cpp:244]     Train net output #0: loss = 0.379243 (* 1 = 0.379243 loss)
I0527 04:52:13.418589 15746 sgd_solver.cpp:106] Iteration 29900, lr = 0.0001
I0527 05:00:01.233759 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_30000.caffemodel
I0527 05:00:01.422554 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_30000.solverstate
I0527 05:00:06.852768 15746 solver.cpp:228] Iteration 30000, loss = 0.56295
I0527 05:00:06.852847 15746 solver.cpp:244]     Train net output #0: loss = 0.562948 (* 1 = 0.562948 loss)
I0527 05:00:06.852857 15746 sgd_solver.cpp:106] Iteration 30000, lr = 1e-05
I0527 05:08:05.970927 15746 solver.cpp:228] Iteration 30100, loss = 0.627515
I0527 05:08:05.971681 15746 solver.cpp:244]     Train net output #0: loss = 0.627514 (* 1 = 0.627514 loss)
I0527 05:08:05.971701 15746 sgd_solver.cpp:106] Iteration 30100, lr = 1e-05
I0527 05:16:11.649958 15746 solver.cpp:228] Iteration 30200, loss = 0.492981
I0527 05:16:11.650733 15746 solver.cpp:244]     Train net output #0: loss = 0.492979 (* 1 = 0.492979 loss)
I0527 05:16:11.650756 15746 sgd_solver.cpp:106] Iteration 30200, lr = 1e-05
I0527 05:24:04.929273 15746 solver.cpp:228] Iteration 30300, loss = 0.760786
I0527 05:24:04.930008 15746 solver.cpp:244]     Train net output #0: loss = 0.760784 (* 1 = 0.760784 loss)
I0527 05:24:04.930032 15746 sgd_solver.cpp:106] Iteration 30300, lr = 1e-05
I0527 05:32:01.599305 15746 solver.cpp:228] Iteration 30400, loss = 0.407795
I0527 05:32:01.600069 15746 solver.cpp:244]     Train net output #0: loss = 0.407793 (* 1 = 0.407793 loss)
I0527 05:32:01.600088 15746 sgd_solver.cpp:106] Iteration 30400, lr = 1e-05
I0527 05:39:55.646224 15746 solver.cpp:228] Iteration 30500, loss = 0.443494
I0527 05:39:55.646975 15746 solver.cpp:244]     Train net output #0: loss = 0.443493 (* 1 = 0.443493 loss)
I0527 05:39:55.646996 15746 sgd_solver.cpp:106] Iteration 30500, lr = 1e-05
I0527 05:47:49.365345 15746 solver.cpp:228] Iteration 30600, loss = 0.707105
I0527 05:47:49.366135 15746 solver.cpp:244]     Train net output #0: loss = 0.707103 (* 1 = 0.707103 loss)
I0527 05:47:49.366158 15746 sgd_solver.cpp:106] Iteration 30600, lr = 1e-05
I0527 05:55:41.919997 15746 solver.cpp:228] Iteration 30700, loss = 0.499582
I0527 05:55:41.920661 15746 solver.cpp:244]     Train net output #0: loss = 0.49958 (* 1 = 0.49958 loss)
I0527 05:55:41.920682 15746 sgd_solver.cpp:106] Iteration 30700, lr = 1e-05
I0527 06:03:45.489768 15746 solver.cpp:228] Iteration 30800, loss = 0.535979
I0527 06:03:45.490420 15746 solver.cpp:244]     Train net output #0: loss = 0.535978 (* 1 = 0.535978 loss)
I0527 06:03:45.490442 15746 sgd_solver.cpp:106] Iteration 30800, lr = 1e-05
I0527 06:11:47.601454 15746 solver.cpp:228] Iteration 30900, loss = 0.408987
I0527 06:11:47.602058 15746 solver.cpp:244]     Train net output #0: loss = 0.408986 (* 1 = 0.408986 loss)
I0527 06:11:47.602071 15746 sgd_solver.cpp:106] Iteration 30900, lr = 1e-05
I0527 06:19:57.230445 15746 solver.cpp:228] Iteration 31000, loss = 0.443428
I0527 06:19:57.231204 15746 solver.cpp:244]     Train net output #0: loss = 0.443427 (* 1 = 0.443427 loss)
I0527 06:19:57.231238 15746 sgd_solver.cpp:106] Iteration 31000, lr = 1e-05
I0527 06:27:59.825987 15746 solver.cpp:228] Iteration 31100, loss = 0.483641
I0527 06:27:59.826684 15746 solver.cpp:244]     Train net output #0: loss = 0.48364 (* 1 = 0.48364 loss)
I0527 06:27:59.826711 15746 sgd_solver.cpp:106] Iteration 31100, lr = 1e-05
I0527 06:35:58.703246 15746 solver.cpp:228] Iteration 31200, loss = 0.510093
I0527 06:35:58.704046 15746 solver.cpp:244]     Train net output #0: loss = 0.510092 (* 1 = 0.510092 loss)
I0527 06:35:58.704073 15746 sgd_solver.cpp:106] Iteration 31200, lr = 1e-05
I0527 06:43:38.771795 15746 solver.cpp:228] Iteration 31300, loss = 0.336893
I0527 06:43:38.772441 15746 solver.cpp:244]     Train net output #0: loss = 0.336892 (* 1 = 0.336892 loss)
I0527 06:43:38.772462 15746 sgd_solver.cpp:106] Iteration 31300, lr = 1e-05
I0527 06:51:29.432469 15746 solver.cpp:228] Iteration 31400, loss = 0.401803
I0527 06:51:29.433182 15746 solver.cpp:244]     Train net output #0: loss = 0.401801 (* 1 = 0.401801 loss)
I0527 06:51:29.433203 15746 sgd_solver.cpp:106] Iteration 31400, lr = 1e-05
I0527 06:59:26.265662 15746 solver.cpp:228] Iteration 31500, loss = 0.604404
I0527 06:59:26.266453 15746 solver.cpp:244]     Train net output #0: loss = 0.604403 (* 1 = 0.604403 loss)
I0527 06:59:26.266485 15746 sgd_solver.cpp:106] Iteration 31500, lr = 1e-05
I0527 07:07:29.416733 15746 solver.cpp:228] Iteration 31600, loss = 0.511782
I0527 07:07:29.417457 15746 solver.cpp:244]     Train net output #0: loss = 0.511781 (* 1 = 0.511781 loss)
I0527 07:07:29.417477 15746 sgd_solver.cpp:106] Iteration 31600, lr = 1e-05
I0527 07:15:16.268467 15746 solver.cpp:228] Iteration 31700, loss = 0.452738
I0527 07:15:16.269103 15746 solver.cpp:244]     Train net output #0: loss = 0.452736 (* 1 = 0.452736 loss)
I0527 07:15:16.269124 15746 sgd_solver.cpp:106] Iteration 31700, lr = 1e-05
I0527 07:23:13.568053 15746 solver.cpp:228] Iteration 31800, loss = 0.41903
I0527 07:23:13.568871 15746 solver.cpp:244]     Train net output #0: loss = 0.419028 (* 1 = 0.419028 loss)
I0527 07:23:13.568892 15746 sgd_solver.cpp:106] Iteration 31800, lr = 1e-05
I0527 07:30:50.119881 15746 solver.cpp:228] Iteration 31900, loss = 0.419291
I0527 07:30:50.120668 15746 solver.cpp:244]     Train net output #0: loss = 0.41929 (* 1 = 0.41929 loss)
I0527 07:30:50.120702 15746 sgd_solver.cpp:106] Iteration 31900, lr = 1e-05
I0527 07:38:39.263738 15746 solver.cpp:228] Iteration 32000, loss = 0.847085
I0527 07:38:39.264562 15746 solver.cpp:244]     Train net output #0: loss = 0.847083 (* 1 = 0.847083 loss)
I0527 07:38:39.264583 15746 sgd_solver.cpp:106] Iteration 32000, lr = 1e-05
I0527 07:46:30.825067 15746 solver.cpp:228] Iteration 32100, loss = 0.85588
I0527 07:46:30.825559 15746 solver.cpp:244]     Train net output #0: loss = 0.855878 (* 1 = 0.855878 loss)
I0527 07:46:30.825587 15746 sgd_solver.cpp:106] Iteration 32100, lr = 1e-05
I0527 07:54:19.960253 15746 solver.cpp:228] Iteration 32200, loss = 0.307687
I0527 07:54:19.961051 15746 solver.cpp:244]     Train net output #0: loss = 0.307685 (* 1 = 0.307685 loss)
I0527 07:54:19.961079 15746 sgd_solver.cpp:106] Iteration 32200, lr = 1e-05
I0527 08:02:05.388090 15746 solver.cpp:228] Iteration 32300, loss = 0.542637
I0527 08:02:05.388782 15746 solver.cpp:244]     Train net output #0: loss = 0.542636 (* 1 = 0.542636 loss)
I0527 08:02:05.388805 15746 sgd_solver.cpp:106] Iteration 32300, lr = 1e-05
I0527 08:10:02.629487 15746 solver.cpp:228] Iteration 32400, loss = 0.47154
I0527 08:10:02.630165 15746 solver.cpp:244]     Train net output #0: loss = 0.471539 (* 1 = 0.471539 loss)
I0527 08:10:02.630187 15746 sgd_solver.cpp:106] Iteration 32400, lr = 1e-05
I0527 08:18:01.267693 15746 solver.cpp:228] Iteration 32500, loss = 0.414459
I0527 08:18:01.268379 15746 solver.cpp:244]     Train net output #0: loss = 0.414457 (* 1 = 0.414457 loss)
I0527 08:18:01.268399 15746 sgd_solver.cpp:106] Iteration 32500, lr = 1e-05
I0527 08:25:53.800609 15746 solver.cpp:228] Iteration 32600, loss = 0.408811
I0527 08:25:53.801312 15746 solver.cpp:244]     Train net output #0: loss = 0.40881 (* 1 = 0.40881 loss)
I0527 08:25:53.801336 15746 sgd_solver.cpp:106] Iteration 32600, lr = 1e-05
I0527 08:30:04.559754 15746 solver.cpp:337] Iteration 32650, Testing net (#0)
I0527 08:30:04.560184 15746 net.cpp:685] Ignoring source layer ratemap
I0527 08:30:04.560204 15746 net.cpp:685] Ignoring source layer amsFeatures
I0527 08:32:56.614764 15746 solver.cpp:404]     Test net output #0: loss = 0.528822 (* 1 = 0.528822 loss)
I0527 08:36:55.933328 15746 solver.cpp:228] Iteration 32700, loss = 0.347313
I0527 08:36:55.933639 15746 solver.cpp:244]     Train net output #0: loss = 0.347312 (* 1 = 0.347312 loss)
I0527 08:36:55.933650 15746 sgd_solver.cpp:106] Iteration 32700, lr = 1e-05
I0527 08:44:52.074498 15746 solver.cpp:228] Iteration 32800, loss = 0.422246
I0527 08:44:52.075234 15746 solver.cpp:244]     Train net output #0: loss = 0.422245 (* 1 = 0.422245 loss)
I0527 08:44:52.075266 15746 sgd_solver.cpp:106] Iteration 32800, lr = 1e-05
I0527 08:52:51.355656 15746 solver.cpp:228] Iteration 32900, loss = 0.607401
I0527 08:52:51.356330 15746 solver.cpp:244]     Train net output #0: loss = 0.607399 (* 1 = 0.607399 loss)
I0527 08:52:51.356364 15746 sgd_solver.cpp:106] Iteration 32900, lr = 1e-05
I0527 09:00:49.444911 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_33000.caffemodel
I0527 09:00:49.642257 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_33000.solverstate
I0527 09:00:55.553490 15746 solver.cpp:228] Iteration 33000, loss = 0.619017
I0527 09:00:55.553570 15746 solver.cpp:244]     Train net output #0: loss = 0.619015 (* 1 = 0.619015 loss)
I0527 09:00:55.553580 15746 sgd_solver.cpp:106] Iteration 33000, lr = 1e-05
I0527 09:08:51.958971 15746 solver.cpp:228] Iteration 33100, loss = 0.826563
I0527 09:08:51.959753 15746 solver.cpp:244]     Train net output #0: loss = 0.826562 (* 1 = 0.826562 loss)
I0527 09:08:51.959772 15746 sgd_solver.cpp:106] Iteration 33100, lr = 1e-05
I0527 09:16:53.302917 15746 solver.cpp:228] Iteration 33200, loss = 0.456543
I0527 09:16:53.303660 15746 solver.cpp:244]     Train net output #0: loss = 0.456541 (* 1 = 0.456541 loss)
I0527 09:16:53.303680 15746 sgd_solver.cpp:106] Iteration 33200, lr = 1e-05
I0527 09:24:39.820053 15746 solver.cpp:228] Iteration 33300, loss = 0.29956
I0527 09:24:39.820827 15746 solver.cpp:244]     Train net output #0: loss = 0.299559 (* 1 = 0.299559 loss)
I0527 09:24:39.820847 15746 sgd_solver.cpp:106] Iteration 33300, lr = 1e-05
I0527 09:32:48.673506 15746 solver.cpp:228] Iteration 33400, loss = 0.863466
I0527 09:32:48.674219 15746 solver.cpp:244]     Train net output #0: loss = 0.863465 (* 1 = 0.863465 loss)
I0527 09:32:48.674242 15746 sgd_solver.cpp:106] Iteration 33400, lr = 1e-05
I0527 09:40:58.078328 15746 solver.cpp:228] Iteration 33500, loss = 0.6025
I0527 09:40:58.079017 15746 solver.cpp:244]     Train net output #0: loss = 0.602498 (* 1 = 0.602498 loss)
I0527 09:40:58.079046 15746 sgd_solver.cpp:106] Iteration 33500, lr = 1e-05
I0527 09:49:21.353536 15746 solver.cpp:228] Iteration 33600, loss = 0.877162
I0527 09:49:21.354217 15746 solver.cpp:244]     Train net output #0: loss = 0.87716 (* 1 = 0.87716 loss)
I0527 09:49:21.354245 15746 sgd_solver.cpp:106] Iteration 33600, lr = 1e-05
I0527 09:57:35.354315 15746 solver.cpp:228] Iteration 33700, loss = 0.459351
I0527 09:57:35.355026 15746 solver.cpp:244]     Train net output #0: loss = 0.45935 (* 1 = 0.45935 loss)
I0527 09:57:35.355051 15746 sgd_solver.cpp:106] Iteration 33700, lr = 1e-05
I0527 10:05:45.244720 15746 solver.cpp:228] Iteration 33800, loss = 0.641407
I0527 10:05:45.245204 15746 solver.cpp:244]     Train net output #0: loss = 0.641406 (* 1 = 0.641406 loss)
I0527 10:05:45.245229 15746 sgd_solver.cpp:106] Iteration 33800, lr = 1e-05
I0527 10:14:03.906426 15746 solver.cpp:228] Iteration 33900, loss = 0.425226
I0527 10:14:03.906922 15746 solver.cpp:244]     Train net output #0: loss = 0.425224 (* 1 = 0.425224 loss)
I0527 10:14:03.906936 15746 sgd_solver.cpp:106] Iteration 33900, lr = 1e-05
I0527 10:22:15.250644 15746 solver.cpp:228] Iteration 34000, loss = 0.506021
I0527 10:22:15.251405 15746 solver.cpp:244]     Train net output #0: loss = 0.50602 (* 1 = 0.50602 loss)
I0527 10:22:15.251418 15746 sgd_solver.cpp:106] Iteration 34000, lr = 1e-05
I0527 10:30:32.011473 15746 solver.cpp:228] Iteration 34100, loss = 0.447611
I0527 10:30:32.012081 15746 solver.cpp:244]     Train net output #0: loss = 0.44761 (* 1 = 0.44761 loss)
I0527 10:30:32.012105 15746 sgd_solver.cpp:106] Iteration 34100, lr = 1e-05
I0527 10:38:45.014300 15746 solver.cpp:228] Iteration 34200, loss = 0.516338
I0527 10:38:45.014992 15746 solver.cpp:244]     Train net output #0: loss = 0.516337 (* 1 = 0.516337 loss)
I0527 10:38:45.015012 15746 sgd_solver.cpp:106] Iteration 34200, lr = 1e-05
I0527 10:47:21.868407 15746 solver.cpp:228] Iteration 34300, loss = 0.705595
I0527 10:47:21.868801 15746 solver.cpp:244]     Train net output #0: loss = 0.705594 (* 1 = 0.705594 loss)
I0527 10:47:21.868823 15746 sgd_solver.cpp:106] Iteration 34300, lr = 1e-05
I0527 10:55:47.440397 15746 solver.cpp:228] Iteration 34400, loss = 0.425674
I0527 10:55:47.441062 15746 solver.cpp:244]     Train net output #0: loss = 0.425673 (* 1 = 0.425673 loss)
I0527 10:55:47.441087 15746 sgd_solver.cpp:106] Iteration 34400, lr = 1e-05
I0527 11:04:21.649446 15746 solver.cpp:228] Iteration 34500, loss = 0.554529
I0527 11:04:21.649776 15746 solver.cpp:244]     Train net output #0: loss = 0.554528 (* 1 = 0.554528 loss)
I0527 11:04:21.649799 15746 sgd_solver.cpp:106] Iteration 34500, lr = 1e-05
I0527 11:12:52.328390 15746 solver.cpp:228] Iteration 34600, loss = 0.41104
I0527 11:12:52.328896 15746 solver.cpp:244]     Train net output #0: loss = 0.411038 (* 1 = 0.411038 loss)
I0527 11:12:52.328927 15746 sgd_solver.cpp:106] Iteration 34600, lr = 1e-05
I0527 11:21:10.246476 15746 solver.cpp:228] Iteration 34700, loss = 0.488325
I0527 11:21:10.246920 15746 solver.cpp:244]     Train net output #0: loss = 0.488324 (* 1 = 0.488324 loss)
I0527 11:21:10.246935 15746 sgd_solver.cpp:106] Iteration 34700, lr = 1e-05
I0527 11:29:41.271306 15746 solver.cpp:228] Iteration 34800, loss = 0.413705
I0527 11:29:41.272025 15746 solver.cpp:244]     Train net output #0: loss = 0.413704 (* 1 = 0.413704 loss)
I0527 11:29:41.272047 15746 sgd_solver.cpp:106] Iteration 34800, lr = 1e-05
I0527 11:38:04.118763 15746 solver.cpp:228] Iteration 34900, loss = 0.485616
I0527 11:38:04.119287 15746 solver.cpp:244]     Train net output #0: loss = 0.485615 (* 1 = 0.485615 loss)
I0527 11:38:04.119315 15746 sgd_solver.cpp:106] Iteration 34900, lr = 1e-05
I0527 11:46:32.159160 15746 solver.cpp:228] Iteration 35000, loss = 0.513988
I0527 11:46:32.159692 15746 solver.cpp:244]     Train net output #0: loss = 0.513987 (* 1 = 0.513987 loss)
I0527 11:46:32.159719 15746 sgd_solver.cpp:106] Iteration 35000, lr = 1e-05
I0527 11:54:44.627583 15746 solver.cpp:228] Iteration 35100, loss = 0.689148
I0527 11:54:44.628070 15746 solver.cpp:244]     Train net output #0: loss = 0.689147 (* 1 = 0.689147 loss)
I0527 11:54:44.628090 15746 sgd_solver.cpp:106] Iteration 35100, lr = 1e-05
I0527 12:02:50.107388 15746 solver.cpp:228] Iteration 35200, loss = 0.335736
I0527 12:02:50.107831 15746 solver.cpp:244]     Train net output #0: loss = 0.335735 (* 1 = 0.335735 loss)
I0527 12:02:50.107854 15746 sgd_solver.cpp:106] Iteration 35200, lr = 1e-05
I0527 12:10:59.130420 15746 solver.cpp:228] Iteration 35300, loss = 0.376591
I0527 12:10:59.130885 15746 solver.cpp:244]     Train net output #0: loss = 0.37659 (* 1 = 0.37659 loss)
I0527 12:10:59.130909 15746 sgd_solver.cpp:106] Iteration 35300, lr = 1e-05
I0527 12:18:48.080658 15746 solver.cpp:228] Iteration 35400, loss = 0.543101
I0527 12:18:48.081123 15746 solver.cpp:244]     Train net output #0: loss = 0.5431 (* 1 = 0.5431 loss)
I0527 12:18:48.081143 15746 sgd_solver.cpp:106] Iteration 35400, lr = 1e-05
I0527 12:26:48.380688 15746 solver.cpp:228] Iteration 35500, loss = 0.536983
I0527 12:26:48.381108 15746 solver.cpp:244]     Train net output #0: loss = 0.536982 (* 1 = 0.536982 loss)
I0527 12:26:48.381131 15746 sgd_solver.cpp:106] Iteration 35500, lr = 1e-05
I0527 12:34:54.085891 15746 solver.cpp:228] Iteration 35600, loss = 0.872199
I0527 12:34:54.086524 15746 solver.cpp:244]     Train net output #0: loss = 0.872198 (* 1 = 0.872198 loss)
I0527 12:34:54.086549 15746 sgd_solver.cpp:106] Iteration 35600, lr = 1e-05
I0527 12:42:49.029263 15746 solver.cpp:228] Iteration 35700, loss = 0.565698
I0527 12:42:49.029953 15746 solver.cpp:244]     Train net output #0: loss = 0.565697 (* 1 = 0.565697 loss)
I0527 12:42:49.029974 15746 sgd_solver.cpp:106] Iteration 35700, lr = 1e-05
I0527 12:50:55.099290 15746 solver.cpp:228] Iteration 35800, loss = 0.511984
I0527 12:50:55.099774 15746 solver.cpp:244]     Train net output #0: loss = 0.511983 (* 1 = 0.511983 loss)
I0527 12:50:55.099795 15746 sgd_solver.cpp:106] Iteration 35800, lr = 1e-05
I0527 12:59:19.823804 15746 solver.cpp:228] Iteration 35900, loss = 0.606176
I0527 12:59:19.824491 15746 solver.cpp:244]     Train net output #0: loss = 0.606175 (* 1 = 0.606175 loss)
I0527 12:59:19.824514 15746 sgd_solver.cpp:106] Iteration 35900, lr = 1e-05
I0527 13:00:36.833024 15746 solver.cpp:337] Iteration 35915, Testing net (#0)
I0527 13:00:36.833315 15746 net.cpp:685] Ignoring source layer ratemap
I0527 13:00:36.833323 15746 net.cpp:685] Ignoring source layer amsFeatures
I0527 13:03:28.951702 15746 solver.cpp:404]     Test net output #0: loss = 0.531277 (* 1 = 0.531277 loss)
I0527 13:10:10.963984 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_36000.caffemodel
I0527 13:10:11.159595 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_36000.solverstate
I0527 13:10:16.613976 15746 solver.cpp:228] Iteration 36000, loss = 0.371187
I0527 13:10:16.614059 15746 solver.cpp:244]     Train net output #0: loss = 0.371186 (* 1 = 0.371186 loss)
I0527 13:10:16.614070 15746 sgd_solver.cpp:106] Iteration 36000, lr = 1e-05
I0527 13:18:22.900533 15746 solver.cpp:228] Iteration 36100, loss = 0.336242
I0527 13:18:22.901201 15746 solver.cpp:244]     Train net output #0: loss = 0.336241 (* 1 = 0.336241 loss)
I0527 13:18:22.901224 15746 sgd_solver.cpp:106] Iteration 36100, lr = 1e-05
I0527 13:26:33.723687 15746 solver.cpp:228] Iteration 36200, loss = 0.469868
I0527 13:26:33.724395 15746 solver.cpp:244]     Train net output #0: loss = 0.469867 (* 1 = 0.469867 loss)
I0527 13:26:33.724419 15746 sgd_solver.cpp:106] Iteration 36200, lr = 1e-05
I0527 13:34:17.574832 15746 solver.cpp:228] Iteration 36300, loss = 0.682127
I0527 13:34:17.575577 15746 solver.cpp:244]     Train net output #0: loss = 0.682126 (* 1 = 0.682126 loss)
I0527 13:34:17.575618 15746 sgd_solver.cpp:106] Iteration 36300, lr = 1e-05
I0527 13:42:25.536046 15746 solver.cpp:228] Iteration 36400, loss = 0.572623
I0527 13:42:25.536824 15746 solver.cpp:244]     Train net output #0: loss = 0.572622 (* 1 = 0.572622 loss)
I0527 13:42:25.536844 15746 sgd_solver.cpp:106] Iteration 36400, lr = 1e-05
I0527 13:50:25.035401 15746 solver.cpp:228] Iteration 36500, loss = 0.522532
I0527 13:50:25.036170 15746 solver.cpp:244]     Train net output #0: loss = 0.522531 (* 1 = 0.522531 loss)
I0527 13:50:25.036201 15746 sgd_solver.cpp:106] Iteration 36500, lr = 1e-05
I0527 13:58:17.467916 15746 solver.cpp:228] Iteration 36600, loss = 0.590157
I0527 13:58:17.468665 15746 solver.cpp:244]     Train net output #0: loss = 0.590156 (* 1 = 0.590156 loss)
I0527 13:58:17.468686 15746 sgd_solver.cpp:106] Iteration 36600, lr = 1e-05
I0527 14:06:34.619947 15746 solver.cpp:228] Iteration 36700, loss = 0.498513
I0527 14:06:34.620667 15746 solver.cpp:244]     Train net output #0: loss = 0.498512 (* 1 = 0.498512 loss)
I0527 14:06:34.620697 15746 sgd_solver.cpp:106] Iteration 36700, lr = 1e-05
I0527 14:14:35.908437 15746 solver.cpp:228] Iteration 36800, loss = 0.523633
I0527 14:14:35.909106 15746 solver.cpp:244]     Train net output #0: loss = 0.523632 (* 1 = 0.523632 loss)
I0527 14:14:35.909126 15746 sgd_solver.cpp:106] Iteration 36800, lr = 1e-05
I0527 14:22:59.729636 15746 solver.cpp:228] Iteration 36900, loss = 0.272975
I0527 14:22:59.730108 15746 solver.cpp:244]     Train net output #0: loss = 0.272974 (* 1 = 0.272974 loss)
I0527 14:22:59.730129 15746 sgd_solver.cpp:106] Iteration 36900, lr = 1e-05
I0527 14:31:05.971271 15746 solver.cpp:228] Iteration 37000, loss = 0.875722
I0527 14:31:05.971750 15746 solver.cpp:244]     Train net output #0: loss = 0.875721 (* 1 = 0.875721 loss)
I0527 14:31:05.971774 15746 sgd_solver.cpp:106] Iteration 37000, lr = 1e-05
I0527 14:39:09.668627 15746 solver.cpp:228] Iteration 37100, loss = 0.45049
I0527 14:39:09.669070 15746 solver.cpp:244]     Train net output #0: loss = 0.450489 (* 1 = 0.450489 loss)
I0527 14:39:09.669083 15746 sgd_solver.cpp:106] Iteration 37100, lr = 1e-05
I0527 14:47:32.335026 15746 solver.cpp:228] Iteration 37200, loss = 0.435521
I0527 14:47:32.335463 15746 solver.cpp:244]     Train net output #0: loss = 0.43552 (* 1 = 0.43552 loss)
I0527 14:47:32.335477 15746 sgd_solver.cpp:106] Iteration 37200, lr = 1e-05
I0527 14:55:44.952510 15746 solver.cpp:228] Iteration 37300, loss = 0.365382
I0527 14:55:44.952978 15746 solver.cpp:244]     Train net output #0: loss = 0.365381 (* 1 = 0.365381 loss)
I0527 14:55:44.952998 15746 sgd_solver.cpp:106] Iteration 37300, lr = 1e-05
I0527 15:03:57.221598 15746 solver.cpp:228] Iteration 37400, loss = 0.405202
I0527 15:03:57.222074 15746 solver.cpp:244]     Train net output #0: loss = 0.405201 (* 1 = 0.405201 loss)
I0527 15:03:57.222095 15746 sgd_solver.cpp:106] Iteration 37400, lr = 1e-05
I0527 15:12:10.769562 15746 solver.cpp:228] Iteration 37500, loss = 0.763249
I0527 15:12:10.770299 15746 solver.cpp:244]     Train net output #0: loss = 0.763249 (* 1 = 0.763249 loss)
I0527 15:12:10.770323 15746 sgd_solver.cpp:106] Iteration 37500, lr = 1e-05
I0527 15:20:05.694584 15746 solver.cpp:228] Iteration 37600, loss = 0.785943
I0527 15:20:05.695040 15746 solver.cpp:244]     Train net output #0: loss = 0.785942 (* 1 = 0.785942 loss)
I0527 15:20:05.695060 15746 sgd_solver.cpp:106] Iteration 37600, lr = 1e-05
I0527 15:28:06.458202 15746 solver.cpp:228] Iteration 37700, loss = 0.623471
I0527 15:28:06.458633 15746 solver.cpp:244]     Train net output #0: loss = 0.62347 (* 1 = 0.62347 loss)
I0527 15:28:06.458662 15746 sgd_solver.cpp:106] Iteration 37700, lr = 1e-05
I0527 15:35:57.753327 15746 solver.cpp:228] Iteration 37800, loss = 0.39301
I0527 15:35:57.753993 15746 solver.cpp:244]     Train net output #0: loss = 0.393009 (* 1 = 0.393009 loss)
I0527 15:35:57.754017 15746 sgd_solver.cpp:106] Iteration 37800, lr = 1e-05
I0527 15:43:48.227908 15746 solver.cpp:228] Iteration 37900, loss = 0.589715
I0527 15:43:48.228580 15746 solver.cpp:244]     Train net output #0: loss = 0.589714 (* 1 = 0.589714 loss)
I0527 15:43:48.228600 15746 sgd_solver.cpp:106] Iteration 37900, lr = 1e-05
I0527 15:51:33.377677 15746 solver.cpp:228] Iteration 38000, loss = 0.346898
I0527 15:51:33.378337 15746 solver.cpp:244]     Train net output #0: loss = 0.346897 (* 1 = 0.346897 loss)
I0527 15:51:33.378360 15746 sgd_solver.cpp:106] Iteration 38000, lr = 1e-05
I0527 15:59:18.651828 15746 solver.cpp:228] Iteration 38100, loss = 0.420147
I0527 15:59:18.652537 15746 solver.cpp:244]     Train net output #0: loss = 0.420147 (* 1 = 0.420147 loss)
I0527 15:59:18.652561 15746 sgd_solver.cpp:106] Iteration 38100, lr = 1e-05
I0527 16:07:14.991433 15746 solver.cpp:228] Iteration 38200, loss = 0.445034
I0527 16:07:14.992112 15746 solver.cpp:244]     Train net output #0: loss = 0.445033 (* 1 = 0.445033 loss)
I0527 16:07:14.992132 15746 sgd_solver.cpp:106] Iteration 38200, lr = 1e-05
I0527 16:15:26.695690 15746 solver.cpp:228] Iteration 38300, loss = 0.676632
I0527 16:15:26.696435 15746 solver.cpp:244]     Train net output #0: loss = 0.676631 (* 1 = 0.676631 loss)
I0527 16:15:26.696460 15746 sgd_solver.cpp:106] Iteration 38300, lr = 1e-05
I0527 16:23:20.033922 15746 solver.cpp:228] Iteration 38400, loss = 0.787926
I0527 16:23:20.034394 15746 solver.cpp:244]     Train net output #0: loss = 0.787925 (* 1 = 0.787925 loss)
I0527 16:23:20.034409 15746 sgd_solver.cpp:106] Iteration 38400, lr = 1e-05
I0527 16:31:25.586118 15746 solver.cpp:228] Iteration 38500, loss = 0.548119
I0527 16:31:25.586513 15746 solver.cpp:244]     Train net output #0: loss = 0.548118 (* 1 = 0.548118 loss)
I0527 16:31:25.586537 15746 sgd_solver.cpp:106] Iteration 38500, lr = 1e-05
I0527 16:39:35.316179 15746 solver.cpp:228] Iteration 38600, loss = 0.359674
I0527 16:39:35.316689 15746 solver.cpp:244]     Train net output #0: loss = 0.359674 (* 1 = 0.359674 loss)
I0527 16:39:35.316717 15746 sgd_solver.cpp:106] Iteration 38600, lr = 1e-05
I0527 16:47:25.606490 15746 solver.cpp:228] Iteration 38700, loss = 0.381352
I0527 16:47:25.606923 15746 solver.cpp:244]     Train net output #0: loss = 0.381351 (* 1 = 0.381351 loss)
I0527 16:47:25.606947 15746 sgd_solver.cpp:106] Iteration 38700, lr = 1e-05
I0527 16:55:26.332967 15746 solver.cpp:228] Iteration 38800, loss = 0.383876
I0527 16:55:26.333755 15746 solver.cpp:244]     Train net output #0: loss = 0.383876 (* 1 = 0.383876 loss)
I0527 16:55:26.333780 15746 sgd_solver.cpp:106] Iteration 38800, lr = 1e-05
I0527 17:03:28.990365 15746 solver.cpp:228] Iteration 38900, loss = 0.549205
I0527 17:03:28.991214 15746 solver.cpp:244]     Train net output #0: loss = 0.549204 (* 1 = 0.549204 loss)
I0527 17:03:28.991247 15746 sgd_solver.cpp:106] Iteration 38900, lr = 1e-05
I0527 17:11:13.011405 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_39000.caffemodel
I0527 17:11:13.193158 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_39000.solverstate
I0527 17:11:18.231210 15746 solver.cpp:228] Iteration 39000, loss = 0.792561
I0527 17:11:18.231262 15746 solver.cpp:244]     Train net output #0: loss = 0.79256 (* 1 = 0.79256 loss)
I0527 17:11:18.231272 15746 sgd_solver.cpp:106] Iteration 39000, lr = 1e-05
I0527 17:19:04.406020 15746 solver.cpp:228] Iteration 39100, loss = 0.43764
I0527 17:19:04.406817 15746 solver.cpp:244]     Train net output #0: loss = 0.437639 (* 1 = 0.437639 loss)
I0527 17:19:04.406838 15746 sgd_solver.cpp:106] Iteration 39100, lr = 1e-05
I0527 17:25:27.330669 15746 solver.cpp:337] Iteration 39180, Testing net (#0)
I0527 17:25:27.331377 15746 net.cpp:685] Ignoring source layer ratemap
I0527 17:25:27.331394 15746 net.cpp:685] Ignoring source layer amsFeatures
I0527 17:28:18.983286 15746 solver.cpp:404]     Test net output #0: loss = 0.530076 (* 1 = 0.530076 loss)
I0527 17:30:05.470154 15746 solver.cpp:228] Iteration 39200, loss = 0.790557
I0527 17:30:05.470504 15746 solver.cpp:244]     Train net output #0: loss = 0.790556 (* 1 = 0.790556 loss)
I0527 17:30:05.470516 15746 sgd_solver.cpp:106] Iteration 39200, lr = 1e-05
I0527 17:37:52.835903 15746 solver.cpp:228] Iteration 39300, loss = 0.440231
I0527 17:37:52.836604 15746 solver.cpp:244]     Train net output #0: loss = 0.440231 (* 1 = 0.440231 loss)
I0527 17:37:52.836628 15746 sgd_solver.cpp:106] Iteration 39300, lr = 1e-05
I0527 17:45:41.031522 15746 solver.cpp:228] Iteration 39400, loss = 0.703623
I0527 17:45:41.032279 15746 solver.cpp:244]     Train net output #0: loss = 0.703622 (* 1 = 0.703622 loss)
I0527 17:45:41.032304 15746 sgd_solver.cpp:106] Iteration 39400, lr = 1e-05
I0527 17:53:59.769039 15746 solver.cpp:228] Iteration 39500, loss = 0.379113
I0527 17:53:59.769660 15746 solver.cpp:244]     Train net output #0: loss = 0.379112 (* 1 = 0.379112 loss)
I0527 17:53:59.769680 15746 sgd_solver.cpp:106] Iteration 39500, lr = 1e-05
I0527 18:01:59.224328 15746 solver.cpp:228] Iteration 39600, loss = 0.510384
I0527 18:01:59.225005 15746 solver.cpp:244]     Train net output #0: loss = 0.510383 (* 1 = 0.510383 loss)
I0527 18:01:59.225036 15746 sgd_solver.cpp:106] Iteration 39600, lr = 1e-05
I0527 18:09:36.330112 15746 solver.cpp:228] Iteration 39700, loss = 0.366979
I0527 18:09:36.330853 15746 solver.cpp:244]     Train net output #0: loss = 0.366978 (* 1 = 0.366978 loss)
I0527 18:09:36.330878 15746 sgd_solver.cpp:106] Iteration 39700, lr = 1e-05
I0527 18:17:21.594146 15746 solver.cpp:228] Iteration 39800, loss = 0.753213
I0527 18:17:21.594935 15746 solver.cpp:244]     Train net output #0: loss = 0.753213 (* 1 = 0.753213 loss)
I0527 18:17:21.594960 15746 sgd_solver.cpp:106] Iteration 39800, lr = 1e-05
I0527 18:25:21.721799 15746 solver.cpp:228] Iteration 39900, loss = 0.754639
I0527 18:25:21.722559 15746 solver.cpp:244]     Train net output #0: loss = 0.754638 (* 1 = 0.754638 loss)
I0527 18:25:21.722584 15746 sgd_solver.cpp:106] Iteration 39900, lr = 1e-05
I0527 18:33:17.147181 15746 solver.cpp:228] Iteration 40000, loss = 0.901154
I0527 18:33:17.147938 15746 solver.cpp:244]     Train net output #0: loss = 0.901153 (* 1 = 0.901153 loss)
I0527 18:33:17.147974 15746 sgd_solver.cpp:106] Iteration 40000, lr = 1e-05
I0527 18:41:25.013838 15746 solver.cpp:228] Iteration 40100, loss = 0.505769
I0527 18:41:25.014601 15746 solver.cpp:244]     Train net output #0: loss = 0.505768 (* 1 = 0.505768 loss)
I0527 18:41:25.014622 15746 sgd_solver.cpp:106] Iteration 40100, lr = 1e-05
I0527 18:49:16.050060 15746 solver.cpp:228] Iteration 40200, loss = 0.47241
I0527 18:49:16.050814 15746 solver.cpp:244]     Train net output #0: loss = 0.472409 (* 1 = 0.472409 loss)
I0527 18:49:16.050843 15746 sgd_solver.cpp:106] Iteration 40200, lr = 1e-05
I0527 18:57:18.493564 15746 solver.cpp:228] Iteration 40300, loss = 0.47411
I0527 18:57:18.494293 15746 solver.cpp:244]     Train net output #0: loss = 0.474109 (* 1 = 0.474109 loss)
I0527 18:57:18.494313 15746 sgd_solver.cpp:106] Iteration 40300, lr = 1e-05
I0527 19:05:02.289921 15746 solver.cpp:228] Iteration 40400, loss = 0.476234
I0527 19:05:02.290654 15746 solver.cpp:244]     Train net output #0: loss = 0.476233 (* 1 = 0.476233 loss)
I0527 19:05:02.290679 15746 sgd_solver.cpp:106] Iteration 40400, lr = 1e-05
I0527 19:12:59.416622 15746 solver.cpp:228] Iteration 40500, loss = 0.966685
I0527 19:12:59.417346 15746 solver.cpp:244]     Train net output #0: loss = 0.966684 (* 1 = 0.966684 loss)
I0527 19:12:59.417366 15746 sgd_solver.cpp:106] Iteration 40500, lr = 1e-05
I0527 19:20:46.810343 15746 solver.cpp:228] Iteration 40600, loss = 0.524623
I0527 19:20:46.811239 15746 solver.cpp:244]     Train net output #0: loss = 0.524623 (* 1 = 0.524623 loss)
I0527 19:20:46.811269 15746 sgd_solver.cpp:106] Iteration 40600, lr = 1e-05
I0527 19:28:42.537456 15746 solver.cpp:228] Iteration 40700, loss = 0.383806
I0527 19:28:42.538180 15746 solver.cpp:244]     Train net output #0: loss = 0.383805 (* 1 = 0.383805 loss)
I0527 19:28:42.538203 15746 sgd_solver.cpp:106] Iteration 40700, lr = 1e-05
I0527 19:36:33.864485 15746 solver.cpp:228] Iteration 40800, loss = 0.437991
I0527 19:36:33.865263 15746 solver.cpp:244]     Train net output #0: loss = 0.437991 (* 1 = 0.437991 loss)
I0527 19:36:33.865283 15746 sgd_solver.cpp:106] Iteration 40800, lr = 1e-05
I0527 19:44:38.698377 15746 solver.cpp:228] Iteration 40900, loss = 0.310673
I0527 19:44:38.699062 15746 solver.cpp:244]     Train net output #0: loss = 0.310673 (* 1 = 0.310673 loss)
I0527 19:44:38.699084 15746 sgd_solver.cpp:106] Iteration 40900, lr = 1e-05
I0527 19:52:42.933142 15746 solver.cpp:228] Iteration 41000, loss = 0.537161
I0527 19:52:42.933792 15746 solver.cpp:244]     Train net output #0: loss = 0.53716 (* 1 = 0.53716 loss)
I0527 19:52:42.933820 15746 sgd_solver.cpp:106] Iteration 41000, lr = 1e-05
I0527 20:00:31.426661 15746 solver.cpp:228] Iteration 41100, loss = 0.445466
I0527 20:00:31.427413 15746 solver.cpp:244]     Train net output #0: loss = 0.445466 (* 1 = 0.445466 loss)
I0527 20:00:31.427448 15746 sgd_solver.cpp:106] Iteration 41100, lr = 1e-05
I0527 20:08:19.795662 15746 solver.cpp:228] Iteration 41200, loss = 0.543394
I0527 20:08:19.796509 15746 solver.cpp:244]     Train net output #0: loss = 0.543393 (* 1 = 0.543393 loss)
I0527 20:08:19.796537 15746 sgd_solver.cpp:106] Iteration 41200, lr = 1e-05
I0527 20:16:16.010009 15746 solver.cpp:228] Iteration 41300, loss = 0.491957
I0527 20:16:16.010752 15746 solver.cpp:244]     Train net output #0: loss = 0.491956 (* 1 = 0.491956 loss)
I0527 20:16:16.010777 15746 sgd_solver.cpp:106] Iteration 41300, lr = 1e-05
I0527 20:23:52.990538 15746 solver.cpp:228] Iteration 41400, loss = 0.358365
I0527 20:23:52.991350 15746 solver.cpp:244]     Train net output #0: loss = 0.358364 (* 1 = 0.358364 loss)
I0527 20:23:52.991371 15746 sgd_solver.cpp:106] Iteration 41400, lr = 1e-05
I0527 20:31:48.725018 15746 solver.cpp:228] Iteration 41500, loss = 0.600703
I0527 20:31:48.725793 15746 solver.cpp:244]     Train net output #0: loss = 0.600702 (* 1 = 0.600702 loss)
I0527 20:31:48.725850 15746 sgd_solver.cpp:106] Iteration 41500, lr = 1e-05
I0527 20:39:50.747164 15746 solver.cpp:228] Iteration 41600, loss = 0.414513
I0527 20:39:50.747951 15746 solver.cpp:244]     Train net output #0: loss = 0.414512 (* 1 = 0.414512 loss)
I0527 20:39:50.747980 15746 sgd_solver.cpp:106] Iteration 41600, lr = 1e-05
I0527 20:47:53.862951 15746 solver.cpp:228] Iteration 41700, loss = 1.12799
I0527 20:47:53.863760 15746 solver.cpp:244]     Train net output #0: loss = 1.12799 (* 1 = 1.12799 loss)
I0527 20:47:53.863780 15746 sgd_solver.cpp:106] Iteration 41700, lr = 1e-05
I0527 20:55:39.175508 15746 solver.cpp:228] Iteration 41800, loss = 0.447227
I0527 20:55:39.176245 15746 solver.cpp:244]     Train net output #0: loss = 0.447226 (* 1 = 0.447226 loss)
I0527 20:55:39.176266 15746 sgd_solver.cpp:106] Iteration 41800, lr = 1e-05
I0527 21:03:35.460090 15746 solver.cpp:228] Iteration 41900, loss = 0.552364
I0527 21:03:35.460738 15746 solver.cpp:244]     Train net output #0: loss = 0.552363 (* 1 = 0.552363 loss)
I0527 21:03:35.460768 15746 sgd_solver.cpp:106] Iteration 41900, lr = 1e-05
I0527 21:11:19.824050 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_42000.caffemodel
I0527 21:11:19.986791 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_42000.solverstate
I0527 21:11:24.324650 15746 solver.cpp:228] Iteration 42000, loss = 0.494373
I0527 21:11:24.324705 15746 solver.cpp:244]     Train net output #0: loss = 0.494372 (* 1 = 0.494372 loss)
I0527 21:11:24.324717 15746 sgd_solver.cpp:106] Iteration 42000, lr = 1e-05
I0527 21:19:31.222231 15746 solver.cpp:228] Iteration 42100, loss = 0.420592
I0527 21:19:31.223002 15746 solver.cpp:244]     Train net output #0: loss = 0.420591 (* 1 = 0.420591 loss)
I0527 21:19:31.223023 15746 sgd_solver.cpp:106] Iteration 42100, lr = 1e-05
I0527 21:27:14.797981 15746 solver.cpp:228] Iteration 42200, loss = 0.53838
I0527 21:27:14.798866 15746 solver.cpp:244]     Train net output #0: loss = 0.538378 (* 1 = 0.538378 loss)
I0527 21:27:14.798890 15746 sgd_solver.cpp:106] Iteration 42200, lr = 1e-05
I0527 21:35:12.994217 15746 solver.cpp:228] Iteration 42300, loss = 0.592427
I0527 21:35:12.994899 15746 solver.cpp:244]     Train net output #0: loss = 0.592425 (* 1 = 0.592425 loss)
I0527 21:35:12.994923 15746 sgd_solver.cpp:106] Iteration 42300, lr = 1e-05
I0527 21:42:59.205467 15746 solver.cpp:228] Iteration 42400, loss = 0.687248
I0527 21:42:59.206151 15746 solver.cpp:244]     Train net output #0: loss = 0.687247 (* 1 = 0.687247 loss)
I0527 21:42:59.206179 15746 sgd_solver.cpp:106] Iteration 42400, lr = 1e-05
I0527 21:46:32.282955 15746 solver.cpp:337] Iteration 42445, Testing net (#0)
I0527 21:46:32.283391 15746 net.cpp:685] Ignoring source layer ratemap
I0527 21:46:32.283418 15746 net.cpp:685] Ignoring source layer amsFeatures
I0527 21:49:22.249755 15746 solver.cpp:404]     Test net output #0: loss = 0.530834 (* 1 = 0.530834 loss)
I0527 21:53:44.984910 15746 solver.cpp:228] Iteration 42500, loss = 0.652482
I0527 21:53:44.985214 15746 solver.cpp:244]     Train net output #0: loss = 0.65248 (* 1 = 0.65248 loss)
I0527 21:53:44.985226 15746 sgd_solver.cpp:106] Iteration 42500, lr = 1e-05
I0527 22:01:35.484683 15746 solver.cpp:228] Iteration 42600, loss = 0.514484
I0527 22:01:35.485457 15746 solver.cpp:244]     Train net output #0: loss = 0.514482 (* 1 = 0.514482 loss)
I0527 22:01:35.485487 15746 sgd_solver.cpp:106] Iteration 42600, lr = 1e-05
I0527 22:09:30.489433 15746 solver.cpp:228] Iteration 42700, loss = 0.387741
I0527 22:09:30.490123 15746 solver.cpp:244]     Train net output #0: loss = 0.387739 (* 1 = 0.387739 loss)
I0527 22:09:30.490146 15746 sgd_solver.cpp:106] Iteration 42700, lr = 1e-05
I0527 22:17:30.166277 15746 solver.cpp:228] Iteration 42800, loss = 0.642165
I0527 22:17:30.167073 15746 solver.cpp:244]     Train net output #0: loss = 0.642164 (* 1 = 0.642164 loss)
I0527 22:17:30.167093 15746 sgd_solver.cpp:106] Iteration 42800, lr = 1e-05
I0527 22:25:43.838426 15746 solver.cpp:228] Iteration 42900, loss = 0.492135
I0527 22:25:43.839061 15746 solver.cpp:244]     Train net output #0: loss = 0.492134 (* 1 = 0.492134 loss)
I0527 22:25:43.839083 15746 sgd_solver.cpp:106] Iteration 42900, lr = 1e-05
I0527 22:33:35.277725 15746 solver.cpp:228] Iteration 43000, loss = 0.832593
I0527 22:33:35.278414 15746 solver.cpp:244]     Train net output #0: loss = 0.832591 (* 1 = 0.832591 loss)
I0527 22:33:35.278434 15746 sgd_solver.cpp:106] Iteration 43000, lr = 1e-05
I0527 22:41:29.744232 15746 solver.cpp:228] Iteration 43100, loss = 0.393759
I0527 22:41:29.744925 15746 solver.cpp:244]     Train net output #0: loss = 0.393757 (* 1 = 0.393757 loss)
I0527 22:41:29.744945 15746 sgd_solver.cpp:106] Iteration 43100, lr = 1e-05
I0527 22:49:19.272114 15746 solver.cpp:228] Iteration 43200, loss = 0.811364
I0527 22:49:19.273000 15746 solver.cpp:244]     Train net output #0: loss = 0.811363 (* 1 = 0.811363 loss)
I0527 22:49:19.273013 15746 sgd_solver.cpp:106] Iteration 43200, lr = 1e-05
I0527 22:57:36.387480 15746 solver.cpp:228] Iteration 43300, loss = 0.371335
I0527 22:57:36.388252 15746 solver.cpp:244]     Train net output #0: loss = 0.371333 (* 1 = 0.371333 loss)
I0527 22:57:36.388275 15746 sgd_solver.cpp:106] Iteration 43300, lr = 1e-05
I0527 23:05:31.806164 15746 solver.cpp:228] Iteration 43400, loss = 0.176549
I0527 23:05:31.806834 15746 solver.cpp:244]     Train net output #0: loss = 0.176547 (* 1 = 0.176547 loss)
I0527 23:05:31.806854 15746 sgd_solver.cpp:106] Iteration 43400, lr = 1e-05
I0527 23:13:38.340642 15746 solver.cpp:228] Iteration 43500, loss = 0.427762
I0527 23:13:38.341303 15746 solver.cpp:244]     Train net output #0: loss = 0.42776 (* 1 = 0.42776 loss)
I0527 23:13:38.341323 15746 sgd_solver.cpp:106] Iteration 43500, lr = 1e-05
I0527 23:21:37.731652 15746 solver.cpp:228] Iteration 43600, loss = 0.416416
I0527 23:21:37.732441 15746 solver.cpp:244]     Train net output #0: loss = 0.416415 (* 1 = 0.416415 loss)
I0527 23:21:37.732461 15746 sgd_solver.cpp:106] Iteration 43600, lr = 1e-05
I0527 23:29:31.693490 15746 solver.cpp:228] Iteration 43700, loss = 0.526332
I0527 23:29:31.694319 15746 solver.cpp:244]     Train net output #0: loss = 0.526331 (* 1 = 0.526331 loss)
I0527 23:29:31.694347 15746 sgd_solver.cpp:106] Iteration 43700, lr = 1e-05
I0527 23:37:23.752761 15746 solver.cpp:228] Iteration 43800, loss = 0.419105
I0527 23:37:23.753453 15746 solver.cpp:244]     Train net output #0: loss = 0.419104 (* 1 = 0.419104 loss)
I0527 23:37:23.753476 15746 sgd_solver.cpp:106] Iteration 43800, lr = 1e-05
I0527 23:45:21.047242 15746 solver.cpp:228] Iteration 43900, loss = 0.57571
I0527 23:45:21.047859 15746 solver.cpp:244]     Train net output #0: loss = 0.575708 (* 1 = 0.575708 loss)
I0527 23:45:21.047871 15746 sgd_solver.cpp:106] Iteration 43900, lr = 1e-05
I0527 23:53:20.951360 15746 solver.cpp:228] Iteration 44000, loss = 0.38279
I0527 23:53:20.952075 15746 solver.cpp:244]     Train net output #0: loss = 0.382788 (* 1 = 0.382788 loss)
I0527 23:53:20.952095 15746 sgd_solver.cpp:106] Iteration 44000, lr = 1e-05
I0528 00:01:20.568872 15746 solver.cpp:228] Iteration 44100, loss = 0.524687
I0528 00:01:20.569578 15746 solver.cpp:244]     Train net output #0: loss = 0.524685 (* 1 = 0.524685 loss)
I0528 00:01:20.569598 15746 sgd_solver.cpp:106] Iteration 44100, lr = 1e-05
I0528 00:09:11.649227 15746 solver.cpp:228] Iteration 44200, loss = 0.367649
I0528 00:09:11.649922 15746 solver.cpp:244]     Train net output #0: loss = 0.367648 (* 1 = 0.367648 loss)
I0528 00:09:11.649956 15746 sgd_solver.cpp:106] Iteration 44200, lr = 1e-05
I0528 00:17:04.511454 15746 solver.cpp:228] Iteration 44300, loss = 0.310017
I0528 00:17:04.512223 15746 solver.cpp:244]     Train net output #0: loss = 0.310016 (* 1 = 0.310016 loss)
I0528 00:17:04.512253 15746 sgd_solver.cpp:106] Iteration 44300, lr = 1e-05
I0528 00:25:03.424746 15746 solver.cpp:228] Iteration 44400, loss = 0.86257
I0528 00:25:03.425472 15746 solver.cpp:244]     Train net output #0: loss = 0.862569 (* 1 = 0.862569 loss)
I0528 00:25:03.425498 15746 sgd_solver.cpp:106] Iteration 44400, lr = 1e-05
I0528 00:33:12.903071 15746 solver.cpp:228] Iteration 44500, loss = 0.512396
I0528 00:33:12.903795 15746 solver.cpp:244]     Train net output #0: loss = 0.512394 (* 1 = 0.512394 loss)
I0528 00:33:12.903816 15746 sgd_solver.cpp:106] Iteration 44500, lr = 1e-05
I0528 00:41:10.359789 15746 solver.cpp:228] Iteration 44600, loss = 0.38234
I0528 00:41:10.360549 15746 solver.cpp:244]     Train net output #0: loss = 0.382339 (* 1 = 0.382339 loss)
I0528 00:41:10.360574 15746 sgd_solver.cpp:106] Iteration 44600, lr = 1e-05
I0528 00:48:58.653849 15746 solver.cpp:228] Iteration 44700, loss = 0.526207
I0528 00:48:58.654556 15746 solver.cpp:244]     Train net output #0: loss = 0.526205 (* 1 = 0.526205 loss)
I0528 00:48:58.654585 15746 sgd_solver.cpp:106] Iteration 44700, lr = 1e-05
I0528 00:57:04.056526 15746 solver.cpp:228] Iteration 44800, loss = 0.636377
I0528 00:57:04.057135 15746 solver.cpp:244]     Train net output #0: loss = 0.636375 (* 1 = 0.636375 loss)
I0528 00:57:04.057148 15746 sgd_solver.cpp:106] Iteration 44800, lr = 1e-05
I0528 01:05:06.567695 15746 solver.cpp:228] Iteration 44900, loss = 0.584424
I0528 01:05:06.568377 15746 solver.cpp:244]     Train net output #0: loss = 0.584423 (* 1 = 0.584423 loss)
I0528 01:05:06.568397 15746 sgd_solver.cpp:106] Iteration 44900, lr = 1e-05
I0528 01:12:57.092742 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_45000.caffemodel
I0528 01:12:57.290196 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_45000.solverstate
I0528 01:13:01.035594 15746 solver.cpp:228] Iteration 45000, loss = 0.556622
I0528 01:13:01.035670 15746 solver.cpp:244]     Train net output #0: loss = 0.55662 (* 1 = 0.55662 loss)
I0528 01:13:01.035681 15746 sgd_solver.cpp:106] Iteration 45000, lr = 1e-05
I0528 01:21:00.763051 15746 solver.cpp:228] Iteration 45100, loss = 0.523624
I0528 01:21:00.763820 15746 solver.cpp:244]     Train net output #0: loss = 0.523622 (* 1 = 0.523622 loss)
I0528 01:21:00.763851 15746 sgd_solver.cpp:106] Iteration 45100, lr = 1e-05
I0528 01:28:58.000991 15746 solver.cpp:228] Iteration 45200, loss = 0.583994
I0528 01:28:58.001751 15746 solver.cpp:244]     Train net output #0: loss = 0.583992 (* 1 = 0.583992 loss)
I0528 01:28:58.001776 15746 sgd_solver.cpp:106] Iteration 45200, lr = 1e-05
I0528 01:36:51.245604 15746 solver.cpp:228] Iteration 45300, loss = 0.439081
I0528 01:36:51.246163 15746 solver.cpp:244]     Train net output #0: loss = 0.439079 (* 1 = 0.439079 loss)
I0528 01:36:51.246176 15746 sgd_solver.cpp:106] Iteration 45300, lr = 1e-05
I0528 01:44:56.137542 15746 solver.cpp:228] Iteration 45400, loss = 0.571613
I0528 01:44:56.138228 15746 solver.cpp:244]     Train net output #0: loss = 0.571611 (* 1 = 0.571611 loss)
I0528 01:44:56.138250 15746 sgd_solver.cpp:106] Iteration 45400, lr = 1e-05
I0528 01:53:00.225630 15746 solver.cpp:228] Iteration 45500, loss = 0.310794
I0528 01:53:00.226394 15746 solver.cpp:244]     Train net output #0: loss = 0.310792 (* 1 = 0.310792 loss)
I0528 01:53:00.226415 15746 sgd_solver.cpp:106] Iteration 45500, lr = 1e-05
I0528 02:00:59.707213 15746 solver.cpp:228] Iteration 45600, loss = 0.760827
I0528 02:00:59.707996 15746 solver.cpp:244]     Train net output #0: loss = 0.760825 (* 1 = 0.760825 loss)
I0528 02:00:59.708019 15746 sgd_solver.cpp:106] Iteration 45600, lr = 1e-05
I0528 02:09:09.241703 15746 solver.cpp:228] Iteration 45700, loss = 0.23243
I0528 02:09:09.242394 15746 solver.cpp:244]     Train net output #0: loss = 0.232428 (* 1 = 0.232428 loss)
I0528 02:09:09.242414 15746 sgd_solver.cpp:106] Iteration 45700, lr = 1e-05
I0528 02:09:58.800168 15746 solver.cpp:337] Iteration 45710, Testing net (#0)
I0528 02:09:58.800618 15746 net.cpp:685] Ignoring source layer ratemap
I0528 02:09:58.800642 15746 net.cpp:685] Ignoring source layer amsFeatures
I0528 02:12:50.065294 15746 solver.cpp:404]     Test net output #0: loss = 0.529972 (* 1 = 0.529972 loss)
I0528 02:20:05.799316 15746 solver.cpp:228] Iteration 45800, loss = 0.472321
I0528 02:20:05.800070 15746 solver.cpp:244]     Train net output #0: loss = 0.472319 (* 1 = 0.472319 loss)
I0528 02:20:05.800101 15746 sgd_solver.cpp:106] Iteration 45800, lr = 1e-05
I0528 02:27:51.219108 15746 solver.cpp:228] Iteration 45900, loss = 0.321368
I0528 02:27:51.219830 15746 solver.cpp:244]     Train net output #0: loss = 0.321366 (* 1 = 0.321366 loss)
I0528 02:27:51.219854 15746 sgd_solver.cpp:106] Iteration 45900, lr = 1e-05
I0528 02:35:39.406069 15746 solver.cpp:228] Iteration 46000, loss = 0.62707
I0528 02:35:39.406705 15746 solver.cpp:244]     Train net output #0: loss = 0.627068 (* 1 = 0.627068 loss)
I0528 02:35:39.406731 15746 sgd_solver.cpp:106] Iteration 46000, lr = 1e-05
I0528 02:43:26.454452 15746 solver.cpp:228] Iteration 46100, loss = 0.518738
I0528 02:43:26.455229 15746 solver.cpp:244]     Train net output #0: loss = 0.518736 (* 1 = 0.518736 loss)
I0528 02:43:26.455250 15746 sgd_solver.cpp:106] Iteration 46100, lr = 1e-05
I0528 02:51:07.143507 15746 solver.cpp:228] Iteration 46200, loss = 0.545926
I0528 02:51:07.144273 15746 solver.cpp:244]     Train net output #0: loss = 0.545923 (* 1 = 0.545923 loss)
I0528 02:51:07.144292 15746 sgd_solver.cpp:106] Iteration 46200, lr = 1e-05
I0528 02:58:50.831665 15746 solver.cpp:228] Iteration 46300, loss = 0.739634
I0528 02:58:50.832396 15746 solver.cpp:244]     Train net output #0: loss = 0.739632 (* 1 = 0.739632 loss)
I0528 02:58:50.832417 15746 sgd_solver.cpp:106] Iteration 46300, lr = 1e-05
I0528 03:06:42.744287 15746 solver.cpp:228] Iteration 46400, loss = 0.378899
I0528 03:06:42.744997 15746 solver.cpp:244]     Train net output #0: loss = 0.378897 (* 1 = 0.378897 loss)
I0528 03:06:42.745018 15746 sgd_solver.cpp:106] Iteration 46400, lr = 1e-05
I0528 03:14:46.593781 15746 solver.cpp:228] Iteration 46500, loss = 0.264933
I0528 03:14:46.594526 15746 solver.cpp:244]     Train net output #0: loss = 0.264931 (* 1 = 0.264931 loss)
I0528 03:14:46.594547 15746 sgd_solver.cpp:106] Iteration 46500, lr = 1e-05
I0528 03:23:07.277714 15746 solver.cpp:228] Iteration 46600, loss = 0.391208
I0528 03:23:07.278475 15746 solver.cpp:244]     Train net output #0: loss = 0.391205 (* 1 = 0.391205 loss)
I0528 03:23:07.278497 15746 sgd_solver.cpp:106] Iteration 46600, lr = 1e-05
I0528 03:31:14.942154 15746 solver.cpp:228] Iteration 46700, loss = 0.781263
I0528 03:31:14.942812 15746 solver.cpp:244]     Train net output #0: loss = 0.781261 (* 1 = 0.781261 loss)
I0528 03:31:14.942837 15746 sgd_solver.cpp:106] Iteration 46700, lr = 1e-05
I0528 03:39:24.518654 15746 solver.cpp:228] Iteration 46800, loss = 0.362204
I0528 03:39:24.519569 15746 solver.cpp:244]     Train net output #0: loss = 0.362202 (* 1 = 0.362202 loss)
I0528 03:39:24.519594 15746 sgd_solver.cpp:106] Iteration 46800, lr = 1e-05
I0528 03:47:22.923822 15746 solver.cpp:228] Iteration 46900, loss = 0.180356
I0528 03:47:22.924450 15746 solver.cpp:244]     Train net output #0: loss = 0.180354 (* 1 = 0.180354 loss)
I0528 03:47:22.924463 15746 sgd_solver.cpp:106] Iteration 46900, lr = 1e-05
I0528 03:55:41.867903 15746 solver.cpp:228] Iteration 47000, loss = 0.380292
I0528 03:55:41.868613 15746 solver.cpp:244]     Train net output #0: loss = 0.38029 (* 1 = 0.38029 loss)
I0528 03:55:41.868633 15746 sgd_solver.cpp:106] Iteration 47000, lr = 1e-05
I0528 04:03:59.374308 15746 solver.cpp:228] Iteration 47100, loss = 0.479632
I0528 04:03:59.375030 15746 solver.cpp:244]     Train net output #0: loss = 0.479629 (* 1 = 0.479629 loss)
I0528 04:03:59.375053 15746 sgd_solver.cpp:106] Iteration 47100, lr = 1e-05
I0528 04:12:18.550942 15746 solver.cpp:228] Iteration 47200, loss = 0.465517
I0528 04:12:18.551744 15746 solver.cpp:244]     Train net output #0: loss = 0.465515 (* 1 = 0.465515 loss)
I0528 04:12:18.551769 15746 sgd_solver.cpp:106] Iteration 47200, lr = 1e-05
I0528 04:20:38.066661 15746 solver.cpp:228] Iteration 47300, loss = 0.532432
I0528 04:20:38.067421 15746 solver.cpp:244]     Train net output #0: loss = 0.53243 (* 1 = 0.53243 loss)
I0528 04:20:38.067446 15746 sgd_solver.cpp:106] Iteration 47300, lr = 1e-05
I0528 04:28:58.277333 15746 solver.cpp:228] Iteration 47400, loss = 0.377758
I0528 04:28:58.278120 15746 solver.cpp:244]     Train net output #0: loss = 0.377756 (* 1 = 0.377756 loss)
I0528 04:28:58.278159 15746 sgd_solver.cpp:106] Iteration 47400, lr = 1e-05
I0528 04:37:12.052963 15746 solver.cpp:228] Iteration 47500, loss = 0.398741
I0528 04:37:12.053725 15746 solver.cpp:244]     Train net output #0: loss = 0.398738 (* 1 = 0.398738 loss)
I0528 04:37:12.053755 15746 sgd_solver.cpp:106] Iteration 47500, lr = 1e-05
I0528 04:45:09.144922 15746 solver.cpp:228] Iteration 47600, loss = 0.678752
I0528 04:45:09.145642 15746 solver.cpp:244]     Train net output #0: loss = 0.67875 (* 1 = 0.67875 loss)
I0528 04:45:09.145655 15746 sgd_solver.cpp:106] Iteration 47600, lr = 1e-05
I0528 04:53:21.618294 15746 solver.cpp:228] Iteration 47700, loss = 0.390325
I0528 04:53:21.618907 15746 solver.cpp:244]     Train net output #0: loss = 0.390323 (* 1 = 0.390323 loss)
I0528 04:53:21.618929 15746 sgd_solver.cpp:106] Iteration 47700, lr = 1e-05
I0528 05:01:31.190843 15746 solver.cpp:228] Iteration 47800, loss = 0.43004
I0528 05:01:31.191587 15746 solver.cpp:244]     Train net output #0: loss = 0.430038 (* 1 = 0.430038 loss)
I0528 05:01:31.191619 15746 sgd_solver.cpp:106] Iteration 47800, lr = 1e-05
I0528 05:09:42.546721 15746 solver.cpp:228] Iteration 47900, loss = 0.472965
I0528 05:09:42.547400 15746 solver.cpp:244]     Train net output #0: loss = 0.472963 (* 1 = 0.472963 loss)
I0528 05:09:42.547421 15746 sgd_solver.cpp:106] Iteration 47900, lr = 1e-05
I0528 05:17:39.155130 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_48000.caffemodel
I0528 05:17:39.315310 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_48000.solverstate
I0528 05:17:43.926537 15746 solver.cpp:228] Iteration 48000, loss = 0.38608
I0528 05:17:43.926591 15746 solver.cpp:244]     Train net output #0: loss = 0.386078 (* 1 = 0.386078 loss)
I0528 05:17:43.926602 15746 sgd_solver.cpp:106] Iteration 48000, lr = 1e-05
I0528 05:26:12.561666 15746 solver.cpp:228] Iteration 48100, loss = 0.613711
I0528 05:26:12.562362 15746 solver.cpp:244]     Train net output #0: loss = 0.613708 (* 1 = 0.613708 loss)
I0528 05:26:12.562383 15746 sgd_solver.cpp:106] Iteration 48100, lr = 1e-05
I0528 05:34:34.013276 15746 solver.cpp:228] Iteration 48200, loss = 0.556116
I0528 05:34:34.017684 15746 solver.cpp:244]     Train net output #0: loss = 0.556114 (* 1 = 0.556114 loss)
I0528 05:34:34.017714 15746 sgd_solver.cpp:106] Iteration 48200, lr = 1e-05
I0528 05:42:55.160871 15746 solver.cpp:228] Iteration 48300, loss = 0.455429
I0528 05:42:55.161478 15746 solver.cpp:244]     Train net output #0: loss = 0.455427 (* 1 = 0.455427 loss)
I0528 05:42:55.161500 15746 sgd_solver.cpp:106] Iteration 48300, lr = 1e-05
I0528 05:51:07.085258 15746 solver.cpp:228] Iteration 48400, loss = 0.339928
I0528 05:51:07.086735 15746 solver.cpp:244]     Train net output #0: loss = 0.339926 (* 1 = 0.339926 loss)
I0528 05:51:07.086757 15746 sgd_solver.cpp:106] Iteration 48400, lr = 1e-05
I0528 05:59:26.090569 15746 solver.cpp:228] Iteration 48500, loss = 0.28759
I0528 05:59:26.093164 15746 solver.cpp:244]     Train net output #0: loss = 0.287588 (* 1 = 0.287588 loss)
I0528 05:59:26.093185 15746 sgd_solver.cpp:106] Iteration 48500, lr = 1e-05
I0528 06:07:41.760934 15746 solver.cpp:228] Iteration 48600, loss = 0.393181
I0528 06:07:41.761916 15746 solver.cpp:244]     Train net output #0: loss = 0.393178 (* 1 = 0.393178 loss)
I0528 06:07:41.761940 15746 sgd_solver.cpp:106] Iteration 48600, lr = 1e-05
I0528 06:15:58.766540 15746 solver.cpp:228] Iteration 48700, loss = 0.403563
I0528 06:15:58.767592 15746 solver.cpp:244]     Train net output #0: loss = 0.40356 (* 1 = 0.40356 loss)
I0528 06:15:58.767621 15746 sgd_solver.cpp:106] Iteration 48700, lr = 1e-05
I0528 06:24:14.395177 15746 solver.cpp:228] Iteration 48800, loss = 0.543444
I0528 06:24:14.396206 15746 solver.cpp:244]     Train net output #0: loss = 0.543442 (* 1 = 0.543442 loss)
I0528 06:24:14.396232 15746 sgd_solver.cpp:106] Iteration 48800, lr = 1e-05
I0528 06:32:24.954537 15746 solver.cpp:228] Iteration 48900, loss = 0.379981
I0528 06:32:24.958374 15746 solver.cpp:244]     Train net output #0: loss = 0.379979 (* 1 = 0.379979 loss)
I0528 06:32:24.958395 15746 sgd_solver.cpp:106] Iteration 48900, lr = 1e-05
I0528 06:38:21.051692 15746 solver.cpp:337] Iteration 48975, Testing net (#0)
I0528 06:38:21.054826 15746 net.cpp:685] Ignoring source layer ratemap
I0528 06:38:21.054847 15746 net.cpp:685] Ignoring source layer amsFeatures
I0528 06:41:13.134698 15746 solver.cpp:404]     Test net output #0: loss = 0.535133 (* 1 = 0.535133 loss)
I0528 06:43:30.884325 15746 solver.cpp:228] Iteration 49000, loss = 0.616187
I0528 06:43:30.907241 15746 solver.cpp:244]     Train net output #0: loss = 0.616185 (* 1 = 0.616185 loss)
I0528 06:43:30.907269 15746 sgd_solver.cpp:106] Iteration 49000, lr = 1e-05
I0528 06:51:50.871995 15746 solver.cpp:228] Iteration 49100, loss = 0.584219
I0528 06:51:51.041882 15746 solver.cpp:244]     Train net output #0: loss = 0.584217 (* 1 = 0.584217 loss)
I0528 06:51:51.041905 15746 sgd_solver.cpp:106] Iteration 49100, lr = 1e-05
I0528 06:59:54.022490 15746 solver.cpp:228] Iteration 49200, loss = 0.333979
I0528 06:59:54.026098 15746 solver.cpp:244]     Train net output #0: loss = 0.333977 (* 1 = 0.333977 loss)
I0528 06:59:54.026123 15746 sgd_solver.cpp:106] Iteration 49200, lr = 1e-05
I0528 07:08:22.164880 15746 solver.cpp:228] Iteration 49300, loss = 0.806691
I0528 07:08:22.165514 15746 solver.cpp:244]     Train net output #0: loss = 0.806688 (* 1 = 0.806688 loss)
I0528 07:08:22.165534 15746 sgd_solver.cpp:106] Iteration 49300, lr = 1e-05
I0528 07:16:39.272313 15746 solver.cpp:228] Iteration 49400, loss = 0.63083
I0528 07:16:39.272866 15746 solver.cpp:244]     Train net output #0: loss = 0.630828 (* 1 = 0.630828 loss)
I0528 07:16:39.272886 15746 sgd_solver.cpp:106] Iteration 49400, lr = 1e-05
I0528 07:24:45.592762 15746 solver.cpp:228] Iteration 49500, loss = 0.302477
I0528 07:24:45.593477 15746 solver.cpp:244]     Train net output #0: loss = 0.302474 (* 1 = 0.302474 loss)
I0528 07:24:45.593509 15746 sgd_solver.cpp:106] Iteration 49500, lr = 1e-05
I0528 07:33:04.308575 15746 solver.cpp:228] Iteration 49600, loss = 0.62136
I0528 07:33:04.313148 15746 solver.cpp:244]     Train net output #0: loss = 0.621358 (* 1 = 0.621358 loss)
I0528 07:33:04.313169 15746 sgd_solver.cpp:106] Iteration 49600, lr = 1e-05
I0528 07:41:26.864171 15746 solver.cpp:228] Iteration 49700, loss = 0.393765
I0528 07:41:26.864720 15746 solver.cpp:244]     Train net output #0: loss = 0.393763 (* 1 = 0.393763 loss)
I0528 07:41:26.864753 15746 sgd_solver.cpp:106] Iteration 49700, lr = 1e-05
I0528 07:49:40.309900 15746 solver.cpp:228] Iteration 49800, loss = 0.480334
I0528 07:49:40.310626 15746 solver.cpp:244]     Train net output #0: loss = 0.480331 (* 1 = 0.480331 loss)
I0528 07:49:40.310650 15746 sgd_solver.cpp:106] Iteration 49800, lr = 1e-05
I0528 07:57:52.949343 15746 solver.cpp:228] Iteration 49900, loss = 0.505799
I0528 07:57:52.953760 15746 solver.cpp:244]     Train net output #0: loss = 0.505796 (* 1 = 0.505796 loss)
I0528 07:57:52.953790 15746 sgd_solver.cpp:106] Iteration 49900, lr = 1e-05
I0528 08:06:10.896693 15746 solver.cpp:228] Iteration 50000, loss = 0.869542
I0528 08:06:10.897337 15746 solver.cpp:244]     Train net output #0: loss = 0.86954 (* 1 = 0.86954 loss)
I0528 08:06:10.897358 15746 sgd_solver.cpp:106] Iteration 50000, lr = 1e-05
I0528 08:14:35.427702 15746 solver.cpp:228] Iteration 50100, loss = 0.365141
I0528 08:14:35.428213 15746 solver.cpp:244]     Train net output #0: loss = 0.365138 (* 1 = 0.365138 loss)
I0528 08:14:35.428234 15746 sgd_solver.cpp:106] Iteration 50100, lr = 1e-05
I0528 08:22:45.502660 15746 solver.cpp:228] Iteration 50200, loss = 0.47328
I0528 08:22:45.503433 15746 solver.cpp:244]     Train net output #0: loss = 0.473278 (* 1 = 0.473278 loss)
I0528 08:22:45.503471 15746 sgd_solver.cpp:106] Iteration 50200, lr = 1e-05
I0528 08:31:01.731168 15746 solver.cpp:228] Iteration 50300, loss = 0.594124
I0528 08:31:01.731842 15746 solver.cpp:244]     Train net output #0: loss = 0.594122 (* 1 = 0.594122 loss)
I0528 08:31:01.731878 15746 sgd_solver.cpp:106] Iteration 50300, lr = 1e-05
I0528 08:39:28.125000 15746 solver.cpp:228] Iteration 50400, loss = 0.499895
I0528 08:39:28.125692 15746 solver.cpp:244]     Train net output #0: loss = 0.499892 (* 1 = 0.499892 loss)
I0528 08:39:28.125720 15746 sgd_solver.cpp:106] Iteration 50400, lr = 1e-05
I0528 08:47:46.619842 15746 solver.cpp:228] Iteration 50500, loss = 0.405238
I0528 08:47:46.623131 15746 solver.cpp:244]     Train net output #0: loss = 0.405236 (* 1 = 0.405236 loss)
I0528 08:47:46.623154 15746 sgd_solver.cpp:106] Iteration 50500, lr = 1e-05
I0528 08:56:06.620874 15746 solver.cpp:228] Iteration 50600, loss = 0.720713
I0528 08:56:06.621469 15746 solver.cpp:244]     Train net output #0: loss = 0.720711 (* 1 = 0.720711 loss)
I0528 08:56:06.621480 15746 sgd_solver.cpp:106] Iteration 50600, lr = 1e-05
I0528 09:04:01.081507 15746 solver.cpp:228] Iteration 50700, loss = 0.369053
I0528 09:04:01.082087 15746 solver.cpp:244]     Train net output #0: loss = 0.369051 (* 1 = 0.369051 loss)
I0528 09:04:01.082106 15746 sgd_solver.cpp:106] Iteration 50700, lr = 1e-05
I0528 09:11:58.009636 15746 solver.cpp:228] Iteration 50800, loss = 0.573058
I0528 09:11:58.010296 15746 solver.cpp:244]     Train net output #0: loss = 0.573056 (* 1 = 0.573056 loss)
I0528 09:11:58.010318 15746 sgd_solver.cpp:106] Iteration 50800, lr = 1e-05
I0528 09:19:56.451973 15746 solver.cpp:228] Iteration 50900, loss = 0.639966
I0528 09:19:56.452636 15746 solver.cpp:244]     Train net output #0: loss = 0.639964 (* 1 = 0.639964 loss)
I0528 09:19:56.452672 15746 sgd_solver.cpp:106] Iteration 50900, lr = 1e-05
I0528 09:27:40.863323 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_51000.caffemodel
I0528 09:27:41.053658 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_51000.solverstate
I0528 09:27:46.383306 15746 solver.cpp:228] Iteration 51000, loss = 0.322799
I0528 09:27:46.383383 15746 solver.cpp:244]     Train net output #0: loss = 0.322797 (* 1 = 0.322797 loss)
I0528 09:27:46.383395 15746 sgd_solver.cpp:106] Iteration 51000, lr = 1e-05
I0528 09:35:35.123098 15746 solver.cpp:228] Iteration 51100, loss = 0.822746
I0528 09:35:35.126559 15746 solver.cpp:244]     Train net output #0: loss = 0.822743 (* 1 = 0.822743 loss)
I0528 09:35:35.126600 15746 sgd_solver.cpp:106] Iteration 51100, lr = 1e-05
I0528 09:43:35.333513 15746 solver.cpp:228] Iteration 51200, loss = 0.795701
I0528 09:43:35.334220 15746 solver.cpp:244]     Train net output #0: loss = 0.795699 (* 1 = 0.795699 loss)
I0528 09:43:35.334254 15746 sgd_solver.cpp:106] Iteration 51200, lr = 1e-05
I0528 09:51:34.633540 15746 solver.cpp:228] Iteration 51300, loss = 0.604055
I0528 09:51:34.634203 15746 solver.cpp:244]     Train net output #0: loss = 0.604052 (* 1 = 0.604052 loss)
I0528 09:51:34.634227 15746 sgd_solver.cpp:106] Iteration 51300, lr = 1e-05
I0528 09:59:27.695104 15746 solver.cpp:228] Iteration 51400, loss = 0.858739
I0528 09:59:27.695778 15746 solver.cpp:244]     Train net output #0: loss = 0.858737 (* 1 = 0.858737 loss)
I0528 09:59:27.695804 15746 sgd_solver.cpp:106] Iteration 51400, lr = 1e-05
I0528 10:07:23.328097 15746 solver.cpp:228] Iteration 51500, loss = 0.494415
I0528 10:07:23.328851 15746 solver.cpp:244]     Train net output #0: loss = 0.494413 (* 1 = 0.494413 loss)
I0528 10:07:23.328874 15746 sgd_solver.cpp:106] Iteration 51500, lr = 1e-05
I0528 10:15:25.309859 15746 solver.cpp:228] Iteration 51600, loss = 0.323458
I0528 10:15:25.310576 15746 solver.cpp:244]     Train net output #0: loss = 0.323455 (* 1 = 0.323455 loss)
I0528 10:15:25.310624 15746 sgd_solver.cpp:106] Iteration 51600, lr = 1e-05
I0528 10:23:14.435206 15746 solver.cpp:228] Iteration 51700, loss = 0.472209
I0528 10:23:14.435992 15746 solver.cpp:244]     Train net output #0: loss = 0.472206 (* 1 = 0.472206 loss)
I0528 10:23:14.436012 15746 sgd_solver.cpp:106] Iteration 51700, lr = 1e-05
I0528 10:31:10.327489 15746 solver.cpp:228] Iteration 51800, loss = 0.458759
I0528 10:31:10.328369 15746 solver.cpp:244]     Train net output #0: loss = 0.458756 (* 1 = 0.458756 loss)
I0528 10:31:10.328392 15746 sgd_solver.cpp:106] Iteration 51800, lr = 1e-05
I0528 10:39:02.676874 15746 solver.cpp:228] Iteration 51900, loss = 0.585413
I0528 10:39:02.677510 15746 solver.cpp:244]     Train net output #0: loss = 0.58541 (* 1 = 0.58541 loss)
I0528 10:39:02.677534 15746 sgd_solver.cpp:106] Iteration 51900, lr = 1e-05
I0528 10:46:48.337940 15746 solver.cpp:228] Iteration 52000, loss = 0.295024
I0528 10:46:48.338670 15746 solver.cpp:244]     Train net output #0: loss = 0.295021 (* 1 = 0.295021 loss)
I0528 10:46:48.338709 15746 sgd_solver.cpp:106] Iteration 52000, lr = 1e-05
I0528 10:54:44.191189 15746 solver.cpp:228] Iteration 52100, loss = 0.364407
I0528 10:54:44.191957 15746 solver.cpp:244]     Train net output #0: loss = 0.364404 (* 1 = 0.364404 loss)
I0528 10:54:44.191985 15746 sgd_solver.cpp:106] Iteration 52100, lr = 1e-05
I0528 11:02:25.532852 15746 solver.cpp:228] Iteration 52200, loss = 0.66598
I0528 11:02:25.533674 15746 solver.cpp:244]     Train net output #0: loss = 0.665978 (* 1 = 0.665978 loss)
I0528 11:02:25.533715 15746 sgd_solver.cpp:106] Iteration 52200, lr = 1e-05
I0528 11:05:24.993125 15746 solver.cpp:337] Iteration 52240, Testing net (#0)
I0528 11:05:24.993526 15746 net.cpp:685] Ignoring source layer ratemap
I0528 11:05:24.993549 15746 net.cpp:685] Ignoring source layer amsFeatures
I0528 11:08:14.922483 15746 solver.cpp:404]     Test net output #0: loss = 0.527082 (* 1 = 0.527082 loss)
I0528 11:13:06.950949 15746 solver.cpp:228] Iteration 52300, loss = 0.527151
I0528 11:13:06.951390 15746 solver.cpp:244]     Train net output #0: loss = 0.527149 (* 1 = 0.527149 loss)
I0528 11:13:06.951413 15746 sgd_solver.cpp:106] Iteration 52300, lr = 1e-05
I0528 11:20:59.076441 15746 solver.cpp:228] Iteration 52400, loss = 1.21567
I0528 11:20:59.077114 15746 solver.cpp:244]     Train net output #0: loss = 1.21567 (* 1 = 1.21567 loss)
I0528 11:20:59.077134 15746 sgd_solver.cpp:106] Iteration 52400, lr = 1e-05
I0528 11:28:53.805591 15746 solver.cpp:228] Iteration 52500, loss = 0.420683
I0528 11:28:53.806313 15746 solver.cpp:244]     Train net output #0: loss = 0.420681 (* 1 = 0.420681 loss)
I0528 11:28:53.806335 15746 sgd_solver.cpp:106] Iteration 52500, lr = 1e-05
I0528 11:36:51.755801 15746 solver.cpp:228] Iteration 52600, loss = 0.824232
I0528 11:36:51.756536 15746 solver.cpp:244]     Train net output #0: loss = 0.824229 (* 1 = 0.824229 loss)
I0528 11:36:51.756558 15746 sgd_solver.cpp:106] Iteration 52600, lr = 1e-05
I0528 11:44:46.052714 15746 solver.cpp:228] Iteration 52700, loss = 0.444184
I0528 11:44:46.053340 15746 solver.cpp:244]     Train net output #0: loss = 0.444181 (* 1 = 0.444181 loss)
I0528 11:44:46.053360 15746 sgd_solver.cpp:106] Iteration 52700, lr = 1e-05
I0528 11:52:54.915911 15746 solver.cpp:228] Iteration 52800, loss = 0.707437
I0528 11:52:54.916533 15746 solver.cpp:244]     Train net output #0: loss = 0.707435 (* 1 = 0.707435 loss)
I0528 11:52:54.916544 15746 sgd_solver.cpp:106] Iteration 52800, lr = 1e-05
I0528 12:00:40.592150 15746 solver.cpp:228] Iteration 52900, loss = 0.425126
I0528 12:00:40.592772 15746 solver.cpp:244]     Train net output #0: loss = 0.425124 (* 1 = 0.425124 loss)
I0528 12:00:40.592795 15746 sgd_solver.cpp:106] Iteration 52900, lr = 1e-05
I0528 12:08:46.207111 15746 solver.cpp:228] Iteration 53000, loss = 0.326065
I0528 12:08:46.207860 15746 solver.cpp:244]     Train net output #0: loss = 0.326062 (* 1 = 0.326062 loss)
I0528 12:08:46.207885 15746 sgd_solver.cpp:106] Iteration 53000, lr = 1e-05
I0528 12:16:30.634963 15746 solver.cpp:228] Iteration 53100, loss = 0.737214
I0528 12:16:30.635648 15746 solver.cpp:244]     Train net output #0: loss = 0.737211 (* 1 = 0.737211 loss)
I0528 12:16:30.635676 15746 sgd_solver.cpp:106] Iteration 53100, lr = 1e-05
I0528 12:24:30.054325 15746 solver.cpp:228] Iteration 53200, loss = 0.479646
I0528 12:24:30.055001 15746 solver.cpp:244]     Train net output #0: loss = 0.479643 (* 1 = 0.479643 loss)
I0528 12:24:30.055022 15746 sgd_solver.cpp:106] Iteration 53200, lr = 1e-05
I0528 12:32:38.759876 15746 solver.cpp:228] Iteration 53300, loss = 0.399326
I0528 12:32:38.760572 15746 solver.cpp:244]     Train net output #0: loss = 0.399323 (* 1 = 0.399323 loss)
I0528 12:32:38.760593 15746 sgd_solver.cpp:106] Iteration 53300, lr = 1e-05
I0528 12:40:29.700709 15746 solver.cpp:228] Iteration 53400, loss = 0.453809
I0528 12:40:29.701344 15746 solver.cpp:244]     Train net output #0: loss = 0.453806 (* 1 = 0.453806 loss)
I0528 12:40:29.701364 15746 sgd_solver.cpp:106] Iteration 53400, lr = 1e-05
I0528 12:48:23.247117 15746 solver.cpp:228] Iteration 53500, loss = 0.482797
I0528 12:48:23.247761 15746 solver.cpp:244]     Train net output #0: loss = 0.482794 (* 1 = 0.482794 loss)
I0528 12:48:23.247795 15746 sgd_solver.cpp:106] Iteration 53500, lr = 1e-05
I0528 12:56:30.655798 15746 solver.cpp:228] Iteration 53600, loss = 0.503263
I0528 12:56:30.656690 15746 solver.cpp:244]     Train net output #0: loss = 0.50326 (* 1 = 0.50326 loss)
I0528 12:56:30.656718 15746 sgd_solver.cpp:106] Iteration 53600, lr = 1e-05
I0528 13:04:28.691647 15746 solver.cpp:228] Iteration 53700, loss = 0.450125
I0528 13:04:28.692368 15746 solver.cpp:244]     Train net output #0: loss = 0.450123 (* 1 = 0.450123 loss)
I0528 13:04:28.692401 15746 sgd_solver.cpp:106] Iteration 53700, lr = 1e-05
I0528 13:12:39.556349 15746 solver.cpp:228] Iteration 53800, loss = 0.590589
I0528 13:12:39.557031 15746 solver.cpp:244]     Train net output #0: loss = 0.590586 (* 1 = 0.590586 loss)
I0528 13:12:39.557051 15746 sgd_solver.cpp:106] Iteration 53800, lr = 1e-05
I0528 13:20:47.149355 15746 solver.cpp:228] Iteration 53900, loss = 0.714684
I0528 13:20:47.150018 15746 solver.cpp:244]     Train net output #0: loss = 0.714682 (* 1 = 0.714682 loss)
I0528 13:20:47.150043 15746 sgd_solver.cpp:106] Iteration 53900, lr = 1e-05
I0528 13:28:49.523598 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_54000.caffemodel
I0528 13:28:49.693943 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_54000.solverstate
I0528 13:28:53.567293 15746 solver.cpp:228] Iteration 54000, loss = 0.763193
I0528 13:28:53.567373 15746 solver.cpp:244]     Train net output #0: loss = 0.76319 (* 1 = 0.76319 loss)
I0528 13:28:53.567383 15746 sgd_solver.cpp:106] Iteration 54000, lr = 1e-05
I0528 13:36:53.375746 15746 solver.cpp:228] Iteration 54100, loss = 0.71774
I0528 13:36:53.376451 15746 solver.cpp:244]     Train net output #0: loss = 0.717737 (* 1 = 0.717737 loss)
I0528 13:36:53.376471 15746 sgd_solver.cpp:106] Iteration 54100, lr = 1e-05
I0528 13:44:50.032824 15746 solver.cpp:228] Iteration 54200, loss = 0.712699
I0528 13:44:50.033538 15746 solver.cpp:244]     Train net output #0: loss = 0.712696 (* 1 = 0.712696 loss)
I0528 13:44:50.033557 15746 sgd_solver.cpp:106] Iteration 54200, lr = 1e-05
I0528 13:52:36.296022 15746 solver.cpp:228] Iteration 54300, loss = 0.470161
I0528 13:52:36.296700 15746 solver.cpp:244]     Train net output #0: loss = 0.470159 (* 1 = 0.470159 loss)
I0528 13:52:36.296720 15746 sgd_solver.cpp:106] Iteration 54300, lr = 1e-05
I0528 14:00:23.051635 15746 solver.cpp:228] Iteration 54400, loss = 0.403719
I0528 14:00:23.052439 15746 solver.cpp:244]     Train net output #0: loss = 0.403716 (* 1 = 0.403716 loss)
I0528 14:00:23.052474 15746 sgd_solver.cpp:106] Iteration 54400, lr = 1e-05
I0528 14:08:05.121409 15746 solver.cpp:228] Iteration 54500, loss = 0.680218
I0528 14:08:05.122061 15746 solver.cpp:244]     Train net output #0: loss = 0.680215 (* 1 = 0.680215 loss)
I0528 14:08:05.122082 15746 sgd_solver.cpp:106] Iteration 54500, lr = 1e-05
I0528 14:16:17.136240 15746 solver.cpp:228] Iteration 54600, loss = 0.805821
I0528 14:16:17.136886 15746 solver.cpp:244]     Train net output #0: loss = 0.805818 (* 1 = 0.805818 loss)
I0528 14:16:17.136898 15746 sgd_solver.cpp:106] Iteration 54600, lr = 1e-05
I0528 14:24:12.842684 15746 solver.cpp:228] Iteration 54700, loss = 0.319975
I0528 14:24:12.843439 15746 solver.cpp:244]     Train net output #0: loss = 0.319972 (* 1 = 0.319972 loss)
I0528 14:24:12.843464 15746 sgd_solver.cpp:106] Iteration 54700, lr = 1e-05
I0528 14:32:10.151653 15746 solver.cpp:228] Iteration 54800, loss = 0.437829
I0528 14:32:10.152431 15746 solver.cpp:244]     Train net output #0: loss = 0.437826 (* 1 = 0.437826 loss)
I0528 14:32:10.152456 15746 sgd_solver.cpp:106] Iteration 54800, lr = 1e-05
I0528 14:40:12.521153 15746 solver.cpp:228] Iteration 54900, loss = 0.299214
I0528 14:40:12.521930 15746 solver.cpp:244]     Train net output #0: loss = 0.299212 (* 1 = 0.299212 loss)
I0528 14:40:12.521950 15746 sgd_solver.cpp:106] Iteration 54900, lr = 1e-05
I0528 14:48:19.189126 15746 solver.cpp:228] Iteration 55000, loss = 0.581805
I0528 14:48:19.189836 15746 solver.cpp:244]     Train net output #0: loss = 0.581802 (* 1 = 0.581802 loss)
I0528 14:48:19.189860 15746 sgd_solver.cpp:106] Iteration 55000, lr = 1e-05
I0528 14:56:12.354176 15746 solver.cpp:228] Iteration 55100, loss = 0.610665
I0528 14:56:12.354883 15746 solver.cpp:244]     Train net output #0: loss = 0.610663 (* 1 = 0.610663 loss)
I0528 14:56:12.354918 15746 sgd_solver.cpp:106] Iteration 55100, lr = 1e-05
I0528 15:04:16.160262 15746 solver.cpp:228] Iteration 55200, loss = 1.00945
I0528 15:04:16.161001 15746 solver.cpp:244]     Train net output #0: loss = 1.00944 (* 1 = 1.00944 loss)
I0528 15:04:16.161037 15746 sgd_solver.cpp:106] Iteration 55200, lr = 1e-05
I0528 15:12:13.925016 15746 solver.cpp:228] Iteration 55300, loss = 0.580324
I0528 15:12:13.925736 15746 solver.cpp:244]     Train net output #0: loss = 0.580321 (* 1 = 0.580321 loss)
I0528 15:12:13.925761 15746 sgd_solver.cpp:106] Iteration 55300, lr = 1e-05
I0528 15:20:23.312124 15746 solver.cpp:228] Iteration 55400, loss = 0.45058
I0528 15:20:23.312873 15746 solver.cpp:244]     Train net output #0: loss = 0.450578 (* 1 = 0.450578 loss)
I0528 15:20:23.312893 15746 sgd_solver.cpp:106] Iteration 55400, lr = 1e-05
I0528 15:28:40.454612 15746 solver.cpp:228] Iteration 55500, loss = 0.422722
I0528 15:28:40.455322 15746 solver.cpp:244]     Train net output #0: loss = 0.422719 (* 1 = 0.422719 loss)
I0528 15:28:40.455345 15746 sgd_solver.cpp:106] Iteration 55500, lr = 1e-05
I0528 15:29:02.282088 15746 solver.cpp:337] Iteration 55505, Testing net (#0)
I0528 15:29:02.282119 15746 net.cpp:685] Ignoring source layer ratemap
I0528 15:29:02.282124 15746 net.cpp:685] Ignoring source layer amsFeatures
I0528 15:31:53.903707 15746 solver.cpp:404]     Test net output #0: loss = 0.529635 (* 1 = 0.529635 loss)
I0528 15:39:24.819198 15746 solver.cpp:228] Iteration 55600, loss = 0.460886
I0528 15:39:24.819886 15746 solver.cpp:244]     Train net output #0: loss = 0.460883 (* 1 = 0.460883 loss)
I0528 15:39:24.819914 15746 sgd_solver.cpp:106] Iteration 55600, lr = 1e-05
I0528 15:47:20.438452 15746 solver.cpp:228] Iteration 55700, loss = 0.555878
I0528 15:47:20.439061 15746 solver.cpp:244]     Train net output #0: loss = 0.555876 (* 1 = 0.555876 loss)
I0528 15:47:20.439074 15746 sgd_solver.cpp:106] Iteration 55700, lr = 1e-05
I0528 15:55:15.305155 15746 solver.cpp:228] Iteration 55800, loss = 0.462163
I0528 15:55:15.307560 15746 solver.cpp:244]     Train net output #0: loss = 0.46216 (* 1 = 0.46216 loss)
I0528 15:55:15.307580 15746 sgd_solver.cpp:106] Iteration 55800, lr = 1e-05
I0528 16:03:16.130250 15746 solver.cpp:228] Iteration 55900, loss = 0.304958
I0528 16:03:16.131011 15746 solver.cpp:244]     Train net output #0: loss = 0.304955 (* 1 = 0.304955 loss)
I0528 16:03:16.131047 15746 sgd_solver.cpp:106] Iteration 55900, lr = 1e-05
I0528 16:11:18.273893 15746 solver.cpp:228] Iteration 56000, loss = 0.66852
I0528 16:11:18.274608 15746 solver.cpp:244]     Train net output #0: loss = 0.668517 (* 1 = 0.668517 loss)
I0528 16:11:18.274633 15746 sgd_solver.cpp:106] Iteration 56000, lr = 1e-05
I0528 16:19:18.833273 15746 solver.cpp:228] Iteration 56100, loss = 0.507414
I0528 16:19:18.833899 15746 solver.cpp:244]     Train net output #0: loss = 0.507411 (* 1 = 0.507411 loss)
I0528 16:19:18.833922 15746 sgd_solver.cpp:106] Iteration 56100, lr = 1e-05
I0528 16:27:13.450383 15746 solver.cpp:228] Iteration 56200, loss = 0.49013
I0528 16:27:13.451216 15746 solver.cpp:244]     Train net output #0: loss = 0.490128 (* 1 = 0.490128 loss)
I0528 16:27:13.451246 15746 sgd_solver.cpp:106] Iteration 56200, lr = 1e-05
I0528 16:35:09.646097 15746 solver.cpp:228] Iteration 56300, loss = 0.344758
I0528 16:35:09.646875 15746 solver.cpp:244]     Train net output #0: loss = 0.344755 (* 1 = 0.344755 loss)
I0528 16:35:09.646895 15746 sgd_solver.cpp:106] Iteration 56300, lr = 1e-05
I0528 16:43:23.111167 15746 solver.cpp:228] Iteration 56400, loss = 0.39178
I0528 16:43:23.111948 15746 solver.cpp:244]     Train net output #0: loss = 0.391777 (* 1 = 0.391777 loss)
I0528 16:43:23.111975 15746 sgd_solver.cpp:106] Iteration 56400, lr = 1e-05
I0528 16:51:33.437034 15746 solver.cpp:228] Iteration 56500, loss = 0.716438
I0528 16:51:33.437818 15746 solver.cpp:244]     Train net output #0: loss = 0.716435 (* 1 = 0.716435 loss)
I0528 16:51:33.437837 15746 sgd_solver.cpp:106] Iteration 56500, lr = 1e-05
I0528 16:59:27.102586 15746 solver.cpp:228] Iteration 56600, loss = 0.41398
I0528 16:59:27.103384 15746 solver.cpp:244]     Train net output #0: loss = 0.413977 (* 1 = 0.413977 loss)
I0528 16:59:27.103415 15746 sgd_solver.cpp:106] Iteration 56600, lr = 1e-05
I0528 17:07:34.985471 15746 solver.cpp:228] Iteration 56700, loss = 0.505696
I0528 17:07:34.986241 15746 solver.cpp:244]     Train net output #0: loss = 0.505693 (* 1 = 0.505693 loss)
I0528 17:07:34.986273 15746 sgd_solver.cpp:106] Iteration 56700, lr = 1e-05
I0528 17:15:44.640877 15746 solver.cpp:228] Iteration 56800, loss = 0.386279
I0528 17:15:44.641609 15746 solver.cpp:244]     Train net output #0: loss = 0.386276 (* 1 = 0.386276 loss)
I0528 17:15:44.641629 15746 sgd_solver.cpp:106] Iteration 56800, lr = 1e-05
I0528 17:23:54.429461 15746 solver.cpp:228] Iteration 56900, loss = 0.588443
I0528 17:23:54.430186 15746 solver.cpp:244]     Train net output #0: loss = 0.58844 (* 1 = 0.58844 loss)
I0528 17:23:54.430207 15746 sgd_solver.cpp:106] Iteration 56900, lr = 1e-05
I0528 17:32:01.259979 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_57000.caffemodel
I0528 17:32:01.448573 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_57000.solverstate
I0528 17:32:06.211143 15746 solver.cpp:228] Iteration 57000, loss = 0.400135
I0528 17:32:06.211210 15746 solver.cpp:244]     Train net output #0: loss = 0.400132 (* 1 = 0.400132 loss)
I0528 17:32:06.211220 15746 sgd_solver.cpp:106] Iteration 57000, lr = 1e-05
I0528 17:40:10.056718 15746 solver.cpp:228] Iteration 57100, loss = 0.474784
I0528 17:40:10.057503 15746 solver.cpp:244]     Train net output #0: loss = 0.474781 (* 1 = 0.474781 loss)
I0528 17:40:10.057539 15746 sgd_solver.cpp:106] Iteration 57100, lr = 1e-05
I0528 17:48:10.896875 15746 solver.cpp:228] Iteration 57200, loss = 0.442116
I0528 17:48:10.897522 15746 solver.cpp:244]     Train net output #0: loss = 0.442113 (* 1 = 0.442113 loss)
I0528 17:48:10.897542 15746 sgd_solver.cpp:106] Iteration 57200, lr = 1e-05
I0528 17:56:08.094403 15746 solver.cpp:228] Iteration 57300, loss = 0.736545
I0528 17:56:08.095119 15746 solver.cpp:244]     Train net output #0: loss = 0.736542 (* 1 = 0.736542 loss)
I0528 17:56:08.095149 15746 sgd_solver.cpp:106] Iteration 57300, lr = 1e-05
I0528 18:04:12.784670 15746 solver.cpp:228] Iteration 57400, loss = 0.427581
I0528 18:04:12.785462 15746 solver.cpp:244]     Train net output #0: loss = 0.427579 (* 1 = 0.427579 loss)
I0528 18:04:12.785487 15746 sgd_solver.cpp:106] Iteration 57400, lr = 1e-05
I0528 18:12:08.774606 15746 solver.cpp:228] Iteration 57500, loss = 0.673616
I0528 18:12:08.775441 15746 solver.cpp:244]     Train net output #0: loss = 0.673614 (* 1 = 0.673614 loss)
I0528 18:12:08.775490 15746 sgd_solver.cpp:106] Iteration 57500, lr = 1e-05
I0528 18:19:55.429116 15746 solver.cpp:228] Iteration 57600, loss = 0.581141
I0528 18:19:55.429942 15746 solver.cpp:244]     Train net output #0: loss = 0.581138 (* 1 = 0.581138 loss)
I0528 18:19:55.429983 15746 sgd_solver.cpp:106] Iteration 57600, lr = 1e-05
I0528 18:27:48.985205 15746 solver.cpp:228] Iteration 57700, loss = 0.543578
I0528 18:27:48.985977 15746 solver.cpp:244]     Train net output #0: loss = 0.543575 (* 1 = 0.543575 loss)
I0528 18:27:48.986011 15746 sgd_solver.cpp:106] Iteration 57700, lr = 1e-05
I0528 18:35:54.307030 15746 solver.cpp:228] Iteration 57800, loss = 0.463371
I0528 18:35:54.307838 15746 solver.cpp:244]     Train net output #0: loss = 0.463368 (* 1 = 0.463368 loss)
I0528 18:35:54.307880 15746 sgd_solver.cpp:106] Iteration 57800, lr = 1e-05
I0528 18:44:01.409905 15746 solver.cpp:228] Iteration 57900, loss = 0.593967
I0528 18:44:01.410548 15746 solver.cpp:244]     Train net output #0: loss = 0.593965 (* 1 = 0.593965 loss)
I0528 18:44:01.410568 15746 sgd_solver.cpp:106] Iteration 57900, lr = 1e-05
I0528 18:51:53.147192 15746 solver.cpp:228] Iteration 58000, loss = 0.356499
I0528 18:51:53.147778 15746 solver.cpp:244]     Train net output #0: loss = 0.356496 (* 1 = 0.356496 loss)
I0528 18:51:53.147799 15746 sgd_solver.cpp:106] Iteration 58000, lr = 1e-05
I0528 18:59:54.578150 15746 solver.cpp:228] Iteration 58100, loss = 0.554669
I0528 18:59:54.578898 15746 solver.cpp:244]     Train net output #0: loss = 0.554666 (* 1 = 0.554666 loss)
I0528 18:59:54.578939 15746 sgd_solver.cpp:106] Iteration 58100, lr = 1e-05
I0528 19:07:51.483464 15746 solver.cpp:228] Iteration 58200, loss = 0.377315
I0528 19:07:51.484158 15746 solver.cpp:244]     Train net output #0: loss = 0.377313 (* 1 = 0.377313 loss)
I0528 19:07:51.484181 15746 sgd_solver.cpp:106] Iteration 58200, lr = 1e-05
I0528 19:15:48.713086 15746 solver.cpp:228] Iteration 58300, loss = 0.306138
I0528 19:15:48.713593 15746 solver.cpp:244]     Train net output #0: loss = 0.306136 (* 1 = 0.306136 loss)
I0528 19:15:48.713613 15746 sgd_solver.cpp:106] Iteration 58300, lr = 1e-05
I0528 19:23:37.418761 15746 solver.cpp:228] Iteration 58400, loss = 0.458792
I0528 19:23:37.419219 15746 solver.cpp:244]     Train net output #0: loss = 0.45879 (* 1 = 0.45879 loss)
I0528 19:23:37.419244 15746 sgd_solver.cpp:106] Iteration 58400, lr = 1e-05
I0528 19:31:42.972981 15746 solver.cpp:228] Iteration 58500, loss = 0.654507
I0528 19:31:42.973414 15746 solver.cpp:244]     Train net output #0: loss = 0.654505 (* 1 = 0.654505 loss)
I0528 19:31:42.973444 15746 sgd_solver.cpp:106] Iteration 58500, lr = 1e-05
I0528 19:39:45.126616 15746 solver.cpp:228] Iteration 58600, loss = 0.710244
I0528 19:39:45.127351 15746 solver.cpp:244]     Train net output #0: loss = 0.710242 (* 1 = 0.710242 loss)
I0528 19:39:45.127368 15746 sgd_solver.cpp:106] Iteration 58600, lr = 1e-05
I0528 19:47:46.380360 15746 solver.cpp:228] Iteration 58700, loss = 0.500576
I0528 19:47:46.381026 15746 solver.cpp:244]     Train net output #0: loss = 0.500573 (* 1 = 0.500573 loss)
I0528 19:47:46.381043 15746 sgd_solver.cpp:106] Iteration 58700, lr = 1e-05
I0528 19:53:25.611169 15746 solver.cpp:337] Iteration 58770, Testing net (#0)
I0528 19:53:25.611749 15746 net.cpp:685] Ignoring source layer ratemap
I0528 19:53:25.611757 15746 net.cpp:685] Ignoring source layer amsFeatures
I0528 19:56:15.337479 15746 solver.cpp:404]     Test net output #0: loss = 0.528745 (* 1 = 0.528745 loss)
I0528 19:58:49.203598 15746 solver.cpp:228] Iteration 58800, loss = 0.331567
I0528 19:58:49.203989 15746 solver.cpp:244]     Train net output #0: loss = 0.331564 (* 1 = 0.331564 loss)
I0528 19:58:49.204005 15746 sgd_solver.cpp:106] Iteration 58800, lr = 1e-05
I0528 20:06:28.908756 15746 solver.cpp:228] Iteration 58900, loss = 0.918306
I0528 20:06:28.909385 15746 solver.cpp:244]     Train net output #0: loss = 0.918303 (* 1 = 0.918303 loss)
I0528 20:06:28.909399 15746 sgd_solver.cpp:106] Iteration 58900, lr = 1e-05
I0528 20:14:27.869585 15746 solver.cpp:228] Iteration 59000, loss = 0.610955
I0528 20:14:27.870348 15746 solver.cpp:244]     Train net output #0: loss = 0.610952 (* 1 = 0.610952 loss)
I0528 20:14:27.870376 15746 sgd_solver.cpp:106] Iteration 59000, lr = 1e-05
I0528 20:22:31.506026 15746 solver.cpp:228] Iteration 59100, loss = 0.542687
I0528 20:22:31.506850 15746 solver.cpp:244]     Train net output #0: loss = 0.542684 (* 1 = 0.542684 loss)
I0528 20:22:31.506875 15746 sgd_solver.cpp:106] Iteration 59100, lr = 1e-05
I0528 20:30:40.874620 15746 solver.cpp:228] Iteration 59200, loss = 0.858877
I0528 20:30:40.875327 15746 solver.cpp:244]     Train net output #0: loss = 0.858874 (* 1 = 0.858874 loss)
I0528 20:30:40.875352 15746 sgd_solver.cpp:106] Iteration 59200, lr = 1e-05
I0528 20:38:40.324756 15746 solver.cpp:228] Iteration 59300, loss = 0.400544
I0528 20:38:40.325428 15746 solver.cpp:244]     Train net output #0: loss = 0.400541 (* 1 = 0.400541 loss)
I0528 20:38:40.325444 15746 sgd_solver.cpp:106] Iteration 59300, lr = 1e-05
I0528 20:47:25.788861 15746 solver.cpp:228] Iteration 59400, loss = 0.517903
I0528 20:47:25.789495 15746 solver.cpp:244]     Train net output #0: loss = 0.5179 (* 1 = 0.5179 loss)
I0528 20:47:25.789511 15746 sgd_solver.cpp:106] Iteration 59400, lr = 1e-05
I0528 20:56:09.253048 15746 solver.cpp:228] Iteration 59500, loss = 0.356786
I0528 20:56:09.253746 15746 solver.cpp:244]     Train net output #0: loss = 0.356783 (* 1 = 0.356783 loss)
I0528 20:56:09.253762 15746 sgd_solver.cpp:106] Iteration 59500, lr = 1e-05
I0528 21:05:08.526036 15746 solver.cpp:228] Iteration 59600, loss = 0.307968
I0528 21:05:08.526690 15746 solver.cpp:244]     Train net output #0: loss = 0.307965 (* 1 = 0.307965 loss)
I0528 21:05:08.526705 15746 sgd_solver.cpp:106] Iteration 59600, lr = 1e-05
I0528 21:14:02.504355 15746 solver.cpp:228] Iteration 59700, loss = 0.476834
I0528 21:14:02.504998 15746 solver.cpp:244]     Train net output #0: loss = 0.476831 (* 1 = 0.476831 loss)
I0528 21:14:02.505014 15746 sgd_solver.cpp:106] Iteration 59700, lr = 1e-05
I0528 21:23:13.349841 15746 solver.cpp:228] Iteration 59800, loss = 0.776021
I0528 21:23:13.350502 15746 solver.cpp:244]     Train net output #0: loss = 0.776019 (* 1 = 0.776019 loss)
I0528 21:23:13.350518 15746 sgd_solver.cpp:106] Iteration 59800, lr = 1e-05
I0528 21:31:52.184646 15746 solver.cpp:228] Iteration 59900, loss = 0.41896
I0528 21:31:52.185283 15746 solver.cpp:244]     Train net output #0: loss = 0.418957 (* 1 = 0.418957 loss)
I0528 21:31:52.185299 15746 sgd_solver.cpp:106] Iteration 59900, lr = 1e-05
I0528 21:40:51.074520 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_60000.caffemodel
I0528 21:40:51.242794 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_60000.solverstate
I0528 21:40:56.931385 15746 solver.cpp:228] Iteration 60000, loss = 0.274718
I0528 21:40:56.931432 15746 solver.cpp:244]     Train net output #0: loss = 0.274716 (* 1 = 0.274716 loss)
I0528 21:40:56.931444 15746 sgd_solver.cpp:106] Iteration 60000, lr = 1e-06
I0528 21:49:24.661550 15746 solver.cpp:228] Iteration 60100, loss = 0.533389
I0528 21:49:24.662200 15746 solver.cpp:244]     Train net output #0: loss = 0.533387 (* 1 = 0.533387 loss)
I0528 21:49:24.662217 15746 sgd_solver.cpp:106] Iteration 60100, lr = 1e-06
I0528 21:58:23.471988 15746 solver.cpp:228] Iteration 60200, loss = 0.461068
I0528 21:58:23.472617 15746 solver.cpp:244]     Train net output #0: loss = 0.461065 (* 1 = 0.461065 loss)
I0528 21:58:23.472631 15746 sgd_solver.cpp:106] Iteration 60200, lr = 1e-06
I0528 22:07:23.436559 15746 solver.cpp:228] Iteration 60300, loss = 0.461843
I0528 22:07:23.437218 15746 solver.cpp:244]     Train net output #0: loss = 0.46184 (* 1 = 0.46184 loss)
I0528 22:07:23.437234 15746 sgd_solver.cpp:106] Iteration 60300, lr = 1e-06
I0528 22:16:01.779305 15746 solver.cpp:228] Iteration 60400, loss = 0.493907
I0528 22:16:01.779897 15746 solver.cpp:244]     Train net output #0: loss = 0.493904 (* 1 = 0.493904 loss)
I0528 22:16:01.779912 15746 sgd_solver.cpp:106] Iteration 60400, lr = 1e-06
I0528 22:24:49.185986 15746 solver.cpp:228] Iteration 60500, loss = 0.415699
I0528 22:24:49.186573 15746 solver.cpp:244]     Train net output #0: loss = 0.415696 (* 1 = 0.415696 loss)
I0528 22:24:49.186588 15746 sgd_solver.cpp:106] Iteration 60500, lr = 1e-06
I0528 22:33:55.897011 15746 solver.cpp:228] Iteration 60600, loss = 0.33964
I0528 22:33:55.897675 15746 solver.cpp:244]     Train net output #0: loss = 0.339637 (* 1 = 0.339637 loss)
I0528 22:33:55.897694 15746 sgd_solver.cpp:106] Iteration 60600, lr = 1e-06
I0528 22:42:46.724741 15746 solver.cpp:228] Iteration 60700, loss = 0.669998
I0528 22:42:46.725414 15746 solver.cpp:244]     Train net output #0: loss = 0.669996 (* 1 = 0.669996 loss)
I0528 22:42:46.725435 15746 sgd_solver.cpp:106] Iteration 60700, lr = 1e-06
I0528 22:51:51.566901 15746 solver.cpp:228] Iteration 60800, loss = 0.442933
I0528 22:51:51.567601 15746 solver.cpp:244]     Train net output #0: loss = 0.442931 (* 1 = 0.442931 loss)
I0528 22:51:51.567616 15746 sgd_solver.cpp:106] Iteration 60800, lr = 1e-06
I0528 23:00:49.787575 15746 solver.cpp:228] Iteration 60900, loss = 0.360679
I0528 23:00:49.788198 15746 solver.cpp:244]     Train net output #0: loss = 0.360676 (* 1 = 0.360676 loss)
I0528 23:00:49.788218 15746 sgd_solver.cpp:106] Iteration 60900, lr = 1e-06
I0528 23:09:34.217571 15746 solver.cpp:228] Iteration 61000, loss = 0.478514
I0528 23:09:34.218278 15746 solver.cpp:244]     Train net output #0: loss = 0.478511 (* 1 = 0.478511 loss)
I0528 23:09:34.218299 15746 sgd_solver.cpp:106] Iteration 61000, lr = 1e-06
I0528 23:18:28.792235 15746 solver.cpp:228] Iteration 61100, loss = 0.577349
I0528 23:18:28.795250 15746 solver.cpp:244]     Train net output #0: loss = 0.577346 (* 1 = 0.577346 loss)
I0528 23:18:28.795264 15746 sgd_solver.cpp:106] Iteration 61100, lr = 1e-06
I0528 23:27:30.955657 15746 solver.cpp:228] Iteration 61200, loss = 0.439946
I0528 23:27:30.956363 15746 solver.cpp:244]     Train net output #0: loss = 0.439944 (* 1 = 0.439944 loss)
I0528 23:27:30.956384 15746 sgd_solver.cpp:106] Iteration 61200, lr = 1e-06
I0528 23:36:03.780138 15746 solver.cpp:228] Iteration 61300, loss = 0.616016
I0528 23:36:03.780746 15746 solver.cpp:244]     Train net output #0: loss = 0.616013 (* 1 = 0.616013 loss)
I0528 23:36:03.780766 15746 sgd_solver.cpp:106] Iteration 61300, lr = 1e-06
I0528 23:44:02.257565 15746 solver.cpp:228] Iteration 61400, loss = 0.5183
I0528 23:44:02.258265 15746 solver.cpp:244]     Train net output #0: loss = 0.518297 (* 1 = 0.518297 loss)
I0528 23:44:02.258291 15746 sgd_solver.cpp:106] Iteration 61400, lr = 1e-06
I0528 23:51:27.737942 15746 solver.cpp:228] Iteration 61500, loss = 0.60923
I0528 23:51:27.738649 15746 solver.cpp:244]     Train net output #0: loss = 0.609227 (* 1 = 0.609227 loss)
I0528 23:51:27.738682 15746 sgd_solver.cpp:106] Iteration 61500, lr = 1e-06
I0528 23:59:11.945569 15746 solver.cpp:228] Iteration 61600, loss = 0.519238
I0528 23:59:11.946241 15746 solver.cpp:244]     Train net output #0: loss = 0.519235 (* 1 = 0.519235 loss)
I0528 23:59:11.946261 15746 sgd_solver.cpp:106] Iteration 61600, lr = 1e-06
I0529 00:07:12.459367 15746 solver.cpp:228] Iteration 61700, loss = 0.663705
I0529 00:07:12.460016 15746 solver.cpp:244]     Train net output #0: loss = 0.663702 (* 1 = 0.663702 loss)
I0529 00:07:12.460034 15746 sgd_solver.cpp:106] Iteration 61700, lr = 1e-06
I0529 00:15:18.389420 15746 solver.cpp:228] Iteration 61800, loss = 0.359175
I0529 00:15:18.390038 15746 solver.cpp:244]     Train net output #0: loss = 0.359172 (* 1 = 0.359172 loss)
I0529 00:15:18.390064 15746 sgd_solver.cpp:106] Iteration 61800, lr = 1e-06
I0529 00:23:04.389627 15746 solver.cpp:228] Iteration 61900, loss = 0.286831
I0529 00:23:04.390290 15746 solver.cpp:244]     Train net output #0: loss = 0.286829 (* 1 = 0.286829 loss)
I0529 00:23:04.390316 15746 sgd_solver.cpp:106] Iteration 61900, lr = 1e-06
I0529 00:31:04.433408 15746 solver.cpp:228] Iteration 62000, loss = 0.724289
I0529 00:31:04.434098 15746 solver.cpp:244]     Train net output #0: loss = 0.724286 (* 1 = 0.724286 loss)
I0529 00:31:04.434134 15746 sgd_solver.cpp:106] Iteration 62000, lr = 1e-06
I0529 00:33:52.402773 15746 solver.cpp:337] Iteration 62035, Testing net (#0)
I0529 00:33:52.403228 15746 net.cpp:685] Ignoring source layer ratemap
I0529 00:33:52.403249 15746 net.cpp:685] Ignoring source layer amsFeatures
I0529 00:36:43.959784 15746 solver.cpp:404]     Test net output #0: loss = 0.529622 (* 1 = 0.529622 loss)
I0529 00:41:59.047297 15746 solver.cpp:228] Iteration 62100, loss = 0.426589
I0529 00:41:59.047703 15746 solver.cpp:244]     Train net output #0: loss = 0.426587 (* 1 = 0.426587 loss)
I0529 00:41:59.047726 15746 sgd_solver.cpp:106] Iteration 62100, lr = 1e-06
I0529 00:49:51.844794 15746 solver.cpp:228] Iteration 62200, loss = 0.645599
I0529 00:49:51.845449 15746 solver.cpp:244]     Train net output #0: loss = 0.645596 (* 1 = 0.645596 loss)
I0529 00:49:51.845480 15746 sgd_solver.cpp:106] Iteration 62200, lr = 1e-06
I0529 00:57:47.968066 15746 solver.cpp:228] Iteration 62300, loss = 0.402286
I0529 00:57:47.968811 15746 solver.cpp:244]     Train net output #0: loss = 0.402283 (* 1 = 0.402283 loss)
I0529 00:57:47.968832 15746 sgd_solver.cpp:106] Iteration 62300, lr = 1e-06
I0529 01:05:40.009798 15746 solver.cpp:228] Iteration 62400, loss = 0.434175
I0529 01:05:40.010521 15746 solver.cpp:244]     Train net output #0: loss = 0.434172 (* 1 = 0.434172 loss)
I0529 01:05:40.010545 15746 sgd_solver.cpp:106] Iteration 62400, lr = 1e-06
I0529 01:13:37.069583 15746 solver.cpp:228] Iteration 62500, loss = 0.508371
I0529 01:13:37.070291 15746 solver.cpp:244]     Train net output #0: loss = 0.508369 (* 1 = 0.508369 loss)
I0529 01:13:37.070312 15746 sgd_solver.cpp:106] Iteration 62500, lr = 1e-06
I0529 01:21:41.790855 15746 solver.cpp:228] Iteration 62600, loss = 0.400943
I0529 01:21:41.791621 15746 solver.cpp:244]     Train net output #0: loss = 0.40094 (* 1 = 0.40094 loss)
I0529 01:21:41.791651 15746 sgd_solver.cpp:106] Iteration 62600, lr = 1e-06
I0529 01:29:44.893344 15746 solver.cpp:228] Iteration 62700, loss = 0.723397
I0529 01:29:44.894137 15746 solver.cpp:244]     Train net output #0: loss = 0.723395 (* 1 = 0.723395 loss)
I0529 01:29:44.894167 15746 sgd_solver.cpp:106] Iteration 62700, lr = 1e-06
I0529 01:37:48.523314 15746 solver.cpp:228] Iteration 62800, loss = 0.369167
I0529 01:37:48.524005 15746 solver.cpp:244]     Train net output #0: loss = 0.369164 (* 1 = 0.369164 loss)
I0529 01:37:48.524029 15746 sgd_solver.cpp:106] Iteration 62800, lr = 1e-06
I0529 01:46:13.264173 15746 solver.cpp:228] Iteration 62900, loss = 0.411036
I0529 01:46:13.264863 15746 solver.cpp:244]     Train net output #0: loss = 0.411033 (* 1 = 0.411033 loss)
I0529 01:46:13.264899 15746 sgd_solver.cpp:106] Iteration 62900, lr = 1e-06
I0529 01:54:21.398641 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_63000.caffemodel
I0529 01:54:21.588210 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_63000.solverstate
I0529 01:54:26.157261 15746 solver.cpp:228] Iteration 63000, loss = 0.371891
I0529 01:54:26.157331 15746 solver.cpp:244]     Train net output #0: loss = 0.371888 (* 1 = 0.371888 loss)
I0529 01:54:26.157341 15746 sgd_solver.cpp:106] Iteration 63000, lr = 1e-06
I0529 02:02:38.388758 15746 solver.cpp:228] Iteration 63100, loss = 0.480986
I0529 02:02:38.389505 15746 solver.cpp:244]     Train net output #0: loss = 0.480984 (* 1 = 0.480984 loss)
I0529 02:02:38.389539 15746 sgd_solver.cpp:106] Iteration 63100, lr = 1e-06
I0529 02:10:39.659782 15746 solver.cpp:228] Iteration 63200, loss = 0.743779
I0529 02:10:39.660601 15746 solver.cpp:244]     Train net output #0: loss = 0.743776 (* 1 = 0.743776 loss)
I0529 02:10:39.660622 15746 sgd_solver.cpp:106] Iteration 63200, lr = 1e-06
I0529 02:18:52.897069 15746 solver.cpp:228] Iteration 63300, loss = 0.559021
I0529 02:18:52.897889 15746 solver.cpp:244]     Train net output #0: loss = 0.559018 (* 1 = 0.559018 loss)
I0529 02:18:52.897910 15746 sgd_solver.cpp:106] Iteration 63300, lr = 1e-06
I0529 02:26:50.082788 15746 solver.cpp:228] Iteration 63400, loss = 0.431327
I0529 02:26:50.083587 15746 solver.cpp:244]     Train net output #0: loss = 0.431324 (* 1 = 0.431324 loss)
I0529 02:26:50.083611 15746 sgd_solver.cpp:106] Iteration 63400, lr = 1e-06
I0529 02:34:51.382705 15746 solver.cpp:228] Iteration 63500, loss = 0.345251
I0529 02:34:51.383448 15746 solver.cpp:244]     Train net output #0: loss = 0.345248 (* 1 = 0.345248 loss)
I0529 02:34:51.383482 15746 sgd_solver.cpp:106] Iteration 63500, lr = 1e-06
I0529 02:43:06.494433 15746 solver.cpp:228] Iteration 63600, loss = 0.294851
I0529 02:43:06.495245 15746 solver.cpp:244]     Train net output #0: loss = 0.294849 (* 1 = 0.294849 loss)
I0529 02:43:06.495290 15746 sgd_solver.cpp:106] Iteration 63600, lr = 1e-06
I0529 02:51:05.714901 15746 solver.cpp:228] Iteration 63700, loss = 0.40098
I0529 02:51:05.715648 15746 solver.cpp:244]     Train net output #0: loss = 0.400977 (* 1 = 0.400977 loss)
I0529 02:51:05.715670 15746 sgd_solver.cpp:106] Iteration 63700, lr = 1e-06
I0529 02:58:59.249896 15746 solver.cpp:228] Iteration 63800, loss = 0.600511
I0529 02:58:59.250628 15746 solver.cpp:244]     Train net output #0: loss = 0.600508 (* 1 = 0.600508 loss)
I0529 02:58:59.250653 15746 sgd_solver.cpp:106] Iteration 63800, lr = 1e-06
I0529 03:06:55.148491 15746 solver.cpp:228] Iteration 63900, loss = 0.484986
I0529 03:06:55.149179 15746 solver.cpp:244]     Train net output #0: loss = 0.484983 (* 1 = 0.484983 loss)
I0529 03:06:55.149201 15746 sgd_solver.cpp:106] Iteration 63900, lr = 1e-06
I0529 03:14:49.972735 15746 solver.cpp:228] Iteration 64000, loss = 0.383944
I0529 03:14:49.973480 15746 solver.cpp:244]     Train net output #0: loss = 0.383941 (* 1 = 0.383941 loss)
I0529 03:14:49.973512 15746 sgd_solver.cpp:106] Iteration 64000, lr = 1e-06
I0529 03:22:50.178990 15746 solver.cpp:228] Iteration 64100, loss = 0.336969
I0529 03:22:50.179687 15746 solver.cpp:244]     Train net output #0: loss = 0.336966 (* 1 = 0.336966 loss)
I0529 03:22:50.179718 15746 sgd_solver.cpp:106] Iteration 64100, lr = 1e-06
I0529 03:30:41.283627 15746 solver.cpp:228] Iteration 64200, loss = 0.533218
I0529 03:30:41.284399 15746 solver.cpp:244]     Train net output #0: loss = 0.533215 (* 1 = 0.533215 loss)
I0529 03:30:41.284435 15746 sgd_solver.cpp:106] Iteration 64200, lr = 1e-06
I0529 03:38:39.485128 15746 solver.cpp:228] Iteration 64300, loss = 0.893797
I0529 03:38:39.485859 15746 solver.cpp:244]     Train net output #0: loss = 0.893794 (* 1 = 0.893794 loss)
I0529 03:38:39.485884 15746 sgd_solver.cpp:106] Iteration 64300, lr = 1e-06
I0529 03:46:43.778256 15746 solver.cpp:228] Iteration 64400, loss = 0.566101
I0529 03:46:43.778803 15746 solver.cpp:244]     Train net output #0: loss = 0.566098 (* 1 = 0.566098 loss)
I0529 03:46:43.778825 15746 sgd_solver.cpp:106] Iteration 64400, lr = 1e-06
I0529 03:54:35.419679 15746 solver.cpp:228] Iteration 64500, loss = 0.587785
I0529 03:54:35.420444 15746 solver.cpp:244]     Train net output #0: loss = 0.587783 (* 1 = 0.587783 loss)
I0529 03:54:35.420464 15746 sgd_solver.cpp:106] Iteration 64500, lr = 1e-06
I0529 04:02:37.505074 15746 solver.cpp:228] Iteration 64600, loss = 0.323943
I0529 04:02:37.505806 15746 solver.cpp:244]     Train net output #0: loss = 0.32394 (* 1 = 0.32394 loss)
I0529 04:02:37.505828 15746 sgd_solver.cpp:106] Iteration 64600, lr = 1e-06
I0529 04:10:27.200999 15746 solver.cpp:228] Iteration 64700, loss = 0.624201
I0529 04:10:27.201640 15746 solver.cpp:244]     Train net output #0: loss = 0.624198 (* 1 = 0.624198 loss)
I0529 04:10:27.201668 15746 sgd_solver.cpp:106] Iteration 64700, lr = 1e-06
I0529 04:18:23.771268 15746 solver.cpp:228] Iteration 64800, loss = 0.590503
I0529 04:18:23.772133 15746 solver.cpp:244]     Train net output #0: loss = 0.5905 (* 1 = 0.5905 loss)
I0529 04:18:23.772164 15746 sgd_solver.cpp:106] Iteration 64800, lr = 1e-06
I0529 04:26:15.898185 15746 solver.cpp:228] Iteration 64900, loss = 0.526395
I0529 04:26:15.898852 15746 solver.cpp:244]     Train net output #0: loss = 0.526392 (* 1 = 0.526392 loss)
I0529 04:26:15.898875 15746 sgd_solver.cpp:106] Iteration 64900, lr = 1e-06
I0529 04:34:03.417346 15746 solver.cpp:228] Iteration 65000, loss = 0.566803
I0529 04:34:03.422047 15746 solver.cpp:244]     Train net output #0: loss = 0.5668 (* 1 = 0.5668 loss)
I0529 04:34:03.422086 15746 sgd_solver.cpp:106] Iteration 65000, lr = 1e-06
I0529 04:42:01.549296 15746 solver.cpp:228] Iteration 65100, loss = 0.290094
I0529 04:42:01.549844 15746 solver.cpp:244]     Train net output #0: loss = 0.290091 (* 1 = 0.290091 loss)
I0529 04:42:01.549865 15746 sgd_solver.cpp:106] Iteration 65100, lr = 1e-06
I0529 04:49:59.333675 15746 solver.cpp:228] Iteration 65200, loss = 0.416112
I0529 04:49:59.335855 15746 solver.cpp:244]     Train net output #0: loss = 0.416109 (* 1 = 0.416109 loss)
I0529 04:49:59.335875 15746 sgd_solver.cpp:106] Iteration 65200, lr = 1e-06
I0529 04:57:55.311731 15746 solver.cpp:337] Iteration 65300, Testing net (#0)
I0529 04:57:55.312389 15746 net.cpp:685] Ignoring source layer ratemap
I0529 04:57:55.312407 15746 net.cpp:685] Ignoring source layer amsFeatures
I0529 05:00:46.339529 15746 solver.cpp:404]     Test net output #0: loss = 0.529113 (* 1 = 0.529113 loss)
I0529 05:00:50.148133 15746 solver.cpp:228] Iteration 65300, loss = 0.768655
I0529 05:00:50.148192 15746 solver.cpp:244]     Train net output #0: loss = 0.768652 (* 1 = 0.768652 loss)
I0529 05:00:50.148203 15746 sgd_solver.cpp:106] Iteration 65300, lr = 1e-06
I0529 05:08:33.902707 15746 solver.cpp:228] Iteration 65400, loss = 0.408462
I0529 05:08:33.906574 15746 solver.cpp:244]     Train net output #0: loss = 0.40846 (* 1 = 0.40846 loss)
I0529 05:08:33.906604 15746 sgd_solver.cpp:106] Iteration 65400, lr = 1e-06
I0529 05:16:34.140018 15746 solver.cpp:228] Iteration 65500, loss = 0.408003
I0529 05:16:34.140789 15746 solver.cpp:244]     Train net output #0: loss = 0.408 (* 1 = 0.408 loss)
I0529 05:16:34.140820 15746 sgd_solver.cpp:106] Iteration 65500, lr = 1e-06
I0529 05:24:31.305713 15746 solver.cpp:228] Iteration 65600, loss = 0.591736
I0529 05:24:31.311339 15746 solver.cpp:244]     Train net output #0: loss = 0.591733 (* 1 = 0.591733 loss)
I0529 05:24:31.311367 15746 sgd_solver.cpp:106] Iteration 65600, lr = 1e-06
I0529 05:32:19.308362 15746 solver.cpp:228] Iteration 65700, loss = 0.427793
I0529 05:32:19.308899 15746 solver.cpp:244]     Train net output #0: loss = 0.42779 (* 1 = 0.42779 loss)
I0529 05:32:19.308926 15746 sgd_solver.cpp:106] Iteration 65700, lr = 1e-06
I0529 05:40:05.938655 15746 solver.cpp:228] Iteration 65800, loss = 0.488626
I0529 05:40:05.943249 15746 solver.cpp:244]     Train net output #0: loss = 0.488624 (* 1 = 0.488624 loss)
I0529 05:40:05.943274 15746 sgd_solver.cpp:106] Iteration 65800, lr = 1e-06
I0529 05:48:16.602551 15746 solver.cpp:228] Iteration 65900, loss = 0.229114
I0529 05:48:16.603229 15746 solver.cpp:244]     Train net output #0: loss = 0.229111 (* 1 = 0.229111 loss)
I0529 05:48:16.603251 15746 sgd_solver.cpp:106] Iteration 65900, lr = 1e-06
I0529 05:55:55.044908 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_66000.caffemodel
I0529 05:55:55.229056 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_66000.solverstate
I0529 05:55:59.961880 15746 solver.cpp:228] Iteration 66000, loss = 0.584407
I0529 05:55:59.961933 15746 solver.cpp:244]     Train net output #0: loss = 0.584405 (* 1 = 0.584405 loss)
I0529 05:55:59.961944 15746 sgd_solver.cpp:106] Iteration 66000, lr = 1e-06
I0529 06:03:52.117689 15746 solver.cpp:228] Iteration 66100, loss = 0.382987
I0529 06:03:52.118391 15746 solver.cpp:244]     Train net output #0: loss = 0.382985 (* 1 = 0.382985 loss)
I0529 06:03:52.118430 15746 sgd_solver.cpp:106] Iteration 66100, lr = 1e-06
I0529 06:11:31.111943 15746 solver.cpp:228] Iteration 66200, loss = 0.648985
I0529 06:11:31.112553 15746 solver.cpp:244]     Train net output #0: loss = 0.648982 (* 1 = 0.648982 loss)
I0529 06:11:31.112576 15746 sgd_solver.cpp:106] Iteration 66200, lr = 1e-06
I0529 06:19:29.458832 15746 solver.cpp:228] Iteration 66300, loss = 0.494997
I0529 06:19:29.463449 15746 solver.cpp:244]     Train net output #0: loss = 0.494994 (* 1 = 0.494994 loss)
I0529 06:19:29.463481 15746 sgd_solver.cpp:106] Iteration 66300, lr = 1e-06
I0529 06:27:20.240159 15746 solver.cpp:228] Iteration 66400, loss = 0.41218
I0529 06:27:20.240849 15746 solver.cpp:244]     Train net output #0: loss = 0.412178 (* 1 = 0.412178 loss)
I0529 06:27:20.240869 15746 sgd_solver.cpp:106] Iteration 66400, lr = 1e-06
I0529 06:35:19.591820 15746 solver.cpp:228] Iteration 66500, loss = 0.311728
I0529 06:35:19.592525 15746 solver.cpp:244]     Train net output #0: loss = 0.311725 (* 1 = 0.311725 loss)
I0529 06:35:19.592548 15746 sgd_solver.cpp:106] Iteration 66500, lr = 1e-06
I0529 06:43:15.454505 15746 solver.cpp:228] Iteration 66600, loss = 0.402398
I0529 06:43:15.456331 15746 solver.cpp:244]     Train net output #0: loss = 0.402396 (* 1 = 0.402396 loss)
I0529 06:43:15.456357 15746 sgd_solver.cpp:106] Iteration 66600, lr = 1e-06
I0529 06:51:11.199920 15746 solver.cpp:228] Iteration 66700, loss = 0.480045
I0529 06:51:11.924325 15746 solver.cpp:244]     Train net output #0: loss = 0.480043 (* 1 = 0.480043 loss)
I0529 06:51:11.924347 15746 sgd_solver.cpp:106] Iteration 66700, lr = 1e-06
I0529 06:59:04.909230 15746 solver.cpp:228] Iteration 66800, loss = 0.656641
I0529 06:59:04.912737 15746 solver.cpp:244]     Train net output #0: loss = 0.656639 (* 1 = 0.656639 loss)
I0529 06:59:04.912761 15746 sgd_solver.cpp:106] Iteration 66800, lr = 1e-06
I0529 07:07:09.297020 15746 solver.cpp:228] Iteration 66900, loss = 0.563417
I0529 07:07:09.372069 15746 solver.cpp:244]     Train net output #0: loss = 0.563414 (* 1 = 0.563414 loss)
I0529 07:07:09.372084 15746 sgd_solver.cpp:106] Iteration 66900, lr = 1e-06
I0529 07:15:04.392948 15746 solver.cpp:228] Iteration 67000, loss = 0.348538
I0529 07:15:04.393635 15746 solver.cpp:244]     Train net output #0: loss = 0.348535 (* 1 = 0.348535 loss)
I0529 07:15:04.393658 15746 sgd_solver.cpp:106] Iteration 67000, lr = 1e-06
I0529 07:22:58.837724 15746 solver.cpp:228] Iteration 67100, loss = 0.514493
I0529 07:22:58.838465 15746 solver.cpp:244]     Train net output #0: loss = 0.51449 (* 1 = 0.51449 loss)
I0529 07:22:58.838486 15746 sgd_solver.cpp:106] Iteration 67100, lr = 1e-06
I0529 07:31:02.185322 15746 solver.cpp:228] Iteration 67200, loss = 0.455547
I0529 07:31:02.186079 15746 solver.cpp:244]     Train net output #0: loss = 0.455544 (* 1 = 0.455544 loss)
I0529 07:31:02.186103 15746 sgd_solver.cpp:106] Iteration 67200, lr = 1e-06
I0529 07:38:57.583343 15746 solver.cpp:228] Iteration 67300, loss = 0.545968
I0529 07:38:57.584017 15746 solver.cpp:244]     Train net output #0: loss = 0.545965 (* 1 = 0.545965 loss)
I0529 07:38:57.584041 15746 sgd_solver.cpp:106] Iteration 67300, lr = 1e-06
I0529 07:47:05.566198 15746 solver.cpp:228] Iteration 67400, loss = 0.725792
I0529 07:47:05.566941 15746 solver.cpp:244]     Train net output #0: loss = 0.725789 (* 1 = 0.725789 loss)
I0529 07:47:05.566982 15746 sgd_solver.cpp:106] Iteration 67400, lr = 1e-06
I0529 07:54:43.434871 15746 solver.cpp:228] Iteration 67500, loss = 0.37599
I0529 07:54:43.435525 15746 solver.cpp:244]     Train net output #0: loss = 0.375988 (* 1 = 0.375988 loss)
I0529 07:54:43.435546 15746 sgd_solver.cpp:106] Iteration 67500, lr = 1e-06
I0529 08:02:33.046921 15746 solver.cpp:228] Iteration 67600, loss = 0.581134
I0529 08:02:33.047418 15746 solver.cpp:244]     Train net output #0: loss = 0.581132 (* 1 = 0.581132 loss)
I0529 08:02:33.047441 15746 sgd_solver.cpp:106] Iteration 67600, lr = 1e-06
I0529 08:10:35.370756 15746 solver.cpp:228] Iteration 67700, loss = 0.540853
I0529 08:10:35.371453 15746 solver.cpp:244]     Train net output #0: loss = 0.54085 (* 1 = 0.54085 loss)
I0529 08:10:35.371474 15746 sgd_solver.cpp:106] Iteration 67700, lr = 1e-06
I0529 08:18:29.906095 15746 solver.cpp:228] Iteration 67800, loss = 0.505649
I0529 08:18:29.906720 15746 solver.cpp:244]     Train net output #0: loss = 0.505646 (* 1 = 0.505646 loss)
I0529 08:18:29.906744 15746 sgd_solver.cpp:106] Iteration 67800, lr = 1e-06
I0529 08:26:29.716603 15746 solver.cpp:228] Iteration 67900, loss = 0.398755
I0529 08:26:29.717741 15746 solver.cpp:244]     Train net output #0: loss = 0.398752 (* 1 = 0.398752 loss)
I0529 08:26:29.717774 15746 sgd_solver.cpp:106] Iteration 67900, lr = 1e-06
I0529 08:34:18.119493 15746 solver.cpp:228] Iteration 68000, loss = 0.859814
I0529 08:34:18.120195 15746 solver.cpp:244]     Train net output #0: loss = 0.859812 (* 1 = 0.859812 loss)
I0529 08:34:18.120215 15746 sgd_solver.cpp:106] Iteration 68000, lr = 1e-06
I0529 08:42:30.690229 15746 solver.cpp:228] Iteration 68100, loss = 0.421688
I0529 08:42:30.690806 15746 solver.cpp:244]     Train net output #0: loss = 0.421686 (* 1 = 0.421686 loss)
I0529 08:42:30.690834 15746 sgd_solver.cpp:106] Iteration 68100, lr = 1e-06
I0529 08:50:35.766578 15746 solver.cpp:228] Iteration 68200, loss = 0.227695
I0529 08:50:35.767128 15746 solver.cpp:244]     Train net output #0: loss = 0.227692 (* 1 = 0.227692 loss)
I0529 08:50:35.767141 15746 sgd_solver.cpp:106] Iteration 68200, lr = 1e-06
I0529 08:58:37.117285 15746 solver.cpp:228] Iteration 68300, loss = 0.371212
I0529 08:58:37.117993 15746 solver.cpp:244]     Train net output #0: loss = 0.371209 (* 1 = 0.371209 loss)
I0529 08:58:37.118027 15746 sgd_solver.cpp:106] Iteration 68300, lr = 1e-06
I0529 09:06:25.278901 15746 solver.cpp:228] Iteration 68400, loss = 0.487744
I0529 09:06:25.280799 15746 solver.cpp:244]     Train net output #0: loss = 0.487741 (* 1 = 0.487741 loss)
I0529 09:06:25.280822 15746 sgd_solver.cpp:106] Iteration 68400, lr = 1e-06
I0529 09:14:24.085150 15746 solver.cpp:228] Iteration 68500, loss = 1.16554
I0529 09:14:24.085836 15746 solver.cpp:244]     Train net output #0: loss = 1.16554 (* 1 = 1.16554 loss)
I0529 09:14:24.085856 15746 sgd_solver.cpp:106] Iteration 68500, lr = 1e-06
I0529 09:19:16.832974 15746 solver.cpp:337] Iteration 68565, Testing net (#0)
I0529 09:19:16.833401 15746 net.cpp:685] Ignoring source layer ratemap
I0529 09:19:16.833427 15746 net.cpp:685] Ignoring source layer amsFeatures
I0529 09:22:08.371975 15746 solver.cpp:404]     Test net output #0: loss = 0.528458 (* 1 = 0.528458 loss)
I0529 09:24:56.698128 15746 solver.cpp:228] Iteration 68600, loss = 0.533529
I0529 09:24:56.698464 15746 solver.cpp:244]     Train net output #0: loss = 0.533526 (* 1 = 0.533526 loss)
I0529 09:24:56.698477 15746 sgd_solver.cpp:106] Iteration 68600, lr = 1e-06
I0529 09:32:46.608469 15746 solver.cpp:228] Iteration 68700, loss = 0.717306
I0529 09:32:46.611722 15746 solver.cpp:244]     Train net output #0: loss = 0.717303 (* 1 = 0.717303 loss)
I0529 09:32:46.611742 15746 sgd_solver.cpp:106] Iteration 68700, lr = 1e-06
I0529 09:40:42.413656 15746 solver.cpp:228] Iteration 68800, loss = 0.362291
I0529 09:40:42.414252 15746 solver.cpp:244]     Train net output #0: loss = 0.362288 (* 1 = 0.362288 loss)
I0529 09:40:42.414278 15746 sgd_solver.cpp:106] Iteration 68800, lr = 1e-06
I0529 09:48:30.812942 15746 solver.cpp:228] Iteration 68900, loss = 0.379718
I0529 09:48:30.816313 15746 solver.cpp:244]     Train net output #0: loss = 0.379715 (* 1 = 0.379715 loss)
I0529 09:48:30.816334 15746 sgd_solver.cpp:106] Iteration 68900, lr = 1e-06
I0529 09:56:18.793298 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_69000.caffemodel
I0529 09:56:18.983671 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_69000.solverstate
I0529 09:56:24.864789 15746 solver.cpp:228] Iteration 69000, loss = 0.542068
I0529 09:56:24.864850 15746 solver.cpp:244]     Train net output #0: loss = 0.542065 (* 1 = 0.542065 loss)
I0529 09:56:24.864861 15746 sgd_solver.cpp:106] Iteration 69000, lr = 1e-06
I0529 10:04:02.597057 15746 solver.cpp:228] Iteration 69100, loss = 0.270898
I0529 10:04:02.597844 15746 solver.cpp:244]     Train net output #0: loss = 0.270896 (* 1 = 0.270896 loss)
I0529 10:04:02.597864 15746 sgd_solver.cpp:106] Iteration 69100, lr = 1e-06
I0529 10:11:43.661569 15746 solver.cpp:228] Iteration 69200, loss = 0.573199
I0529 10:11:43.662616 15746 solver.cpp:244]     Train net output #0: loss = 0.573196 (* 1 = 0.573196 loss)
I0529 10:11:43.662652 15746 sgd_solver.cpp:106] Iteration 69200, lr = 1e-06
I0529 10:19:51.438069 15746 solver.cpp:228] Iteration 69300, loss = 0.39072
I0529 10:19:51.438756 15746 solver.cpp:244]     Train net output #0: loss = 0.390718 (* 1 = 0.390718 loss)
I0529 10:19:51.438781 15746 sgd_solver.cpp:106] Iteration 69300, lr = 1e-06
I0529 10:28:13.703577 15746 solver.cpp:228] Iteration 69400, loss = 0.413543
I0529 10:28:13.704350 15746 solver.cpp:244]     Train net output #0: loss = 0.41354 (* 1 = 0.41354 loss)
I0529 10:28:13.704375 15746 sgd_solver.cpp:106] Iteration 69400, lr = 1e-06
I0529 10:36:54.616386 15746 solver.cpp:228] Iteration 69500, loss = 0.389621
I0529 10:36:54.617063 15746 solver.cpp:244]     Train net output #0: loss = 0.389619 (* 1 = 0.389619 loss)
I0529 10:36:54.617086 15746 sgd_solver.cpp:106] Iteration 69500, lr = 1e-06
I0529 10:45:12.450222 15746 solver.cpp:228] Iteration 69600, loss = 0.547402
I0529 10:45:12.461386 15746 solver.cpp:244]     Train net output #0: loss = 0.547399 (* 1 = 0.547399 loss)
I0529 10:45:12.461406 15746 sgd_solver.cpp:106] Iteration 69600, lr = 1e-06
I0529 10:53:18.088907 15746 solver.cpp:228] Iteration 69700, loss = 0.348128
I0529 10:53:18.089519 15746 solver.cpp:244]     Train net output #0: loss = 0.348126 (* 1 = 0.348126 loss)
I0529 10:53:18.089545 15746 sgd_solver.cpp:106] Iteration 69700, lr = 1e-06
I0529 11:01:47.716362 15746 solver.cpp:228] Iteration 69800, loss = 0.379581
I0529 11:01:47.717139 15746 solver.cpp:244]     Train net output #0: loss = 0.379578 (* 1 = 0.379578 loss)
I0529 11:01:47.717164 15746 sgd_solver.cpp:106] Iteration 69800, lr = 1e-06
I0529 11:10:14.913909 15746 solver.cpp:228] Iteration 69900, loss = 0.785552
I0529 11:10:14.914664 15746 solver.cpp:244]     Train net output #0: loss = 0.785549 (* 1 = 0.785549 loss)
I0529 11:10:14.914683 15746 sgd_solver.cpp:106] Iteration 69900, lr = 1e-06
I0529 11:18:34.072073 15746 solver.cpp:228] Iteration 70000, loss = 0.525369
I0529 11:18:34.075886 15746 solver.cpp:244]     Train net output #0: loss = 0.525366 (* 1 = 0.525366 loss)
I0529 11:18:34.075908 15746 sgd_solver.cpp:106] Iteration 70000, lr = 1e-06
I0529 11:26:38.504395 15746 solver.cpp:228] Iteration 70100, loss = 0.29248
I0529 11:26:38.505137 15746 solver.cpp:244]     Train net output #0: loss = 0.292477 (* 1 = 0.292477 loss)
I0529 11:26:38.505162 15746 sgd_solver.cpp:106] Iteration 70100, lr = 1e-06
I0529 11:35:14.795999 15746 solver.cpp:228] Iteration 70200, loss = 0.451839
I0529 11:35:14.796977 15746 solver.cpp:244]     Train net output #0: loss = 0.451836 (* 1 = 0.451836 loss)
I0529 11:35:14.797003 15746 sgd_solver.cpp:106] Iteration 70200, lr = 1e-06
I0529 11:43:32.236167 15746 solver.cpp:228] Iteration 70300, loss = 0.512887
I0529 11:43:32.236814 15746 solver.cpp:244]     Train net output #0: loss = 0.512884 (* 1 = 0.512884 loss)
I0529 11:43:32.236837 15746 sgd_solver.cpp:106] Iteration 70300, lr = 1e-06
I0529 11:51:36.285648 15746 solver.cpp:228] Iteration 70400, loss = 0.36961
I0529 11:51:36.286274 15746 solver.cpp:244]     Train net output #0: loss = 0.369607 (* 1 = 0.369607 loss)
I0529 11:51:36.286294 15746 sgd_solver.cpp:106] Iteration 70400, lr = 1e-06
I0529 12:00:01.736135 15746 solver.cpp:228] Iteration 70500, loss = 0.367402
I0529 12:00:01.736737 15746 solver.cpp:244]     Train net output #0: loss = 0.367399 (* 1 = 0.367399 loss)
I0529 12:00:01.736757 15746 sgd_solver.cpp:106] Iteration 70500, lr = 1e-06
I0529 12:08:19.587633 15746 solver.cpp:228] Iteration 70600, loss = 0.510666
I0529 12:08:19.588338 15746 solver.cpp:244]     Train net output #0: loss = 0.510663 (* 1 = 0.510663 loss)
I0529 12:08:19.588372 15746 sgd_solver.cpp:106] Iteration 70600, lr = 1e-06
I0529 12:16:22.042649 15746 solver.cpp:228] Iteration 70700, loss = 0.690979
I0529 12:16:22.043130 15746 solver.cpp:244]     Train net output #0: loss = 0.690976 (* 1 = 0.690976 loss)
I0529 12:16:22.043151 15746 sgd_solver.cpp:106] Iteration 70700, lr = 1e-06
I0529 12:24:39.302145 15746 solver.cpp:228] Iteration 70800, loss = 0.577629
I0529 12:24:39.302629 15746 solver.cpp:244]     Train net output #0: loss = 0.577626 (* 1 = 0.577626 loss)
I0529 12:24:39.302661 15746 sgd_solver.cpp:106] Iteration 70800, lr = 1e-06
I0529 12:32:32.368007 15746 solver.cpp:228] Iteration 70900, loss = 0.340133
I0529 12:32:32.368445 15746 solver.cpp:244]     Train net output #0: loss = 0.34013 (* 1 = 0.34013 loss)
I0529 12:32:32.368470 15746 sgd_solver.cpp:106] Iteration 70900, lr = 1e-06
I0529 12:41:03.855343 15746 solver.cpp:228] Iteration 71000, loss = 0.539086
I0529 12:41:03.855860 15746 solver.cpp:244]     Train net output #0: loss = 0.539083 (* 1 = 0.539083 loss)
I0529 12:41:03.855880 15746 sgd_solver.cpp:106] Iteration 71000, lr = 1e-06
I0529 12:49:26.511783 15746 solver.cpp:228] Iteration 71100, loss = 0.40964
I0529 12:49:26.512244 15746 solver.cpp:244]     Train net output #0: loss = 0.409636 (* 1 = 0.409636 loss)
I0529 12:49:26.512265 15746 sgd_solver.cpp:106] Iteration 71100, lr = 1e-06
I0529 12:57:53.137091 15746 solver.cpp:228] Iteration 71200, loss = 0.394613
I0529 12:57:53.137547 15746 solver.cpp:244]     Train net output #0: loss = 0.39461 (* 1 = 0.39461 loss)
I0529 12:57:53.137572 15746 sgd_solver.cpp:106] Iteration 71200, lr = 1e-06
I0529 13:06:00.959455 15746 solver.cpp:228] Iteration 71300, loss = 0.679323
I0529 13:06:00.959925 15746 solver.cpp:244]     Train net output #0: loss = 0.67932 (* 1 = 0.67932 loss)
I0529 13:06:00.959954 15746 sgd_solver.cpp:106] Iteration 71300, lr = 1e-06
I0529 13:14:18.346850 15746 solver.cpp:228] Iteration 71400, loss = 0.362011
I0529 13:14:18.347640 15746 solver.cpp:244]     Train net output #0: loss = 0.362008 (* 1 = 0.362008 loss)
I0529 13:14:18.347662 15746 sgd_solver.cpp:106] Iteration 71400, lr = 1e-06
I0529 13:22:44.726029 15746 solver.cpp:228] Iteration 71500, loss = 0.410417
I0529 13:22:44.726897 15746 solver.cpp:244]     Train net output #0: loss = 0.410414 (* 1 = 0.410414 loss)
I0529 13:22:44.726917 15746 sgd_solver.cpp:106] Iteration 71500, lr = 1e-06
I0529 13:30:58.549998 15746 solver.cpp:228] Iteration 71600, loss = 0.31494
I0529 13:30:58.550468 15746 solver.cpp:244]     Train net output #0: loss = 0.314936 (* 1 = 0.314936 loss)
I0529 13:30:58.550488 15746 sgd_solver.cpp:106] Iteration 71600, lr = 1e-06
I0529 13:39:16.775068 15746 solver.cpp:228] Iteration 71700, loss = 0.58569
I0529 13:39:16.775516 15746 solver.cpp:244]     Train net output #0: loss = 0.585687 (* 1 = 0.585687 loss)
I0529 13:39:16.775540 15746 sgd_solver.cpp:106] Iteration 71700, lr = 1e-06
I0529 13:47:40.877816 15746 solver.cpp:228] Iteration 71800, loss = 0.488733
I0529 13:47:40.878741 15746 solver.cpp:244]     Train net output #0: loss = 0.48873 (* 1 = 0.48873 loss)
I0529 13:47:40.878785 15746 sgd_solver.cpp:106] Iteration 71800, lr = 1e-06
I0529 13:50:04.910848 15746 solver.cpp:337] Iteration 71830, Testing net (#0)
I0529 13:50:04.911315 15746 net.cpp:685] Ignoring source layer ratemap
I0529 13:50:04.911336 15746 net.cpp:685] Ignoring source layer amsFeatures
I0529 13:52:54.760834 15746 solver.cpp:404]     Test net output #0: loss = 0.529521 (* 1 = 0.529521 loss)
I0529 13:58:42.026087 15746 solver.cpp:228] Iteration 71900, loss = 0.432429
I0529 13:58:42.026891 15746 solver.cpp:244]     Train net output #0: loss = 0.432425 (* 1 = 0.432425 loss)
I0529 13:58:42.026923 15746 sgd_solver.cpp:106] Iteration 71900, lr = 1e-06
I0529 14:06:36.421447 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_72000.caffemodel
I0529 14:06:36.583765 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_72000.solverstate
I0529 14:06:41.134330 15746 solver.cpp:228] Iteration 72000, loss = 0.759286
I0529 14:06:41.134383 15746 solver.cpp:244]     Train net output #0: loss = 0.759283 (* 1 = 0.759283 loss)
I0529 14:06:41.134393 15746 sgd_solver.cpp:106] Iteration 72000, lr = 1e-06
I0529 14:14:31.456095 15746 solver.cpp:228] Iteration 72100, loss = 0.178509
I0529 14:14:31.460275 15746 solver.cpp:244]     Train net output #0: loss = 0.178505 (* 1 = 0.178505 loss)
I0529 14:14:31.460300 15746 sgd_solver.cpp:106] Iteration 72100, lr = 1e-06
I0529 14:22:33.628703 15746 solver.cpp:228] Iteration 72200, loss = 0.520672
I0529 14:22:33.629312 15746 solver.cpp:244]     Train net output #0: loss = 0.520669 (* 1 = 0.520669 loss)
I0529 14:22:33.629343 15746 sgd_solver.cpp:106] Iteration 72200, lr = 1e-06
I0529 14:30:30.328634 15746 solver.cpp:228] Iteration 72300, loss = 0.355777
I0529 14:30:30.329360 15746 solver.cpp:244]     Train net output #0: loss = 0.355774 (* 1 = 0.355774 loss)
I0529 14:30:30.329383 15746 sgd_solver.cpp:106] Iteration 72300, lr = 1e-06
I0529 14:38:30.671072 15746 solver.cpp:228] Iteration 72400, loss = 0.530274
I0529 14:38:30.671561 15746 solver.cpp:244]     Train net output #0: loss = 0.530271 (* 1 = 0.530271 loss)
I0529 14:38:30.671591 15746 sgd_solver.cpp:106] Iteration 72400, lr = 1e-06
I0529 14:46:24.369503 15746 solver.cpp:228] Iteration 72500, loss = 0.367902
I0529 14:46:24.370131 15746 solver.cpp:244]     Train net output #0: loss = 0.367899 (* 1 = 0.367899 loss)
I0529 14:46:24.370156 15746 sgd_solver.cpp:106] Iteration 72500, lr = 1e-06
I0529 14:54:24.650086 15746 solver.cpp:228] Iteration 72600, loss = 0.470685
I0529 14:54:24.654659 15746 solver.cpp:244]     Train net output #0: loss = 0.470682 (* 1 = 0.470682 loss)
I0529 14:54:24.654682 15746 sgd_solver.cpp:106] Iteration 72600, lr = 1e-06
I0529 15:02:36.080247 15746 solver.cpp:228] Iteration 72700, loss = 0.627558
I0529 15:02:36.080703 15746 solver.cpp:244]     Train net output #0: loss = 0.627555 (* 1 = 0.627555 loss)
I0529 15:02:36.080732 15746 sgd_solver.cpp:106] Iteration 72700, lr = 1e-06
I0529 15:10:49.877517 15746 solver.cpp:228] Iteration 72800, loss = 0.256751
I0529 15:10:49.878695 15746 solver.cpp:244]     Train net output #0: loss = 0.256747 (* 1 = 0.256747 loss)
I0529 15:10:49.878715 15746 sgd_solver.cpp:106] Iteration 72800, lr = 1e-06
I0529 15:19:19.138399 15746 solver.cpp:228] Iteration 72900, loss = 0.633307
I0529 15:19:19.139122 15746 solver.cpp:244]     Train net output #0: loss = 0.633304 (* 1 = 0.633304 loss)
I0529 15:19:19.139142 15746 sgd_solver.cpp:106] Iteration 72900, lr = 1e-06
I0529 15:27:47.401773 15746 solver.cpp:228] Iteration 73000, loss = 0.38046
I0529 15:27:47.402261 15746 solver.cpp:244]     Train net output #0: loss = 0.380457 (* 1 = 0.380457 loss)
I0529 15:27:47.402283 15746 sgd_solver.cpp:106] Iteration 73000, lr = 1e-06
I0529 15:36:17.545562 15746 solver.cpp:228] Iteration 73100, loss = 0.313702
I0529 15:36:17.546002 15746 solver.cpp:244]     Train net output #0: loss = 0.313699 (* 1 = 0.313699 loss)
I0529 15:36:17.546016 15746 sgd_solver.cpp:106] Iteration 73100, lr = 1e-06
I0529 15:44:44.761209 15746 solver.cpp:228] Iteration 73200, loss = 0.738201
I0529 15:44:44.761956 15746 solver.cpp:244]     Train net output #0: loss = 0.738198 (* 1 = 0.738198 loss)
I0529 15:44:44.761977 15746 sgd_solver.cpp:106] Iteration 73200, lr = 1e-06
I0529 15:53:06.040963 15746 solver.cpp:228] Iteration 73300, loss = 0.563477
I0529 15:53:06.041456 15746 solver.cpp:244]     Train net output #0: loss = 0.563474 (* 1 = 0.563474 loss)
I0529 15:53:06.041488 15746 sgd_solver.cpp:106] Iteration 73300, lr = 1e-06
I0529 16:02:23.228848 15746 solver.cpp:228] Iteration 73400, loss = 0.710152
I0529 16:02:23.229504 15746 solver.cpp:244]     Train net output #0: loss = 0.710149 (* 1 = 0.710149 loss)
I0529 16:02:23.229518 15746 sgd_solver.cpp:106] Iteration 73400, lr = 1e-06
I0529 16:10:53.983256 15746 solver.cpp:228] Iteration 73500, loss = 0.528369
I0529 16:10:53.983984 15746 solver.cpp:244]     Train net output #0: loss = 0.528366 (* 1 = 0.528366 loss)
I0529 16:10:53.984005 15746 sgd_solver.cpp:106] Iteration 73500, lr = 1e-06
I0529 16:19:10.336906 15746 solver.cpp:228] Iteration 73600, loss = 0.452943
I0529 16:19:10.337615 15746 solver.cpp:244]     Train net output #0: loss = 0.45294 (* 1 = 0.45294 loss)
I0529 16:19:10.337640 15746 sgd_solver.cpp:106] Iteration 73600, lr = 1e-06
I0529 16:27:34.664616 15746 solver.cpp:228] Iteration 73700, loss = 0.411845
I0529 16:27:34.665372 15746 solver.cpp:244]     Train net output #0: loss = 0.411842 (* 1 = 0.411842 loss)
I0529 16:27:34.665396 15746 sgd_solver.cpp:106] Iteration 73700, lr = 1e-06
I0529 16:35:58.009543 15746 solver.cpp:228] Iteration 73800, loss = 0.380836
I0529 16:35:58.010159 15746 solver.cpp:244]     Train net output #0: loss = 0.380833 (* 1 = 0.380833 loss)
I0529 16:35:58.010182 15746 sgd_solver.cpp:106] Iteration 73800, lr = 1e-06
I0529 16:44:25.848812 15746 solver.cpp:228] Iteration 73900, loss = 0.49884
I0529 16:44:25.849493 15746 solver.cpp:244]     Train net output #0: loss = 0.498837 (* 1 = 0.498837 loss)
I0529 16:44:25.849516 15746 sgd_solver.cpp:106] Iteration 73900, lr = 1e-06
I0529 16:52:57.374464 15746 solver.cpp:228] Iteration 74000, loss = 0.656086
I0529 16:52:57.375033 15746 solver.cpp:244]     Train net output #0: loss = 0.656083 (* 1 = 0.656083 loss)
I0529 16:52:57.375058 15746 sgd_solver.cpp:106] Iteration 74000, lr = 1e-06
I0529 17:01:28.424099 15746 solver.cpp:228] Iteration 74100, loss = 0.666039
I0529 17:01:28.424821 15746 solver.cpp:244]     Train net output #0: loss = 0.666036 (* 1 = 0.666036 loss)
I0529 17:01:28.424846 15746 sgd_solver.cpp:106] Iteration 74100, lr = 1e-06
I0529 17:09:41.468334 15746 solver.cpp:228] Iteration 74200, loss = 0.429487
I0529 17:09:41.469085 15746 solver.cpp:244]     Train net output #0: loss = 0.429484 (* 1 = 0.429484 loss)
I0529 17:09:41.469110 15746 sgd_solver.cpp:106] Iteration 74200, lr = 1e-06
I0529 17:17:59.308938 15746 solver.cpp:228] Iteration 74300, loss = 0.76354
I0529 17:17:59.309599 15746 solver.cpp:244]     Train net output #0: loss = 0.763537 (* 1 = 0.763537 loss)
I0529 17:17:59.309622 15746 sgd_solver.cpp:106] Iteration 74300, lr = 1e-06
I0529 17:26:24.140892 15746 solver.cpp:228] Iteration 74400, loss = 0.394898
I0529 17:26:24.141706 15746 solver.cpp:244]     Train net output #0: loss = 0.394895 (* 1 = 0.394895 loss)
I0529 17:26:24.141731 15746 sgd_solver.cpp:106] Iteration 74400, lr = 1e-06
I0529 17:34:48.325811 15746 solver.cpp:228] Iteration 74500, loss = 0.694054
I0529 17:34:48.327431 15746 solver.cpp:244]     Train net output #0: loss = 0.694051 (* 1 = 0.694051 loss)
I0529 17:34:48.327461 15746 sgd_solver.cpp:106] Iteration 74500, lr = 1e-06
I0529 17:43:24.092017 15746 solver.cpp:228] Iteration 74600, loss = 0.41339
I0529 17:43:24.092440 15746 solver.cpp:244]     Train net output #0: loss = 0.413387 (* 1 = 0.413387 loss)
I0529 17:43:24.092460 15746 sgd_solver.cpp:106] Iteration 74600, lr = 1e-06
I0529 17:51:54.388340 15746 solver.cpp:228] Iteration 74700, loss = 0.288226
I0529 17:51:54.388806 15746 solver.cpp:244]     Train net output #0: loss = 0.288223 (* 1 = 0.288223 loss)
I0529 17:51:54.388828 15746 sgd_solver.cpp:106] Iteration 74700, lr = 1e-06
I0529 18:00:06.356092 15746 solver.cpp:228] Iteration 74800, loss = 0.625733
I0529 18:00:06.356442 15746 solver.cpp:244]     Train net output #0: loss = 0.62573 (* 1 = 0.62573 loss)
I0529 18:00:06.356467 15746 sgd_solver.cpp:106] Iteration 74800, lr = 1e-06
I0529 18:08:37.230463 15746 solver.cpp:228] Iteration 74900, loss = 0.375759
I0529 18:08:37.232931 15746 solver.cpp:244]     Train net output #0: loss = 0.375756 (* 1 = 0.375756 loss)
I0529 18:08:37.232946 15746 sgd_solver.cpp:106] Iteration 74900, lr = 1e-06
I0529 18:17:57.396939 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_75000.caffemodel
I0529 18:17:57.582195 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_75000.solverstate
I0529 18:18:04.569203 15746 solver.cpp:228] Iteration 75000, loss = 0.31288
I0529 18:18:04.569262 15746 solver.cpp:244]     Train net output #0: loss = 0.312877 (* 1 = 0.312877 loss)
I0529 18:18:04.569273 15746 sgd_solver.cpp:106] Iteration 75000, lr = 1e-06
I0529 18:27:08.993407 15746 solver.cpp:337] Iteration 75095, Testing net (#0)
I0529 18:27:08.993732 15746 net.cpp:685] Ignoring source layer ratemap
I0529 18:27:08.993741 15746 net.cpp:685] Ignoring source layer amsFeatures
I0529 18:29:59.747417 15746 solver.cpp:404]     Test net output #0: loss = 0.527559 (* 1 = 0.527559 loss)
I0529 18:30:32.175401 15746 solver.cpp:228] Iteration 75100, loss = 0.393357
I0529 18:30:32.175506 15746 solver.cpp:244]     Train net output #0: loss = 0.393354 (* 1 = 0.393354 loss)
I0529 18:30:32.175519 15746 sgd_solver.cpp:106] Iteration 75100, lr = 1e-06
I0529 18:40:01.389467 15746 solver.cpp:228] Iteration 75200, loss = 0.405457
I0529 18:40:01.389827 15746 solver.cpp:244]     Train net output #0: loss = 0.405454 (* 1 = 0.405454 loss)
I0529 18:40:01.389842 15746 sgd_solver.cpp:106] Iteration 75200, lr = 1e-06
I0529 18:49:45.275861 15746 solver.cpp:228] Iteration 75300, loss = 0.473632
I0529 18:49:45.276473 15746 solver.cpp:244]     Train net output #0: loss = 0.473629 (* 1 = 0.473629 loss)
I0529 18:49:45.276489 15746 sgd_solver.cpp:106] Iteration 75300, lr = 1e-06
I0529 18:58:59.396150 15746 solver.cpp:228] Iteration 75400, loss = 0.462766
I0529 18:58:59.396569 15746 solver.cpp:244]     Train net output #0: loss = 0.462763 (* 1 = 0.462763 loss)
I0529 18:58:59.396595 15746 sgd_solver.cpp:106] Iteration 75400, lr = 1e-06
I0529 19:06:33.752594 15746 solver.cpp:228] Iteration 75500, loss = 0.274284
I0529 19:06:33.753083 15746 solver.cpp:244]     Train net output #0: loss = 0.274281 (* 1 = 0.274281 loss)
I0529 19:06:33.753113 15746 sgd_solver.cpp:106] Iteration 75500, lr = 1e-06
I0529 19:15:07.320283 15746 solver.cpp:228] Iteration 75600, loss = 0.948581
I0529 19:15:07.320627 15746 solver.cpp:244]     Train net output #0: loss = 0.948578 (* 1 = 0.948578 loss)
I0529 19:15:07.320642 15746 sgd_solver.cpp:106] Iteration 75600, lr = 1e-06
I0529 19:24:52.476603 15746 solver.cpp:228] Iteration 75700, loss = 0.285638
I0529 19:24:52.476966 15746 solver.cpp:244]     Train net output #0: loss = 0.285635 (* 1 = 0.285635 loss)
I0529 19:24:52.476982 15746 sgd_solver.cpp:106] Iteration 75700, lr = 1e-06
I0529 19:34:40.442348 15746 solver.cpp:228] Iteration 75800, loss = 0.667231
I0529 19:34:40.442698 15746 solver.cpp:244]     Train net output #0: loss = 0.667228 (* 1 = 0.667228 loss)
I0529 19:34:40.442713 15746 sgd_solver.cpp:106] Iteration 75800, lr = 1e-06
I0529 19:44:14.005591 15746 solver.cpp:228] Iteration 75900, loss = 0.351579
I0529 19:44:14.005970 15746 solver.cpp:244]     Train net output #0: loss = 0.351576 (* 1 = 0.351576 loss)
I0529 19:44:14.005982 15746 sgd_solver.cpp:106] Iteration 75900, lr = 1e-06
I0529 19:53:48.214663 15746 solver.cpp:228] Iteration 76000, loss = 0.514883
I0529 19:53:48.215023 15746 solver.cpp:244]     Train net output #0: loss = 0.51488 (* 1 = 0.51488 loss)
I0529 19:53:48.215039 15746 sgd_solver.cpp:106] Iteration 76000, lr = 1e-06
I0529 20:03:29.340862 15746 solver.cpp:228] Iteration 76100, loss = 0.497594
I0529 20:03:29.341217 15746 solver.cpp:244]     Train net output #0: loss = 0.497591 (* 1 = 0.497591 loss)
I0529 20:03:29.341233 15746 sgd_solver.cpp:106] Iteration 76100, lr = 1e-06
I0529 20:13:07.382494 15746 solver.cpp:228] Iteration 76200, loss = 0.416022
I0529 20:13:07.382859 15746 solver.cpp:244]     Train net output #0: loss = 0.416019 (* 1 = 0.416019 loss)
I0529 20:13:07.382874 15746 sgd_solver.cpp:106] Iteration 76200, lr = 1e-06
I0529 20:22:06.795295 15746 solver.cpp:228] Iteration 76300, loss = 0.200534
I0529 20:22:06.795781 15746 solver.cpp:244]     Train net output #0: loss = 0.200531 (* 1 = 0.200531 loss)
I0529 20:22:06.795801 15746 sgd_solver.cpp:106] Iteration 76300, lr = 1e-06
I0529 20:30:03.786077 15746 solver.cpp:228] Iteration 76400, loss = 0.437253
I0529 20:30:03.786458 15746 solver.cpp:244]     Train net output #0: loss = 0.43725 (* 1 = 0.43725 loss)
I0529 20:30:03.786470 15746 sgd_solver.cpp:106] Iteration 76400, lr = 1e-06
I0529 20:37:57.291188 15746 solver.cpp:228] Iteration 76500, loss = 0.746992
I0529 20:37:57.291575 15746 solver.cpp:244]     Train net output #0: loss = 0.746989 (* 1 = 0.746989 loss)
I0529 20:37:57.291599 15746 sgd_solver.cpp:106] Iteration 76500, lr = 1e-06
I0529 20:46:27.846717 15746 solver.cpp:228] Iteration 76600, loss = 0.592241
I0529 20:46:27.847249 15746 solver.cpp:244]     Train net output #0: loss = 0.592237 (* 1 = 0.592237 loss)
I0529 20:46:27.847275 15746 sgd_solver.cpp:106] Iteration 76600, lr = 1e-06
I0529 20:55:23.559351 15746 solver.cpp:228] Iteration 76700, loss = 0.506193
I0529 20:55:23.559729 15746 solver.cpp:244]     Train net output #0: loss = 0.50619 (* 1 = 0.50619 loss)
I0529 20:55:23.559746 15746 sgd_solver.cpp:106] Iteration 76700, lr = 1e-06
I0529 21:04:09.403769 15746 solver.cpp:228] Iteration 76800, loss = 0.971827
I0529 21:04:09.404425 15746 solver.cpp:244]     Train net output #0: loss = 0.971824 (* 1 = 0.971824 loss)
I0529 21:04:09.404440 15746 sgd_solver.cpp:106] Iteration 76800, lr = 1e-06
I0529 21:12:47.293689 15746 solver.cpp:228] Iteration 76900, loss = 0.766745
I0529 21:12:47.294230 15746 solver.cpp:244]     Train net output #0: loss = 0.766742 (* 1 = 0.766742 loss)
I0529 21:12:47.294245 15746 sgd_solver.cpp:106] Iteration 76900, lr = 1e-06
I0529 21:22:04.534344 15746 solver.cpp:228] Iteration 77000, loss = 0.427682
I0529 21:22:04.535486 15746 solver.cpp:244]     Train net output #0: loss = 0.427679 (* 1 = 0.427679 loss)
I0529 21:22:04.535503 15746 sgd_solver.cpp:106] Iteration 77000, lr = 1e-06
I0529 21:31:26.083371 15746 solver.cpp:228] Iteration 77100, loss = 0.650803
I0529 21:31:26.083773 15746 solver.cpp:244]     Train net output #0: loss = 0.6508 (* 1 = 0.6508 loss)
I0529 21:31:26.083789 15746 sgd_solver.cpp:106] Iteration 77100, lr = 1e-06
I0529 21:40:10.285641 15746 solver.cpp:228] Iteration 77200, loss = 0.431758
I0529 21:40:10.286038 15746 solver.cpp:244]     Train net output #0: loss = 0.431754 (* 1 = 0.431754 loss)
I0529 21:40:10.286054 15746 sgd_solver.cpp:106] Iteration 77200, lr = 1e-06
I0529 21:48:40.532392 15746 solver.cpp:228] Iteration 77300, loss = 0.265845
I0529 21:48:40.532764 15746 solver.cpp:244]     Train net output #0: loss = 0.265841 (* 1 = 0.265841 loss)
I0529 21:48:40.532779 15746 sgd_solver.cpp:106] Iteration 77300, lr = 1e-06
I0529 21:57:19.186933 15746 solver.cpp:228] Iteration 77400, loss = 0.489754
I0529 21:57:19.187590 15746 solver.cpp:244]     Train net output #0: loss = 0.48975 (* 1 = 0.48975 loss)
I0529 21:57:19.187605 15746 sgd_solver.cpp:106] Iteration 77400, lr = 1e-06
I0529 22:06:06.330469 15746 solver.cpp:228] Iteration 77500, loss = 0.542331
I0529 22:06:06.330916 15746 solver.cpp:244]     Train net output #0: loss = 0.542328 (* 1 = 0.542328 loss)
I0529 22:06:06.330935 15746 sgd_solver.cpp:106] Iteration 77500, lr = 1e-06
I0529 22:15:33.664058 15746 solver.cpp:228] Iteration 77600, loss = 0.288276
I0529 22:15:33.671429 15746 solver.cpp:244]     Train net output #0: loss = 0.288273 (* 1 = 0.288273 loss)
I0529 22:15:33.671439 15746 sgd_solver.cpp:106] Iteration 77600, lr = 1e-06
I0529 22:25:22.398625 15746 solver.cpp:228] Iteration 77700, loss = 0.428866
I0529 22:25:22.399274 15746 solver.cpp:244]     Train net output #0: loss = 0.428862 (* 1 = 0.428862 loss)
I0529 22:25:22.399291 15746 sgd_solver.cpp:106] Iteration 77700, lr = 1e-06
I0529 22:34:52.819654 15746 solver.cpp:228] Iteration 77800, loss = 0.340563
I0529 22:34:52.823246 15746 solver.cpp:244]     Train net output #0: loss = 0.34056 (* 1 = 0.34056 loss)
I0529 22:34:52.823256 15746 sgd_solver.cpp:106] Iteration 77800, lr = 1e-06
I0529 22:44:23.906826 15746 solver.cpp:228] Iteration 77900, loss = 0.302734
I0529 22:44:23.907297 15746 solver.cpp:244]     Train net output #0: loss = 0.30273 (* 1 = 0.30273 loss)
I0529 22:44:23.907310 15746 sgd_solver.cpp:106] Iteration 77900, lr = 1e-06
I0529 22:52:35.233611 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_78000.caffemodel
I0529 22:52:35.581110 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_78000.solverstate
I0529 22:52:41.521198 15746 solver.cpp:228] Iteration 78000, loss = 0.426999
I0529 22:52:41.521245 15746 solver.cpp:244]     Train net output #0: loss = 0.426996 (* 1 = 0.426996 loss)
I0529 22:52:41.521255 15746 sgd_solver.cpp:106] Iteration 78000, lr = 1e-06
I0529 23:01:16.501144 15746 solver.cpp:228] Iteration 78100, loss = 0.720117
I0529 23:01:16.501816 15746 solver.cpp:244]     Train net output #0: loss = 0.720113 (* 1 = 0.720113 loss)
I0529 23:01:16.501832 15746 sgd_solver.cpp:106] Iteration 78100, lr = 1e-06
I0529 23:10:23.962435 15746 solver.cpp:228] Iteration 78200, loss = 0.392739
I0529 23:10:23.962826 15746 solver.cpp:244]     Train net output #0: loss = 0.392735 (* 1 = 0.392735 loss)
I0529 23:10:23.962844 15746 sgd_solver.cpp:106] Iteration 78200, lr = 1e-06
I0529 23:19:25.036666 15746 solver.cpp:228] Iteration 78300, loss = 0.67678
I0529 23:19:25.037286 15746 solver.cpp:244]     Train net output #0: loss = 0.676777 (* 1 = 0.676777 loss)
I0529 23:19:25.037302 15746 sgd_solver.cpp:106] Iteration 78300, lr = 1e-06
I0529 23:25:08.116061 15746 solver.cpp:337] Iteration 78360, Testing net (#0)
I0529 23:25:08.116485 15746 net.cpp:685] Ignoring source layer ratemap
I0529 23:25:08.116503 15746 net.cpp:685] Ignoring source layer amsFeatures
I0529 23:27:58.827208 15746 solver.cpp:404]     Test net output #0: loss = 0.527844 (* 1 = 0.527844 loss)
I0529 23:32:06.050784 15746 solver.cpp:228] Iteration 78400, loss = 0.20667
I0529 23:32:06.051146 15746 solver.cpp:244]     Train net output #0: loss = 0.206667 (* 1 = 0.206667 loss)
I0529 23:32:06.051168 15746 sgd_solver.cpp:106] Iteration 78400, lr = 1e-06
I0529 23:41:43.934376 15746 solver.cpp:228] Iteration 78500, loss = 0.334655
I0529 23:41:43.934727 15746 solver.cpp:244]     Train net output #0: loss = 0.334651 (* 1 = 0.334651 loss)
I0529 23:41:43.934746 15746 sgd_solver.cpp:106] Iteration 78500, lr = 1e-06
I0529 23:51:37.806553 15746 solver.cpp:228] Iteration 78600, loss = 0.475123
I0529 23:51:37.811269 15746 solver.cpp:244]     Train net output #0: loss = 0.475119 (* 1 = 0.475119 loss)
I0529 23:51:37.811286 15746 sgd_solver.cpp:106] Iteration 78600, lr = 1e-06
I0530 00:01:02.352640 15746 solver.cpp:228] Iteration 78700, loss = 0.401526
I0530 00:01:02.355252 15746 solver.cpp:244]     Train net output #0: loss = 0.401522 (* 1 = 0.401522 loss)
I0530 00:01:02.355265 15746 sgd_solver.cpp:106] Iteration 78700, lr = 1e-06
I0530 00:10:04.522346 15746 solver.cpp:228] Iteration 78800, loss = 0.374319
I0530 00:10:04.522979 15746 solver.cpp:244]     Train net output #0: loss = 0.374316 (* 1 = 0.374316 loss)
I0530 00:10:04.522996 15746 sgd_solver.cpp:106] Iteration 78800, lr = 1e-06
I0530 00:19:28.111001 15746 solver.cpp:228] Iteration 78900, loss = 0.355456
I0530 00:19:28.111402 15746 solver.cpp:244]     Train net output #0: loss = 0.355452 (* 1 = 0.355452 loss)
I0530 00:19:28.111416 15746 sgd_solver.cpp:106] Iteration 78900, lr = 1e-06
I0530 00:29:01.310386 15746 solver.cpp:228] Iteration 79000, loss = 0.472725
I0530 00:29:01.310974 15746 solver.cpp:244]     Train net output #0: loss = 0.472721 (* 1 = 0.472721 loss)
I0530 00:29:01.310992 15746 sgd_solver.cpp:106] Iteration 79000, lr = 1e-06
I0530 00:38:34.586760 15746 solver.cpp:228] Iteration 79100, loss = 0.375972
I0530 00:38:34.587518 15746 solver.cpp:244]     Train net output #0: loss = 0.375968 (* 1 = 0.375968 loss)
I0530 00:38:34.587538 15746 sgd_solver.cpp:106] Iteration 79100, lr = 1e-06
I0530 00:48:03.691032 15746 solver.cpp:228] Iteration 79200, loss = 0.474734
I0530 00:48:03.691686 15746 solver.cpp:244]     Train net output #0: loss = 0.47473 (* 1 = 0.47473 loss)
I0530 00:48:03.691704 15746 sgd_solver.cpp:106] Iteration 79200, lr = 1e-06
I0530 00:57:28.364667 15746 solver.cpp:228] Iteration 79300, loss = 0.392116
I0530 00:57:28.367521 15746 solver.cpp:244]     Train net output #0: loss = 0.392112 (* 1 = 0.392112 loss)
I0530 00:57:28.367540 15746 sgd_solver.cpp:106] Iteration 79300, lr = 1e-06
I0530 01:06:59.709929 15746 solver.cpp:228] Iteration 79400, loss = 0.513351
I0530 01:06:59.715199 15746 solver.cpp:244]     Train net output #0: loss = 0.513348 (* 1 = 0.513348 loss)
I0530 01:06:59.715209 15746 sgd_solver.cpp:106] Iteration 79400, lr = 1e-06
I0530 01:16:25.197204 15746 solver.cpp:228] Iteration 79500, loss = 0.549566
I0530 01:16:25.197857 15746 solver.cpp:244]     Train net output #0: loss = 0.549562 (* 1 = 0.549562 loss)
I0530 01:16:25.197875 15746 sgd_solver.cpp:106] Iteration 79500, lr = 1e-06
I0530 01:25:08.872617 15746 solver.cpp:228] Iteration 79600, loss = 0.667683
I0530 01:25:08.873050 15746 solver.cpp:244]     Train net output #0: loss = 0.667679 (* 1 = 0.667679 loss)
I0530 01:25:08.873065 15746 sgd_solver.cpp:106] Iteration 79600, lr = 1e-06
I0530 01:33:44.641681 15746 solver.cpp:228] Iteration 79700, loss = 0.929865
I0530 01:33:44.642319 15746 solver.cpp:244]     Train net output #0: loss = 0.929861 (* 1 = 0.929861 loss)
I0530 01:33:44.642335 15746 sgd_solver.cpp:106] Iteration 79700, lr = 1e-06
I0530 01:42:38.092285 15746 solver.cpp:228] Iteration 79800, loss = 0.413617
I0530 01:42:38.092890 15746 solver.cpp:244]     Train net output #0: loss = 0.413613 (* 1 = 0.413613 loss)
I0530 01:42:38.092910 15746 sgd_solver.cpp:106] Iteration 79800, lr = 1e-06
I0530 01:51:16.253239 15746 solver.cpp:228] Iteration 79900, loss = 0.751642
I0530 01:51:16.253851 15746 solver.cpp:244]     Train net output #0: loss = 0.751638 (* 1 = 0.751638 loss)
I0530 01:51:16.253867 15746 sgd_solver.cpp:106] Iteration 79900, lr = 1e-06
I0530 02:00:07.021426 15746 solver.cpp:228] Iteration 80000, loss = 0.305726
I0530 02:00:07.022194 15746 solver.cpp:244]     Train net output #0: loss = 0.305722 (* 1 = 0.305722 loss)
I0530 02:00:07.022215 15746 sgd_solver.cpp:106] Iteration 80000, lr = 1e-06
I0530 02:07:54.317850 15746 solver.cpp:228] Iteration 80100, loss = 0.485489
I0530 02:07:54.318676 15746 solver.cpp:244]     Train net output #0: loss = 0.485485 (* 1 = 0.485485 loss)
I0530 02:07:54.318706 15746 sgd_solver.cpp:106] Iteration 80100, lr = 1e-06
I0530 02:15:56.419083 15746 solver.cpp:228] Iteration 80200, loss = 0.353071
I0530 02:15:56.419867 15746 solver.cpp:244]     Train net output #0: loss = 0.353067 (* 1 = 0.353067 loss)
I0530 02:15:56.419888 15746 sgd_solver.cpp:106] Iteration 80200, lr = 1e-06
I0530 02:23:54.703029 15746 solver.cpp:228] Iteration 80300, loss = 0.368636
I0530 02:23:54.703615 15746 solver.cpp:244]     Train net output #0: loss = 0.368633 (* 1 = 0.368633 loss)
I0530 02:23:54.703641 15746 sgd_solver.cpp:106] Iteration 80300, lr = 1e-06
I0530 02:31:50.024251 15746 solver.cpp:228] Iteration 80400, loss = 0.979342
I0530 02:31:50.024921 15746 solver.cpp:244]     Train net output #0: loss = 0.979339 (* 1 = 0.979339 loss)
I0530 02:31:50.024951 15746 sgd_solver.cpp:106] Iteration 80400, lr = 1e-06
I0530 02:39:27.340893 15746 solver.cpp:228] Iteration 80500, loss = 0.57297
I0530 02:39:27.341661 15746 solver.cpp:244]     Train net output #0: loss = 0.572966 (* 1 = 0.572966 loss)
I0530 02:39:27.341683 15746 sgd_solver.cpp:106] Iteration 80500, lr = 1e-06
I0530 02:47:10.798969 15746 solver.cpp:228] Iteration 80600, loss = 0.364496
I0530 02:47:10.799751 15746 solver.cpp:244]     Train net output #0: loss = 0.364492 (* 1 = 0.364492 loss)
I0530 02:47:10.799778 15746 sgd_solver.cpp:106] Iteration 80600, lr = 1e-06
I0530 02:55:08.436717 15746 solver.cpp:228] Iteration 80700, loss = 0.778389
I0530 02:55:08.437472 15746 solver.cpp:244]     Train net output #0: loss = 0.778385 (* 1 = 0.778385 loss)
I0530 02:55:08.437495 15746 sgd_solver.cpp:106] Iteration 80700, lr = 1e-06
I0530 03:02:59.300770 15746 solver.cpp:228] Iteration 80800, loss = 0.553695
I0530 03:02:59.301548 15746 solver.cpp:244]     Train net output #0: loss = 0.553692 (* 1 = 0.553692 loss)
I0530 03:02:59.301563 15746 sgd_solver.cpp:106] Iteration 80800, lr = 1e-06
I0530 03:10:51.507088 15746 solver.cpp:228] Iteration 80900, loss = 0.306057
I0530 03:10:51.507813 15746 solver.cpp:244]     Train net output #0: loss = 0.306053 (* 1 = 0.306053 loss)
I0530 03:10:51.507843 15746 sgd_solver.cpp:106] Iteration 80900, lr = 1e-06
I0530 03:18:51.177811 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_81000.caffemodel
I0530 03:18:51.346354 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_81000.solverstate
I0530 03:18:56.748709 15746 solver.cpp:228] Iteration 81000, loss = 0.436477
I0530 03:18:56.748774 15746 solver.cpp:244]     Train net output #0: loss = 0.436473 (* 1 = 0.436473 loss)
I0530 03:18:56.748785 15746 sgd_solver.cpp:106] Iteration 81000, lr = 1e-06
I0530 03:27:03.441925 15746 solver.cpp:228] Iteration 81100, loss = 0.576885
I0530 03:27:03.442766 15746 solver.cpp:244]     Train net output #0: loss = 0.576882 (* 1 = 0.576882 loss)
I0530 03:27:03.442790 15746 sgd_solver.cpp:106] Iteration 81100, lr = 1e-06
I0530 03:34:51.880919 15746 solver.cpp:228] Iteration 81200, loss = 0.636082
I0530 03:34:51.881686 15746 solver.cpp:244]     Train net output #0: loss = 0.636078 (* 1 = 0.636078 loss)
I0530 03:34:51.881711 15746 sgd_solver.cpp:106] Iteration 81200, lr = 1e-06
I0530 03:42:48.822760 15746 solver.cpp:228] Iteration 81300, loss = 0.43609
I0530 03:42:48.823505 15746 solver.cpp:244]     Train net output #0: loss = 0.436086 (* 1 = 0.436086 loss)
I0530 03:42:48.823528 15746 sgd_solver.cpp:106] Iteration 81300, lr = 1e-06
I0530 03:50:51.336217 15746 solver.cpp:228] Iteration 81400, loss = 0.271093
I0530 03:50:51.336926 15746 solver.cpp:244]     Train net output #0: loss = 0.27109 (* 1 = 0.27109 loss)
I0530 03:50:51.336951 15746 sgd_solver.cpp:106] Iteration 81400, lr = 1e-06
I0530 03:58:34.178067 15746 solver.cpp:228] Iteration 81500, loss = 0.47863
I0530 03:58:34.178751 15746 solver.cpp:244]     Train net output #0: loss = 0.478626 (* 1 = 0.478626 loss)
I0530 03:58:34.178766 15746 sgd_solver.cpp:106] Iteration 81500, lr = 1e-06
I0530 04:06:31.986986 15746 solver.cpp:228] Iteration 81600, loss = 0.265073
I0530 04:06:31.987773 15746 solver.cpp:244]     Train net output #0: loss = 0.265069 (* 1 = 0.265069 loss)
I0530 04:06:31.987797 15746 sgd_solver.cpp:106] Iteration 81600, lr = 1e-06
I0530 04:08:32.280503 15746 solver.cpp:337] Iteration 81625, Testing net (#0)
I0530 04:08:32.280911 15746 net.cpp:685] Ignoring source layer ratemap
I0530 04:08:32.280932 15746 net.cpp:685] Ignoring source layer amsFeatures
I0530 04:11:24.195768 15746 solver.cpp:404]     Test net output #0: loss = 0.526988 (* 1 = 0.526988 loss)
I0530 04:17:20.904865 15746 solver.cpp:228] Iteration 81700, loss = 0.594742
I0530 04:17:20.905642 15746 solver.cpp:244]     Train net output #0: loss = 0.594739 (* 1 = 0.594739 loss)
I0530 04:17:20.905678 15746 sgd_solver.cpp:106] Iteration 81700, lr = 1e-06
I0530 04:25:30.529479 15746 solver.cpp:228] Iteration 81800, loss = 0.849773
I0530 04:25:30.530123 15746 solver.cpp:244]     Train net output #0: loss = 0.849769 (* 1 = 0.849769 loss)
I0530 04:25:30.530144 15746 sgd_solver.cpp:106] Iteration 81800, lr = 1e-06
I0530 04:33:33.993738 15746 solver.cpp:228] Iteration 81900, loss = 0.461333
I0530 04:33:33.994292 15746 solver.cpp:244]     Train net output #0: loss = 0.46133 (* 1 = 0.46133 loss)
I0530 04:33:33.994303 15746 sgd_solver.cpp:106] Iteration 81900, lr = 1e-06
I0530 04:41:29.416869 15746 solver.cpp:228] Iteration 82000, loss = 0.608967
I0530 04:41:29.417594 15746 solver.cpp:244]     Train net output #0: loss = 0.608964 (* 1 = 0.608964 loss)
I0530 04:41:29.417615 15746 sgd_solver.cpp:106] Iteration 82000, lr = 1e-06
I0530 04:49:18.558364 15746 solver.cpp:228] Iteration 82100, loss = 0.370582
I0530 04:49:18.559059 15746 solver.cpp:244]     Train net output #0: loss = 0.370579 (* 1 = 0.370579 loss)
I0530 04:49:18.559079 15746 sgd_solver.cpp:106] Iteration 82100, lr = 1e-06
I0530 04:57:09.031504 15746 solver.cpp:228] Iteration 82200, loss = 0.663509
I0530 04:57:09.032263 15746 solver.cpp:244]     Train net output #0: loss = 0.663506 (* 1 = 0.663506 loss)
I0530 04:57:09.032286 15746 sgd_solver.cpp:106] Iteration 82200, lr = 1e-06
I0530 05:05:10.974776 15746 solver.cpp:228] Iteration 82300, loss = 0.792983
I0530 05:05:10.975384 15746 solver.cpp:244]     Train net output #0: loss = 0.792979 (* 1 = 0.792979 loss)
I0530 05:05:10.975397 15746 sgd_solver.cpp:106] Iteration 82300, lr = 1e-06
I0530 05:13:31.882712 15746 solver.cpp:228] Iteration 82400, loss = 0.782678
I0530 05:13:31.883435 15746 solver.cpp:244]     Train net output #0: loss = 0.782675 (* 1 = 0.782675 loss)
I0530 05:13:31.883455 15746 sgd_solver.cpp:106] Iteration 82400, lr = 1e-06
I0530 05:21:28.054199 15746 solver.cpp:228] Iteration 82500, loss = 0.270728
I0530 05:21:28.054997 15746 solver.cpp:244]     Train net output #0: loss = 0.270725 (* 1 = 0.270725 loss)
I0530 05:21:28.055035 15746 sgd_solver.cpp:106] Iteration 82500, lr = 1e-06
I0530 05:29:24.529726 15746 solver.cpp:228] Iteration 82600, loss = 0.515947
I0530 05:29:24.530318 15746 solver.cpp:244]     Train net output #0: loss = 0.515944 (* 1 = 0.515944 loss)
I0530 05:29:24.530342 15746 sgd_solver.cpp:106] Iteration 82600, lr = 1e-06
I0530 05:37:19.911339 15746 solver.cpp:228] Iteration 82700, loss = 0.456178
I0530 05:37:19.912042 15746 solver.cpp:244]     Train net output #0: loss = 0.456175 (* 1 = 0.456175 loss)
I0530 05:37:19.912072 15746 sgd_solver.cpp:106] Iteration 82700, lr = 1e-06
I0530 05:45:15.627281 15746 solver.cpp:228] Iteration 82800, loss = 0.568421
I0530 05:45:15.627907 15746 solver.cpp:244]     Train net output #0: loss = 0.568418 (* 1 = 0.568418 loss)
I0530 05:45:15.627925 15746 sgd_solver.cpp:106] Iteration 82800, lr = 1e-06
I0530 05:53:03.343789 15746 solver.cpp:228] Iteration 82900, loss = 0.434254
I0530 05:53:03.346246 15746 solver.cpp:244]     Train net output #0: loss = 0.43425 (* 1 = 0.43425 loss)
I0530 05:53:03.346276 15746 sgd_solver.cpp:106] Iteration 82900, lr = 1e-06
I0530 06:01:02.932394 15746 solver.cpp:228] Iteration 83000, loss = 0.834433
I0530 06:01:02.933080 15746 solver.cpp:244]     Train net output #0: loss = 0.83443 (* 1 = 0.83443 loss)
I0530 06:01:02.933104 15746 sgd_solver.cpp:106] Iteration 83000, lr = 1e-06
I0530 06:09:05.411823 15746 solver.cpp:228] Iteration 83100, loss = 0.305469
I0530 06:09:05.412567 15746 solver.cpp:244]     Train net output #0: loss = 0.305465 (* 1 = 0.305465 loss)
I0530 06:09:05.412591 15746 sgd_solver.cpp:106] Iteration 83100, lr = 1e-06
I0530 06:16:56.716866 15746 solver.cpp:228] Iteration 83200, loss = 0.380307
I0530 06:16:56.718495 15746 solver.cpp:244]     Train net output #0: loss = 0.380304 (* 1 = 0.380304 loss)
I0530 06:16:56.718519 15746 sgd_solver.cpp:106] Iteration 83200, lr = 1e-06
I0530 06:25:12.943609 15746 solver.cpp:228] Iteration 83300, loss = 0.633448
I0530 06:25:12.944315 15746 solver.cpp:244]     Train net output #0: loss = 0.633445 (* 1 = 0.633445 loss)
I0530 06:25:12.944339 15746 sgd_solver.cpp:106] Iteration 83300, lr = 1e-06
I0530 06:33:29.869437 15746 solver.cpp:228] Iteration 83400, loss = 0.477858
I0530 06:33:29.869995 15746 solver.cpp:244]     Train net output #0: loss = 0.477854 (* 1 = 0.477854 loss)
I0530 06:33:29.870018 15746 sgd_solver.cpp:106] Iteration 83400, lr = 1e-06
I0530 06:41:30.487433 15746 solver.cpp:228] Iteration 83500, loss = 0.44176
I0530 06:41:30.489665 15746 solver.cpp:244]     Train net output #0: loss = 0.441757 (* 1 = 0.441757 loss)
I0530 06:41:30.489687 15746 sgd_solver.cpp:106] Iteration 83500, lr = 1e-06
I0530 06:49:56.894680 15746 solver.cpp:228] Iteration 83600, loss = 0.280502
I0530 06:49:56.895443 15746 solver.cpp:244]     Train net output #0: loss = 0.280498 (* 1 = 0.280498 loss)
I0530 06:49:56.895468 15746 sgd_solver.cpp:106] Iteration 83600, lr = 1e-06
I0530 06:58:34.154719 15746 solver.cpp:228] Iteration 83700, loss = 0.648226
I0530 06:58:34.155517 15746 solver.cpp:244]     Train net output #0: loss = 0.648223 (* 1 = 0.648223 loss)
I0530 06:58:34.155550 15746 sgd_solver.cpp:106] Iteration 83700, lr = 1e-06
I0530 07:06:58.932600 15746 solver.cpp:228] Iteration 83800, loss = 0.512324
I0530 07:06:58.933228 15746 solver.cpp:244]     Train net output #0: loss = 0.51232 (* 1 = 0.51232 loss)
I0530 07:06:58.933243 15746 sgd_solver.cpp:106] Iteration 83800, lr = 1e-06
I0530 07:15:16.993192 15746 solver.cpp:228] Iteration 83900, loss = 0.29815
I0530 07:15:16.993891 15746 solver.cpp:244]     Train net output #0: loss = 0.298147 (* 1 = 0.298147 loss)
I0530 07:15:16.993916 15746 sgd_solver.cpp:106] Iteration 83900, lr = 1e-06
I0530 07:23:34.160547 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_84000.caffemodel
I0530 07:23:34.320941 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_84000.solverstate
I0530 07:23:37.934033 15746 solver.cpp:228] Iteration 84000, loss = 0.431277
I0530 07:23:37.934084 15746 solver.cpp:244]     Train net output #0: loss = 0.431273 (* 1 = 0.431273 loss)
I0530 07:23:37.934094 15746 sgd_solver.cpp:106] Iteration 84000, lr = 1e-06
I0530 07:31:30.679006 15746 solver.cpp:228] Iteration 84100, loss = 0.25305
I0530 07:31:30.679801 15746 solver.cpp:244]     Train net output #0: loss = 0.253047 (* 1 = 0.253047 loss)
I0530 07:31:30.679827 15746 sgd_solver.cpp:106] Iteration 84100, lr = 1e-06
I0530 07:39:18.147637 15746 solver.cpp:228] Iteration 84200, loss = 0.2674
I0530 07:39:18.148350 15746 solver.cpp:244]     Train net output #0: loss = 0.267397 (* 1 = 0.267397 loss)
I0530 07:39:18.148375 15746 sgd_solver.cpp:106] Iteration 84200, lr = 1e-06
I0530 07:47:26.472864 15746 solver.cpp:228] Iteration 84300, loss = 0.370692
I0530 07:47:26.473664 15746 solver.cpp:244]     Train net output #0: loss = 0.370689 (* 1 = 0.370689 loss)
I0530 07:47:26.473685 15746 sgd_solver.cpp:106] Iteration 84300, lr = 1e-06
I0530 07:55:26.468477 15746 solver.cpp:228] Iteration 84400, loss = 0.409585
I0530 07:55:26.469120 15746 solver.cpp:244]     Train net output #0: loss = 0.409582 (* 1 = 0.409582 loss)
I0530 07:55:26.469142 15746 sgd_solver.cpp:106] Iteration 84400, lr = 1e-06
I0530 08:03:18.682873 15746 solver.cpp:228] Iteration 84500, loss = 0.427759
I0530 08:03:18.683313 15746 solver.cpp:244]     Train net output #0: loss = 0.427756 (* 1 = 0.427756 loss)
I0530 08:03:18.683333 15746 sgd_solver.cpp:106] Iteration 84500, lr = 1e-06
I0530 08:11:07.922950 15746 solver.cpp:228] Iteration 84600, loss = 0.499987
I0530 08:11:07.923686 15746 solver.cpp:244]     Train net output #0: loss = 0.499984 (* 1 = 0.499984 loss)
I0530 08:11:07.923710 15746 sgd_solver.cpp:106] Iteration 84600, lr = 1e-06
I0530 08:19:07.293918 15746 solver.cpp:228] Iteration 84700, loss = 0.36039
I0530 08:19:07.294700 15746 solver.cpp:244]     Train net output #0: loss = 0.360386 (* 1 = 0.360386 loss)
I0530 08:19:07.294721 15746 sgd_solver.cpp:106] Iteration 84700, lr = 1e-06
I0530 08:27:22.250226 15746 solver.cpp:228] Iteration 84800, loss = 0.434893
I0530 08:27:22.250989 15746 solver.cpp:244]     Train net output #0: loss = 0.43489 (* 1 = 0.43489 loss)
I0530 08:27:22.251013 15746 sgd_solver.cpp:106] Iteration 84800, lr = 1e-06
I0530 08:34:53.932792 15746 solver.cpp:337] Iteration 84890, Testing net (#0)
I0530 08:34:53.933461 15746 net.cpp:685] Ignoring source layer ratemap
I0530 08:34:53.933475 15746 net.cpp:685] Ignoring source layer amsFeatures
I0530 08:37:44.598146 15746 solver.cpp:404]     Test net output #0: loss = 0.528145 (* 1 = 0.528145 loss)
I0530 08:38:41.908185 15746 solver.cpp:228] Iteration 84900, loss = 0.656389
I0530 08:38:41.908498 15746 solver.cpp:244]     Train net output #0: loss = 0.656385 (* 1 = 0.656385 loss)
I0530 08:38:41.908509 15746 sgd_solver.cpp:106] Iteration 84900, lr = 1e-06
I0530 08:46:48.344775 15746 solver.cpp:228] Iteration 85000, loss = 0.457656
I0530 08:46:48.345242 15746 solver.cpp:244]     Train net output #0: loss = 0.457652 (* 1 = 0.457652 loss)
I0530 08:46:48.345268 15746 sgd_solver.cpp:106] Iteration 85000, lr = 1e-06
I0530 08:55:30.043157 15746 solver.cpp:228] Iteration 85100, loss = 0.395625
I0530 08:55:30.043797 15746 solver.cpp:244]     Train net output #0: loss = 0.395621 (* 1 = 0.395621 loss)
I0530 08:55:30.043814 15746 sgd_solver.cpp:106] Iteration 85100, lr = 1e-06
I0530 09:04:29.531836 15746 solver.cpp:228] Iteration 85200, loss = 0.646439
I0530 09:04:29.532414 15746 solver.cpp:244]     Train net output #0: loss = 0.646436 (* 1 = 0.646436 loss)
I0530 09:04:29.532428 15746 sgd_solver.cpp:106] Iteration 85200, lr = 1e-06
I0530 09:13:36.555184 15746 solver.cpp:228] Iteration 85300, loss = 0.392762
I0530 09:13:36.555938 15746 solver.cpp:244]     Train net output #0: loss = 0.392758 (* 1 = 0.392758 loss)
I0530 09:13:36.555963 15746 sgd_solver.cpp:106] Iteration 85300, lr = 1e-06
I0530 09:22:47.474838 15746 solver.cpp:228] Iteration 85400, loss = 0.411892
I0530 09:22:47.475517 15746 solver.cpp:244]     Train net output #0: loss = 0.411888 (* 1 = 0.411888 loss)
I0530 09:22:47.475528 15746 sgd_solver.cpp:106] Iteration 85400, lr = 1e-06
I0530 09:32:03.645272 15746 solver.cpp:228] Iteration 85500, loss = 0.332648
I0530 09:32:03.645917 15746 solver.cpp:244]     Train net output #0: loss = 0.332644 (* 1 = 0.332644 loss)
I0530 09:32:03.645934 15746 sgd_solver.cpp:106] Iteration 85500, lr = 1e-06
I0530 09:41:05.628337 15746 solver.cpp:228] Iteration 85600, loss = 0.424719
I0530 09:41:05.629004 15746 solver.cpp:244]     Train net output #0: loss = 0.424715 (* 1 = 0.424715 loss)
I0530 09:41:05.629022 15746 sgd_solver.cpp:106] Iteration 85600, lr = 1e-06
I0530 09:50:12.493441 15746 solver.cpp:228] Iteration 85700, loss = 0.621785
I0530 09:50:12.494098 15746 solver.cpp:244]     Train net output #0: loss = 0.621782 (* 1 = 0.621782 loss)
I0530 09:50:12.494115 15746 sgd_solver.cpp:106] Iteration 85700, lr = 1e-06
I0530 09:59:10.083259 15746 solver.cpp:228] Iteration 85800, loss = 0.525118
I0530 09:59:10.083917 15746 solver.cpp:244]     Train net output #0: loss = 0.525114 (* 1 = 0.525114 loss)
I0530 09:59:10.083935 15746 sgd_solver.cpp:106] Iteration 85800, lr = 1e-06
I0530 10:08:16.766564 15746 solver.cpp:228] Iteration 85900, loss = 0.740346
I0530 10:08:16.767240 15746 solver.cpp:244]     Train net output #0: loss = 0.740342 (* 1 = 0.740342 loss)
I0530 10:08:16.767257 15746 sgd_solver.cpp:106] Iteration 85900, lr = 1e-06
I0530 10:17:19.496677 15746 solver.cpp:228] Iteration 86000, loss = 0.840572
I0530 10:17:19.497050 15746 solver.cpp:244]     Train net output #0: loss = 0.840568 (* 1 = 0.840568 loss)
I0530 10:17:19.497067 15746 sgd_solver.cpp:106] Iteration 86000, lr = 1e-06
I0530 10:25:58.457237 15746 solver.cpp:228] Iteration 86100, loss = 0.64286
I0530 10:25:58.457624 15746 solver.cpp:244]     Train net output #0: loss = 0.642856 (* 1 = 0.642856 loss)
I0530 10:25:58.457641 15746 sgd_solver.cpp:106] Iteration 86100, lr = 1e-06
I0530 10:35:09.541126 15746 solver.cpp:228] Iteration 86200, loss = 0.443122
I0530 10:35:09.541790 15746 solver.cpp:244]     Train net output #0: loss = 0.443118 (* 1 = 0.443118 loss)
I0530 10:35:09.541805 15746 sgd_solver.cpp:106] Iteration 86200, lr = 1e-06
I0530 10:44:12.790526 15746 solver.cpp:228] Iteration 86300, loss = 0.427566
I0530 10:44:12.791004 15746 solver.cpp:244]     Train net output #0: loss = 0.427563 (* 1 = 0.427563 loss)
I0530 10:44:12.791019 15746 sgd_solver.cpp:106] Iteration 86300, lr = 1e-06
I0530 10:53:17.342078 15746 solver.cpp:228] Iteration 86400, loss = 0.266985
I0530 10:53:17.342841 15746 solver.cpp:244]     Train net output #0: loss = 0.266981 (* 1 = 0.266981 loss)
I0530 10:53:17.342864 15746 sgd_solver.cpp:106] Iteration 86400, lr = 1e-06
I0530 11:02:23.993703 15746 solver.cpp:228] Iteration 86500, loss = 0.529713
I0530 11:02:23.994374 15746 solver.cpp:244]     Train net output #0: loss = 0.529709 (* 1 = 0.529709 loss)
I0530 11:02:23.994393 15746 sgd_solver.cpp:106] Iteration 86500, lr = 1e-06
I0530 11:11:23.884348 15746 solver.cpp:228] Iteration 86600, loss = 0.465764
I0530 11:11:23.885133 15746 solver.cpp:244]     Train net output #0: loss = 0.46576 (* 1 = 0.46576 loss)
I0530 11:11:23.885151 15746 sgd_solver.cpp:106] Iteration 86600, lr = 1e-06
I0530 11:20:31.083320 15746 solver.cpp:228] Iteration 86700, loss = 0.413284
I0530 11:20:31.083645 15746 solver.cpp:244]     Train net output #0: loss = 0.41328 (* 1 = 0.41328 loss)
I0530 11:20:31.083662 15746 sgd_solver.cpp:106] Iteration 86700, lr = 1e-06
I0530 11:29:41.559535 15746 solver.cpp:228] Iteration 86800, loss = 0.503603
I0530 11:29:41.559880 15746 solver.cpp:244]     Train net output #0: loss = 0.5036 (* 1 = 0.5036 loss)
I0530 11:29:41.559895 15746 sgd_solver.cpp:106] Iteration 86800, lr = 1e-06
I0530 11:38:51.056267 15746 solver.cpp:228] Iteration 86900, loss = 0.447047
I0530 11:38:51.056655 15746 solver.cpp:244]     Train net output #0: loss = 0.447043 (* 1 = 0.447043 loss)
I0530 11:38:51.056674 15746 sgd_solver.cpp:106] Iteration 86900, lr = 1e-06
I0530 11:48:15.879030 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_87000.caffemodel
I0530 11:48:16.061882 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_87000.solverstate
I0530 11:48:23.022789 15746 solver.cpp:228] Iteration 87000, loss = 0.419962
I0530 11:48:23.022855 15746 solver.cpp:244]     Train net output #0: loss = 0.419958 (* 1 = 0.419958 loss)
I0530 11:48:23.022872 15746 sgd_solver.cpp:106] Iteration 87000, lr = 1e-06
I0530 11:57:26.631345 15746 solver.cpp:228] Iteration 87100, loss = 0.376093
I0530 11:57:26.631822 15746 solver.cpp:244]     Train net output #0: loss = 0.376089 (* 1 = 0.376089 loss)
I0530 11:57:26.631840 15746 sgd_solver.cpp:106] Iteration 87100, lr = 1e-06
I0530 12:06:32.778339 15746 solver.cpp:228] Iteration 87200, loss = 0.798356
I0530 12:06:32.778707 15746 solver.cpp:244]     Train net output #0: loss = 0.798353 (* 1 = 0.798353 loss)
I0530 12:06:32.778725 15746 sgd_solver.cpp:106] Iteration 87200, lr = 1e-06
I0530 12:15:47.891947 15746 solver.cpp:228] Iteration 87300, loss = 0.57191
I0530 12:15:47.892601 15746 solver.cpp:244]     Train net output #0: loss = 0.571906 (* 1 = 0.571906 loss)
I0530 12:15:47.892639 15746 sgd_solver.cpp:106] Iteration 87300, lr = 1e-06
I0530 12:25:04.747836 15746 solver.cpp:228] Iteration 87400, loss = 0.422449
I0530 12:25:04.748517 15746 solver.cpp:244]     Train net output #0: loss = 0.422445 (* 1 = 0.422445 loss)
I0530 12:25:04.748533 15746 sgd_solver.cpp:106] Iteration 87400, lr = 1e-06
I0530 12:34:11.326815 15746 solver.cpp:228] Iteration 87500, loss = 0.309926
I0530 12:34:11.327505 15746 solver.cpp:244]     Train net output #0: loss = 0.309922 (* 1 = 0.309922 loss)
I0530 12:34:11.327523 15746 sgd_solver.cpp:106] Iteration 87500, lr = 1e-06
I0530 12:43:25.452838 15746 solver.cpp:228] Iteration 87600, loss = 0.422196
I0530 12:43:25.453418 15746 solver.cpp:244]     Train net output #0: loss = 0.422192 (* 1 = 0.422192 loss)
I0530 12:43:25.453434 15746 sgd_solver.cpp:106] Iteration 87600, lr = 1e-06
I0530 12:52:11.876890 15746 solver.cpp:228] Iteration 87700, loss = 0.308981
I0530 12:52:11.877567 15746 solver.cpp:244]     Train net output #0: loss = 0.308977 (* 1 = 0.308977 loss)
I0530 12:52:11.877593 15746 sgd_solver.cpp:106] Iteration 87700, lr = 1e-06
I0530 13:00:44.268319 15746 solver.cpp:228] Iteration 87800, loss = 0.4137
I0530 13:00:44.269011 15746 solver.cpp:244]     Train net output #0: loss = 0.413696 (* 1 = 0.413696 loss)
I0530 13:00:44.269027 15746 sgd_solver.cpp:106] Iteration 87800, lr = 1e-06
I0530 13:09:09.273535 15746 solver.cpp:228] Iteration 87900, loss = 0.284661
I0530 13:09:09.274163 15746 solver.cpp:244]     Train net output #0: loss = 0.284657 (* 1 = 0.284657 loss)
I0530 13:09:09.274179 15746 sgd_solver.cpp:106] Iteration 87900, lr = 1e-06
I0530 13:17:49.317630 15746 solver.cpp:228] Iteration 88000, loss = 0.619677
I0530 13:17:49.318316 15746 solver.cpp:244]     Train net output #0: loss = 0.619673 (* 1 = 0.619673 loss)
I0530 13:17:49.318334 15746 sgd_solver.cpp:106] Iteration 88000, lr = 1e-06
I0530 13:26:24.796254 15746 solver.cpp:228] Iteration 88100, loss = 0.321595
I0530 13:26:24.796896 15746 solver.cpp:244]     Train net output #0: loss = 0.321591 (* 1 = 0.321591 loss)
I0530 13:26:24.796913 15746 sgd_solver.cpp:106] Iteration 88100, lr = 1e-06
I0530 13:31:00.508570 15746 solver.cpp:337] Iteration 88155, Testing net (#0)
I0530 13:31:00.508942 15746 net.cpp:685] Ignoring source layer ratemap
I0530 13:31:00.508951 15746 net.cpp:685] Ignoring source layer amsFeatures
I0530 13:33:50.778419 15746 solver.cpp:404]     Test net output #0: loss = 0.526545 (* 1 = 0.526545 loss)
I0530 13:37:53.712743 15746 solver.cpp:228] Iteration 88200, loss = 0.771021
I0530 13:37:53.713201 15746 solver.cpp:244]     Train net output #0: loss = 0.771017 (* 1 = 0.771017 loss)
I0530 13:37:53.713222 15746 sgd_solver.cpp:106] Iteration 88200, lr = 1e-06
I0530 13:46:38.511628 15746 solver.cpp:228] Iteration 88300, loss = 0.566305
I0530 13:46:38.512308 15746 solver.cpp:244]     Train net output #0: loss = 0.566301 (* 1 = 0.566301 loss)
I0530 13:46:38.512323 15746 sgd_solver.cpp:106] Iteration 88300, lr = 1e-06
I0530 13:55:18.737624 15746 solver.cpp:228] Iteration 88400, loss = 0.521689
I0530 13:55:18.738247 15746 solver.cpp:244]     Train net output #0: loss = 0.521685 (* 1 = 0.521685 loss)
I0530 13:55:18.738262 15746 sgd_solver.cpp:106] Iteration 88400, lr = 1e-06
I0530 14:03:50.460202 15746 solver.cpp:228] Iteration 88500, loss = 0.462357
I0530 14:03:50.460862 15746 solver.cpp:244]     Train net output #0: loss = 0.462353 (* 1 = 0.462353 loss)
I0530 14:03:50.460878 15746 sgd_solver.cpp:106] Iteration 88500, lr = 1e-06
I0530 14:12:24.489229 15746 solver.cpp:228] Iteration 88600, loss = 0.698797
I0530 14:12:24.489922 15746 solver.cpp:244]     Train net output #0: loss = 0.698794 (* 1 = 0.698794 loss)
I0530 14:12:24.489946 15746 sgd_solver.cpp:106] Iteration 88600, lr = 1e-06
I0530 14:20:56.915874 15746 solver.cpp:228] Iteration 88700, loss = 0.567591
I0530 14:20:56.916504 15746 solver.cpp:244]     Train net output #0: loss = 0.567587 (* 1 = 0.567587 loss)
I0530 14:20:56.916518 15746 sgd_solver.cpp:106] Iteration 88700, lr = 1e-06
I0530 14:29:38.184273 15746 solver.cpp:228] Iteration 88800, loss = 0.739371
I0530 14:29:38.184957 15746 solver.cpp:244]     Train net output #0: loss = 0.739367 (* 1 = 0.739367 loss)
I0530 14:29:38.184972 15746 sgd_solver.cpp:106] Iteration 88800, lr = 1e-06
I0530 14:38:05.790827 15746 solver.cpp:228] Iteration 88900, loss = 0.562363
I0530 14:38:05.791484 15746 solver.cpp:244]     Train net output #0: loss = 0.562359 (* 1 = 0.562359 loss)
I0530 14:38:05.791496 15746 sgd_solver.cpp:106] Iteration 88900, lr = 1e-06
I0530 14:46:49.287343 15746 solver.cpp:228] Iteration 89000, loss = 0.508337
I0530 14:46:49.287982 15746 solver.cpp:244]     Train net output #0: loss = 0.508334 (* 1 = 0.508334 loss)
I0530 14:46:49.287997 15746 sgd_solver.cpp:106] Iteration 89000, lr = 1e-06
I0530 14:55:35.485600 15746 solver.cpp:228] Iteration 89100, loss = 0.551821
I0530 14:55:35.486254 15746 solver.cpp:244]     Train net output #0: loss = 0.551818 (* 1 = 0.551818 loss)
I0530 14:55:35.486273 15746 sgd_solver.cpp:106] Iteration 89100, lr = 1e-06
I0530 15:04:06.449791 15746 solver.cpp:228] Iteration 89200, loss = 0.411084
I0530 15:04:06.450139 15746 solver.cpp:244]     Train net output #0: loss = 0.411081 (* 1 = 0.411081 loss)
I0530 15:04:06.450151 15746 sgd_solver.cpp:106] Iteration 89200, lr = 1e-06
I0530 15:12:42.510587 15746 solver.cpp:228] Iteration 89300, loss = 0.364045
I0530 15:12:42.510972 15746 solver.cpp:244]     Train net output #0: loss = 0.364042 (* 1 = 0.364042 loss)
I0530 15:12:42.510998 15746 sgd_solver.cpp:106] Iteration 89300, lr = 1e-06
I0530 15:21:20.594463 15746 solver.cpp:228] Iteration 89400, loss = 0.318723
I0530 15:21:20.595036 15746 solver.cpp:244]     Train net output #0: loss = 0.318719 (* 1 = 0.318719 loss)
I0530 15:21:20.595052 15746 sgd_solver.cpp:106] Iteration 89400, lr = 1e-06
I0530 15:30:04.232637 15746 solver.cpp:228] Iteration 89500, loss = 0.438785
I0530 15:30:04.233281 15746 solver.cpp:244]     Train net output #0: loss = 0.438781 (* 1 = 0.438781 loss)
I0530 15:30:04.233302 15746 sgd_solver.cpp:106] Iteration 89500, lr = 1e-06
I0530 15:38:53.208379 15746 solver.cpp:228] Iteration 89600, loss = 0.592972
I0530 15:38:53.208950 15746 solver.cpp:244]     Train net output #0: loss = 0.592968 (* 1 = 0.592968 loss)
I0530 15:38:53.208963 15746 sgd_solver.cpp:106] Iteration 89600, lr = 1e-06
I0530 15:47:24.862922 15746 solver.cpp:228] Iteration 89700, loss = 0.191848
I0530 15:47:24.863384 15746 solver.cpp:244]     Train net output #0: loss = 0.191845 (* 1 = 0.191845 loss)
I0530 15:47:24.863409 15746 sgd_solver.cpp:106] Iteration 89700, lr = 1e-06
I0530 15:56:20.214164 15746 solver.cpp:228] Iteration 89800, loss = 0.388928
I0530 15:56:20.214548 15746 solver.cpp:244]     Train net output #0: loss = 0.388925 (* 1 = 0.388925 loss)
I0530 15:56:20.214561 15746 sgd_solver.cpp:106] Iteration 89800, lr = 1e-06
I0530 16:05:03.972774 15746 solver.cpp:228] Iteration 89900, loss = 0.307938
I0530 16:05:03.973495 15746 solver.cpp:244]     Train net output #0: loss = 0.307935 (* 1 = 0.307935 loss)
I0530 16:05:03.973520 15746 sgd_solver.cpp:106] Iteration 89900, lr = 1e-06
I0530 16:13:09.691839 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_90000.caffemodel
I0530 16:13:09.880077 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_90000.solverstate
I0530 16:13:14.409108 15746 solver.cpp:228] Iteration 90000, loss = 0.591767
I0530 16:13:14.409158 15746 solver.cpp:244]     Train net output #0: loss = 0.591764 (* 1 = 0.591764 loss)
I0530 16:13:14.409173 15746 sgd_solver.cpp:106] Iteration 90000, lr = 1e-07
I0530 16:21:23.672834 15746 solver.cpp:228] Iteration 90100, loss = 0.24823
I0530 16:21:23.673504 15746 solver.cpp:244]     Train net output #0: loss = 0.248227 (* 1 = 0.248227 loss)
I0530 16:21:23.673530 15746 sgd_solver.cpp:106] Iteration 90100, lr = 1e-07
I0530 16:29:24.549638 15746 solver.cpp:228] Iteration 90200, loss = 0.492373
I0530 16:29:24.550348 15746 solver.cpp:244]     Train net output #0: loss = 0.49237 (* 1 = 0.49237 loss)
I0530 16:29:24.550374 15746 sgd_solver.cpp:106] Iteration 90200, lr = 1e-07
I0530 16:37:28.069510 15746 solver.cpp:228] Iteration 90300, loss = 0.419755
I0530 16:37:28.069960 15746 solver.cpp:244]     Train net output #0: loss = 0.419752 (* 1 = 0.419752 loss)
I0530 16:37:28.069986 15746 sgd_solver.cpp:106] Iteration 90300, lr = 1e-07
I0530 16:45:37.864074 15746 solver.cpp:228] Iteration 90400, loss = 0.579788
I0530 16:45:37.864527 15746 solver.cpp:244]     Train net output #0: loss = 0.579784 (* 1 = 0.579784 loss)
I0530 16:45:37.864562 15746 sgd_solver.cpp:106] Iteration 90400, lr = 1e-07
I0530 16:53:34.647773 15746 solver.cpp:228] Iteration 90500, loss = 0.375511
I0530 16:53:34.648277 15746 solver.cpp:244]     Train net output #0: loss = 0.375507 (* 1 = 0.375507 loss)
I0530 16:53:34.648298 15746 sgd_solver.cpp:106] Iteration 90500, lr = 1e-07
I0530 17:01:41.802850 15746 solver.cpp:228] Iteration 90600, loss = 0.24148
I0530 17:01:41.803639 15746 solver.cpp:244]     Train net output #0: loss = 0.241477 (* 1 = 0.241477 loss)
I0530 17:01:41.803654 15746 sgd_solver.cpp:106] Iteration 90600, lr = 1e-07
I0530 17:09:40.194638 15746 solver.cpp:228] Iteration 90700, loss = 0.673192
I0530 17:09:40.195349 15746 solver.cpp:244]     Train net output #0: loss = 0.673189 (* 1 = 0.673189 loss)
I0530 17:09:40.195375 15746 sgd_solver.cpp:106] Iteration 90700, lr = 1e-07
I0530 17:17:36.005038 15746 solver.cpp:228] Iteration 90800, loss = 0.625356
I0530 17:17:36.005496 15746 solver.cpp:244]     Train net output #0: loss = 0.625353 (* 1 = 0.625353 loss)
I0530 17:17:36.005517 15746 sgd_solver.cpp:106] Iteration 90800, lr = 1e-07
I0530 17:26:23.631418 15746 solver.cpp:228] Iteration 90900, loss = 0.413853
I0530 17:26:23.633844 15746 solver.cpp:244]     Train net output #0: loss = 0.41385 (* 1 = 0.41385 loss)
I0530 17:26:23.633860 15746 sgd_solver.cpp:106] Iteration 90900, lr = 1e-07
I0530 17:35:45.320996 15746 solver.cpp:228] Iteration 91000, loss = 0.391087
I0530 17:35:45.321614 15746 solver.cpp:244]     Train net output #0: loss = 0.391084 (* 1 = 0.391084 loss)
I0530 17:35:45.321632 15746 sgd_solver.cpp:106] Iteration 91000, lr = 1e-07
I0530 17:44:49.389614 15746 solver.cpp:228] Iteration 91100, loss = 0.687233
I0530 17:44:49.390244 15746 solver.cpp:244]     Train net output #0: loss = 0.687229 (* 1 = 0.687229 loss)
I0530 17:44:49.390256 15746 sgd_solver.cpp:106] Iteration 91100, lr = 1e-07
I0530 17:53:46.707545 15746 solver.cpp:228] Iteration 91200, loss = 0.772975
I0530 17:53:46.707885 15746 solver.cpp:244]     Train net output #0: loss = 0.772972 (* 1 = 0.772972 loss)
I0530 17:53:46.707900 15746 sgd_solver.cpp:106] Iteration 91200, lr = 1e-07
I0530 18:02:40.660120 15746 solver.cpp:228] Iteration 91300, loss = 0.750208
I0530 18:02:40.660817 15746 solver.cpp:244]     Train net output #0: loss = 0.750204 (* 1 = 0.750204 loss)
I0530 18:02:40.660838 15746 sgd_solver.cpp:106] Iteration 91300, lr = 1e-07
I0530 18:11:55.381585 15746 solver.cpp:228] Iteration 91400, loss = 0.334761
I0530 18:11:55.382282 15746 solver.cpp:244]     Train net output #0: loss = 0.334757 (* 1 = 0.334757 loss)
I0530 18:11:55.382298 15746 sgd_solver.cpp:106] Iteration 91400, lr = 1e-07
I0530 18:13:42.207890 15746 solver.cpp:337] Iteration 91420, Testing net (#0)
I0530 18:13:42.208384 15746 net.cpp:685] Ignoring source layer ratemap
I0530 18:13:42.208394 15746 net.cpp:685] Ignoring source layer amsFeatures
I0530 18:16:32.806408 15746 solver.cpp:404]     Test net output #0: loss = 0.528084 (* 1 = 0.528084 loss)
I0530 18:23:49.432250 15746 solver.cpp:228] Iteration 91500, loss = 0.580384
I0530 18:23:49.432934 15746 solver.cpp:244]     Train net output #0: loss = 0.580381 (* 1 = 0.580381 loss)
I0530 18:23:49.432955 15746 sgd_solver.cpp:106] Iteration 91500, lr = 1e-07
I0530 18:32:55.704363 15746 solver.cpp:228] Iteration 91600, loss = 0.478391
I0530 18:32:55.705011 15746 solver.cpp:244]     Train net output #0: loss = 0.478388 (* 1 = 0.478388 loss)
I0530 18:32:55.705029 15746 sgd_solver.cpp:106] Iteration 91600, lr = 1e-07
I0530 18:42:15.197649 15746 solver.cpp:228] Iteration 91700, loss = 0.656277
I0530 18:42:15.198288 15746 solver.cpp:244]     Train net output #0: loss = 0.656273 (* 1 = 0.656273 loss)
I0530 18:42:15.198305 15746 sgd_solver.cpp:106] Iteration 91700, lr = 1e-07
I0530 18:51:24.957988 15746 solver.cpp:228] Iteration 91800, loss = 0.517792
I0530 18:51:24.963203 15746 solver.cpp:244]     Train net output #0: loss = 0.517788 (* 1 = 0.517788 loss)
I0530 18:51:24.963227 15746 sgd_solver.cpp:106] Iteration 91800, lr = 1e-07
I0530 19:00:30.996291 15746 solver.cpp:228] Iteration 91900, loss = 0.506066
I0530 19:00:30.997040 15746 solver.cpp:244]     Train net output #0: loss = 0.506063 (* 1 = 0.506063 loss)
I0530 19:00:30.997061 15746 sgd_solver.cpp:106] Iteration 91900, lr = 1e-07
I0530 19:08:49.358291 15746 solver.cpp:228] Iteration 92000, loss = 0.815319
I0530 19:08:49.358979 15746 solver.cpp:244]     Train net output #0: loss = 0.815315 (* 1 = 0.815315 loss)
I0530 19:08:49.359004 15746 sgd_solver.cpp:106] Iteration 92000, lr = 1e-07
I0530 19:16:44.693704 15746 solver.cpp:228] Iteration 92100, loss = 0.542385
I0530 19:16:44.694465 15746 solver.cpp:244]     Train net output #0: loss = 0.542381 (* 1 = 0.542381 loss)
I0530 19:16:44.694489 15746 sgd_solver.cpp:106] Iteration 92100, lr = 1e-07
I0530 19:24:53.966267 15746 solver.cpp:228] Iteration 92200, loss = 1.38548
I0530 19:24:53.967006 15746 solver.cpp:244]     Train net output #0: loss = 1.38548 (* 1 = 1.38548 loss)
I0530 19:24:53.967028 15746 sgd_solver.cpp:106] Iteration 92200, lr = 1e-07
I0530 19:32:55.712400 15746 solver.cpp:228] Iteration 92300, loss = 0.38711
I0530 19:32:55.712853 15746 solver.cpp:244]     Train net output #0: loss = 0.387107 (* 1 = 0.387107 loss)
I0530 19:32:55.712878 15746 sgd_solver.cpp:106] Iteration 92300, lr = 1e-07
I0530 19:40:47.717370 15746 solver.cpp:228] Iteration 92400, loss = 0.5354
I0530 19:40:47.718070 15746 solver.cpp:244]     Train net output #0: loss = 0.535396 (* 1 = 0.535396 loss)
I0530 19:40:47.718094 15746 sgd_solver.cpp:106] Iteration 92400, lr = 1e-07
I0530 19:48:43.841393 15746 solver.cpp:228] Iteration 92500, loss = 0.297766
I0530 19:48:43.842108 15746 solver.cpp:244]     Train net output #0: loss = 0.297763 (* 1 = 0.297763 loss)
I0530 19:48:43.842126 15746 sgd_solver.cpp:106] Iteration 92500, lr = 1e-07
I0530 19:56:33.620221 15746 solver.cpp:228] Iteration 92600, loss = 0.504872
I0530 19:56:33.620661 15746 solver.cpp:244]     Train net output #0: loss = 0.504869 (* 1 = 0.504869 loss)
I0530 19:56:33.620687 15746 sgd_solver.cpp:106] Iteration 92600, lr = 1e-07
I0530 20:04:36.343000 15746 solver.cpp:228] Iteration 92700, loss = 0.512604
I0530 20:04:36.343492 15746 solver.cpp:244]     Train net output #0: loss = 0.512601 (* 1 = 0.512601 loss)
I0530 20:04:36.343523 15746 sgd_solver.cpp:106] Iteration 92700, lr = 1e-07
I0530 20:12:42.892246 15746 solver.cpp:228] Iteration 92800, loss = 0.237525
I0530 20:12:42.892701 15746 solver.cpp:244]     Train net output #0: loss = 0.237521 (* 1 = 0.237521 loss)
I0530 20:12:42.892727 15746 sgd_solver.cpp:106] Iteration 92800, lr = 1e-07
I0530 20:20:42.989574 15746 solver.cpp:228] Iteration 92900, loss = 0.683055
I0530 20:20:42.990283 15746 solver.cpp:244]     Train net output #0: loss = 0.683051 (* 1 = 0.683051 loss)
I0530 20:20:42.990314 15746 sgd_solver.cpp:106] Iteration 92900, lr = 1e-07
I0530 20:28:45.801738 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_93000.caffemodel
I0530 20:28:45.962191 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_93000.solverstate
I0530 20:28:50.763682 15746 solver.cpp:228] Iteration 93000, loss = 0.537817
I0530 20:28:50.763731 15746 solver.cpp:244]     Train net output #0: loss = 0.537813 (* 1 = 0.537813 loss)
I0530 20:28:50.763742 15746 sgd_solver.cpp:106] Iteration 93000, lr = 1e-07
I0530 20:36:57.696292 15746 solver.cpp:228] Iteration 93100, loss = 0.239691
I0530 20:36:57.696781 15746 solver.cpp:244]     Train net output #0: loss = 0.239687 (* 1 = 0.239687 loss)
I0530 20:36:57.696802 15746 sgd_solver.cpp:106] Iteration 93100, lr = 1e-07
I0530 20:45:00.520294 15746 solver.cpp:228] Iteration 93200, loss = 0.319596
I0530 20:45:00.521013 15746 solver.cpp:244]     Train net output #0: loss = 0.319593 (* 1 = 0.319593 loss)
I0530 20:45:00.521039 15746 sgd_solver.cpp:106] Iteration 93200, lr = 1e-07
I0530 20:52:44.695771 15746 solver.cpp:228] Iteration 93300, loss = 0.33117
I0530 20:52:44.696542 15746 solver.cpp:244]     Train net output #0: loss = 0.331167 (* 1 = 0.331167 loss)
I0530 20:52:44.696568 15746 sgd_solver.cpp:106] Iteration 93300, lr = 1e-07
I0530 21:00:33.556015 15746 solver.cpp:228] Iteration 93400, loss = 0.295357
I0530 21:00:33.556771 15746 solver.cpp:244]     Train net output #0: loss = 0.295353 (* 1 = 0.295353 loss)
I0530 21:00:33.556797 15746 sgd_solver.cpp:106] Iteration 93400, lr = 1e-07
I0530 21:08:30.324877 15746 solver.cpp:228] Iteration 93500, loss = 0.255157
I0530 21:08:30.325495 15746 solver.cpp:244]     Train net output #0: loss = 0.255154 (* 1 = 0.255154 loss)
I0530 21:08:30.325521 15746 sgd_solver.cpp:106] Iteration 93500, lr = 1e-07
I0530 21:16:21.679718 15746 solver.cpp:228] Iteration 93600, loss = 0.37799
I0530 21:16:21.680399 15746 solver.cpp:244]     Train net output #0: loss = 0.377986 (* 1 = 0.377986 loss)
I0530 21:16:21.680423 15746 sgd_solver.cpp:106] Iteration 93600, lr = 1e-07
I0530 21:24:16.629467 15746 solver.cpp:228] Iteration 93700, loss = 0.376743
I0530 21:24:16.630316 15746 solver.cpp:244]     Train net output #0: loss = 0.376739 (* 1 = 0.376739 loss)
I0530 21:24:16.630339 15746 sgd_solver.cpp:106] Iteration 93700, lr = 1e-07
I0530 21:32:27.754719 15746 solver.cpp:228] Iteration 93800, loss = 0.861291
I0530 21:32:27.755314 15746 solver.cpp:244]     Train net output #0: loss = 0.861287 (* 1 = 0.861287 loss)
I0530 21:32:27.755339 15746 sgd_solver.cpp:106] Iteration 93800, lr = 1e-07
I0530 21:40:26.473685 15746 solver.cpp:228] Iteration 93900, loss = 0.377046
I0530 21:40:26.474477 15746 solver.cpp:244]     Train net output #0: loss = 0.377042 (* 1 = 0.377042 loss)
I0530 21:40:26.474498 15746 sgd_solver.cpp:106] Iteration 93900, lr = 1e-07
I0530 21:48:18.833506 15746 solver.cpp:228] Iteration 94000, loss = 0.328875
I0530 21:48:18.834208 15746 solver.cpp:244]     Train net output #0: loss = 0.328872 (* 1 = 0.328872 loss)
I0530 21:48:18.834233 15746 sgd_solver.cpp:106] Iteration 94000, lr = 1e-07
I0530 21:56:15.992004 15746 solver.cpp:228] Iteration 94100, loss = 0.286199
I0530 21:56:15.992766 15746 solver.cpp:244]     Train net output #0: loss = 0.286195 (* 1 = 0.286195 loss)
I0530 21:56:15.992790 15746 sgd_solver.cpp:106] Iteration 94100, lr = 1e-07
I0530 22:04:04.220427 15746 solver.cpp:228] Iteration 94200, loss = 0.775552
I0530 22:04:04.221122 15746 solver.cpp:244]     Train net output #0: loss = 0.775549 (* 1 = 0.775549 loss)
I0530 22:04:04.221145 15746 sgd_solver.cpp:106] Iteration 94200, lr = 1e-07
I0530 22:12:14.982125 15746 solver.cpp:228] Iteration 94300, loss = 0.304532
I0530 22:12:14.982976 15746 solver.cpp:244]     Train net output #0: loss = 0.304528 (* 1 = 0.304528 loss)
I0530 22:12:14.983001 15746 sgd_solver.cpp:106] Iteration 94300, lr = 1e-07
I0530 22:20:13.366235 15746 solver.cpp:228] Iteration 94400, loss = 0.661138
I0530 22:20:13.366981 15746 solver.cpp:244]     Train net output #0: loss = 0.661134 (* 1 = 0.661134 loss)
I0530 22:20:13.367015 15746 sgd_solver.cpp:106] Iteration 94400, lr = 1e-07
I0530 22:27:56.717042 15746 solver.cpp:228] Iteration 94500, loss = 0.461036
I0530 22:27:56.717874 15746 solver.cpp:244]     Train net output #0: loss = 0.461033 (* 1 = 0.461033 loss)
I0530 22:27:56.717901 15746 sgd_solver.cpp:106] Iteration 94500, lr = 1e-07
I0530 22:35:45.746289 15746 solver.cpp:228] Iteration 94600, loss = 0.80858
I0530 22:35:45.747048 15746 solver.cpp:244]     Train net output #0: loss = 0.808576 (* 1 = 0.808576 loss)
I0530 22:35:45.747072 15746 sgd_solver.cpp:106] Iteration 94600, lr = 1e-07
I0530 22:42:41.169523 15746 solver.cpp:337] Iteration 94685, Testing net (#0)
I0530 22:42:41.169935 15746 net.cpp:685] Ignoring source layer ratemap
I0530 22:42:41.169960 15746 net.cpp:685] Ignoring source layer amsFeatures
I0530 22:45:31.131176 15746 solver.cpp:404]     Test net output #0: loss = 0.528443 (* 1 = 0.528443 loss)
I0530 22:46:47.344449 15746 solver.cpp:228] Iteration 94700, loss = 0.577353
I0530 22:46:47.344902 15746 solver.cpp:244]     Train net output #0: loss = 0.577349 (* 1 = 0.577349 loss)
I0530 22:46:47.344936 15746 sgd_solver.cpp:106] Iteration 94700, lr = 1e-07
I0530 22:54:49.635308 15746 solver.cpp:228] Iteration 94800, loss = 0.416144
I0530 22:54:49.636111 15746 solver.cpp:244]     Train net output #0: loss = 0.41614 (* 1 = 0.41614 loss)
I0530 22:54:49.636140 15746 sgd_solver.cpp:106] Iteration 94800, lr = 1e-07
I0530 23:02:37.842952 15746 solver.cpp:228] Iteration 94900, loss = 0.404646
I0530 23:02:37.843642 15746 solver.cpp:244]     Train net output #0: loss = 0.404642 (* 1 = 0.404642 loss)
I0530 23:02:37.843667 15746 sgd_solver.cpp:106] Iteration 94900, lr = 1e-07
I0530 23:10:28.567181 15746 solver.cpp:228] Iteration 95000, loss = 0.462989
I0530 23:10:28.567886 15746 solver.cpp:244]     Train net output #0: loss = 0.462985 (* 1 = 0.462985 loss)
I0530 23:10:28.567910 15746 sgd_solver.cpp:106] Iteration 95000, lr = 1e-07
I0530 23:18:22.495594 15746 solver.cpp:228] Iteration 95100, loss = 0.212125
I0530 23:18:22.496376 15746 solver.cpp:244]     Train net output #0: loss = 0.212121 (* 1 = 0.212121 loss)
I0530 23:18:22.496399 15746 sgd_solver.cpp:106] Iteration 95100, lr = 1e-07
I0530 23:26:08.378540 15746 solver.cpp:228] Iteration 95200, loss = 0.381258
I0530 23:26:08.379320 15746 solver.cpp:244]     Train net output #0: loss = 0.381254 (* 1 = 0.381254 loss)
I0530 23:26:08.379344 15746 sgd_solver.cpp:106] Iteration 95200, lr = 1e-07
I0530 23:34:11.467566 15746 solver.cpp:228] Iteration 95300, loss = 0.627305
I0530 23:34:11.468319 15746 solver.cpp:244]     Train net output #0: loss = 0.627301 (* 1 = 0.627301 loss)
I0530 23:34:11.468345 15746 sgd_solver.cpp:106] Iteration 95300, lr = 1e-07
I0530 23:42:11.518731 15746 solver.cpp:228] Iteration 95400, loss = 0.419464
I0530 23:42:11.519510 15746 solver.cpp:244]     Train net output #0: loss = 0.41946 (* 1 = 0.41946 loss)
I0530 23:42:11.519531 15746 sgd_solver.cpp:106] Iteration 95400, lr = 1e-07
I0530 23:50:12.358078 15746 solver.cpp:228] Iteration 95500, loss = 0.26861
I0530 23:50:12.358834 15746 solver.cpp:244]     Train net output #0: loss = 0.268606 (* 1 = 0.268606 loss)
I0530 23:50:12.358860 15746 sgd_solver.cpp:106] Iteration 95500, lr = 1e-07
I0530 23:58:08.411180 15746 solver.cpp:228] Iteration 95600, loss = 0.282748
I0530 23:58:08.411967 15746 solver.cpp:244]     Train net output #0: loss = 0.282745 (* 1 = 0.282745 loss)
I0530 23:58:08.411996 15746 sgd_solver.cpp:106] Iteration 95600, lr = 1e-07
I0531 00:06:05.040264 15746 solver.cpp:228] Iteration 95700, loss = 0.840629
I0531 00:06:05.041055 15746 solver.cpp:244]     Train net output #0: loss = 0.840626 (* 1 = 0.840626 loss)
I0531 00:06:05.041080 15746 sgd_solver.cpp:106] Iteration 95700, lr = 1e-07
I0531 00:13:59.154832 15746 solver.cpp:228] Iteration 95800, loss = 0.369192
I0531 00:13:59.155516 15746 solver.cpp:244]     Train net output #0: loss = 0.369188 (* 1 = 0.369188 loss)
I0531 00:13:59.155540 15746 sgd_solver.cpp:106] Iteration 95800, lr = 1e-07
I0531 00:22:00.215948 15746 solver.cpp:228] Iteration 95900, loss = 0.351262
I0531 00:22:00.216681 15746 solver.cpp:244]     Train net output #0: loss = 0.351259 (* 1 = 0.351259 loss)
I0531 00:22:00.216707 15746 sgd_solver.cpp:106] Iteration 95900, lr = 1e-07
I0531 00:29:57.878449 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_96000.caffemodel
I0531 00:29:58.644569 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_96000.solverstate
I0531 00:30:03.700852 15746 solver.cpp:228] Iteration 96000, loss = 0.450642
I0531 00:30:03.700906 15746 solver.cpp:244]     Train net output #0: loss = 0.450639 (* 1 = 0.450639 loss)
I0531 00:30:03.700917 15746 sgd_solver.cpp:106] Iteration 96000, lr = 1e-07
I0531 00:37:58.098888 15746 solver.cpp:228] Iteration 96100, loss = 0.509045
I0531 00:37:58.099623 15746 solver.cpp:244]     Train net output #0: loss = 0.509042 (* 1 = 0.509042 loss)
I0531 00:37:58.099649 15746 sgd_solver.cpp:106] Iteration 96100, lr = 1e-07
I0531 00:45:53.697240 15746 solver.cpp:228] Iteration 96200, loss = 0.407162
I0531 00:45:53.697926 15746 solver.cpp:244]     Train net output #0: loss = 0.407159 (* 1 = 0.407159 loss)
I0531 00:45:53.697950 15746 sgd_solver.cpp:106] Iteration 96200, lr = 1e-07
I0531 00:53:56.529768 15746 solver.cpp:228] Iteration 96300, loss = 0.540537
I0531 00:53:56.530519 15746 solver.cpp:244]     Train net output #0: loss = 0.540534 (* 1 = 0.540534 loss)
I0531 00:53:56.530544 15746 sgd_solver.cpp:106] Iteration 96300, lr = 1e-07
I0531 01:01:47.583600 15746 solver.cpp:228] Iteration 96400, loss = 0.382342
I0531 01:01:47.584326 15746 solver.cpp:244]     Train net output #0: loss = 0.382339 (* 1 = 0.382339 loss)
I0531 01:01:47.584350 15746 sgd_solver.cpp:106] Iteration 96400, lr = 1e-07
I0531 01:09:37.201063 15746 solver.cpp:228] Iteration 96500, loss = 0.426489
I0531 01:09:37.201813 15746 solver.cpp:244]     Train net output #0: loss = 0.426486 (* 1 = 0.426486 loss)
I0531 01:09:37.201839 15746 sgd_solver.cpp:106] Iteration 96500, lr = 1e-07
I0531 01:17:23.084420 15746 solver.cpp:228] Iteration 96600, loss = 0.511744
I0531 01:17:23.085199 15746 solver.cpp:244]     Train net output #0: loss = 0.51174 (* 1 = 0.51174 loss)
I0531 01:17:23.085224 15746 sgd_solver.cpp:106] Iteration 96600, lr = 1e-07
I0531 01:25:05.346441 15746 solver.cpp:228] Iteration 96700, loss = 0.668654
I0531 01:25:05.347264 15746 solver.cpp:244]     Train net output #0: loss = 0.668651 (* 1 = 0.668651 loss)
I0531 01:25:05.347292 15746 sgd_solver.cpp:106] Iteration 96700, lr = 1e-07
I0531 01:33:06.073035 15746 solver.cpp:228] Iteration 96800, loss = 0.282666
I0531 01:33:06.073746 15746 solver.cpp:244]     Train net output #0: loss = 0.282663 (* 1 = 0.282663 loss)
I0531 01:33:06.073761 15746 sgd_solver.cpp:106] Iteration 96800, lr = 1e-07
I0531 01:41:07.263538 15746 solver.cpp:228] Iteration 96900, loss = 0.372821
I0531 01:41:07.264194 15746 solver.cpp:244]     Train net output #0: loss = 0.372818 (* 1 = 0.372818 loss)
I0531 01:41:07.264219 15746 sgd_solver.cpp:106] Iteration 96900, lr = 1e-07
I0531 01:49:00.758705 15746 solver.cpp:228] Iteration 97000, loss = 0.395447
I0531 01:49:00.759486 15746 solver.cpp:244]     Train net output #0: loss = 0.395443 (* 1 = 0.395443 loss)
I0531 01:49:00.759511 15746 sgd_solver.cpp:106] Iteration 97000, lr = 1e-07
I0531 01:57:04.466601 15746 solver.cpp:228] Iteration 97100, loss = 0.957426
I0531 01:57:04.467393 15746 solver.cpp:244]     Train net output #0: loss = 0.957422 (* 1 = 0.957422 loss)
I0531 01:57:04.467417 15746 sgd_solver.cpp:106] Iteration 97100, lr = 1e-07
I0531 02:05:02.694842 15746 solver.cpp:228] Iteration 97200, loss = 0.393848
I0531 02:05:02.695654 15746 solver.cpp:244]     Train net output #0: loss = 0.393844 (* 1 = 0.393844 loss)
I0531 02:05:02.695675 15746 sgd_solver.cpp:106] Iteration 97200, lr = 1e-07
I0531 02:12:59.322129 15746 solver.cpp:228] Iteration 97300, loss = 0.568419
I0531 02:12:59.322893 15746 solver.cpp:244]     Train net output #0: loss = 0.568415 (* 1 = 0.568415 loss)
I0531 02:12:59.322917 15746 sgd_solver.cpp:106] Iteration 97300, lr = 1e-07
I0531 02:20:56.702795 15746 solver.cpp:228] Iteration 97400, loss = 0.581703
I0531 02:20:56.703524 15746 solver.cpp:244]     Train net output #0: loss = 0.5817 (* 1 = 0.5817 loss)
I0531 02:20:56.703548 15746 sgd_solver.cpp:106] Iteration 97400, lr = 1e-07
I0531 02:28:44.597975 15746 solver.cpp:228] Iteration 97500, loss = 0.317067
I0531 02:28:44.598723 15746 solver.cpp:244]     Train net output #0: loss = 0.317064 (* 1 = 0.317064 loss)
I0531 02:28:44.598747 15746 sgd_solver.cpp:106] Iteration 97500, lr = 1e-07
I0531 02:36:48.996405 15746 solver.cpp:228] Iteration 97600, loss = 0.566801
I0531 02:36:48.997150 15746 solver.cpp:244]     Train net output #0: loss = 0.566797 (* 1 = 0.566797 loss)
I0531 02:36:48.997174 15746 sgd_solver.cpp:106] Iteration 97600, lr = 1e-07
I0531 02:44:43.396683 15746 solver.cpp:228] Iteration 97700, loss = 0.54989
I0531 02:44:43.397512 15746 solver.cpp:244]     Train net output #0: loss = 0.549886 (* 1 = 0.549886 loss)
I0531 02:44:43.397544 15746 sgd_solver.cpp:106] Iteration 97700, lr = 1e-07
I0531 02:52:39.403795 15746 solver.cpp:228] Iteration 97800, loss = 0.608128
I0531 02:52:39.404574 15746 solver.cpp:244]     Train net output #0: loss = 0.608125 (* 1 = 0.608125 loss)
I0531 02:52:39.404595 15746 sgd_solver.cpp:106] Iteration 97800, lr = 1e-07
I0531 03:00:33.537219 15746 solver.cpp:228] Iteration 97900, loss = 0.543744
I0531 03:00:33.537926 15746 solver.cpp:244]     Train net output #0: loss = 0.54374 (* 1 = 0.54374 loss)
I0531 03:00:33.537963 15746 sgd_solver.cpp:106] Iteration 97900, lr = 1e-07
I0531 03:04:23.212600 15746 solver.cpp:337] Iteration 97950, Testing net (#0)
I0531 03:04:23.213068 15746 net.cpp:685] Ignoring source layer ratemap
I0531 03:04:23.213093 15746 net.cpp:685] Ignoring source layer amsFeatures
I0531 03:07:13.051463 15746 solver.cpp:404]     Test net output #0: loss = 0.528582 (* 1 = 0.528582 loss)
I0531 03:11:16.626072 15746 solver.cpp:228] Iteration 98000, loss = 0.459203
I0531 03:11:16.626560 15746 solver.cpp:244]     Train net output #0: loss = 0.4592 (* 1 = 0.4592 loss)
I0531 03:11:16.626596 15746 sgd_solver.cpp:106] Iteration 98000, lr = 1e-07
I0531 03:19:11.105271 15746 solver.cpp:228] Iteration 98100, loss = 1.04718
I0531 03:19:11.106014 15746 solver.cpp:244]     Train net output #0: loss = 1.04717 (* 1 = 1.04717 loss)
I0531 03:19:11.106040 15746 sgd_solver.cpp:106] Iteration 98100, lr = 1e-07
I0531 03:26:57.156823 15746 solver.cpp:228] Iteration 98200, loss = 0.335064
I0531 03:26:57.159934 15746 solver.cpp:244]     Train net output #0: loss = 0.33506 (* 1 = 0.33506 loss)
I0531 03:26:57.159960 15746 sgd_solver.cpp:106] Iteration 98200, lr = 1e-07
I0531 03:34:50.899547 15746 solver.cpp:228] Iteration 98300, loss = 0.67017
I0531 03:34:50.900359 15746 solver.cpp:244]     Train net output #0: loss = 0.670167 (* 1 = 0.670167 loss)
I0531 03:34:50.900384 15746 sgd_solver.cpp:106] Iteration 98300, lr = 1e-07
I0531 03:43:02.552748 15746 solver.cpp:228] Iteration 98400, loss = 0.298903
I0531 03:43:02.553515 15746 solver.cpp:244]     Train net output #0: loss = 0.2989 (* 1 = 0.2989 loss)
I0531 03:43:02.553541 15746 sgd_solver.cpp:106] Iteration 98400, lr = 1e-07
I0531 03:50:44.472745 15746 solver.cpp:228] Iteration 98500, loss = 0.413684
I0531 03:50:44.473314 15746 solver.cpp:244]     Train net output #0: loss = 0.413681 (* 1 = 0.413681 loss)
I0531 03:50:44.473335 15746 sgd_solver.cpp:106] Iteration 98500, lr = 1e-07
I0531 03:58:46.133476 15746 solver.cpp:228] Iteration 98600, loss = 0.477426
I0531 03:58:46.134232 15746 solver.cpp:244]     Train net output #0: loss = 0.477423 (* 1 = 0.477423 loss)
I0531 03:58:46.134253 15746 sgd_solver.cpp:106] Iteration 98600, lr = 1e-07
I0531 04:06:36.111222 15746 solver.cpp:228] Iteration 98700, loss = 0.723185
I0531 04:06:36.113983 15746 solver.cpp:244]     Train net output #0: loss = 0.723182 (* 1 = 0.723182 loss)
I0531 04:06:36.114008 15746 sgd_solver.cpp:106] Iteration 98700, lr = 1e-07
I0531 04:14:37.665143 15746 solver.cpp:228] Iteration 98800, loss = 0.187526
I0531 04:14:37.667853 15746 solver.cpp:244]     Train net output #0: loss = 0.187523 (* 1 = 0.187523 loss)
I0531 04:14:37.667879 15746 sgd_solver.cpp:106] Iteration 98800, lr = 1e-07
I0531 04:22:32.833922 15746 solver.cpp:228] Iteration 98900, loss = 0.561252
I0531 04:22:32.836622 15746 solver.cpp:244]     Train net output #0: loss = 0.561248 (* 1 = 0.561248 loss)
I0531 04:22:32.836655 15746 sgd_solver.cpp:106] Iteration 98900, lr = 1e-07
I0531 04:30:33.476739 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_99000.caffemodel
I0531 04:30:33.671043 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_99000.solverstate
I0531 04:30:38.545032 15746 solver.cpp:228] Iteration 99000, loss = 0.716107
I0531 04:30:38.545083 15746 solver.cpp:244]     Train net output #0: loss = 0.716103 (* 1 = 0.716103 loss)
I0531 04:30:38.545094 15746 sgd_solver.cpp:106] Iteration 99000, lr = 1e-07
I0531 04:38:34.689677 15746 solver.cpp:228] Iteration 99100, loss = 0.356421
I0531 04:38:34.690423 15746 solver.cpp:244]     Train net output #0: loss = 0.356418 (* 1 = 0.356418 loss)
I0531 04:38:34.690448 15746 sgd_solver.cpp:106] Iteration 99100, lr = 1e-07
I0531 04:46:19.873891 15746 solver.cpp:228] Iteration 99200, loss = 0.340104
I0531 04:46:19.874495 15746 solver.cpp:244]     Train net output #0: loss = 0.3401 (* 1 = 0.3401 loss)
I0531 04:46:19.874517 15746 sgd_solver.cpp:106] Iteration 99200, lr = 1e-07
I0531 04:54:09.162791 15746 solver.cpp:228] Iteration 99300, loss = 0.659598
I0531 04:54:09.163455 15746 solver.cpp:244]     Train net output #0: loss = 0.659595 (* 1 = 0.659595 loss)
I0531 04:54:09.163480 15746 sgd_solver.cpp:106] Iteration 99300, lr = 1e-07
I0531 05:01:59.549787 15746 solver.cpp:228] Iteration 99400, loss = 0.44464
I0531 05:01:59.553107 15746 solver.cpp:244]     Train net output #0: loss = 0.444637 (* 1 = 0.444637 loss)
I0531 05:01:59.553133 15746 sgd_solver.cpp:106] Iteration 99400, lr = 1e-07
I0531 05:09:45.611362 15746 solver.cpp:228] Iteration 99500, loss = 0.419614
I0531 05:09:45.613714 15746 solver.cpp:244]     Train net output #0: loss = 0.419611 (* 1 = 0.419611 loss)
I0531 05:09:45.613729 15746 sgd_solver.cpp:106] Iteration 99500, lr = 1e-07
I0531 05:17:50.704303 15746 solver.cpp:228] Iteration 99600, loss = 0.405717
I0531 05:17:50.705047 15746 solver.cpp:244]     Train net output #0: loss = 0.405714 (* 1 = 0.405714 loss)
I0531 05:17:50.705073 15746 sgd_solver.cpp:106] Iteration 99600, lr = 1e-07
I0531 05:25:53.025946 15746 solver.cpp:228] Iteration 99700, loss = 1.30586
I0531 05:25:53.026690 15746 solver.cpp:244]     Train net output #0: loss = 1.30586 (* 1 = 1.30586 loss)
I0531 05:25:53.026721 15746 sgd_solver.cpp:106] Iteration 99700, lr = 1e-07
I0531 05:33:50.192399 15746 solver.cpp:228] Iteration 99800, loss = 0.170942
I0531 05:33:50.193086 15746 solver.cpp:244]     Train net output #0: loss = 0.170939 (* 1 = 0.170939 loss)
I0531 05:33:50.193117 15746 sgd_solver.cpp:106] Iteration 99800, lr = 1e-07
I0531 05:41:54.601634 15746 solver.cpp:228] Iteration 99900, loss = 0.382573
I0531 05:41:54.602455 15746 solver.cpp:244]     Train net output #0: loss = 0.38257 (* 1 = 0.38257 loss)
I0531 05:41:54.602480 15746 sgd_solver.cpp:106] Iteration 99900, lr = 1e-07
I0531 05:49:37.834503 15746 solver.cpp:454] Snapshotting to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_100000.caffemodel
I0531 05:49:38.030064 15746 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /mnt/raid/dnn/cindy/modelfiles/s2/te_iter_100000.solverstate
I0531 05:49:41.000665 15746 solver.cpp:317] Iteration 100000, loss = 0.486382
I0531 05:49:41.000736 15746 solver.cpp:322] Optimization Done.
I0531 05:49:41.000743 15746 caffe.cpp:222] Optimization Done.
